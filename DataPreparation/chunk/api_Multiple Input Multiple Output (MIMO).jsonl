"## Stream Management\n\nStream management determines which transmitter is sending which stream to\nwhich receiver. Transmitters and receivers can be user terminals or base\nstations, depending on whether uplink or downlink transmissions are considered.\nThe [`StreamManagement`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.StreamManagement) class has various properties that\nare needed to recover desired or interfering channel coefficients for precoding\nand equalization. In order to understand how the various properties of\n[`StreamManagement`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.StreamManagement) can be used, we recommend to have a look\nat the source code of the [`LMMSEEqualizer`](ofdm.html#sionna.ofdm.LMMSEEqualizer) or\n[`ZFPrecoder`](ofdm.html#sionna.ofdm.ZFPrecoder).\n\nThe following code snippet shows how to configure\n[`StreamManagement`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.StreamManagement) for a simple uplink scenario, where\nfour transmitters send each one stream to a receiver. Note that\n[`StreamManagement`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.StreamManagement) is independent of the actual number of\nantennas at the transmitters and receivers.\n```python\nnum_tx = 4\nnum_rx = 1\nnum_streams_per_tx = 1\n# Indicate which transmitter is associated with which receiver\n# rx_tx_association[i,j] = 1 means that transmitter j sends one\n# or mutiple streams to receiver i.\nrx_tx_association = np.zeros([num_rx, num_tx])\nrx_tx_association[0,0] = 1\nrx_tx_association[0,1] = 1\nrx_tx_association[0,2] = 1\nrx_tx_association[0,3] = 1\nsm = StreamManagement(rx_tx_association, num_streams_per_tx)\n```\n`class` `sionna.mimo.``StreamManagement`(*`rx_tx_association`*, *`num_streams_per_tx`*)[`[source]`](../_modules/sionna/mimo/stream_management.html#StreamManagement)\n\nClass for management of streams in multi-cell MIMO networks.\nParameters\n\n- **rx_tx_association** (*[**num_rx**, **num_tx**]**, **np.int*)  A binary NumPy array where `rx_tx_association[i,j]=1` means\nthat receiver <cite>i</cite> gets one or multiple streams from\ntransmitter <cite>j</cite>.\n- **num_streams_per_tx** (*int*)  Indicates the number of streams that are transmitted by each\ntransmitter.\n\n\n**Note**\n\nSeveral symmetry constraints on `rx_tx_association` are imposed\nto ensure efficient processing. All row sums and all column sums\nmust be equal, i.e., all receivers have the same number of associated\ntransmitters and all transmitters have the same number of associated\nreceivers. It is also assumed that all transmitters send the same\nnumber of streams `num_streams_per_tx`.\n\n`property` `detection_desired_ind`\n\nIndices needed to gather desired channels for receive processing.\n\nA NumPy array of shape <cite>[num_rx*num_streams_per_rx]</cite> that\ncan be used to gather desired channels from the flattened\nchannel tensor of shape\n<cite>[,num_rx, num_tx, num_streams_per_tx,]</cite>.\nThe result of the gather operation can be reshaped to\n<cite>[,num_rx, num_streams_per_rx,]</cite>.\n\n\n`property` `detection_undesired_ind`\n\nIndices needed to gather undesired channels for receive processing.\n\nA NumPy array of shape <cite>[num_rx*num_streams_per_rx]</cite> that\ncan be used to gather undesired channels from the flattened\nchannel tensor of shape <cite>[,num_rx, num_tx, num_streams_per_tx,]</cite>.\nThe result of the gather operation can be reshaped to\n<cite>[,num_rx, num_interfering_streams_per_rx,]</cite>.\n\n\n`property` `num_interfering_streams_per_rx`\n\nNumber of interfering streams received at each eceiver.\n\n\n`property` `num_rx`\n\nNumber of receivers.\n\n\n`property` `num_rx_per_tx`\n\nNumber of receivers communicating with a transmitter.\n\n\n`property` `num_streams_per_rx`\n\nNumber of streams transmitted to each receiver.\n\n\n`property` `num_streams_per_tx`\n\nNumber of streams per transmitter.\n\n\n`property` `num_tx`\n\nNumber of transmitters.\n\n\n`property` `num_tx_per_rx`\n\nNumber of transmitters communicating with a receiver.\n\n\n`property` `precoding_ind`\n\nIndices needed to gather channels for precoding.\n\nA NumPy array of shape <cite>[num_tx, num_rx_per_tx]</cite>,\nwhere `precoding_ind[i,:]` contains the indices of the\nreceivers to which transmitter <cite>i</cite> is sending streams.\n\n\n`property` `rx_stream_ids`\n\nMapping of streams to receivers.\n\nA Numpy array of shape <cite>[num_rx, num_streams_per_rx]</cite>.\nThis array is obtained from `tx_stream_ids` together with\nthe `rx_tx_association`. `rx_stream_ids[i,:]` contains\nthe indices of streams that are supposed to be decoded by receiver <cite>i</cite>.\n\n\n`property` `rx_tx_association`\n\nAssociation between receivers and transmitters.\n\nA binary NumPy array of shape <cite>[num_rx, num_tx]</cite>,\nwhere `rx_tx_association[i,j]=1` means that receiver <cite>i</cite>\ngets one ore multiple streams from transmitter <cite>j</cite>.\n\n\n`property` `stream_association`\n\nAssociation between receivers, transmitters, and streams.\n\nA binary NumPy array of shape\n<cite>[num_rx, num_tx, num_streams_per_tx]</cite>, where\n`stream_association[i,j,k]=1` means that receiver <cite>i</cite> gets\nthe <cite>k</cite> th stream from transmitter <cite>j</cite>.\n\n\n`property` `stream_ind`\n\nIndices needed to gather received streams in the correct order.\n\nA NumPy array of shape <cite>[num_rx*num_streams_per_rx]</cite> that can be\nused to gather streams from the flattened tensor of received streams\nof shape <cite>[,num_rx, num_streams_per_rx,]</cite>. The result of the\ngather operation is then reshaped to\n<cite>[,num_tx, num_streams_per_tx,]</cite>.\n\n\n`property` `tx_stream_ids`\n\nMapping of streams to transmitters.\n\nA NumPy array of shape <cite>[num_tx, num_streams_per_tx]</cite>.\nStreams are numbered from 0,1, and assiged to transmitters in\nincreasing order, i.e., transmitter 0 gets the first\n<cite>num_streams_per_tx</cite> and so on."
"### zero_forcing_precoder\n\n`sionna.mimo.``zero_forcing_precoder`(*`x`*, *`h`*, *`return_precoding_matrix``=``False`*)[`[source]`](../_modules/sionna/mimo/precoding.html#zero_forcing_precoder)\n\nZero-Forcing (ZF) Precoder\n\nThis function implements ZF precoding for a MIMO link, assuming the\nfollowing model:\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{G}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^K$ is the received signal vector,\n$\\mathbf{H}\\in\\mathbb{C}^{K\\times M}$ is the known channel matrix,\n$\\mathbf{G}\\in\\mathbb{C}^{M\\times K}$ is the precoding matrix,\n$\\mathbf{x}\\in\\mathbb{C}^K$ is the symbol vector to be precoded,\nand $\\mathbf{n}\\in\\mathbb{C}^K$ is a noise vector. It is assumed that\n$K\\le M$.\n\nThe precoding matrix $\\mathbf{G}$ is defined as (Eq. 4.37) [[BHS2017]](channel.wireless.html#bhs2017) :\n\n$$\n\\mathbf{G} = \\mathbf{V}\\mathbf{D}\n$$\n\nwhere\n\n$$\n\\begin{split}\\mathbf{V} &= \\mathbf{H}^{\\mathsf{H}}\\left(\\mathbf{H} \\mathbf{H}^{\\mathsf{H}}\\right)^{-1}\\\\\n\\mathbf{D} &= \\mathop{\\text{diag}}\\left( \\lVert \\mathbf{v}_{k} \\rVert_2^{-1}, k=0,\\dots,K-1 \\right).\\end{split}\n$$\n\nThis ensures that each stream is precoded with a unit-norm vector,\ni.e., $\\mathop{\\text{tr}}\\left(\\mathbf{G}\\mathbf{G}^{\\mathsf{H}}\\right)=K$.\nThe function returns the precoded vector $\\mathbf{G}\\mathbf{x}$.\nInput\n\n- **x** (*[,K], tf.complex*)  1+D tensor containing the symbol vectors to be precoded.\n- **h** (*[,K,M], tf.complex*)  2+D tensor containing the channel matrices\n- **return_precoding_matrices** (*bool*)  Indicates if the precoding matrices should be returned or not.\nDefaults to False.\n\n\nOutput\n\n- **x_precoded** (*[,M], tf.complex*)  Tensor of the same shape and dtype as `x` apart from the last\ndimensions that has changed from <cite>K</cite> to <cite>M</cite>. It contains the\nprecoded symbol vectors.\n- **g** (*[,M,K], tf.complex*)  2+D tensor containing the precoding matrices. It is only returned\nif `return_precoding_matrices=True`.\n\n\n**Note**\n\nIf you want to use this function in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### lmmse_equalizer\n\n`sionna.mimo.``lmmse_equalizer`(*`y`*, *`h`*, *`s`*, *`whiten_interference``=``True`*)[`[source]`](../_modules/sionna/mimo/equalization.html#lmmse_equalizer)\n\nMIMO LMMSE Equalizer\n\nThis function implements LMMSE equalization for a MIMO link, assuming the\nfollowing model:\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^M$ is the received signal vector,\n$\\mathbf{x}\\in\\mathbb{C}^K$ is the vector of transmitted symbols,\n$\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$ is the known channel matrix,\nand $\\mathbf{n}\\in\\mathbb{C}^M$ is a noise vector.\nIt is assumed that $\\mathbb{E}\\left[\\mathbf{x}\\right]=\\mathbb{E}\\left[\\mathbf{n}\\right]=\\mathbf{0}$,\n$\\mathbb{E}\\left[\\mathbf{x}\\mathbf{x}^{\\mathsf{H}}\\right]=\\mathbf{I}_K$ and\n$\\mathbb{E}\\left[\\mathbf{n}\\mathbf{n}^{\\mathsf{H}}\\right]=\\mathbf{S}$.\n\nThe estimated symbol vector $\\hat{\\mathbf{x}}\\in\\mathbb{C}^K$ is given as\n(Lemma B.19) [[BHS2017]](channel.wireless.html#bhs2017) :\n\n$$\n\\hat{\\mathbf{x}} = \\mathop{\\text{diag}}\\left(\\mathbf{G}\\mathbf{H}\\right)^{-1}\\mathbf{G}\\mathbf{y}\n$$\n\nwhere\n\n$$\n\\mathbf{G} = \\mathbf{H}^{\\mathsf{H}} \\left(\\mathbf{H}\\mathbf{H}^{\\mathsf{H}} + \\mathbf{S}\\right)^{-1}.\n$$\n\nThis leads to the post-equalized per-symbol model:\n\n$$\n\\hat{x}_k = x_k + e_k,\\quad k=0,\\dots,K-1\n$$\n\nwhere the variances $\\sigma^2_k$ of the effective residual noise\nterms $e_k$ are given by the diagonal elements of\n\n$$\n\\mathop{\\text{diag}}\\left(\\mathbb{E}\\left[\\mathbf{e}\\mathbf{e}^{\\mathsf{H}}\\right]\\right)\n= \\mathop{\\text{diag}}\\left(\\mathbf{G}\\mathbf{H} \\right)^{-1} - \\mathbf{I}.\n$$\n\nNote that the scaling by $\\mathop{\\text{diag}}\\left(\\mathbf{G}\\mathbf{H}\\right)^{-1}$\nis important for the [`Demapper`](mapping.html#sionna.mapping.Demapper) although it does\nnot change the signal-to-noise ratio.\n\nThe function returns $\\hat{\\mathbf{x}}$ and\n$\\boldsymbol{\\sigma}^2=\\left[\\sigma^2_0,\\dots, \\sigma^2_{K-1}\\right]^{\\mathsf{T}}$.\nInput\n\n- **y** (*[,M], tf.complex*)  1+D tensor containing the received signals.\n- **h** (*[,M,K], tf.complex*)  2+D tensor containing the channel matrices.\n- **s** (*[,M,M], tf.complex*)  2+D tensor containing the noise covariance matrices.\n- **whiten_interference** (*bool*)  If <cite>True</cite> (default), the interference is first whitened before equalization.\nIn this case, an alternative expression for the receive filter is used that\ncan be numerically more stable. Defaults to <cite>True</cite>.\n\n\nOutput\n\n- **x_hat** (*[,K], tf.complex*)  1+D tensor representing the estimated symbol vectors.\n- **no_eff** (*tf.float*)  Tensor of the same shape as `x_hat` containing the effective noise\nvariance estimates.\n\n\n**Note**\n\nIf you want to use this function in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### mf_equalizer\n\n`sionna.mimo.``mf_equalizer`(*`y`*, *`h`*, *`s`*)[`[source]`](../_modules/sionna/mimo/equalization.html#mf_equalizer)\n\nMIMO MF Equalizer\n\nThis function implements matched filter (MF) equalization for a\nMIMO link, assuming the following model:\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^M$ is the received signal vector,\n$\\mathbf{x}\\in\\mathbb{C}^K$ is the vector of transmitted symbols,\n$\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$ is the known channel matrix,\nand $\\mathbf{n}\\in\\mathbb{C}^M$ is a noise vector.\nIt is assumed that $\\mathbb{E}\\left[\\mathbf{x}\\right]=\\mathbb{E}\\left[\\mathbf{n}\\right]=\\mathbf{0}$,\n$\\mathbb{E}\\left[\\mathbf{x}\\mathbf{x}^{\\mathsf{H}}\\right]=\\mathbf{I}_K$ and\n$\\mathbb{E}\\left[\\mathbf{n}\\mathbf{n}^{\\mathsf{H}}\\right]=\\mathbf{S}$.\n\nThe estimated symbol vector $\\hat{\\mathbf{x}}\\in\\mathbb{C}^K$ is given as\n(Eq. 4.11) [[BHS2017]](channel.wireless.html#bhs2017) :\n\n$$\n\\hat{\\mathbf{x}} = \\mathbf{G}\\mathbf{y}\n$$\n\nwhere\n\n$$\n\\mathbf{G} = \\mathop{\\text{diag}}\\left(\\mathbf{H}^{\\mathsf{H}}\\mathbf{H}\\right)^{-1}\\mathbf{H}^{\\mathsf{H}}.\n$$\n\nThis leads to the post-equalized per-symbol model:\n\n$$\n\\hat{x}_k = x_k + e_k,\\quad k=0,\\dots,K-1\n$$\n\nwhere the variances $\\sigma^2_k$ of the effective residual noise\nterms $e_k$ are given by the diagonal elements of the matrix\n\n$$\n\\mathbb{E}\\left[\\mathbf{e}\\mathbf{e}^{\\mathsf{H}}\\right]\n= \\left(\\mathbf{I}-\\mathbf{G}\\mathbf{H} \\right)\\left(\\mathbf{I}-\\mathbf{G}\\mathbf{H} \\right)^{\\mathsf{H}} + \\mathbf{G}\\mathbf{S}\\mathbf{G}^{\\mathsf{H}}.\n$$\n\nNote that the scaling by $\\mathop{\\text{diag}}\\left(\\mathbf{H}^{\\mathsf{H}}\\mathbf{H}\\right)^{-1}$\nin the definition of $\\mathbf{G}$\nis important for the [`Demapper`](mapping.html#sionna.mapping.Demapper) although it does\nnot change the signal-to-noise ratio.\n\nThe function returns $\\hat{\\mathbf{x}}$ and\n$\\boldsymbol{\\sigma}^2=\\left[\\sigma^2_0,\\dots, \\sigma^2_{K-1}\\right]^{\\mathsf{T}}$.\nInput\n\n- **y** (*[,M], tf.complex*)  1+D tensor containing the received signals.\n- **h** (*[,M,K], tf.complex*)  2+D tensor containing the channel matrices.\n- **s** (*[,M,M], tf.complex*)  2+D tensor containing the noise covariance matrices.\n\n\nOutput\n\n- **x_hat** (*[,K], tf.complex*)  1+D tensor representing the estimated symbol vectors.\n- **no_eff** (*tf.float*)  Tensor of the same shape as `x_hat` containing the effective noise\nvariance estimates."
"### zf_equalizer\n\n`sionna.mimo.``zf_equalizer`(*`y`*, *`h`*, *`s`*)[`[source]`](../_modules/sionna/mimo/equalization.html#zf_equalizer)\n\nMIMO ZF Equalizer\n\nThis function implements zero-forcing (ZF) equalization for a MIMO link, assuming the\nfollowing model:\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^M$ is the received signal vector,\n$\\mathbf{x}\\in\\mathbb{C}^K$ is the vector of transmitted symbols,\n$\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$ is the known channel matrix,\nand $\\mathbf{n}\\in\\mathbb{C}^M$ is a noise vector.\nIt is assumed that $\\mathbb{E}\\left[\\mathbf{x}\\right]=\\mathbb{E}\\left[\\mathbf{n}\\right]=\\mathbf{0}$,\n$\\mathbb{E}\\left[\\mathbf{x}\\mathbf{x}^{\\mathsf{H}}\\right]=\\mathbf{I}_K$ and\n$\\mathbb{E}\\left[\\mathbf{n}\\mathbf{n}^{\\mathsf{H}}\\right]=\\mathbf{S}$.\n\nThe estimated symbol vector $\\hat{\\mathbf{x}}\\in\\mathbb{C}^K$ is given as\n(Eq. 4.10) [[BHS2017]](channel.wireless.html#bhs2017) :\n\n$$\n\\hat{\\mathbf{x}} = \\mathbf{G}\\mathbf{y}\n$$\n\nwhere\n\n$$\n\\mathbf{G} = \\left(\\mathbf{H}^{\\mathsf{H}}\\mathbf{H}\\right)^{-1}\\mathbf{H}^{\\mathsf{H}}.\n$$\n\nThis leads to the post-equalized per-symbol model:\n\n$$\n\\hat{x}_k = x_k + e_k,\\quad k=0,\\dots,K-1\n$$\n\nwhere the variances $\\sigma^2_k$ of the effective residual noise\nterms $e_k$ are given by the diagonal elements of the matrix\n\n$$\n\\mathbb{E}\\left[\\mathbf{e}\\mathbf{e}^{\\mathsf{H}}\\right]\n= \\mathbf{G}\\mathbf{S}\\mathbf{G}^{\\mathsf{H}}.\n$$\n\nThe function returns $\\hat{\\mathbf{x}}$ and\n$\\boldsymbol{\\sigma}^2=\\left[\\sigma^2_0,\\dots, \\sigma^2_{K-1}\\right]^{\\mathsf{T}}$.\nInput\n\n- **y** (*[,M], tf.complex*)  1+D tensor containing the received signals.\n- **h** (*[,M,K], tf.complex*)  2+D tensor containing the channel matrices.\n- **s** (*[,M,M], tf.complex*)  2+D tensor containing the noise covariance matrices.\n\n\nOutput\n\n- **x_hat** (*[,K], tf.complex*)  1+D tensor representing the estimated symbol vectors.\n- **no_eff** (*tf.float*)  Tensor of the same shape as `x_hat` containing the effective noise\nvariance estimates.\n\n\n**Note**\n\nIf you want to use this function in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### EPDetector\n\n`class` `sionna.mimo.``EPDetector`(*`output`*, *`num_bits_per_symbol`*, *`hard_out``=``False`*, *`l``=``10`*, *`beta``=``0.9`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/mimo/detection.html#EPDetector)\n\nMIMO Expectation Propagation (EP) detector\n\nThis layer implements Expectation Propagation (EP) MIMO detection as described\nin [[EP2014]](https://nvlabs.github.io/sionna/api/mimo.html#ep2014). It can generate hard- or soft-decisions for symbols or bits.\n\nThis layer assumes the following channel model:\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^M$ is the received signal vector,\n$\\mathbf{x}\\in\\mathcal{C}^S$ is the vector of transmitted symbols which\nare uniformly and independently drawn from the constellation $\\mathcal{C}$,\n$\\mathbf{H}\\in\\mathbb{C}^{M\\times S}$ is the known channel matrix,\nand $\\mathbf{n}\\in\\mathbb{C}^M$ is a complex Gaussian noise vector.\nIt is assumed that $\\mathbb{E}\\left[\\mathbf{n}\\right]=\\mathbf{0}$ and\n$\\mathbb{E}\\left[\\mathbf{n}\\mathbf{n}^{\\mathsf{H}}\\right]=\\mathbf{S}$,\nwhere $\\mathbf{S}$ has full rank.\n\nThe channel model is first whitened using [`whiten_channel()`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.whiten_channel)\nand then converted to its real-valued equivalent,\nsee [`complex2real_channel()`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.complex2real_channel), prior to MIMO detection.\n\nThe computation of LLRs is done by converting the symbol logits\nthat naturally arise in the algorithm to LLRs using\n[`PAM2QAM()`](mapping.html#sionna.mapping.PAM2QAM). Custom conversions of symbol logits to LLRs\ncan be implemented by using the soft-symbol output.\nParameters\n\n- **output** (*One of** [**\"bit\"**, **\"symbol\"**]**, **str*)  The type of output, either bits or symbols. Whether soft- or\nhard-decisions are returned can be configured with the\n`hard_out` flag.\n- **num_bits_per_symbol** (*int*)  The number of bits per QAM constellation symbol, e.g., 4 for QAM16.\n- **hard_out** (*bool*)  If <cite>True</cite>, the detector computes hard-decided bit values or\nconstellation point indices instead of soft-values.\nDefaults to <cite>False</cite>.\n- **l** (*int*)  Number of iterations. Defaults to 10.\n- **beta** (*float*)  Parameter $\\beta\\in[0,1]$ for update smoothing.\nDefaults to 0.9.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**] **tf.DType** (**dtype**)*)  Precision used for internal computations. Defaults to `tf.complex64`.\nEspecially for large MIMO setups, the precision can make a significant\nperformance difference.\n\n\nInput\n\n- **(y, h, s)**  Tuple:\n- **y** (*[,M], tf.complex*)  1+D tensor containing the received signals\n- **h** (*[,M,num_streams], tf.complex*)  2+D tensor containing the channel matrices\n- **s** (*[,M,M], tf.complex*)  2+D tensor containing the noise covariance matrices\n\n\nOutput\n\n- **One of**\n- *[,num_streams,num_bits_per_symbol], tf.float*  LLRs or hard-decisions for every bit of every stream, if `output` equals <cite>bit</cite>\n- *[,num_streams,2**num_bits_per_symbol], tf.float or [,num_streams], tf.int*  Logits or hard-decisions for constellation symbols for every stream, if `output` equals <cite>symbol</cite>\n\n\n**Note**\n\nFor numerical stability, we do not recommend to use this function in Graph\nmode with XLA, i.e., within a function that is decorated with\n`@tf.function(jit_compile=True)`.\nHowever, it is possible to do so by setting\n`sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### KBestDetector\n\n`class` `sionna.mimo.``KBestDetector`(*`output`*, *`num_streams`*, *`k`*, *`constellation_type``=``None`*, *`num_bits_per_symbol``=``None`*, *`constellation``=``None`*, *`hard_out``=``False`*, *`use_real_rep``=``False`*, *`list2llr``=``None`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/mimo/detection.html#KBestDetector)\n\nMIMO K-Best detector\n\nThis layer implements K-Best MIMO detection as described\nin (Eq. 4-5) [[FT2015]](https://nvlabs.github.io/sionna/api/mimo.html#ft2015). It can either generate hard decisions (for symbols\nor bits) or compute LLRs.\n\nThe algorithm operates in either the complex or real-valued domain.\nAlthough both options produce identical results, the former has the advantage\nthat it can be applied to arbitrary non-QAM constellations. It also reduces\nthe number of streams (or depth) by a factor of two.\n\nThe way soft-outputs (i.e., LLRs) are computed is determined by the\n`list2llr` function. The default solution\n[`List2LLRSimple`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.List2LLRSimple) assigns a predetermined\nvalue to all LLRs without counter-hypothesis.\n\nThis layer assumes the following channel model:\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^M$ is the received signal vector,\n$\\mathbf{x}\\in\\mathcal{C}^S$ is the vector of transmitted symbols which\nare uniformly and independently drawn from the constellation $\\mathcal{C}$,\n$\\mathbf{H}\\in\\mathbb{C}^{M\\times S}$ is the known channel matrix,\nand $\\mathbf{n}\\in\\mathbb{C}^M$ is a complex Gaussian noise vector.\nIt is assumed that $\\mathbb{E}\\left[\\mathbf{n}\\right]=\\mathbf{0}$ and\n$\\mathbb{E}\\left[\\mathbf{n}\\mathbf{n}^{\\mathsf{H}}\\right]=\\mathbf{S}$,\nwhere $\\mathbf{S}$ has full rank.\n\nIn a first optional step, the channel model is converted to its real-valued equivalent,\nsee [`complex2real_channel()`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.complex2real_channel). We assume in the sequel the complex-valued\nrepresentation. Then, the channel is whitened using [`whiten_channel()`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.whiten_channel):\n\n$$\n\\begin{split}\\tilde{\\mathbf{y}} &= \\mathbf{S}^{-\\frac{1}{2}}\\mathbf{y}\\\\\n&=  \\mathbf{S}^{-\\frac{1}{2}}\\mathbf{H}\\mathbf{x} + \\mathbf{S}^{-\\frac{1}{2}}\\mathbf{n}\\\\\n&= \\tilde{\\mathbf{H}}\\mathbf{x} + \\tilde{\\mathbf{n}}.\\end{split}\n$$\n\nNext, the columns of $\\tilde{\\mathbf{H}}$ are sorted according\nto their norm in descending order. Then, the QR decomposition of the\nresulting channel matrix is computed:\n\n$$\n\\tilde{\\mathbf{H}} = \\mathbf{Q}\\mathbf{R}\n$$\n\nwhere $\\mathbf{Q}\\in\\mathbb{C}^{M\\times S}$ is unitary and\n$\\mathbf{R}\\in\\mathbb{C}^{S\\times S}$ is upper-triangular.\nThe channel outputs are then pre-multiplied by $\\mathbf{Q}^{\\mathsf{H}}$.\nThis leads to the final channel model on which the K-Best detection algorithm operates:\n\n$$\n\\bar{\\mathbf{y}} = \\mathbf{R}\\bar{\\mathbf{x}} + \\bar{\\mathbf{n}}\n$$\n\nwhere $\\bar{\\mathbf{y}}\\in\\mathbb{C}^S$,\n$\\bar{\\mathbf{x}}\\in\\mathbb{C}^S$, and $\\bar{\\mathbf{n}}\\in\\mathbb{C}^S$\nwith $\\mathbb{E}\\left[\\bar{\\mathbf{n}}\\right]=\\mathbf{0}$ and\n$\\mathbb{E}\\left[\\bar{\\mathbf{n}}\\bar{\\mathbf{n}}^{\\mathsf{H}}\\right]=\\mathbf{I}$.\n\n**LLR Computation**\n\nThe K-Best algorithm produces $K$ candidate solutions $\\bar{\\mathbf{x}}_k\\in\\mathcal{C}^S$\nand their associated distance metrics $d_k=\\lVert \\bar{\\mathbf{y}} - \\mathbf{R}\\bar{\\mathbf{x}}_k \\rVert^2$\nfor $k=1,\\dots,K$. If the real-valued channel representation is used, the distance\nmetrics are scaled by 0.5 to account for the reduced noise power in each complex dimension.\nA hard-decision is simply the candidate with the shortest distance.\nVarious ways to compute LLRs from this list (and possibly\nadditional side-information) are possible. The (sub-optimal) default solution\nis [`List2LLRSimple`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.List2LLRSimple). Custom solutions can be provided.\nParameters\n\n- **output** (*One of** [**\"bit\"**, **\"symbol\"**]**, **str*)  The type of output, either bits or symbols. Whether soft- or\nhard-decisions are returned can be configured with the\n`hard_out` flag.\n- **num_streams** (*tf.int*)  Number of transmitted streams\n- **k** (*tf.int*)  The number of paths to keep. Cannot be larger than the\nnumber of constellation points to the power of the number of\nstreams.\n- **constellation_type** (*One of** [**\"qam\"**, **\"pam\"**, **\"custom\"**]**, **str*)  For custom, an instance of [`Constellation`](mapping.html#sionna.mapping.Constellation)\nmust be provided.\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation symbol, e.g., 4 for QAM16.\nOnly required for `constellation_type` in [qam, pam].\n- **constellation** ()  An instance of [`Constellation`](mapping.html#sionna.mapping.Constellation) or <cite>None</cite>.\nIn the latter case, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n- **hard_out** (*bool*)  If <cite>True</cite>, the detector computes hard-decided bit values or\nconstellation point indices instead of soft-values.\nDefaults to <cite>False</cite>. The detector cannot compute soft-symbols.\n- **use_real_rep** (*bool*)  If <cite>True</cite>, the detector use the real-valued equivalent representation\nof the channel. Note that this only works with a QAM constellation.\nDefaults to <cite>False</cite>.\n- **list2llr** (<cite>None</cite> or instance of [`List2LLR`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.List2LLR))  The function to be used to compute LLRs from a list of candidate solutions.\nIf <cite>None</cite>, the default solution [`List2LLRSimple`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.List2LLRSimple)\nis used.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**] **tf.DType** (**dtype**)*)  The dtype of `y`. Defaults to tf.complex64.\nThe output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n\nInput\n\n- **(y, h, s)**  Tuple:\n- **y** (*[,M], tf.complex*)  1+D tensor containing the received signals\n- **h** (*[,M,num_streams], tf.complex*)  2+D tensor containing the channel matrices\n- **s** (*[,M,M], tf.complex*)  2+D tensor containing the noise covariance matrices\n\n\nOutput\n\n- **One of**\n- *[,num_streams,num_bits_per_symbol], tf.float*  LLRs or hard-decisions for every bit of every stream, if `output` equals <cite>bit</cite>\n- *[,num_streams,2**num_points], tf.float or [,num_streams], tf.int*  Logits or hard-decisions for constellation symbols for every stream, if `output` equals <cite>symbol</cite>\nHard-decisions correspond to the symbol indices.\n\n\n**Note**\n\nIf you want to use this layer in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### LinearDetector\n\n`class` `sionna.mimo.``LinearDetector`(*`equalizer`*, *`output`*, *`demapping_method`*, *`constellation_type``=``None`*, *`num_bits_per_symbol``=``None`*, *`constellation``=``None`*, *`hard_out``=``False`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/mimo/detection.html#LinearDetector)\n\nConvenience class that combines an equalizer,\nsuch as [`lmmse_equalizer()`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.lmmse_equalizer), and a [`Demapper`](mapping.html#sionna.mapping.Demapper).\nParameters\n\n- **equalizer** (*str**, **one of** [**\"lmmse\"**, **\"zf\"**, **\"mf\"**]**, or **an equalizer function*)  The equalizer to be used. Either one of the existing equalizers\n[`lmmse_equalizer()`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.lmmse_equalizer), [`zf_equalizer()`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.zf_equalizer), or\n[`mf_equalizer()`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.mf_equalizer) can be used, or a custom equalizer\ncallable provided that has the same input/output specification.\n- **output** (*One of** [**\"bit\"**, **\"symbol\"**]**, **str*)  The type of output, either LLRs on bits or logits on constellation symbols.\n- **demapping_method** (*One of** [**\"app\"**, **\"maxlog\"**]**, **str*)  The demapping method used.\n- **constellation_type** (*One of** [**\"qam\"**, **\"pam\"**, **\"custom\"**]**, **str*)  For custom, an instance of [`Constellation`](mapping.html#sionna.mapping.Constellation)\nmust be provided.\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation symbol, e.g., 4 for QAM16.\nOnly required for `constellation_type` in [qam, pam].\n- **constellation** ()  An instance of [`Constellation`](mapping.html#sionna.mapping.Constellation) or <cite>None</cite>.\nIn the latter case, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n- **hard_out** (*bool*)  If <cite>True</cite>, the detector computes hard-decided bit values or\nconstellation point indices instead of soft-values.\nDefaults to <cite>False</cite>.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**] **tf.DType** (**dtype**)*)  The dtype of `y`. Defaults to tf.complex64.\nThe output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n\nInput\n\n- **(y, h, s)**  Tuple:\n- **y** (*[,M], tf.complex*)  1+D tensor containing the received signals\n- **h** (*[,M,num_streams], tf.complex*)  2+D tensor containing the channel matrices\n- **s** (*[,M,M], tf.complex*)  2+D tensor containing the noise covariance matrices\n\n\nOutput\n\n- **One of**\n- *[, num_streams, num_bits_per_symbol], tf.float*  LLRs or hard-decisions for every bit of every stream, if `output` equals <cite>bit</cite>\n- *[, num_streams, num_points], tf.float or [, num_streams], tf.int*  Logits or hard-decisions for constellation symbols for every stream, if `output` equals <cite>symbol</cite>\nHard-decisions correspond to the symbol indices.\n\n\n**Note**\n\nIf you want to use this layer in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou might need to set `sionna.Config.xla_compat=true`. This depends on the\nchosen equalizer function. See [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### MaximumLikelihoodDetector\n\n`class` `sionna.mimo.``MaximumLikelihoodDetector`(*`output`*, *`demapping_method`*, *`num_streams`*, *`constellation_type``=``None`*, *`num_bits_per_symbol``=``None`*, *`constellation``=``None`*, *`hard_out``=``False`*, *`with_prior``=``False`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/mimo/detection.html#MaximumLikelihoodDetector)\n\nMIMO maximum-likelihood (ML) detector.\nIf the `with_prior` flag is set, prior knowledge on the bits or constellation points is assumed to be available.\n\nThis layer implements MIMO maximum-likelihood (ML) detection assuming the\nfollowing channel model:\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^M$ is the received signal vector,\n$\\mathbf{x}\\in\\mathcal{C}^K$ is the vector of transmitted symbols which\nare uniformly and independently drawn from the constellation $\\mathcal{C}$,\n$\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$ is the known channel matrix,\nand $\\mathbf{n}\\in\\mathbb{C}^M$ is a complex Gaussian noise vector.\nIt is assumed that $\\mathbb{E}\\left[\\mathbf{n}\\right]=\\mathbf{0}$ and\n$\\mathbb{E}\\left[\\mathbf{n}\\mathbf{n}^{\\mathsf{H}}\\right]=\\mathbf{S}$,\nwhere $\\mathbf{S}$ has full rank.\nIf the `with_prior` flag is set, it is assumed that prior information of the transmitted signal $\\mathbf{x}$ is available,\nprovided either as LLRs on the bits mapped onto $\\mathbf{x}$ or as logits on the individual\nconstellation points forming $\\mathbf{x}$.\n\nPrior to demapping, the received signal is whitened:\n\n$$\n\\begin{split}\\tilde{\\mathbf{y}} &= \\mathbf{S}^{-\\frac{1}{2}}\\mathbf{y}\\\\\n&=  \\mathbf{S}^{-\\frac{1}{2}}\\mathbf{H}\\mathbf{x} + \\mathbf{S}^{-\\frac{1}{2}}\\mathbf{n}\\\\\n&= \\tilde{\\mathbf{H}}\\mathbf{x} + \\tilde{\\mathbf{n}}\\end{split}\n$$\n\nThe layer can compute ML detection of symbols or bits with either\nsoft- or hard-decisions. Note that decisions are computed symbol-/bit-wise\nand not jointly for the entire vector $\\textbf{x}$ (or the underlying vector\nof bits).\n\n**ML detection of bits:**\n\nSoft-decisions on bits are called log-likelihood ratios (LLR).\nWith the app demapping method, the LLR for the $i\\text{th}$ bit\nof the $k\\text{th}$ user is then computed according to\n\n$$\n\\begin{split}\\begin{align}\n    LLR(k,i)&= \\ln\\left(\\frac{\\Pr\\left(b_{k,i}=1\\lvert \\mathbf{y},\\mathbf{H}\\right)}{\\Pr\\left(b_{k,i}=0\\lvert \\mathbf{y},\\mathbf{H}\\right)}\\right)\\\\\n            &=\\ln\\left(\\frac{\n            \\sum_{\\mathbf{x}\\in\\mathcal{C}_{k,i,1}} \\exp\\left(\n                -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2\n                \\right) \\Pr\\left( \\mathbf{x} \\right)\n            }{\n            \\sum_{\\mathbf{x}\\in\\mathcal{C}_{k,i,0}} \\exp\\left(\n                -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2\n                \\right) \\Pr\\left( \\mathbf{x} \\right)\n            }\\right)\n\\end{align}\\end{split}\n$$\n\nwhere $\\mathcal{C}_{k,i,1}$ and $\\mathcal{C}_{k,i,0}$ are the\nsets of vectors of constellation points for which the $i\\text{th}$ bit\nof the $k\\text{th}$ user is equal to 1 and 0, respectively.\n$\\Pr\\left( \\mathbf{x} \\right)$ is the prior distribution of the vector of\nconstellation points $\\mathbf{x}$. Assuming that the constellation points and\nbit levels are independent, it is computed from the prior of the bits according to\n\n$$\n\\Pr\\left( \\mathbf{x} \\right) = \\prod_{k=1}^K \\prod_{i=1}^{I} \\sigma \\left( LLR_p(k,i) \\right)\n$$\n\nwhere $LLR_p(k,i)$ is the prior knowledge of the $i\\text{th}$ bit of the\n$k\\text{th}$ user given as an LLR and which is set to $0$ if no prior knowledge is assumed to be available,\nand $\\sigma\\left(\\cdot\\right)$ is the sigmoid function.\nThe definition of the LLR has been chosen such that it is equivalent with that of logit. This is\ndifferent from many textbooks in communications, where the LLR is\ndefined as $LLR(k,i) = \\ln\\left(\\frac{\\Pr\\left(b_{k,i}=0\\lvert \\mathbf{y},\\mathbf{H}\\right)}{\\Pr\\left(b_{k,i}=1\\lvert \\mathbf{y},\\mathbf{H}\\right)}\\right)$.\n\nWith the maxlog demapping method, the LLR for the $i\\text{th}$ bit\nof the $k\\text{th}$ user is approximated like\n\n$$\n\\begin{split}\\begin{align}\n    LLR(k,i) \\approx&\\ln\\left(\\frac{\n        \\max_{\\mathbf{x}\\in\\mathcal{C}_{k,i,1}} \\left( \\exp\\left(\n            -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2\n            \\right) \\Pr\\left( \\mathbf{x} \\right) \\right)\n        }{\n        \\max_{\\mathbf{x}\\in\\mathcal{C}_{k,i,0}} \\left( \\exp\\left(\n            -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2\n            \\right) \\Pr\\left( \\mathbf{x} \\right) \\right)\n        }\\right)\\\\\n        = &\\min_{\\mathbf{x}\\in\\mathcal{C}_{k,i,0}} \\left( \\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2 - \\ln \\left(\\Pr\\left( \\mathbf{x} \\right) \\right) \\right) -\n            \\min_{\\mathbf{x}\\in\\mathcal{C}_{k,i,1}} \\left( \\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2 - \\ln \\left( \\Pr\\left( \\mathbf{x} \\right) \\right) \\right).\n    \\end{align}\\end{split}\n$$\n\n**ML detection of symbols:**\n\nSoft-decisions on symbols are called logits (i.e., unnormalized log-probability).\n\nWith the app demapping method, the logit for the\nconstellation point $c \\in \\mathcal{C}$ of the $k\\text{th}$ user  is computed according to\n\n$$\n\\begin{align}\n    \\text{logit}(k,c) &= \\ln\\left(\\sum_{\\mathbf{x} : x_k = c} \\exp\\left(\n                -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2\n                \\right)\\Pr\\left( \\mathbf{x} \\right)\\right).\n\\end{align}\n$$\n\nWith the maxlog demapping method, the logit for the constellation point $c \\in \\mathcal{C}$\nof the $k\\text{th}$ user  is approximated like\n\n$$\n\\text{logit}(k,c) \\approx \\max_{\\mathbf{x} : x_k = c} \\left(\n        -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2 + \\ln \\left( \\Pr\\left( \\mathbf{x} \\right) \\right)\n        \\right).\n$$\n\nWhen hard decisions are requested, this layer returns for the $k$ th stream\n\n$$\n\\hat{c}_k = \\underset{c \\in \\mathcal{C}}{\\text{argmax}} \\left( \\sum_{\\mathbf{x} : x_k = c} \\exp\\left(\n                -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2\n                \\right)\\Pr\\left( \\mathbf{x} \\right) \\right)\n$$\n\nwhere $\\mathcal{C}$ is the set of constellation points.\nParameters\n\n- **output** (*One of** [**\"bit\"**, **\"symbol\"**]**, **str*)  The type of output, either LLRs on bits or logits on constellation symbols.\n- **demapping_method** (*One of** [**\"app\"**, **\"maxlog\"**]**, **str*)  The demapping method used.\n- **num_streams** (*tf.int*)  Number of transmitted streams\n- **constellation_type** (*One of** [**\"qam\"**, **\"pam\"**, **\"custom\"**]**, **str*)  For custom, an instance of [`Constellation`](mapping.html#sionna.mapping.Constellation)\nmust be provided.\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation symbol, e.g., 4 for QAM16.\nOnly required for `constellation_type` in [qam, pam].\n- **constellation** ()  An instance of [`Constellation`](mapping.html#sionna.mapping.Constellation) or <cite>None</cite>.\nIn the latter case, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n- **hard_out** (*bool*)  If <cite>True</cite>, the detector computes hard-decided bit values or\nconstellation point indices instead of soft-values.\nDefaults to <cite>False</cite>.\n- **with_prior** (*bool*)  If <cite>True</cite>, it is assumed that prior knowledge on the bits or constellation points is available.\nThis prior information is given as LLRs (for bits) or log-probabilities (for constellation points) as an\nadditional input to the layer.\nDefaults to <cite>False</cite>.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**] **tf.DType** (**dtype**)*)  The dtype of `y`. Defaults to tf.complex64.\nThe output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n\nInput\n\n- **(y, h, s) or (y, h, prior, s)**  Tuple:\n- **y** (*[,M], tf.complex*)  1+D tensor containing the received signals.\n- **h** (*[,M,num_streams], tf.complex*)  2+D tensor containing the channel matrices.\n- **prior** (*[,num_streams,num_bits_per_symbol] or [,num_streams,num_points], tf.float*)  Prior of the transmitted signals.\nIf `output` equals bit, then LLRs of the transmitted bits are expected.\nIf `output` equals symbol, then logits of the transmitted constellation points are expected.\nOnly required if the `with_prior` flag is set.\n- **s** (*[,M,M], tf.complex*)  2+D tensor containing the noise covariance matrices.\n\n\nOutput\n\n- **One of**\n- *[, num_streams, num_bits_per_symbol], tf.float*  LLRs or hard-decisions for every bit of every stream, if `output` equals <cite>bit</cite>.\n- *[, num_streams, num_points], tf.float or [, num_streams], tf.int*  Logits or hard-decisions for constellation symbols for every stream, if `output` equals <cite>symbol</cite>.\nHard-decisions correspond to the symbol indices.\n\n\n**Note**\n\nIf you want to use this layer in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### MaximumLikelihoodDetectorWithPrior\n\n`class` `sionna.mimo.``MaximumLikelihoodDetectorWithPrior`(*`output`*, *`demapping_method`*, *`num_streams`*, *`constellation_type``=``None`*, *`num_bits_per_symbol``=``None`*, *`constellation``=``None`*, *`hard_out``=``False`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/mimo/detection.html#MaximumLikelihoodDetectorWithPrior)\n\nMIMO maximum-likelihood (ML) detector, assuming prior\nknowledge on the bits or constellation points is available.\n\nThis class is deprecated as the functionality has been integrated\ninto [`MaximumLikelihoodDetector`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.MaximumLikelihoodDetector).\n\nThis layer implements MIMO maximum-likelihood (ML) detection assuming the\nfollowing channel model:\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^M$ is the received signal vector,\n$\\mathbf{x}\\in\\mathcal{C}^K$ is the vector of transmitted symbols which\nare uniformly and independently drawn from the constellation $\\mathcal{C}$,\n$\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$ is the known channel matrix,\nand $\\mathbf{n}\\in\\mathbb{C}^M$ is a complex Gaussian noise vector.\nIt is assumed that $\\mathbb{E}\\left[\\mathbf{n}\\right]=\\mathbf{0}$ and\n$\\mathbb{E}\\left[\\mathbf{n}\\mathbf{n}^{\\mathsf{H}}\\right]=\\mathbf{S}$,\nwhere $\\mathbf{S}$ has full rank.\nIt is assumed that prior information of the transmitted signal $\\mathbf{x}$ is available,\nprovided either as LLRs on the bits modulated onto $\\mathbf{x}$ or as logits on the individual\nconstellation points forming $\\mathbf{x}$.\n\nPrior to demapping, the received signal is whitened:\n\n$$\n\\begin{split}\\tilde{\\mathbf{y}} &= \\mathbf{S}^{-\\frac{1}{2}}\\mathbf{y}\\\\\n&=  \\mathbf{S}^{-\\frac{1}{2}}\\mathbf{H}\\mathbf{x} + \\mathbf{S}^{-\\frac{1}{2}}\\mathbf{n}\\\\\n&= \\tilde{\\mathbf{H}}\\mathbf{x} + \\tilde{\\mathbf{n}}\\end{split}\n$$\n\nThe layer can compute ML detection of symbols or bits with either\nsoft- or hard-decisions. Note that decisions are computed symbol-/bit-wise\nand not jointly for the entire vector $\\textbf{x}$ (or the underlying vector\nof bits).\n\n**ML detection of bits:**\n\nSoft-decisions on bits are called log-likelihood ratios (LLR).\nWith the app demapping method, the LLR for the $i\\text{th}$ bit\nof the $k\\text{th}$ user is then computed according to\n\n$$\n\\begin{split}\\begin{align}\n    LLR(k,i)&= \\ln\\left(\\frac{\\Pr\\left(b_{k,i}=1\\lvert \\mathbf{y},\\mathbf{H}\\right)}{\\Pr\\left(b_{k,i}=0\\lvert \\mathbf{y},\\mathbf{H}\\right)}\\right)\\\\\n            &=\\ln\\left(\\frac{\n            \\sum_{\\mathbf{x}\\in\\mathcal{C}_{k,i,1}} \\exp\\left(\n                -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2\n                \\right) \\Pr\\left( \\mathbf{x} \\right)\n            }{\n            \\sum_{\\mathbf{x}\\in\\mathcal{C}_{k,i,0}} \\exp\\left(\n                -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2\n                \\right) \\Pr\\left( \\mathbf{x} \\right)\n            }\\right)\n\\end{align}\\end{split}\n$$\n\nwhere $\\mathcal{C}_{k,i,1}$ and $\\mathcal{C}_{k,i,0}$ are the\nsets of vectors of constellation points for which the $i\\text{th}$ bit\nof the $k\\text{th}$ user is equal to 1 and 0, respectively.\n$\\Pr\\left( \\mathbf{x} \\right)$ is the prior distribution of the vector of\nconstellation points $\\mathbf{x}$. Assuming that the constellation points and\nbit levels are independent, it is computed from the prior of the bits according to\n\n$$\n\\Pr\\left( \\mathbf{x} \\right) = \\prod_{k=1}^K \\prod_{i=1}^{I} \\sigma \\left( LLR_p(k,i) \\right)\n$$\n\nwhere $LLR_p(k,i)$ is the prior knowledge of the $i\\text{th}$ bit of the\n$k\\text{th}$ user given as an LLR, and $\\sigma\\left(\\cdot\\right)$ is the sigmoid function.\nThe definition of the LLR has been chosen such that it is equivalent with that of logit. This is\ndifferent from many textbooks in communications, where the LLR is\ndefined as $LLR(k,i) = \\ln\\left(\\frac{\\Pr\\left(b_{k,i}=0\\lvert \\mathbf{y},\\mathbf{H}\\right)}{\\Pr\\left(b_{k,i}=1\\lvert \\mathbf{y},\\mathbf{H}\\right)}\\right)$.\n\nWith the maxlog demapping method, the LLR for the $i\\text{th}$ bit\nof the $k\\text{th}$ user is approximated like\n\n$$\n\\begin{split}\\begin{align}\n    LLR(k,i) \\approx&\\ln\\left(\\frac{\n        \\max_{\\mathbf{x}\\in\\mathcal{C}_{k,i,1}} \\left( \\exp\\left(\n            -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2\n            \\right) \\Pr\\left( \\mathbf{x} \\right) \\right)\n        }{\n        \\max_{\\mathbf{x}\\in\\mathcal{C}_{k,i,0}} \\left( \\exp\\left(\n            -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2\n            \\right) \\Pr\\left( \\mathbf{x} \\right) \\right)\n        }\\right)\\\\\n        = &\\min_{\\mathbf{x}\\in\\mathcal{C}_{k,i,0}} \\left( \\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2 - \\ln \\left(\\Pr\\left( \\mathbf{x} \\right) \\right) \\right) -\n            \\min_{\\mathbf{x}\\in\\mathcal{C}_{k,i,1}} \\left( \\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2 - \\ln \\left( \\Pr\\left( \\mathbf{x} \\right) \\right) \\right).\n    \\end{align}\\end{split}\n$$\n\n**ML detection of symbols:**\n\nSoft-decisions on symbols are called logits (i.e., unnormalized log-probability).\n\nWith the app demapping method, the logit for the\nconstellation point $c \\in \\mathcal{C}$ of the $k\\text{th}$ user  is computed according to\n\n$$\n\\begin{align}\n    \\text{logit}(k,c) &= \\ln\\left(\\sum_{\\mathbf{x} : x_k = c} \\exp\\left(\n                -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2\n                \\right)\\Pr\\left( \\mathbf{x} \\right)\\right).\n\\end{align}\n$$\n\nWith the maxlog demapping method, the logit for the constellation point $c \\in \\mathcal{C}$\nof the $k\\text{th}$ user  is approximated like\n\n$$\n\\text{logit}(k,c) \\approx \\max_{\\mathbf{x} : x_k = c} \\left(\n        -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2 + \\ln \\left( \\Pr\\left( \\mathbf{x} \\right) \\right)\n        \\right).\n$$\n\nWhen hard decisions are requested, this layer returns for the $k$ th stream\n\n$$\n\\hat{c}_k = \\underset{c \\in \\mathcal{C}}{\\text{argmax}} \\left( \\sum_{\\mathbf{x} : x_k = c} \\exp\\left(\n                -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2\n                \\right)\\Pr\\left( \\mathbf{x} \\right) \\right)\n$$\n\nwhere $\\mathcal{C}$ is the set of constellation points.\nParameters\n\n- **output** (*One of** [**\"bit\"**, **\"symbol\"**]**, **str*)  The type of output, either LLRs on bits or logits on constellation symbols.\n- **demapping_method** (*One of** [**\"app\"**, **\"maxlog\"**]**, **str*)  The demapping method used.\n- **num_streams** (*tf.int*)  Number of transmitted streams\n- **constellation_type** (*One of** [**\"qam\"**, **\"pam\"**, **\"custom\"**]**, **str*)  For custom, an instance of [`Constellation`](mapping.html#sionna.mapping.Constellation)\nmust be provided.\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation symbol, e.g., 4 for QAM16.\nOnly required for `constellation_type` in [qam, pam].\n- **constellation** ()  An instance of [`Constellation`](mapping.html#sionna.mapping.Constellation) or <cite>None</cite>.\nIn the latter case, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n- **hard_out** (*bool*)  If <cite>True</cite>, the detector computes hard-decided bit values or\nconstellation point indices instead of soft-values.\nDefaults to <cite>False</cite>.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**] **tf.DType** (**dtype**)*)  The dtype of `y`. Defaults to tf.complex64.\nThe output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n\nInput\n\n- **(y, h, prior, s)**  Tuple:\n- **y** (*[,M], tf.complex*)  1+D tensor containing the received signals.\n- **h** (*[,M,num_streams], tf.complex*)  2+D tensor containing the channel matrices.\n- **prior** (*[,num_streams,num_bits_per_symbol] or [,num_streams,num_points], tf.float*)  Prior of the transmitted signals.\nIf `output` equals bit, then LLRs of the transmitted bits are expected.\nIf `output` equals symbol, then logits of the transmitted constellation points are expected.\n- **s** (*[,M,M], tf.complex*)  2+D tensor containing the noise covariance matrices.\n\n\nOutput\n\n- **One of**\n- *[, num_streams, num_bits_per_symbol], tf.float*  LLRs or hard-decisions for every bit of every stream, if `output` equals <cite>bit</cite>.\n- *[, num_streams, num_points], tf.float or [, num_streams], tf.int*  Logits or hard-decisions for constellation symbols for every stream, if `output` equals <cite>symbol</cite>.\nHard-decisions correspond to the symbol indices.\n\n\n**Note**\n\nIf you want to use this layer in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### MMSE-PIC\n\n`class` `sionna.mimo.``MMSEPICDetector`(*`output`*, *`demapping_method``=``'maxlog'`*, *`num_iter``=``1`*, *`constellation_type``=``None`*, *`num_bits_per_symbol``=``None`*, *`constellation``=``None`*, *`hard_out``=``False`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/mimo/detection.html#MMSEPICDetector)\n\nMinimum mean square error (MMSE) with parallel interference cancellation (PIC) detector\n\nThis layer implements the MMSE PIC detector, as proposed in [[CST2011]](https://nvlabs.github.io/sionna/api/mimo.html#cst2011).\nFor `num_iter`>1, this implementation performs MMSE PIC self-iterations.\nMMSE PIC self-iterations can be understood as a concatenation of MMSE PIC\ndetectors from [[CST2011]](https://nvlabs.github.io/sionna/api/mimo.html#cst2011), which forward intrinsic LLRs to the next\nself-iteration.\n\nCompared to [[CST2011]](https://nvlabs.github.io/sionna/api/mimo.html#cst2011), this implementation also accepts priors on the\nconstellation symbols as an alternative to priors on the bits.\n\nThis layer assumes the following channel model:\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^M$ is the received signal vector,\n$\\mathbf{x}\\in\\mathcal{C}^S$ is the vector of transmitted symbols which\nare uniformly and independently drawn from the constellation $\\mathcal{C}$,\n$\\mathbf{H}\\in\\mathbb{C}^{M\\times S}$ is the known channel matrix,\nand $\\mathbf{n}\\in\\mathbb{C}^M$ is a complex Gaussian noise vector.\nIt is assumed that $\\mathbb{E}\\left[\\mathbf{n}\\right]=\\mathbf{0}$ and\n$\\mathbb{E}\\left[\\mathbf{n}\\mathbf{n}^{\\mathsf{H}}\\right]=\\mathbf{S}$,\nwhere $\\mathbf{S}$ has full rank.\n\nThe algorithm starts by computing the soft symbols\n$\\bar{x}_s=\\mathbb{E}\\left[ x_s \\right]$ and\nvariances $v_s=\\mathbb{E}\\left[ |e_s|^2\\right]$ from the priors,\nwhere $e_s = x_s - \\bar{x}_s$, for all $s=1,\\dots,S$.\n\nNext, for each stream, the interference caused by all other streams is cancelled\nfrom the observation $\\mathbf{y}$, leading to\n\n$$\n\\hat{\\mathbf{y}}_s = \\mathbf{y} - \\sum_{j\\neq s} \\mathbf{h}_j x_j = \\mathbf{h}_s x_s + \\tilde{\\mathbf{n}}_s,\\quad s=1,\\dots,S\n$$\n\nwhere $\\tilde{\\mathbf{n}}_s=\\sum_{j\\neq s} \\mathbf{h}_j e_j + \\mathbf{n}$.\n\nThen, a linear MMSE filter $\\mathbf{w}_s$ is computed to reduce the resdiual noise\nfor each observation $\\hat{\\mathbf{y}}_s$, which is given as\n\n$$\n\\mathbf{w}_s = \\mathbf{h}_s^{\\mathsf{H}}\\left( \\mathbf{H} \\mathbf{D}_s\\mathbf{H}^{\\mathsf{H}} +\\mathbf{S} \\right)^{-1}\n$$\n\nwhere $\\mathbf{D}_s \\in \\mathbb{C}^{S\\times S}$ is diagonal with entries\n\n$$\n\\begin{split}\\left[\\mathbf{D}_s\\right]_{i,i} = \\begin{cases}\n                                    v_i & i\\neq s \\\\\n                                    1 & i=s.\n                                  \\end{cases}\\end{split}\n$$\n\nThe filtered observations\n\n$$\n\\tilde{z}_s = \\mathbf{w}_s^{\\mathsf{H}} \\hat{\\mathbf{y}}_s = \\tilde{\\mu}_s x_s + \\mathbf{w}_s^{\\mathsf{H}}\\tilde{\\mathbf{n}}_s\n$$\n\nwhere $\\tilde{\\mu}_s=\\mathbf{w}_s^{\\mathsf{H}} \\mathbf{h}_s$, are then demapped to either symbol logits or LLRs, assuming that the remaining noise is Gaussian with variance\n\n$$\n\\nu_s^2 = \\mathop{\\text{Var}}\\left[\\tilde{z}_s\\right] = \\mathbf{w}_s^{\\mathsf{H}} \\left(\\sum_{j\\neq s} \\mathbf{h}_j \\mathbf{h}_j^{\\mathsf{H}} v_j +\\mathbf{S} \\right)\\mathbf{w}_s.\n$$\n\nThe resulting soft-symbols can then be used for the next self-iteration of the algorithm.\n\nNote that this algorithm can be substantially simplified as described in [[CST2011]](https://nvlabs.github.io/sionna/api/mimo.html#cst2011) to avoid\nthe computation of different matrix inverses for each stream. This is the version which is\nimplemented.\nParameters\n\n- **output** (*One of** [**\"bit\"**, **\"symbol\"**]**, **str*)  The type of output, either LLRs on bits or logits on constellation\nsymbols.\n- **demapping_method** (*One of** [**\"app\"**, **\"maxlog\"**]**, **str*)  The demapping method used.\nDefaults to maxlog.\n- **num_iter** (*int*)  Number of MMSE PIC iterations.\nDefaults to 1.\n- **constellation_type** (*One of** [**\"qam\"**, **\"pam\"**, **\"custom\"**]**, **str*)  For custom, an instance of [`Constellation`](mapping.html#sionna.mapping.Constellation)\nmust be provided.\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation symbol, e.g., 4 for QAM16.\nOnly required for `constellation_type` in [qam, pam].\n- **constellation** ()  An instance of [`Constellation`](mapping.html#sionna.mapping.Constellation) or <cite>None</cite>.\nIn the latter case, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n- **hard_out** (*bool*)  If <cite>True</cite>, the detector computes hard-decided bit values or\nconstellation point indices instead of soft-values.\nDefaults to <cite>False</cite>.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**] **tf.DType** (**dtype**)*)  The dtype of `y`. Defaults to tf.complex64.\nThe output dtype is the corresponding real dtype\n(tf.float32 or tf.float64).\n\n\nInput\n\n- **(y, h, prior, s)**  Tuple:\n- **y** (*[,M], tf.complex*)  1+D tensor containing the received signals\n- **h** (*[,M,S], tf.complex*)  2+D tensor containing the channel matrices\n- **prior** (*[,S,num_bits_per_symbol] or [,S,num_points], tf.float*)  Prior of the transmitted signals.\nIf `output` equals bit, then LLRs of the transmitted bits are expected.\nIf `output` equals symbol, then logits of the transmitted constellation points are expected.\n- **s** (*[,M,M], tf.complex*)  2+D tensor containing the noise covariance matrices\n\n\nOutput\n\n- **One of**\n- *[,S,num_bits_per_symbol], tf.float*  LLRs or hard-decisions for every bit of every stream, if `output` equals <cite>bit</cite>\n- *[,S,2**num_bits_per_symbol], tf.float or [,S], tf.int*  Logits or hard-decisions for constellation symbols for every stream, if `output` equals <cite>symbol</cite>\n\n\n**Note**\n\nFor numerical stability, we do not recommend to use this function in Graph\nmode with XLA, i.e., within a function that is decorated with\n`@tf.function(jit_compile=True)`.\nHowever, it is possible to do so by setting\n`sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### List2LLR\n\n`class` `sionna.mimo.``List2LLR`[`[source]`](../_modules/sionna/mimo/utils.html#List2LLR)\n\nAbstract class defining a callable to compute LLRs from a list of\ncandidate vectors (or paths) provided by a MIMO detector.\n\nThe following channel model is assumed\n\n$$\n\\bar{\\mathbf{y}} = \\mathbf{R}\\bar{\\mathbf{x}} + \\bar{\\mathbf{n}}\n$$\n\nwhere $\\bar{\\mathbf{y}}\\in\\mathbb{C}^S$ are the channel outputs,\n$\\mathbf{R}\\in\\mathbb{C}^{S\\times S}$ is an upper-triangular matrix,\n$\\bar{\\mathbf{x}}\\in\\mathbb{C}^S$ is the transmitted vector whose entries\nare uniformly and independently drawn from the constellation $\\mathcal{C}$,\nand $\\bar{\\mathbf{n}}\\in\\mathbb{C}^S$ is white noise\nwith $\\mathbb{E}\\left[\\bar{\\mathbf{n}}\\right]=\\mathbf{0}$ and\n$\\mathbb{E}\\left[\\bar{\\mathbf{n}}\\bar{\\mathbf{n}}^{\\mathsf{H}}\\right]=\\mathbf{I}$.\n\nIt is assumed that a MIMO detector such as [`KBestDetector`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.KBestDetector)\nproduces $K$ candidate solutions $\\bar{\\mathbf{x}}_k\\in\\mathcal{C}^S$\nand their associated distance metrics $d_k=\\lVert \\bar{\\mathbf{y}} - \\mathbf{R}\\bar{\\mathbf{x}}_k \\rVert^2$\nfor $k=1,\\dots,K$. This layer can also be used with the real-valued representation of the channel.\nInput\n\n- **(y, r, dists, path_inds, path_syms)**  Tuple:\n- **y** (*[,M], tf.complex or tf.float*)  Channel outputs of the whitened channel\n- **r** ([,num_streams, num_streams], same dtype as `y`)  Upper triangular channel matrix of the whitened channel\n- **dists** (*[,num_paths], tf.float*)  Distance metric for each path (or candidate)\n- **path_inds** (*[,num_paths,num_streams], tf.int32*)  Symbol indices for every stream of every path (or candidate)\n- **path_syms** ([,num_path,num_streams], same dtype as `y`)  Constellation symbol for every stream of every path (or candidate)\n\n\nOutput\n\n**llr** (*[num_streams,num_bits_per_symbol], tf.float*)  LLRs for all bits of every stream\n\n\n**Note**\n\nAn implementation of this class does not need to make use of all of\nthe provided inputs which enable various different implementations."
"### List2LLRSimple\n\n`class` `sionna.mimo.``List2LLRSimple`(*`num_bits_per_symbol`*, *`llr_clip_val``=``20.0`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/mimo/utils.html#List2LLRSimple)\n\nComputes LLRs from a list of candidate vectors (or paths) provided by a MIMO detector.\n\nThe following channel model is assumed:\n\n$$\n\\bar{\\mathbf{y}} = \\mathbf{R}\\bar{\\mathbf{x}} + \\bar{\\mathbf{n}}\n$$\n\nwhere $\\bar{\\mathbf{y}}\\in\\mathbb{C}^S$ are the channel outputs,\n$\\mathbf{R}\\in\\mathbb{C}^{S\\times S}$ is an upper-triangular matrix,\n$\\bar{\\mathbf{x}}\\in\\mathbb{C}^S$ is the transmitted vector whose entries\nare uniformly and independently drawn from the constellation $\\mathcal{C}$,\nand $\\bar{\\mathbf{n}}\\in\\mathbb{C}^S$ is white noise\nwith $\\mathbb{E}\\left[\\bar{\\mathbf{n}}\\right]=\\mathbf{0}$ and\n$\\mathbb{E}\\left[\\bar{\\mathbf{n}}\\bar{\\mathbf{n}}^{\\mathsf{H}}\\right]=\\mathbf{I}$.\n\nIt is assumed that a MIMO detector such as [`KBestDetector`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.KBestDetector)\nproduces $K$ candidate solutions $\\bar{\\mathbf{x}}_k\\in\\mathcal{C}^S$\nand their associated distance metrics $d_k=\\lVert \\bar{\\mathbf{y}} - \\mathbf{R}\\bar{\\mathbf{x}}_k \\rVert^2$\nfor $k=1,\\dots,K$. This layer can also be used with the real-valued representation of the channel.\n\nThe LLR for the $i\\text{th}$ bit of the $k\\text{th}$ stream is computed as\n\n$$\n\\begin{split}\\begin{align}\n    LLR(k,i) &= \\log\\left(\\frac{\\Pr(b_{k,i}=1|\\bar{\\mathbf{y}},\\mathbf{R})}{\\Pr(b_{k,i}=0|\\bar{\\mathbf{y}},\\mathbf{R})}\\right)\\\\\n        &\\approx \\min_{j \\in  \\mathcal{C}_{k,i,0}}d_j - \\min_{j \\in  \\mathcal{C}_{k,i,1}}d_j\n\\end{align}\\end{split}\n$$\n\nwhere $\\mathcal{C}_{k,i,1}$ and $\\mathcal{C}_{k,i,0}$ are the set of indices\nin the list of candidates for which the $i\\text{th}$ bit of the $k\\text{th}$\nstream is equal to 1 and 0, respectively. The LLRs are clipped to $\\pm LLR_\\text{clip}$\nwhich can be configured through the parameter `llr_clip_val`.\n\nIf $\\mathcal{C}_{k,i,0}$ is empty, $LLR(k,i)=LLR_\\text{clip}$;\nif $\\mathcal{C}_{k,i,1}$ is empty, $LLR(k,i)=-LLR_\\text{clip}$.\nParameters\n\n- **num_bits_per_symbol** (*int*)  Number of bits per constellation symbol\n- **llr_clip_val** (*float*)  The absolute values of LLRs are clipped to this value.\nDefaults to 20.0. Can also be a trainable variable.\n\n\nInput\n\n- **(y, r, dists, path_inds, path_syms)**  Tuple:\n- **y** (*[,M], tf.complex or tf.float*)  Channel outputs of the whitened channel\n- **r** ([,num_streams, num_streams], same dtype as `y`)  Upper triangular channel matrix of the whitened channel\n- **dists** (*[,num_paths], tf.float*)  Distance metric for each path (or candidate)\n- **path_inds** (*[,num_paths,num_streams], tf.int32*)  Symbol indices for every stream of every path (or candidate)\n- **path_syms** ([,num_path,num_streams], same dtype as `y`)  Constellation symbol for every stream of every path (or candidate)\n\n\nOutput\n\n**llr** (*[num_streams,num_bits_per_symbol], tf.float*)  LLRs for all bits of every stream"
"### complex2real_vector\n\n`sionna.mimo.``complex2real_vector`(*`z`*)[`[source]`](../_modules/sionna/mimo/utils.html#complex2real_vector)\n\nTransforms a complex-valued vector into its real-valued equivalent.\n\nTransforms the last dimension of a complex-valued tensor into\nits real-valued equivalent by stacking the real and imaginary\nparts on top of each other.\n\nFor a vector $\\mathbf{z}\\in \\mathbb{C}^M$ with real and imaginary\nparts $\\mathbf{x}\\in \\mathbb{R}^M$ and\n$\\mathbf{y}\\in \\mathbb{R}^M$, respectively, this function returns\nthe vector $\\left[\\mathbf{x}^{\\mathsf{T}}, \\mathbf{y}^{\\mathsf{T}} \\right ]^{\\mathsf{T}}\\in\\mathbb{R}^{2M}$.\nInput\n\n*[,M], tf.complex*\n\nOutput\n\n*[,2M], tf.complex.real_dtype*"
"### real2complex_vector\n\n`sionna.mimo.``real2complex_vector`(*`z`*)[`[source]`](../_modules/sionna/mimo/utils.html#real2complex_vector)\n\nTransforms a real-valued vector into its complex-valued equivalent.\n\nTransforms the last dimension of a real-valued tensor into\nits complex-valued equivalent by interpreting the first half\nas the real and the second half as the imaginary part.\n\nFor a vector $\\mathbf{z}=\\left[\\mathbf{x}^{\\mathsf{T}}, \\mathbf{y}^{\\mathsf{T}} \\right ]^{\\mathsf{T}}\\in \\mathbb{R}^{2M}$\nwith $\\mathbf{x}\\in \\mathbb{R}^M$ and $\\mathbf{y}\\in \\mathbb{R}^M$,\nthis function returns\nthe vector $\\mathbf{x}+j\\mathbf{y}\\in\\mathbb{C}^M$.\nInput\n\n*[,2M], tf.float*\n\nOutput\n\n*[,M], tf.complex*"
"### complex2real_matrix\n\n`sionna.mimo.``complex2real_matrix`(*`z`*)[`[source]`](../_modules/sionna/mimo/utils.html#complex2real_matrix)\n\nTransforms a complex-valued matrix into its real-valued equivalent.\n\nTransforms the last two dimensions of a complex-valued tensor into\ntheir real-valued matrix equivalent representation.\n\nFor a matrix $\\mathbf{Z}\\in \\mathbb{C}^{M\\times K}$ with real and imaginary\nparts $\\mathbf{X}\\in \\mathbb{R}^{M\\times K}$ and\n$\\mathbf{Y}\\in \\mathbb{R}^{M\\times K}$, respectively, this function returns\nthe matrix $\\tilde{\\mathbf{Z}}\\in \\mathbb{R}^{2M\\times 2K}$, given as\n\n$$\n\\begin{split}\\tilde{\\mathbf{Z}} = \\begin{pmatrix}\n                        \\mathbf{X} & -\\mathbf{Y}\\\\\n                        \\mathbf{Y} & \\mathbf{X}\n                     \\end{pmatrix}.\\end{split}\n$$\n\nInput\n\n*[,M,K], tf.complex*\n\nOutput\n\n*[,2M, 2K], tf.complex.real_dtype*"
"### real2complex_matrix\n\n`sionna.mimo.``real2complex_matrix`(*`z`*)[`[source]`](../_modules/sionna/mimo/utils.html#real2complex_matrix)\n\nTransforms a real-valued matrix into its complex-valued equivalent.\n\nTransforms the last two dimensions of a real-valued tensor into\ntheir complex-valued matrix equivalent representation.\n\nFor a matrix $\\tilde{\\mathbf{Z}}\\in \\mathbb{R}^{2M\\times 2K}$,\nsatisfying\n\n$$\n\\begin{split}\\tilde{\\mathbf{Z}} = \\begin{pmatrix}\n                        \\mathbf{X} & -\\mathbf{Y}\\\\\n                        \\mathbf{Y} & \\mathbf{X}\n                     \\end{pmatrix}\\end{split}\n$$\n\nwith $\\mathbf{X}\\in \\mathbb{R}^{M\\times K}$ and\n$\\mathbf{Y}\\in \\mathbb{R}^{M\\times K}$, this function returns\nthe matrix $\\mathbf{Z}=\\mathbf{X}+j\\mathbf{Y}\\in\\mathbb{C}^{M\\times K}$.\nInput\n\n*[,2M,2K], tf.float*\n\nOutput\n\n*[,M, 2], tf.complex*"
"### complex2real_covariance\n\n`sionna.mimo.``complex2real_covariance`(*`r`*)[`[source]`](../_modules/sionna/mimo/utils.html#complex2real_covariance)\n\nTransforms a complex-valued covariance matrix to its real-valued equivalent.\n\nAssume a proper complex random variable $\\mathbf{z}\\in\\mathbb{C}^M$ [[ProperRV]](https://nvlabs.github.io/sionna/api/mimo.html#properrv)\nwith covariance matrix $\\mathbf{R}= \\in\\mathbb{C}^{M\\times M}$\nand real and imaginary parts $\\mathbf{x}\\in \\mathbb{R}^M$ and\n$\\mathbf{y}\\in \\mathbb{R}^M$, respectively.\nThis function transforms the given $\\mathbf{R}$ into the covariance matrix of the real-valued equivalent\nvector $\\tilde{\\mathbf{z}}=\\left[\\mathbf{x}^{\\mathsf{T}}, \\mathbf{y}^{\\mathsf{T}} \\right ]^{\\mathsf{T}}\\in\\mathbb{R}^{2M}$, which\nis computed as [[CovProperRV]](https://nvlabs.github.io/sionna/api/mimo.html#covproperrv)\n\n$$\n\\begin{split}\\mathbb{E}\\left[\\tilde{\\mathbf{z}}\\tilde{\\mathbf{z}}^{\\mathsf{H}} \\right] =\n\\begin{pmatrix}\n    \\frac12\\Re\\{\\mathbf{R}\\} & -\\frac12\\Im\\{\\mathbf{R}\\}\\\\\n    \\frac12\\Im\\{\\mathbf{R}\\} & \\frac12\\Re\\{\\mathbf{R}\\}\n\\end{pmatrix}.\\end{split}\n$$\n\nInput\n\n*[,M,M], tf.complex*\n\nOutput\n\n*[,2M, 2M], tf.complex.real_dtype*"
"### real2complex_covariance\n\n`sionna.mimo.``real2complex_covariance`(*`q`*)[`[source]`](../_modules/sionna/mimo/utils.html#real2complex_covariance)\n\nTransforms a real-valued covariance matrix to its complex-valued equivalent.\n\nAssume a proper complex random variable $\\mathbf{z}\\in\\mathbb{C}^M$ [[ProperRV]](https://nvlabs.github.io/sionna/api/mimo.html#properrv)\nwith covariance matrix $\\mathbf{R}= \\in\\mathbb{C}^{M\\times M}$\nand real and imaginary parts $\\mathbf{x}\\in \\mathbb{R}^M$ and\n$\\mathbf{y}\\in \\mathbb{R}^M$, respectively.\nThis function transforms the given covariance matrix of the real-valued equivalent\nvector $\\tilde{\\mathbf{z}}=\\left[\\mathbf{x}^{\\mathsf{T}}, \\mathbf{y}^{\\mathsf{T}} \\right ]^{\\mathsf{T}}\\in\\mathbb{R}^{2M}$, which\nis given as [[CovProperRV]](https://nvlabs.github.io/sionna/api/mimo.html#covproperrv)\n\n$$\n\\begin{split}\\mathbb{E}\\left[\\tilde{\\mathbf{z}}\\tilde{\\mathbf{z}}^{\\mathsf{H}} \\right] =\n\\begin{pmatrix}\n    \\frac12\\Re\\{\\mathbf{R}\\} & -\\frac12\\Im\\{\\mathbf{R}\\}\\\\\n    \\frac12\\Im\\{\\mathbf{R}\\} & \\frac12\\Re\\{\\mathbf{R}\\}\n\\end{pmatrix},\\end{split}\n$$\n\ninto is complex-valued equivalent $\\mathbf{R}$.\nInput\n\n*[,2M,2M], tf.float*\n\nOutput\n\n*[,M, M], tf.complex*"
"### complex2real_channel\n\n`sionna.mimo.``complex2real_channel`(*`y`*, *`h`*, *`s`*)[`[source]`](../_modules/sionna/mimo/utils.html#complex2real_channel)\n\nTransforms a complex-valued MIMO channel into its real-valued equivalent.\n\nAssume the canonical MIMO channel model\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^M$ is the received signal vector,\n$\\mathbf{x}\\in\\mathbb{C}^K$ is the vector of transmitted symbols,\n$\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$ is the known channel matrix,\nand $\\mathbf{n}\\in\\mathbb{C}^M$ is a noise vector with covariance\nmatrix $\\mathbf{S}\\in\\mathbb{C}^{M\\times M}$.\n\nThis function returns the real-valued equivalent representations of\n$\\mathbf{y}$, $\\mathbf{H}$, and $\\mathbf{S}$,\nwhich are used by a wide variety of MIMO detection algorithms (Section VII) [[YH2015]](https://nvlabs.github.io/sionna/api/mimo.html#yh2015).\nThese are obtained by applying [`complex2real_vector()`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.complex2real_vector) to $\\mathbf{y}$,\n[`complex2real_matrix()`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.complex2real_matrix) to $\\mathbf{H}$,\nand [`complex2real_covariance()`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.complex2real_covariance) to $\\mathbf{S}$.\nInput\n\n- **y** (*[,M], tf.complex*)  1+D tensor containing the received signals.\n- **h** (*[,M,K], tf.complex*)  2+D tensor containing the channel matrices.\n- **s** (*[,M,M], tf.complex*)  2+D tensor containing the noise covariance matrices.\n\n\nOutput\n\n- *[,2M], tf.complex.real_dtype*  1+D tensor containing the real-valued equivalent received signals.\n- *[,2M,2K], tf.complex.real_dtype*  2+D tensor containing the real-valued equivalent channel matrices.\n- *[,2M,2M], tf.complex.real_dtype*  2+D tensor containing the real-valued equivalent noise covariance matrices."
"### real2complex_channel\n\n`sionna.mimo.``real2complex_channel`(*`y`*, *`h`*, *`s`*)[`[source]`](../_modules/sionna/mimo/utils.html#real2complex_channel)\n\nTransforms a real-valued MIMO channel into its complex-valued equivalent.\n\nAssume the canonical MIMO channel model\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^M$ is the received signal vector,\n$\\mathbf{x}\\in\\mathbb{C}^K$ is the vector of transmitted symbols,\n$\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$ is the known channel matrix,\nand $\\mathbf{n}\\in\\mathbb{C}^M$ is a noise vector with covariance\nmatrix $\\mathbf{S}\\in\\mathbb{C}^{M\\times M}$.\n\nThis function transforms the real-valued equivalent representations of\n$\\mathbf{y}$, $\\mathbf{H}$, and $\\mathbf{S}$, as, e.g.,\nobtained with the function [`complex2real_channel()`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.complex2real_channel),\nback to their complex-valued equivalents (Section VII) [[YH2015]](https://nvlabs.github.io/sionna/api/mimo.html#yh2015).\nInput\n\n- **y** (*[,2M], tf.float*)  1+D tensor containing the real-valued received signals.\n- **h** (*[,2M,2K], tf.float*)  2+D tensor containing the real-valued channel matrices.\n- **s** (*[,2M,2M], tf.float*)  2+D tensor containing the real-valued noise covariance matrices.\n\n\nOutput\n\n- *[,M], tf.complex*  1+D tensor containing the complex-valued equivalent received signals.\n- *[,M,K], tf.complex*  2+D tensor containing the complex-valued equivalent channel matrices.\n- *[,M,M], tf.complex*  2+D tensor containing the complex-valued equivalent noise covariance matrices."
"### whiten_channel\n\n`sionna.mimo.``whiten_channel`(*`y`*, *`h`*, *`s`*, *`return_s``=``True`*)[`[source]`](../_modules/sionna/mimo/utils.html#whiten_channel)\n\nWhitens a canonical MIMO channel.\n\nAssume the canonical MIMO channel model\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^M(\\mathbb{R}^M)$ is the received signal vector,\n$\\mathbf{x}\\in\\mathbb{C}^K(\\mathbb{R}^K)$ is the vector of transmitted symbols,\n$\\mathbf{H}\\in\\mathbb{C}^{M\\times K}(\\mathbb{R}^{M\\times K})$ is the known channel matrix,\nand $\\mathbf{n}\\in\\mathbb{C}^M(\\mathbb{R}^M)$ is a noise vector with covariance\nmatrix $\\mathbf{S}\\in\\mathbb{C}^{M\\times M}(\\mathbb{R}^{M\\times M})$.\n\nThis function whitens this channel by multiplying $\\mathbf{y}$ and\n$\\mathbf{H}$ from the left by $\\mathbf{S}^{-\\frac{1}{2}}$.\nOptionally, the whitened noise covariance matrix $\\mathbf{I}_M$\ncan be returned.\nInput\n\n- **y** (*[,M], tf.float or tf.complex*)  1+D tensor containing the received signals.\n- **h** (*[,M,K], tf.float or tf.complex*)  2+D tensor containing the  channel matrices.\n- **s** (*[,M,M], tf.float or complex*)  2+D tensor containing the noise covariance matrices.\n- **return_s** (*bool*)  If <cite>True</cite>, the whitened covariance matrix is returned.\nDefaults to <cite>True</cite>.\n\n\nOutput\n\n- *[,M], tf.float or tf.complex*  1+D tensor containing the whitened received signals.\n- *[,M,K], tf.float or tf.complex*  2+D tensor containing the whitened channel matrices.\n- *[,M,M], tf.float or tf.complex*  2+D tensor containing the whitened noise covariance matrices.\nOnly returned if `return_s` is <cite>True</cite>.\n\n\nReferences:\nProperRV([1](https://nvlabs.github.io/sionna/api/mimo.html#id11),[2](https://nvlabs.github.io/sionna/api/mimo.html#id13))\n\n[Proper complex random variables](https://en.wikipedia.org/wiki/Complex_random_variable#Proper_complex_random_variables),\nWikipedia, accessed 11 September, 2022.\n\nCovProperRV([1](https://nvlabs.github.io/sionna/api/mimo.html#id12),[2](https://nvlabs.github.io/sionna/api/mimo.html#id14))\n\n[Covariance matrices of real and imaginary parts](https://en.wikipedia.org/wiki/Complex_random_vector#Covariance_matrices_of_real_and_imaginary_parts),\nWikipedia, accessed 11 September, 2022.\n\nYH2015([1](https://nvlabs.github.io/sionna/api/mimo.html#id15),[2](https://nvlabs.github.io/sionna/api/mimo.html#id16))\n\nS. Yang and L. Hanzo, [Fifty Years of MIMO Detection: The Road to Large-Scale MIMOs](https://ieeexplore.ieee.org/abstract/document/7244171),\nIEEE Communications Surveys & Tutorials, vol. 17, no. 4, pp. 1941-1988, 2015.\n\n[FT2015](https://nvlabs.github.io/sionna/api/mimo.html#id6)\n\nW. Fu and J. S. Thompson, [Performance analysis of K-best detection with adaptive modulation](https://ieeexplore.ieee.org/abstract/document/7454351), IEEE Int. Symp. Wirel. Commun. Sys. (ISWCS), 2015.\n\n[EP2014](https://nvlabs.github.io/sionna/api/mimo.html#id5)\n\nJ. Cspedes, P. M. Olmos, M. Snchez-Fernndez, and F. Perez-Cruz,\n[Expectation Propagation Detection for High-Order High-Dimensional MIMO Systems](https://ieeexplore.ieee.org/abstract/document/6841617),\nIEEE Trans. Commun., vol. 62, no. 8, pp. 2840-2849, Aug. 2014.\n\nCST2011([1](https://nvlabs.github.io/sionna/api/mimo.html#id7),[2](https://nvlabs.github.io/sionna/api/mimo.html#id8),[3](https://nvlabs.github.io/sionna/api/mimo.html#id9),[4](https://nvlabs.github.io/sionna/api/mimo.html#id10))\n\nC. Studer, S. Fateh, and D. Seethaler,\n[ASIC Implementation of Soft-Input Soft-Output MIMO Detection Using MMSE Parallel Interference Cancellation](https://ieeexplore.ieee.org/abstract/document/5779722),\nIEEE Journal of Solid-State Circuits, vol. 46, no. 7, pp. 17541765, July 2011."

"# End-to-end Learning with Autoencoders\n\nIn this notebook, you will learn how to implement an end-to-end communication system as an autoencoder [1]. The implemented system is shown in the figure below. An additive white Gaussian noise (AWGN) channel is considered. On the transmitter side, joint training of the constellation geometry and bit-labeling is performed, as in [2]. On the receiver side, a neural network-based demapper that computes log-likelihood ratios (LLRs) on the transmitted bits from the received samples is optimized. The\nconsidered autoencoder is benchmarked against a quadrature amplitude modulation (QAM) with Gray labeling and the optimal AWGN demapper.\n\n\nTwo algorithms for training the autoencoder are implemented in this notebook:\n\n- Conventional stochastic gradient descent (SGD) with backpropagation, which assumes a differentiable channel model and therefore optimizes the end-to-end system by backpropagating the gradients through the channel (see, e.g., [1]).\n- The training algorithm from [3], which does not assume a differentiable channel model, and which trains the end-to-end system by alternating between conventional training of the receiver and reinforcement learning (RL)-based training of the transmitter. Compared to [3], an additional step of fine-tuning of the receiver is performed after alternating training.\n\n\n**Note:** For an introduction to the implementation of differentiable communication systems and their optimization through SGD and backpropagation with Sionna, please refer to [the Part 2 of the Sionna tutorial for Beginners](https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part2.html)."
"## GPU Configuration and Imports\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\nfrom sionna.channel import AWGN\nfrom sionna.utils import BinarySource, ebnodb2no, log10, expand_to_rank, insert_dims\nfrom sionna.fec.ldpc.encoding import LDPC5GEncoder\nfrom sionna.fec.ldpc.decoding import LDPC5GDecoder\nfrom sionna.mapping import Mapper, Demapper, Constellation\nfrom sionna.utils import sim_ber\n```\n\n```python\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pickle\n```\n\n```python\n# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n# For more details, see https://www.tensorflow.org/guide/gpu\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Layer, Dense\n```"
"## Simulation Parameters\n\n\n```python\n###############################################\n# SNR range for evaluation and training [dB]\n###############################################\nebno_db_min = 4.0\nebno_db_max = 8.0\n###############################################\n# Modulation and coding configuration\n###############################################\nnum_bits_per_symbol = 6 # Baseline is 64-QAM\nmodulation_order = 2**num_bits_per_symbol\ncoderate = 0.5 # Coderate for the outer code\nn = 1500 # Codeword length [bit]. Must be a multiple of num_bits_per_symbol\nnum_symbols_per_codeword = n//num_bits_per_symbol # Number of modulated baseband symbols per codeword\nk = int(n*coderate) # Number of information bits per codeword\n###############################################\n# Training configuration\n###############################################\nnum_training_iterations_conventional = 10000 # Number of training iterations for conventional training\n# Number of training iterations with RL-based training for the alternating training phase and fine-tuning of the receiver phase\nnum_training_iterations_rl_alt = 7000\nnum_training_iterations_rl_finetuning = 3000\ntraining_batch_size = tf.constant(128, tf.int32) # Training batch size\nrl_perturbation_var = 0.01 # Variance of the perturbation used for RL-based training of the transmitter\nmodel_weights_path_conventional_training = \"awgn_autoencoder_weights_conventional_training\" # Filename to save the autoencoder weights once conventional training is done\nmodel_weights_path_rl_training = \"awgn_autoencoder_weights_rl_training\" # Filename to save the autoencoder weights once RL-based training is done\n###############################################\n# Evaluation configuration\n###############################################\nresults_filename = \"awgn_autoencoder_results\" # Location to save the results\n```"
"## Neural Demapper\n\nThe neural network-based demapper shown in the figure above is made of three dense layers with ReLU activation.\n\nThe input of the demapper consists of a received sample $y \\in \\mathbb{C}$ and the noise power spectral density $N_0$ in log-10 scale to handle different orders of magnitude for the SNR.\n\nAs the neural network can only process real-valued inputs, these values are fed as a 3-dimensional vector\n\n$$\n\\left[ \\mathcal{R}(y), \\mathcal{I}(y), \\log_{10}(N_0) \\right]\n$$\n\nwhere $\\mathcal{R}(y)$ and $\\mathcal{I}(y)$ refer to the real and imaginary component of $y$, respectively.\n\nThe output of the neural network-based demapper consists of LLRs on the `num_bits_per_symbol` bits mapped to a constellation point. Therefore, the last layer consists of `num_bits_per_symbol` units.\n\n**Note**: The neural network-based demapper processes the received samples $y$ forming a block individually. The [neural receiver notebook](https://nvlabs.github.io/sionna/examples/Neural_Receiver.html) provides an example of a more advanced neural network-based receiver that jointly processes a resource grid of received symbols.\n\n\n```python\nclass NeuralDemapper(Layer):\n    def __init__(self):\n        super().__init__()\n        self._dense_1 = Dense(128, 'relu')\n        self._dense_2 = Dense(128, 'relu')\n        self._dense_3 = Dense(num_bits_per_symbol, None) # The feature correspond to the LLRs for every bits carried by a symbol\n    def call(self, inputs):\n        y,no = inputs\n        # Using log10 scale helps with the performance\n        no_db = log10(no)\n        # Stacking the real and imaginary components of the complex received samples\n        # and the noise variance\n        no_db = tf.tile(no_db, [1, num_symbols_per_codeword]) # [batch size, num_symbols_per_codeword]\n        z = tf.stack([tf.math.real(y),\n                      tf.math.imag(y),\n                      no_db], axis=2) # [batch size, num_symbols_per_codeword, 3]\n        llr = self._dense_1(z)\n        llr = self._dense_2(llr)\n        llr = self._dense_3(llr) # [batch size, num_symbols_per_codeword, num_bits_per_symbol]\n        return llr\n```"
"## Trainable End-to-end System: Conventional Training\n\nThe following cell defines an end-to-end communication system that transmits bits modulated using a trainable constellation over an AWGN channel.\n\nThe receiver uses the previously defined neural network-based demapper to compute LLRs on the transmitted (coded) bits.\n\nAs in [1], the constellation and neural network-based demapper are jointly trained through SGD and backpropagation using the binary cross entropy (BCE) as loss function.\n\nTraining on the BCE is known to be equivalent to maximizing an achievable information rate [2].\n\nThe following model can be instantiated either for training (`training` `=` `True`) or evaluation (`training` `=` `False`).\n\nIn the former case, the BCE is returned and no outer code is used to reduce computational complexity and as it does not impact the training of the constellation or demapper.\n\nWhen setting `training` to `False`, an LDPC outer code from 5G NR is applied.\n\n\n```python\nclass E2ESystemConventionalTraining(Model):\n    def __init__(self, training):\n        super().__init__()\n        self._training = training\n        ################\n        ## Transmitter\n        ################\n        self._binary_source = BinarySource()\n        # To reduce the computational complexity of training, the outer code is not used when training,\n        # as it is not required\n        if not self._training:\n            # num_bits_per_symbol is required for the interleaver\n            self._encoder = LDPC5GEncoder(k, n, num_bits_per_symbol)\n        # Trainable constellation\n        constellation = Constellation(\"qam\", num_bits_per_symbol, trainable=True)\n        self.constellation = constellation\n        self._mapper = Mapper(constellation=constellation)\n        ################\n        ## Channel\n        ################\n        self._channel = AWGN()\n        ################\n        ## Receiver\n        ################\n        # We use the previously defined neural network for demapping\n        self._demapper = NeuralDemapper()\n        # To reduce the computational complexity of training, the outer code is not used when training,\n        # as it is not required\n        if not self._training:\n            self._decoder = LDPC5GDecoder(self._encoder, hard_out=True)\n        #################\n        # Loss function\n        #################\n        if self._training:\n            self._bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n    @tf.function(jit_compile=True)\n    def call(self, batch_size, ebno_db):\n        # If `ebno_db` is a scalar, a tensor with shape [batch size] is created as it is what is expected by some layers\n        if len(ebno_db.shape) == 0:\n            ebno_db = tf.fill([batch_size], ebno_db)\n        no = ebnodb2no(ebno_db, num_bits_per_symbol, coderate)\n        no = expand_to_rank(no, 2)\n        ################\n        ## Transmitter\n        ################\n        # Outer coding is only performed if not training\n        if self._training:\n            c = self._binary_source([batch_size, n])\n        else:\n            b = self._binary_source([batch_size, k])\n            c = self._encoder(b)\n        # Modulation\n        x = self._mapper(c) # x [batch size, num_symbols_per_codeword]\n        ################\n        ## Channel\n        ################\n        y = self._channel([x, no]) # [batch size, num_symbols_per_codeword]\n        ################\n        ## Receiver\n        ################\n        llr = self._demapper([y, no])\n        llr = tf.reshape(llr, [batch_size, n])\n        # If training, outer decoding is not performed and the BCE is returned\n        if self._training:\n            loss = self._bce(c, llr)\n            return loss\n        else:\n            # Outer decoding\n            b_hat = self._decoder(llr)\n            return b,b_hat # Ground truth and reconstructed information bits returned for BER/BLER computation\n```"
"A simple training loop is defined in the next cell, which performs `num_training_iterations_conventional` training iterations of SGD. Training is done over a range of SNR, by randomly sampling a batch of SNR values at each iteration.\n\n**Note:** For an introduction to the implementation of differentiable communication systems and their optimization through SGD and backpropagation with Sionna, please refer to [the Part 2 of the Sionna tutorial for Beginners](https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part2.html).\n\n\n```python\ndef conventional_training(model):\n    # Optimizer used to apply gradients\n    optimizer = tf.keras.optimizers.Adam()\n    for i in range(num_training_iterations_conventional):\n        # Sampling a batch of SNRs\n        ebno_db = tf.random.uniform(shape=[training_batch_size], minval=ebno_db_min, maxval=ebno_db_max)\n        # Forward pass\n        with tf.GradientTape() as tape:\n            loss = model(training_batch_size, ebno_db) # The model is assumed to return the BMD rate\n        # Computing and applying gradients\n        weights = model.trainable_weights\n        grads = tape.gradient(loss, weights)\n        optimizer.apply_gradients(zip(grads, weights))\n        # Printing periodically the progress\n        if i % 100 == 0:\n            print('Iteration {}/{}  BCE: {:.4f}'.format(i, num_training_iterations_conventional, loss.numpy()), end='\\r')\n```\n\n\nThe next cell defines a utility function for saving the weights using [pickle](https://docs.python.org/3/library/pickle.html).\n\n\n```python\ndef save_weights(model, model_weights_path):\n    weights = model.get_weights()\n    with open(model_weights_path, 'wb') as f:\n        pickle.dump(weights, f)\n```\n\n\nIn the next cell, an instance of the model defined previously is instantiated and trained.\n\n\n```python\n# Fix the seed for reproducible trainings\ntf.random.set_seed(1)\n# Instantiate and train the end-to-end system\nmodel = E2ESystemConventionalTraining(training=True)\nconventional_training(model)\n# Save weights\nsave_weights(model, model_weights_path_conventional_training)\n```\n\n\n```python\nIteration 9900/10000  BCE: 0.2820\n```"
"## Trainable End-to-end System: RL-based Training\n\nThe following cell defines the same end-to-end system as before, but stop the gradients after the channel to simulate a non-differentiable channel.\n\nTo jointly train the transmitter and receiver over a non-differentiable channel, we follow [3], which key idea is to alternate between:\n\n- Training of the receiver on the BCE using conventional backpropagation and SGD.\n- Training of the transmitter by applying (known) perturbations to the transmitter output to enable estimation of the gradient of the transmitter weights with respect to an approximation of the loss function.\n\n\nWhen `training` is set to `True`, both losses for training the receiver and the transmitter are returned.\n\n\n```python\nclass E2ESystemRLTraining(Model):\n    def __init__(self, training):\n        super().__init__()\n        self._training = training\n        ################\n        ## Transmitter\n        ################\n        self._binary_source = BinarySource()\n        # To reduce the computational complexity of training, the outer code is not used when training,\n        # as it is not required\n        if not self._training:\n            self._encoder = LDPC5GEncoder(k, n, num_bits_per_symbol)\n        # Trainable constellation\n        constellation = Constellation(\"qam\", num_bits_per_symbol, trainable=True)\n        self.constellation = constellation\n        self._mapper = Mapper(constellation=constellation)\n        ################\n        ## Channel\n        ################\n        self._channel = AWGN()\n        ################\n        ## Receiver\n        ################\n        # We use the previously defined neural network for demapping\n        self._demapper = NeuralDemapper()\n        # To reduce the computational complexity of training, the outer code is not used when training,\n        # as it is not required\n        if not self._training:\n            self._decoder = LDPC5GDecoder(self._encoder, hard_out=True)\n    @tf.function(jit_compile=True)\n    def call(self, batch_size, ebno_db, perturbation_variance=tf.constant(0.0, tf.float32)):\n        # If `ebno_db` is a scalar, a tensor with shape [batch size] is created as it is what is expected by some layers\n        if len(ebno_db.shape) == 0:\n            ebno_db = tf.fill([batch_size], ebno_db)\n        no = ebnodb2no(ebno_db, num_bits_per_symbol, coderate)\n        no = expand_to_rank(no, 2)\n        ################\n        ## Transmitter\n        ################\n        # Outer coding is only performed if not training\n        if self._training:\n            c = self._binary_source([batch_size, n])\n        else:\n            b = self._binary_source([batch_size, k])\n            c = self._encoder(b)\n        # Modulation\n        x = self._mapper(c) # x [batch size, num_symbols_per_codeword]\n        # Adding perturbation\n        # If ``perturbation_variance`` is 0, then the added perturbation is null\n        epsilon_r = tf.random.normal(tf.shape(x))*tf.sqrt(0.5*perturbation_variance)\n        epsilon_i = tf.random.normal(tf.shape(x))*tf.sqrt(0.5*perturbation_variance)\n        epsilon = tf.complex(epsilon_r, epsilon_i) # [batch size, num_symbols_per_codeword]\n        x_p = x + epsilon # [batch size, num_symbols_per_codeword]\n        ################\n        ## Channel\n        ################\n        y = self._channel([x_p, no]) # [batch size, num_symbols_per_codeword]\n        y = tf.stop_gradient(y) # Stop gradient here\n        ################\n        ## Receiver\n        ################\n        llr = self._demapper([y, no])\n        # If training, outer decoding is not performed\n        if self._training:\n            # Average BCE for each baseband symbol and each batch example\n            c = tf.reshape(c, [-1, num_symbols_per_codeword, num_bits_per_symbol])\n            bce = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(c, llr), axis=2) # Avergare over the bits mapped to a same baseband symbol\n            # The RX loss is the usual average BCE\n            rx_loss = tf.reduce_mean(bce)\n            # From the TX side, the BCE is seen as a feedback from the RX through which backpropagation is not possible\n            bce = tf.stop_gradient(bce) # [batch size, num_symbols_per_codeword]\n            x_p = tf.stop_gradient(x_p)\n            p = x_p-x # [batch size, num_symbols_per_codeword] Gradient is backpropagated through `x`\n            tx_loss = tf.square(tf.math.real(p)) + tf.square(tf.math.imag(p)) # [batch size, num_symbols_per_codeword]\n            tx_loss = -bce*tx_loss/rl_perturbation_var # [batch size, num_symbols_per_codeword]\n            tx_loss = tf.reduce_mean(tx_loss)\n            return tx_loss, rx_loss\n        else:\n            llr = tf.reshape(llr, [-1, n]) # Reshape as expected by the outer decoder\n            b_hat = self._decoder(llr)\n            return b,b_hat\n```"
"The next cell implements the training algorithm from [3], which alternates between conventional training of the neural network-based receiver, and RL-based training of the transmitter.\n\n\n```python\ndef rl_based_training(model):\n    # Optimizers used to apply gradients\n    optimizer_tx = tf.keras.optimizers.Adam() # For training the transmitter\n    optimizer_rx = tf.keras.optimizers.Adam() # For training the receiver\n    # Function that implements one transmitter training iteration using RL.\n    def train_tx():\n        # Sampling a batch of SNRs\n        ebno_db = tf.random.uniform(shape=[training_batch_size], minval=ebno_db_min, maxval=ebno_db_max)\n        # Forward pass\n        with tf.GradientTape() as tape:\n            # Keep only the TX loss\n            tx_loss, _ = model(training_batch_size, ebno_db,\n                               tf.constant(rl_perturbation_var, tf.float32)) # Perturbation are added to enable RL exploration\n        ## Computing and applying gradients\n        weights = model.trainable_weights\n        grads = tape.gradient(tx_loss, weights)\n        optimizer_tx.apply_gradients(zip(grads, weights))\n    # Function that implements one receiver training iteration\n    def train_rx():\n        # Sampling a batch of SNRs\n        ebno_db = tf.random.uniform(shape=[training_batch_size], minval=ebno_db_min, maxval=ebno_db_max)\n        # Forward pass\n        with tf.GradientTape() as tape:\n            # Keep only the RX loss\n            _, rx_loss = model(training_batch_size, ebno_db) # No perturbation is added\n        ## Computing and applying gradients\n        weights = model.trainable_weights\n        grads = tape.gradient(rx_loss, weights)\n        optimizer_rx.apply_gradients(zip(grads, weights))\n        # The RX loss is returned to print the progress\n        return rx_loss\n    # Training loop.\n    for i in range(num_training_iterations_rl_alt):\n        # 10 steps of receiver training are performed to keep it ahead of the transmitter\n        # as it is used for computing the losses when training the transmitter\n        for _ in range(10):\n            rx_loss = train_rx()\n        # One step of transmitter training\n        train_tx()\n        # Printing periodically the progress\n        if i % 100 == 0:\n            print('Iteration {}/{}  BCE {:.4f}'.format(i, num_training_iterations_rl_alt, rx_loss.numpy()), end='\\r')\n    print() # Line break\n    # Once alternating training is done, the receiver is fine-tuned.\n    print('Receiver fine-tuning... ')\n    for i in range(num_training_iterations_rl_finetuning):\n        rx_loss = train_rx()\n        if i % 100 == 0:\n            print('Iteration {}/{}  BCE {:.4f}'.format(i, num_training_iterations_rl_finetuning, rx_loss.numpy()), end='\\r')\n```"
"In the next cell, an instance of the model defined previously is instantiated and trained.\n\n\n```python\n# Fix the seed for reproducible trainings\ntf.random.set_seed(1)\n# Instantiate and train the end-to-end system\nmodel = E2ESystemRLTraining(training=True)\nrl_based_training(model)\n# Save weights\nsave_weights(model, model_weights_path_rl_training)\n```\n\n\n```python\nIteration 6900/7000  BCE 0.2802\nReceiver fine-tuning...\nIteration 2900/3000  BCE 0.2777\n```"
"## Evaluation\n\nThe following cell implements a baseline which uses QAM with Gray labeling and conventional demapping for AWGN channel.\n\n\n```python\nclass Baseline(Model):\n    def __init__(self):\n        super().__init__()\n        ################\n        ## Transmitter\n        ################\n        self._binary_source = BinarySource()\n        self._encoder = LDPC5GEncoder(k, n, num_bits_per_symbol)\n        constellation = Constellation(\"qam\", num_bits_per_symbol, trainable=False)\n        self.constellation = constellation\n        self._mapper = Mapper(constellation=constellation)\n        ################\n        ## Channel\n        ################\n        self._channel = AWGN()\n        ################\n        ## Receiver\n        ################\n        self._demapper = Demapper(\"app\", constellation=constellation)\n        self._decoder = LDPC5GDecoder(self._encoder, hard_out=True)\n    @tf.function(jit_compile=True)\n    def call(self, batch_size, ebno_db, perturbation_variance=tf.constant(0.0, tf.float32)):\n        # If `ebno_db` is a scalar, a tensor with shape [batch size] is created as it is what is expected by some layers\n        if len(ebno_db.shape) == 0:\n            ebno_db = tf.fill([batch_size], ebno_db)\n        no = ebnodb2no(ebno_db, num_bits_per_symbol, coderate)\n        no = expand_to_rank(no, 2)\n        ################\n        ## Transmitter\n        ################\n        b = self._binary_source([batch_size, k])\n        c = self._encoder(b)\n        # Modulation\n        x = self._mapper(c) # x [batch size, num_symbols_per_codeword]\n        ################\n        ## Channel\n        ################\n        y = self._channel([x, no]) # [batch size, num_symbols_per_codeword]\n        ################\n        ## Receiver\n        ################\n        llr = self._demapper([y, no])\n        # Outer decoding\n        b_hat = self._decoder(llr)\n        return b,b_hat # Ground truth and reconstructed information bits returned for BER/BLER computation\n```\n\n```python\n# Range of SNRs over which the systems are evaluated\nebno_dbs = np.arange(ebno_db_min, # Min SNR for evaluation\n                     ebno_db_max, # Max SNR for evaluation\n                     0.5) # Step\n```"
"```python\n# Utility function to load and set weights of a model\ndef load_weights(model, model_weights_path):\n    model(1, tf.constant(10.0, tf.float32))\n    with open(model_weights_path, 'rb') as f:\n        weights = pickle.load(f)\n    model.set_weights(weights)\n```\n\n\nThe next cell evaluate the baseline and the two autoencoder-based communication systems, trained with different method. The results are stored in the dictionary `BLER`.\n\n\n```python\n# Dictionnary storing the results\nBLER = {}\nmodel_baseline = Baseline()\n_,bler = sim_ber(model_baseline, ebno_dbs, batch_size=128, num_target_block_errors=1000, max_mc_iter=1000)\nBLER['baseline'] = bler.numpy()\nmodel_conventional = E2ESystemConventionalTraining(training=False)\nload_weights(model_conventional, model_weights_path_conventional_training)\n_,bler = sim_ber(model_conventional, ebno_dbs, batch_size=128, num_target_block_errors=1000, max_mc_iter=1000)\nBLER['autoencoder-conv'] = bler.numpy()\nmodel_rl = E2ESystemRLTraining(training=False)\nload_weights(model_rl, model_weights_path_rl_training)\n_,bler = sim_ber(model_rl, ebno_dbs, batch_size=128, num_target_block_errors=1000, max_mc_iter=1000)\nBLER['autoencoder-rl'] = bler.numpy()\nwith open(results_filename, 'wb') as f:\n    pickle.dump((ebno_dbs, BLER), f)\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      4.0 | 1.2364e-01 | 1.0000e+00 |       94957 |      768000 |         1024 |        1024 |         3.2 |reached target block errors\n      4.5 | 9.7535e-02 | 9.9805e-01 |       74907 |      768000 |         1022 |        1024 |         0.1 |reached target block errors\n      5.0 | 5.7527e-02 | 9.0712e-01 |       49703 |      864000 |         1045 |        1152 |         0.1 |reached target block errors\n      5.5 | 1.9050e-02 | 5.1562e-01 |       29261 |     1536000 |         1056 |        2048 |         0.2 |reached target block errors\n      6.0 | 2.3017e-03 | 1.0621e-01 |       16351 |     7104000 |         1006 |        9472 |         0.7 |reached target block errors\n      6.5 | 1.2964e-04 | 9.6213e-03 |       10106 |    77952000 |         1000 |      103936 |         7.6 |reached target block errors\n      7.0 | 7.8333e-06 | 7.2656e-04 |         752 |    96000000 |           93 |      128000 |         9.3 |reached max iter\n      7.5 | 1.4583e-07 | 3.1250e-05 |          14 |    96000000 |            4 |      128000 |         9.4 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      4.0 | 1.0696e-01 | 9.9707e-01 |       82149 |      768000 |         1021 |        1024 |         0.9 |reached target block errors\n      4.5 | 6.9547e-02 | 9.3142e-01 |       60089 |      864000 |         1073 |        1152 |         0.1 |reached target block errors\n      5.0 | 2.3789e-02 | 5.4010e-01 |       34256 |     1440000 |         1037 |        1920 |         0.1 |reached target block errors\n      5.5 | 4.2181e-03 | 1.5472e-01 |       20652 |     4896000 |         1010 |        6528 |         0.5 |reached target block errors\n      6.0 | 2.4640e-04 | 1.6292e-02 |       11354 |    46080000 |         1001 |       61440 |         4.3 |reached target block errors\n      6.5 | 1.2156e-05 | 9.3750e-04 |        1167 |    96000000 |          120 |      128000 |         9.1 |reached max iter\n      7.0 | 1.1667e-06 | 7.0312e-05 |         112 |    96000000 |            9 |      128000 |         9.1 |reached max iter\n      7.5 | 8.7500e-07 | 3.9063e-05 |          84 |    96000000 |            5 |      128000 |         9.1 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      4.0 | 1.0489e-01 | 9.9805e-01 |       80553 |      768000 |         1022 |        1024 |         1.1 |reached target block errors\n      4.5 | 6.4516e-02 | 9.2101e-01 |       55742 |      864000 |         1061 |        1152 |         0.1 |reached target block errors\n      5.0 | 2.3047e-02 | 5.2812e-01 |       33187 |     1440000 |         1014 |        1920 |         0.1 |reached target block errors\n      5.5 | 3.7078e-03 | 1.4318e-01 |       19577 |     5280000 |         1008 |        7040 |         0.5 |reached target block errors\n      6.0 | 2.2505e-04 | 1.4167e-02 |       11926 |    52992000 |         1001 |       70656 |         5.0 |reached target block errors\n      6.5 | 8.1771e-06 | 8.5938e-04 |         785 |    96000000 |          110 |      128000 |         9.2 |reached max iter\n      7.0 | 7.0833e-07 | 5.4688e-05 |          68 |    96000000 |            7 |      128000 |         9.1 |reached max iter\n      7.5 | 1.1458e-07 | 1.5625e-05 |          11 |    96000000 |            2 |      128000 |         9.1 |reached max iter\n```"
"```python\nplt.figure(figsize=(10,8))\n# Baseline - Perfect CSI\nplt.semilogy(ebno_dbs, BLER['baseline'], 'o-', c=f'C0', label=f'Baseline')\n# Autoencoder - conventional training\nplt.semilogy(ebno_dbs, BLER['autoencoder-conv'], 'x-.', c=f'C1', label=f'Autoencoder - conventional training')\n# Autoencoder - RL-based training\nplt.semilogy(ebno_dbs, BLER['autoencoder-rl'], 'o-.', c=f'C2', label=f'Autoencoder - RL-based training')\nplt.xlabel(r\"$E_b/N_0$ (dB)\")\nplt.ylabel(\"BLER\")\nplt.grid(which=\"both\")\nplt.ylim((1e-4, 1.0))\nplt.legend()\nplt.tight_layout()\n```"
"## Visualizing the Learned Constellations\n\n\n```python\nmodel_conventional = E2ESystemConventionalTraining(training=True)\nload_weights(model_conventional, model_weights_path_conventional_training)\nfig = model_conventional.constellation.show()\nfig.suptitle('Conventional training');\n```\n\n\n```python\nmodel_rl = E2ESystemRLTraining(training=False)\nload_weights(model_rl, model_weights_path_rl_training)\nfig = model_rl.constellation.show()\nfig.suptitle('RL-based training');\n```"
"## References\n\n[1] T. OShea and J. Hoydis, An Introduction to Deep Learning for the Physical Layer, in IEEE Transactions on Cognitive Communications and Networking, vol.3, no. 4, pp.563-575, Dec.2017, doi: 10.1109/TCCN.2017.2758370.\n\n[2] S. Cammerer, F. Ait Aoudia, S. Drner, M. Stark, J. Hoydis and S. ten Brink, Trainable Communication Systems: Concepts and Prototype, in IEEE Transactions on Communications, vol.68, no. 9, pp.5489-5503, Sept.2020, doi: 10.1109/TCOMM.2020.3002915.\n\n[3] F. Ait Aoudia and J. Hoydis, Model-Free Training of End-to-End Communication Systems, in IEEE Journal on Selected Areas in Communications, vol.37, no. 11, pp.2503-2516, Nov.2019, doi: 10.1109/JSAC.2019.2933891.\n[3] F. Ait Aoudia and J. Hoydis, Model-Free Training of End-to-End Communication Systems, in IEEE Journal on Selected Areas in Communications, vol.37, no. 11, pp.2503-2516, Nov.2019, doi: 10.1109/JSAC.2019.2933891.\n[3] F. Ait Aoudia and J. Hoydis, Model-Free Training of End-to-End Communication Systems, in IEEE Journal on Selected Areas in Communications, vol.37, no. 11, pp.2503-2516, Nov.2019, doi: 10.1109/JSAC.2019.2933891."

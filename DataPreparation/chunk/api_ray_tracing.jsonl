"# Ray Tracing\n\nThis module provides a differentiable ray tracer for radio propagation modeling.\nThe best way to get started is by having a look at the [Sionna Ray Tracing Tutorial](../examples/Sionna_Ray_Tracing_Introduction.html).\nThe [Primer on Electromagnetics](../em_primer.html) provides useful background knowledge and various definitions that are used throughout the API documentation.\n\nThe most important component of the ray tracer is the [`Scene`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene).\nIt has methods for the computation of propagation [`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths) ([`compute_paths()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_paths)) and [`CoverageMap`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.CoverageMap) ([`coverage_map()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.coverage_map)).\nSionna has several integrated [Example Scenes](https://nvlabs.github.io/sionna/api/rt.html#example-scenes) that you can use for your own experiments. In this [video](https://youtu.be/7xHLDxUaQ7c), we explain how you can create your own scenes using [OpenStreetMap](https://www.openstreetmap.org) and [Blender](https://www.blender.org).\nYou can preview a scene within a Jupyter notebook ([`preview()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.preview)) or render it to a file from the viewpoint of a camera ([`render()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.render) or [`render_to_file()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.render_to_file)).\n\nPropagation [`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths) can be transformed into time-varying channel impulse responses (CIRs) via [`cir()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths.cir). The CIRs can then be used for link-level simulations in Sionna via the functions [`cir_to_time_channel()`](channel.wireless.html#sionna.channel.cir_to_time_channel) or [`cir_to_ofdm_channel()`](channel.wireless.html#sionna.channel.cir_to_ofdm_channel). Alternatively, you can create a dataset of CIRs that can be used by a channel model with the help of [`CIRDataset`](channel.wireless.html#sionna.channel.CIRDataset).\n\nThe paper [Sionna RT: Differentiable Ray Tracing for Radio Propagation Modeling](https://nvlabs.github.io/sionna/made_with_sionna.html#sionna-rt-differentiable-ray-tracing-for-radio-propagation-modeling) shows how differentiable ray tracing can be used for various optimization tasks. The related [notebooks](https://nvlabs.github.io/sionna/made_with_sionna.html#sionna-rt-differentiable-ray-tracing-for-radio-propagation-modeling) can be a good starting point for your own experiments."
"## Scene\n\nThe scene contains everything that is needed for radio propagation simulation\nand rendering.\n\nA scene is a collection of multiple instances of [`SceneObject`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.SceneObject) which define\nthe geometry and materials of the objects in the scene.\nThe scene also includes transmitters ([`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter)) and receivers ([`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver))\nfor which propagation [`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths) or  channel impulse responses (CIRs) can be computed,\nas well as cameras ([`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera)) for rendering.\n\nA scene is loaded from a file using the [`load_scene()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.load_scene) function.\nSionna contains a few [Example Scenes](https://nvlabs.github.io/sionna/api/rt.html#example-scenes).\nThe following code snippet shows how to load one of them and\nrender it through the lens of the preconfigured scene [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) scene-cam-0:\n```python\nscene = load_scene(sionna.rt.scene.munich)\nscene.render(camera=\"scene-cam-0\")\n```\n\n\nYou can preview a scene in an interactive 3D viewer within a Jupyter notebook using [`preview()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.preview):\n```python\nscene.preview()\n```\n\n\nIn the code snippet above, the [`load_scene()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.load_scene) function returns the [`Scene`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene) instance which can be used\nto access scene objects, transmitters, receivers, cameras, and to set the\nfrequency for radio wave propagation simulation. Note that you can load only a single scene at a time.\n\nIt is important to understand that all transmitters in a scene share the same [`AntennaArray`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.AntennaArray) which can be set\nthrough the scene property [`tx_array`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.tx_array). The same holds for all receivers whose [`AntennaArray`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.AntennaArray)\ncan be set through [`rx_array`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.rx_array). However, each transmitter and receiver can have a different position and orientation.\n\nThe code snippet below shows how to configure the [`tx_array`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.tx_array) and [`rx_array`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.rx_array) and\nto instantiate a transmitter and receiver."
"```python\n# Configure antenna array for all transmitters\nscene.tx_array = PlanarArray(num_rows=8,\n                          num_cols=2,\n                          vertical_spacing=0.7,\n                          horizontal_spacing=0.5,\n                          pattern=\"tr38901\",\n                          polarization=\"VH\")\n# Configure antenna array for all receivers\nscene.rx_array = PlanarArray(num_rows=1,\n                          num_cols=1,\n                          vertical_spacing=0.5,\n                          horizontal_spacing=0.5,\n                          pattern=\"dipole\",\n                          polarization=\"cross\")\n# Create transmitter\ntx = Transmitter(name=\"tx\",\n              position=[8.5,21,27],\n              orientation=[0,0,0])\nscene.add(tx)\n# Create a receiver\nrx = Receiver(name=\"rx\",\n           position=[45,90,1.5],\n           orientation=[0,0,0])\nscene.add(rx)\n# TX points towards RX\ntx.look_at(rx)\nprint(scene.transmitters)\nprint(scene.receivers)\n```\n\n```python\n{'tx': <sionna.rt.transmitter.Transmitter object at 0x7f83d0555d30>}\n{'rx': <sionna.rt.receiver.Receiver object at 0x7f81f00ef0a0>}\n```\n\n\nOnce you have loaded a scene and configured transmitters and receivers, you can use the scene method\n[`compute_paths()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_paths) to compute propagation paths:\n```python\npaths = scene.compute_paths()\n```\n\n\nThe output of this function is an instance of [`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths) and can be used to compute channel\nimpulse responses (CIRs) using the method [`cir()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths.cir).\nYou can visualize the paths within a scene by one of the following commands:\n```python\nscene.preview(paths=paths) # Open preview showing paths\nscene.render(camera=\"preview\", paths=paths) # Render scene with paths from preview camera\nscene.render_to_file(camera=\"preview\",\n                     filename=\"scene.png\",\n                     paths=paths) # Render scene with paths to file\n```\n\n\nNote that the calls to the render functions in the code above use the preview camera which is configured through\n[`preview()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.preview). You can use any other [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) that you create here as well.\n\nThe function [`coverage_map()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.coverage_map) computes a [`CoverageMap`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.CoverageMap) for every transmitter in a scene:"
"```python\ncm = scene.coverage_map(cm_cell_size=[1.,1.], # Configure size of each cell\n                        num_samples=1e7) # Number of rays to trace\n```\n\n\nCoverage maps can be visualized in the same way as propagation paths:\n```python\nscene.preview(coverage_map=cm) # Open preview showing coverage map\nscene.render(camera=\"preview\", coverage_map=cm) # Render scene with coverage map\nscene.render_to_file(camera=\"preview\",\n                     filename=\"scene.png\",\n                     coverage_map=cm) # Render scene with coverage map to file\n```"
"### Scene\n\n`class` `sionna.rt.``Scene`[`[source]`](../_modules/sionna/rt/scene.html#Scene)\n\nThe scene contains everything that is needed for radio propagation simulation\nand rendering.\n\nA scene is a collection of multiple instances of [`SceneObject`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.SceneObject) which define\nthe geometry and materials of the objects in the scene.\nThe scene also includes transmitters ([`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter)) and receivers ([`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver))\nfor which propagation [`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths), channel impulse responses (CIRs) or coverage maps ([`CoverageMap`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.CoverageMap)) can be computed,\nas well as cameras ([`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera)) for rendering.\n\nThe only way to instantiate a scene is by calling `load_scene()`.\nNote that only a single scene can be loaded at a time.\n\nExample scenes can be loaded as follows:\n```python\nscene = load_scene(sionna.rt.scene.munich)\nscene.preview()\n```\n\n\n`add`(*`item`*)[`[source]`](../_modules/sionna/rt/scene.html#Scene.add)\n\nAdds a transmitter, receiver, radio material, or camera to the scene.\n\nIf a different item with the same name as `item` is already part of the scene,\nan error is raised.\nInput\n\n**item** ([`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter) | [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver) | [`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial) | [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera))  Item to add to the scene\n\n\n`property` `cameras`\n\nDictionary\nof cameras in the scene\nType\n\n<cite>dict</cite> (read-only), { name, [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera)}\n\n\n`property` `center`\n\nGet the center of the scene\nType\n\n[3], tf.float\n\n\n`property` `dtype`\n\nDatatype used in tensors\nType\n\n<cite>tf.complex64 | tf.complex128</cite>\n\n\n`property` `frequency`\n\nGet/set the carrier frequency [Hz]\n\nSetting the frequency updates the parameters of frequency-dependent\nradio materials. Defaults to 3.5e9.\nType\n\nfloat\n\n\n`get`(*`name`*)[`[source]`](../_modules/sionna/rt/scene.html#Scene.get)\n\nReturns a scene object, transmitter, receiver, camera, or radio material\nInput\n\n**name** (*str*)  Name of the item to retrieve\n\nOutput\n\n**item** ([`SceneObject`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.SceneObject) | [`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial) | [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter) | [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver) | [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) | <cite>None</cite>)  Retrieved item. Returns <cite>None</cite> if no corresponding item was found in the scene.\n\n\n`property` `objects`\n\nDictionary\nof scene objects\nType\n\n<cite>dict</cite> (read-only), { name, [`SceneObject`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.SceneObject)}\n\n\n`property` `radio_material_callable`\n\nGet/set a callable that computes the radio material properties at the\npoints of intersection between the rays and the scene objects.\n\nIf set, then the [`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial) of the objects are\nnot used and the callable is invoked instead to obtain the\nelectromagnetic properties required to simulate the propagation of radio\nwaves.\n\nIf not set, i.e., <cite>None</cite> (default), then the\n[`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial) of objects are used to simulate the\npropagation of radio waves in the scene.\n\nThis callable is invoked on batches of intersection points.\nIt takes as input the following tensors:\n\n- `object_id` (<cite>[batch_dims]</cite>, <cite>int</cite>) : Integers uniquely identifying the intersected objects\n- `points` (<cite>[batch_dims, 3]</cite>, <cite>float</cite>) : Positions of the intersection points\n\n\nThe callable must output a tuple/list of the following tensors:\n\n- `complex_relative_permittivity` (<cite>[batch_dims]</cite>, <cite>complex</cite>) : Complex relative permittivities $\\eta$ [(9)](../em_primer.html#equation-eta)\n- `scattering_coefficient` (<cite>[batch_dims]</cite>, <cite>float</cite>) : Scattering coefficients $S\\in[0,1]$ [(37)](../em_primer.html#equation-scattering-coefficient)\n- `xpd_coefficient` (<cite>[batch_dims]</cite>, <cite>float</cite>) : Cross-polarization discrimination coefficients $K_x\\in[0,1]$ [(39)](../em_primer.html#equation-xpd). Only relevant for the scattered field.\n\n\n**Note:** The number of batch dimensions is not necessarily equal to one.\n\n\n`property` `radio_materials`\n\nDictionary\nof radio materials\nType\n\n<cite>dict</cite> (read-only), { name, [`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial)}\n\n\n`property` `receivers`\n\nDictionary\nof receivers in the scene\nType\n\n<cite>dict</cite> (read-only), { name, [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver)}\n\n\n`remove`(*`name`*)[`[source]`](../_modules/sionna/rt/scene.html#Scene.remove)\n\nRemoves a transmitter, receiver, camera, or radio material from the\nscene.\n\nIn the case of a radio material, it must not be used by any object of\nthe scene.\nInput\n\n**name** (*str*)  Name of the item to remove\n\n\n`property` `rx_array`\n\nGet/set the antenna array used by\nall receivers in the scene. Defaults to <cite>None</cite>.\nType\n\n[`AntennaArray`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.AntennaArray)\n\n\n`property` `scattering_pattern_callable`\n\nGet/set a callable that computes the scattering pattern at the\npoints of intersection between the rays and the scene objects.\n\nIf set, then the [`scattering_pattern`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial.scattering_pattern) of\nthe radio materials of the objects are not used and the callable is invoked\ninstead to evaluate the scattering pattern required to simulate the\npropagation of diffusely reflected radio waves.\n\nIf not set, i.e., <cite>None</cite> (default), then the\n[`scattering_pattern`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial.scattering_pattern) of the objects\nradio materials are used to simulate the propagation of diffusely\nreflected radio waves in the scene.\n\nThis callable is invoked on batches of intersection points.\nIt takes as input the following tensors:\n\n- `object_id` (<cite>[batch_dims]</cite>, <cite>int</cite>) : Integers uniquely identifying the intersected objects\n- `points` (<cite>[batch_dims, 3]</cite>, <cite>float</cite>) : Positions of the intersection points\n- `k_i` (<cite>[batch_dims, 3]</cite>, <cite>float</cite>) : Unitary vector corresponding to the direction of incidence in the scenes global coordinate system\n- `k_s` (<cite>[batch_dims, 3]</cite>, <cite>float</cite>) : Unitary vector corresponding to the direction of the diffuse reflection in the scenes global coordinate system\n- `n` (<cite>[batch_dims, 3]</cite>, <cite>float</cite>) : Unitary vector corresponding to the normal to the surface at the intersection point\n\n\nThe callable must output the following tensor:\n\n- `f_s` (<cite>[batch_dims]</cite>, <cite>float</cite>) : The scattering pattern evaluated for the previous inputs\n\n\n**Note:** The number of batch dimensions is not necessarily equal to one.\n\n\n`property` `size`\n\nGet the size of the scene, i.e., the size of the\naxis-aligned minimum bounding box for the scene\nType\n\n[3], tf.float\n\n\n`property` `synthetic_array`\n\nGet/set if the antenna arrays are applied synthetically.\nDefaults to <cite>True</cite>.\nType\n\nbool\n\n\n`property` `transmitters`\n\nDictionary\nof transmitters in the scene\nType\n\n<cite>dict</cite> (read-only), { name, [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter)}\n\n\n`property` `tx_array`\n\nGet/set the antenna array used by\nall transmitters in the scene. Defaults to <cite>None</cite>.\nType\n\n[`AntennaArray`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.AntennaArray)\n\n\n`property` `wavelength`\n\nWavelength [m]\nType\n\nfloat (read-only)"
"### compute_paths\n\n`sionna.rt.Scene.``compute_paths`(*`self`*, *`max_depth``=``3`*, *`method``=``'fibonacci'`*, *`num_samples``=``1000000`*, *`los``=``True`*, *`reflection``=``True`*, *`diffraction``=``False`*, *`scattering``=``False`*, *`scat_keep_prob``=``0.001`*, *`edge_diffraction``=``False`*, *`check_scene``=``True`*, *`scat_random_phases``=``True`*, *`testing``=``False`*)\n\nComputes propagation paths\n\nThis function computes propagation paths between the antennas of\nall transmitters and receivers in the current scene.\nFor each propagation path $i$, the corresponding channel coefficient\n$a_i$ and delay $\\tau_i$, as well as the\nangles of departure $(\\theta_{\\text{T},i}, \\varphi_{\\text{T},i})$\nand arrival $(\\theta_{\\text{R},i}, \\varphi_{\\text{R},i})$ are returned.\nFor more detail, see [(26)](../em_primer.html#equation-h-final).\nDifferent propagation phenomena, such as line-of-sight, reflection, diffraction,\nand diffuse scattering can be individually enabled/disabled.\n\nIf the scene is configured to use synthetic arrays\n([`synthetic_array`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.synthetic_array) is <cite>True</cite>), transmitters and receivers\nare modelled as if they had a single antenna located at their\n[`position`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter.position). The channel responses for each\nindividual antenna of the arrays are then computed synthetically by applying\nappropriate phase shifts. This reduces the complexity significantly\nfor large arrays. Time evolution of the channel coefficients can be simulated with\nthe help of the function [`apply_doppler()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths.apply_doppler) of the returned\n[`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths) object.\n\nThe path computation consists of two main steps as shown in the below figure.\n\nFor a configured [`Scene`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene), the function first traces geometric propagation paths\nusing [`trace_paths()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.trace_paths). This step is independent of the\n[`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial) of the scene objects as well as the transmitters and receivers\nantenna [`patterns`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Antenna.patterns) and  [`orientation`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter.orientation),\nbut depends on the selected propagation\nphenomena, such as reflection, scattering, and diffraction. The traced paths\nare then converted to EM fields by the function [`compute_fields()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_fields).\nThe resulting [`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths) object can be used to compute channel\nimpulse responses via [`cir()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths.cir). The advantage of separating path tracing\nand field computation is that one can study the impact of different radio materials\nby executing [`compute_fields()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_fields) multiple times without\nre-tracing the propagation paths. This can for example speed-up the calibration of scene parameters\nby several orders of magnitude.\n xample"
"```python\nimport sionna\nfrom sionna.rt import load_scene, Camera, Transmitter, Receiver, PlanarArray\n# Load example scene\nscene = load_scene(sionna.rt.scene.munich)\n# Configure antenna array for all transmitters\nscene.tx_array = PlanarArray(num_rows=8,\n                          num_cols=2,\n                          vertical_spacing=0.7,\n                          horizontal_spacing=0.5,\n                          pattern=\"tr38901\",\n                          polarization=\"VH\")\n# Configure antenna array for all receivers\nscene.rx_array = PlanarArray(num_rows=1,\n                          num_cols=1,\n                          vertical_spacing=0.5,\n                          horizontal_spacing=0.5,\n                          pattern=\"dipole\",\n                          polarization=\"cross\")\n# Create transmitter\ntx = Transmitter(name=\"tx\",\n              position=[8.5,21,27],\n              orientation=[0,0,0])\nscene.add(tx)\n# Create a receiver\nrx = Receiver(name=\"rx\",\n           position=[45,90,1.5],\n           orientation=[0,0,0])\nscene.add(rx)\n# TX points towards RX\ntx.look_at(rx)\n# Compute paths\npaths = scene.compute_paths()\n# Open preview showing paths\nscene.preview(paths=paths, resolution=[1000,600])\n```\n\n\nInput\n\n- **max_depth** (*int*)  Maximum depth (i.e., number of bounces) allowed for tracing the\npaths. Defaults to 3.\n- **method** (*str (exhaustive|fibonacci)*)  Ray tracing method to be used.\nThe exhaustive method tests all possible combinations of primitives.\nThis method is not compatible with scattering.\nThe fibonacci method uses a shoot-and-bounce approach to find\ncandidate chains of primitives. Initial ray directions are chosen\naccording to a Fibonacci lattice on the unit sphere. This method can be\napplied to very large scenes. However, there is no guarantee that\nall possible paths are found.\nDefaults to fibonacci.\n- **num_samples** (*int*)  Number of rays to trace in order to generate candidates with\nthe fibonacci method.\nThis number is split equally among the different transmitters\n(when using synthetic arrays) or transmit antennas (when not using\nsynthetic arrays).\nThis parameter is ignored when using the exhaustive method.\nTracing more rays can lead to better precision\nat the cost of increased memory requirements.\nDefaults to 1e6.\n- **los** (*bool*)  If set to <cite>True</cite>, then the LoS paths are computed.\nDefaults to <cite>True</cite>.\n- **reflection** (*bool*)  If set to <cite>True</cite>, then the reflected paths are computed.\nDefaults to <cite>True</cite>.\n- **diffraction** (*bool*)  If set to <cite>True</cite>, then the diffracted paths are computed.\nDefaults to <cite>False</cite>.\n- **scattering** (*bool*)  if set to <cite>True</cite>, then the scattered paths are computed.\nOnly works with the Fibonacci method.\nDefaults to <cite>False</cite>.\n- **scat_keep_prob** (*float*)  Probability with which a scattered path is kept.\nThis is helpful to reduce the number of computed scattered\npaths, which might be prohibitively high in some scenes.\nMust be in the range (0,1). Defaults to 0.001.\n- **edge_diffraction** (*bool*)  If set to <cite>False</cite>, only diffraction on wedges, i.e., edges that\nconnect two primitives, is considered.\nDefaults to <cite>False</cite>.\n- **check_scene** (*bool*)  If set to <cite>True</cite>, checks that the scene is well configured before\ncomputing the paths. This can add a significant overhead.\nDefaults to <cite>True</cite>.\n- **scat_random_phases** (*bool*)  If set to <cite>True</cite> and if scattering is enabled, random uniform phase\nshifts are added to the scattered paths.\nDefaults to <cite>True</cite>.\n- **testing** (*bool*)  If set to <cite>True</cite>, then additional data is returned for testing.\nDefaults to <cite>False</cite>.\n\n\nOutput\n\npaths : [`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths)  Simulated paths"
"### trace_paths\n\n`sionna.rt.Scene.``trace_paths`(*`self`*, *`max_depth``=``3`*, *`method``=``'fibonacci'`*, *`num_samples``=``1000000`*, *`los``=``True`*, *`reflection``=``True`*, *`diffraction``=``False`*, *`scattering``=``False`*, *`scat_keep_prob``=``0.001`*, *`edge_diffraction``=``False`*, *`check_scene``=``True`*)\n\nComputes the trajectories of the paths by shooting rays\n\nThe EM fields corresponding to the traced paths are not computed.\nThey can be computed using [`compute_fields()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_fields):\n```python\ntraced_paths = scene.trace_paths()\npaths = scene.compute_fields(*traced_paths)\n```\n\n\nPath tracing is independent of the radio materials, antenna patterns,\nand radio device orientations.\nTherefore, a set of traced paths could be reused for different values\nof these quantities, e.g., to calibrate the ray tracer.\nThis can enable significant resource savings as path tracing is\ntypically significantly more resource-intensive than field computation.\n\nNote that [`compute_paths()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_paths) does both path tracing and\nfield computation.\nInput\n\n- **max_depth** (*int*)  Maximum depth (i.e., number of interaction with objects in the scene)\nallowed for tracing the paths.\nDefaults to 3.\n- **method** (*str (exhaustive|fibonacci)*)  Method to be used to list candidate paths.\nThe exhaustive method tests all possible combination of primitives as\npaths. This method is not compatible with scattering.\nThe fibonacci method uses a shoot-and-bounce approach to find\ncandidate chains of primitives. Initial ray directions are arranged\nin a Fibonacci lattice on the unit sphere. This method can be\napplied to very large scenes. However, there is no guarantee that\nall possible paths are found.\nDefaults to fibonacci.\n- **num_samples** (*int*)  Number of random rays to trace in order to generate candidates.\nA large sample count may exhaust GPU memory.\nDefaults to 1e6. Only needed if `method` is fibonacci.\n- **los** (*bool*)  If set to <cite>True</cite>, then the LoS paths are computed.\nDefaults to <cite>True</cite>.\n- **reflection** (*bool*)  If set to <cite>True</cite>, then the reflected paths are computed.\nDefaults to <cite>True</cite>.\n- **diffraction** (*bool*)  If set to <cite>True</cite>, then the diffracted paths are computed.\nDefaults to <cite>False</cite>.\n- **scattering** (*bool*)  If set to <cite>True</cite>, then the scattered paths are computed.\nOnly works with the Fibonacci method.\nDefaults to <cite>False</cite>.\n- **scat_keep_prob** (*float*)  Probability with which to keep scattered paths.\nThis is helpful to reduce the number of scattered paths computed,\nwhich might be prohibitively high in some setup.\nMust be in the range (0,1).\nDefaults to 0.001.\n- **edge_diffraction** (*bool*)  If set to <cite>False</cite>, only diffraction on wedges, i.e., edges that\nconnect two primitives, is considered.\nDefaults to <cite>False</cite>.\n- **check_scene** (*bool*)  If set to <cite>True</cite>, checks that the scene is well configured before\ncomputing the paths. This can add a significant overhead.\nDefaults to <cite>True</cite>.\n\n\nOutput\n\n- **spec_paths** ([`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths))  Computed specular paths\n- **diff_paths** ([`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths))  Computed diffracted paths\n- **scat_paths** ([`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths))  Computed scattered paths\n- **spec_paths_tmp** (`PathsTmpData`)  Additional data required to compute the EM fields of the specular\npaths\n- **diff_paths_tmp** (`PathsTmpData`)  Additional data required to compute the EM fields of the diffracted\npaths\n- **scat_paths_tmp** (`PathsTmpData`)  Additional data required to compute the EM fields of the scattered\npaths"
"### compute_fields\n\n`sionna.rt.Scene.``compute_fields`(*`self`*, *`spec_paths`*, *`diff_paths`*, *`scat_paths`*, *`spec_paths_tmp`*, *`diff_paths_tmp`*, *`scat_paths_tmp`*, *`check_scene``=``True`*, *`scat_random_phases``=``True`*)\n\nComputes the EM fields corresponding to traced paths\n\nPaths can be traced using [`trace_paths()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.trace_paths).\nThis method can then be used to finalize the paths calculation by\ncomputing the corresponding fields:\n```python\ntraced_paths = scene.trace_paths()\npaths = scene.compute_fields(*traced_paths)\n```\n\n\nPaths tracing is independent from the radio materials, antenna patterns,\nand radio devices orientations.\nTherefore, a set of traced paths could be reused for different values\nof these quantities, e.g., to calibrate the ray tracer.\nThis can enable significant resource savings as paths tracing is\ntypically significantly more resource-intensive than field computation.\n\nNote that [`compute_paths()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_paths) does both tracing and\nfield computation.\nInput\n\n- **spec_paths** ([`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths))  Specular paths\n- **diff_paths** ([`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths))  Diffracted paths\n- **scat_paths** ([`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths))  Scattered paths\n- **spec_paths_tmp** (`PathsTmpData`)  Additional data required to compute the EM fields of the specular\npaths\n- **diff_paths_tmp** (`PathsTmpData`)  Additional data required to compute the EM fields of the diffracted\npaths\n- **scat_paths_tmp** (`PathsTmpData`)  Additional data required to compute the EM fields of the scattered\npaths\n- **check_scene** (*bool*)  If set to <cite>True</cite>, checks that the scene is well configured before\ncomputing the paths. This can add a significant overhead.\nDefaults to <cite>True</cite>.\n- **scat_random_phases** (*bool*)  If set to <cite>True</cite> and if scattering is enabled, random uniform phase\nshifts are added to the scattered paths.\nDefaults to <cite>True</cite>.\n\n\nOutput\n\n**paths** ([`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths))  Computed paths"
"### coverage_map\n\n`sionna.rt.Scene.``coverage_map`(*`self`*, *`rx_orientation``=``(0.0,` `0.0,` `0.0)`*, *`max_depth``=``3`*, *`cm_center``=``None`*, *`cm_orientation``=``None`*, *`cm_size``=``None`*, *`cm_cell_size``=``(10.0,` `10.0)`*, *`combining_vec``=``None`*, *`precoding_vec``=``None`*, *`num_samples``=``2000000`*, *`los``=``True`*, *`reflection``=``True`*, *`diffraction``=``False`*, *`scattering``=``False`*, *`edge_diffraction``=``False`*, *`check_scene``=``True`*)\n\nThis function computes a coverage map for every transmitter in the scene.\n\nFor a given transmitter, a coverage map is a rectangular surface with\narbitrary orientation subdivded\ninto rectangular cells of size $\\lvert C \\rvert = \\texttt{cm_cell_size[0]} \\times  \\texttt{cm_cell_size[1]}$.\nThe parameter `cm_cell_size` therefore controls the granularity of the map.\nThe coverage map associates with every cell $(i,j)$ the quantity\n\n$$\nb_{i,j} = \\frac{1}{\\lvert C \\rvert} \\int_{C_{i,j}} \\lvert h(s) \\rvert^2 ds\n$$\n\nwhere $\\lvert h(s) \\rvert^2$ is the squared amplitude\nof the path coefficients $a_i$ at position $s=(x,y)$,\nthe integral is over the cell $C_{i,j}$, and\n$ds$ is the infinitesimal small surface element\n$ds=dx \\cdot dy$.\nThe dimension indexed by $i$ ($j$) corresponds to the $y\\, (x)$-axis of the\ncoverage map in its local coordinate system.\n\nFor specularly and diffusely reflected paths, [(43)](https://nvlabs.github.io/sionna/api/rt.html#equation-cm-def) can be rewritten as an integral over the directions\nof departure of the rays from the transmitter, by substituting $s$\nwith the corresponding direction $\\omega$:\n\n$$\nb_{i,j} = \\frac{1}{\\lvert C \\rvert} \\int_{\\Omega} \\lvert h\\left(s(\\omega) \\right) \\rvert^2 \\frac{r(\\omega)^2}{\\lvert \\cos{\\alpha(\\omega)} \\rvert} \\mathbb{1}_{\\left\\{ s(\\omega) \\in C_{i,j} \\right\\}} d\\omega\n$$\n\nwhere the integration is over the unit sphere $\\Omega$, $r(\\omega)$ is the length of\nthe path with direction of departure $\\omega$, $s(\\omega)$ is the point\nwhere the path with direction of departure $\\omega$ intersects the coverage map,\n$\\alpha(\\omega)$ is the angle between the coverage map normal and the direction of arrival\nof the path with direction of departure $\\omega$,\nand $\\mathbb{1}_{\\left\\{ s(\\omega) \\in C_{i,j} \\right\\}}$ is the function that takes as value\none if $s(\\omega) \\in C_{i,j}$ and zero otherwise.\nNote that $ds = \\frac{r(\\omega)^2 d\\omega}{\\lvert \\cos{\\alpha(\\omega)} \\rvert}$.\n\nThe previous integral is approximated through Monte Carlo sampling by shooting $N$ rays\nwith directions $\\omega_n$ arranged as a Fibonacci lattice on the unit sphere around the transmitter,\nand bouncing the rays on the intersected objects until the maximum depth (`max_depth`) is reached or\nthe ray bounces out of the scene.\nAt every intersection with an object of the scene, a new ray is shot from the intersection which corresponds to either\nspecular reflection or diffuse scattering, following a Bernoulli distribution with parameter the\nsquared scattering coefficient.\nWhen diffuse scattering is selected, the direction of the scattered ray is uniformly sampled on the half-sphere.\nThe resulting Monte Carlo estimate is:\n\n$$\n\\hat{b}_{i,j}^{\\text{(ref)}} = \\frac{4\\pi}{N\\lvert C \\rvert} \\sum_{n=1}^N \\lvert h\\left(s(\\omega_n)\\right)  \\rvert^2 \\frac{r(\\omega_n)^2}{\\lvert \\cos{\\alpha(\\omega_n)} \\rvert} \\mathbb{1}_{\\left\\{ s(\\omega_n) \\in C_{i,j} \\right\\}}.\n$$\n\nFor the diffracted paths, [(43)](https://nvlabs.github.io/sionna/api/rt.html#equation-cm-def) can be rewritten for any wedge\nwith length $L$ and opening angle $\\Phi$ as an integral over the wedge and its opening angle,\nby substituting $s$ with the position on the wedge $\\ell \\in [1,L]$ and the angle $\\phi \\in [0, \\Phi]$:\n\n$$\nb_{i,j} = \\frac{1}{\\lvert C \\rvert} \\int_{\\ell} \\int_{\\phi} \\lvert h\\left(s(\\ell,\\phi) \\right) \\rvert^2 \\mathbb{1}_{\\left\\{ s(\\ell,\\phi) \\in C_{i,j} \\right\\}} \\left\\lVert \\frac{\\partial r}{\\partial \\ell} \\times \\frac{\\partial r}{\\partial \\phi} \\right\\rVert d\\ell d\\phi\n$$\n\nwhere the integral is over the wedge length $L$ and opening angle $\\Phi$, and\n$r\\left( \\ell, \\phi \\right)$ is the reparametrization with respected to $(\\ell, \\phi)$ of the\nintersection between the diffraction cone at $\\ell$ and the rectangle defining the coverage map (see, e.g., [[SurfaceIntegral]](https://nvlabs.github.io/sionna/api/rt.html#surfaceintegral)).\nThe previous integral is approximated through Monte Carlo sampling by shooting $N'$ rays from equally spaced\nlocations $\\ell_n$ along the wedge with directions $\\phi_n$ sampled uniformly from $(0, \\Phi)$:\n\n$$\n\\hat{b}_{i,j}^{\\text{(diff)}} = \\frac{L\\Phi}{N'\\lvert C \\rvert} \\sum_{n=1}^{N'} \\lvert h\\left(s(\\ell_n,\\phi_n)\\right) \\rvert^2 \\mathbb{1}_{\\left\\{ s(\\ell_n,\\phi_n) \\in C_{i,j} \\right\\}} \\left\\lVert \\left(\\frac{\\partial r}{\\partial \\ell}\\right)_n \\times \\left(\\frac{\\partial r}{\\partial \\phi}\\right)_n \\right\\rVert.\n$$\n\nThe output of this function is therefore a real-valued matrix of size `[num_cells_y,` `num_cells_x]`,\nfor every transmitter, with elements equal to the sum of the contributions of the reflected and scattered paths\n[(44)](https://nvlabs.github.io/sionna/api/rt.html#equation-cm-mc-ref) and diffracted paths [(45)](https://nvlabs.github.io/sionna/api/rt.html#equation-cm-mc-diff) for all the wedges, and where\n\n$$\n\\begin{split}\\texttt{num_cells_x} = \\bigg\\lceil\\frac{\\texttt{cm_size[0]}}{\\texttt{cm_cell_size[0]}} \\bigg\\rceil\\\\\n\\texttt{num_cells_y} = \\bigg\\lceil \\frac{\\texttt{cm_size[1]}}{\\texttt{cm_cell_size[1]}} \\bigg\\rceil.\\end{split}\n$$\n\nThe surface defining the coverage map is a rectangle centered at\n`cm_center`, with orientation `cm_orientation`, and with size\n`cm_size`. An orientation of (0,0,0) corresponds to\na coverage map parallel to the XY plane, with surface normal pointing towards\nthe $+z$ axis. By default, the coverage map\nis parallel to the XY plane, covers all of the scene, and has\nan elevation of $z = 1.5\\text{m}$.\nThe receiver is assumed to use the antenna array\n`scene.rx_array`. If transmitter and/or receiver have multiple antennas, transmit precoding\nand receive combining are applied which are defined by `precoding_vec` and\n`combining_vec`, respectively.\n\nThe $(i,j)$ indices are omitted in the following for clarity.\nFor reflection and scattering, paths are generated by shooting `num_samples` rays from the\ntransmitters with directions arranged in a Fibonacci lattice on the unit\nsphere and by simulating their propagation for up to `max_depth` interactions with\nscene objects.\nIf `max_depth` is set to 0 and if `los` is set to <cite>True</cite>,\nonly the line-of-sight path is considered.\nFor diffraction, paths are generated by shooting `num_samples` rays from equally\nspaced locations along the wedges in line-of-sight with the transmitter, with\ndirections uniformly sampled on the diffraction cone.\n\nFor every ray $n$ intersecting the coverage map cell $(i,j)$, the\nchannel coefficients, $a_n$, and the angles of departure (AoDs)\n$(\\theta_{\\text{T},n}, \\varphi_{\\text{T},n})$\nand arrival (AoAs) $(\\theta_{\\text{R},n}, \\varphi_{\\text{R},n})$\nare computed. See the [Primer on Electromagnetics](../em_primer.html) for more details.\n\nA synthetic array is simulated by adding additional phase shifts that depend on the\nantenna position relative to the position of the transmitter (receiver) as well as the AoDs (AoAs).\nFor the $k^\\text{th}$ transmit antenna and $\\ell^\\text{th}$ receive antenna, let\nus denote by $\\mathbf{d}_{\\text{T},k}$ and $\\mathbf{d}_{\\text{R},\\ell}$ the relative positions (with respect to\nthe positions of the transmitter/receiver) of the pair of antennas\nfor which the channel impulse response shall be computed. These can be accessed through the antenna arrays property\n[`positions`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.AntennaArray.positions). Using a plane-wave assumption, the resulting phase shifts\nfrom these displacements can be computed as\n\n$$\n\\begin{split}p_{\\text{T}, n,k} &= \\frac{2\\pi}{\\lambda}\\hat{\\mathbf{r}}(\\theta_{\\text{T},n}, \\varphi_{\\text{T},n})^\\mathsf{T} \\mathbf{d}_{\\text{T},k}\\\\\np_{\\text{R}, n,\\ell} &= \\frac{2\\pi}{\\lambda}\\hat{\\mathbf{r}}(\\theta_{\\text{R},n}, \\varphi_{\\text{R},n})^\\mathsf{T} \\mathbf{d}_{\\text{R},\\ell}.\\end{split}\n$$\n\nThe final expression for the path coefficient is\n\n$$\nh_{n,k,\\ell} =  a_n e^{j(p_{\\text{T}, i,k} + p_{\\text{R}, i,\\ell})}\n$$\n\nfor every transmit antenna $k$ and receive antenna $\\ell$.\nThese coefficients form the complex-valued channel matrix, $\\mathbf{H}_n$,\nof size $\\texttt{num_rx_ant} \\times \\texttt{num_tx_ant}$.\n\nFinally, the coefficient of the equivalent SISO channel is\n\n$$\nh_n =  \\mathbf{c}^{\\mathsf{H}} \\mathbf{H}_n \\mathbf{p}\n$$\n\nwhere $\\mathbf{c}$ and $\\mathbf{p}$ are the combining and\nprecoding vectors (`combining_vec` and `precoding_vec`),\nrespectively.\n xample"
"```python\nimport sionna\nfrom sionna.rt import load_scene, PlanarArray, Transmitter, Receiver\nscene = load_scene(sionna.rt.scene.munich)\n# Configure antenna array for all transmitters\nscene.tx_array = PlanarArray(num_rows=8,\n                        num_cols=2,\n                        vertical_spacing=0.7,\n                        horizontal_spacing=0.5,\n                        pattern=\"tr38901\",\n                        polarization=\"VH\")\n# Configure antenna array for all receivers\nscene.rx_array = PlanarArray(num_rows=1,\n                        num_cols=1,\n                        vertical_spacing=0.5,\n                        horizontal_spacing=0.5,\n                        pattern=\"dipole\",\n                        polarization=\"cross\")\n# Add a transmitters\ntx = Transmitter(name=\"tx\",\n            position=[8.5,21,30],\n            orientation=[0,0,0])\nscene.add(tx)\ntx.look_at([40,80,1.5])\n# Compute coverage map\ncm = scene.coverage_map(cm_cell_size=[1.,1.],\n                    num_samples=int(10e6))\n# Visualize coverage in preview\nscene.preview(coverage_map=cm,\n            resolution=[1000, 600])\n```\n\n\nInput\n\n- **rx_orientation** (*[3], float*)  Orientation of the receiver $(\\alpha, \\beta, \\gamma)$\nspecified through three angles corresponding to a 3D rotation\nas defined in [(3)](../em_primer.html#equation-rotation). Defaults to $(0,0,0)$.\n- **max_depth** (*int*)  Maximum depth (i.e., number of bounces) allowed for tracing the\npaths. Defaults to 3.\n- **cm_center** ([3], float | <cite>None</cite>)  Center of the coverage map $(x,y,z)$ as three-dimensional\nvector. If set to <cite>None</cite>, the coverage map is centered on the\ncenter of the scene, except for the elevation $z$ that is set\nto 1.5m. Otherwise, `cm_orientation` and `cm_scale` must also\nnot be <cite>None</cite>. Defaults to <cite>None</cite>.\n- **cm_orientation** ([3], float | <cite>None</cite>)  Orientation of the coverage map $(\\alpha, \\beta, \\gamma)$\nspecified through three angles corresponding to a 3D rotation\nas defined in [(3)](../em_primer.html#equation-rotation).\nAn orientation of $(0,0,0)$ or <cite>None</cite> corresponds to a\ncoverage map that is parallel to the XY plane.\nIf not set to <cite>None</cite>, then `cm_center` and `cm_scale` must also\nnot be <cite>None</cite>.\nDefaults to <cite>None</cite>.\n- **cm_size** ([2], float | <cite>None</cite>)  Size of the coverage map [m].\nIf set to <cite>None</cite>, then the size of the coverage map is set such that\nit covers the entire scene.\nOtherwise, `cm_center` and `cm_orientation` must also not be\n<cite>None</cite>. Defaults to <cite>None</cite>.\n- **cm_cell_size** (*[2], float*)  Size of a cell of the coverage map [m].\nDefaults to $(10,10)$.\n- **combining_vec** (*[num_rx_ant], complex | None*)  Combining vector.\nIf set to <cite>None</cite>, then no combining is applied, and\nthe energy received by all antennas is summed.\n- **precoding_vec** (*[num_tx_ant], complex | None*)  Precoding vector.\nIf set to <cite>None</cite>, then defaults to\n$\\frac{1}{\\sqrt{\\text{num_tx_ant}}} [1,\\dots,1]^{\\mathsf{T}}$.\n- **num_samples** (*int*)  Number of random rays to trace.\nFor the reflected paths, this number is split equally over the different transmitters.\nFor the diffracted paths, it is split over the wedges in line-of-sight with the\ntransmitters such that the number of rays allocated\nto a wedge is proportional to its length.\nDefaults to 2e6.\n- **los** (*bool*)  If set to <cite>True</cite>, then the LoS paths are computed.\nDefaults to <cite>True</cite>.\n- **reflection** (*bool*)  If set to <cite>True</cite>, then the reflected paths are computed.\nDefaults to <cite>True</cite>.\n- **diffraction** (*bool*)  If set to <cite>True</cite>, then the diffracted paths are computed.\nDefaults to <cite>False</cite>.\n- **scattering** (*bool*)  If set to <cite>True</cite>, then the scattered paths are computed.\nDefaults to <cite>False</cite>.\n- **edge_diffraction** (*bool*)  If set to <cite>False</cite>, only diffraction on wedges, i.e., edges that\nconnect two primitives, is considered.\nDefaults to <cite>False</cite>.\n- **check_scene** (*bool*)  If set to <cite>True</cite>, checks that the scene is well configured before\ncomputing the coverage map. This can add a significant overhead.\nDefaults to <cite>True</cite>.\n\n\nOutput\n\ncm : [`CoverageMap`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.CoverageMap)  The coverage maps"
"### load_scene\n\n`sionna.rt.``load_scene`(*`filename``=``None`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/scene.html#load_scene)\n\nLoad a scene from file\n\nNote that only one scene can be loaded at a time.\nInput\n\n- **filename** (*str*)  Name of a valid scene file. Sionna uses the simple XML-based format\nfrom [Mitsuba 3](https://mitsuba.readthedocs.io/en/stable/src/key_topics/scene_format.html).\nDefaults to <cite>None</cite> for which an empty scene is created.\n- **dtype** (*tf.complex*)  Dtype used for all internal computations and outputs.\nDefaults to <cite>tf.complex64</cite>.\n\n\nOutput\n\n**scene** ([`Scene`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene))  Reference to the current scene"
"### preview\n\n`sionna.rt.Scene.``preview`(*`paths``=``None`*, *`show_paths``=``True`*, *`show_devices``=``True`*, *`coverage_map``=``None`*, *`cm_tx``=``0`*, *`cm_vmin``=``None`*, *`cm_vmax``=``None`*, *`resolution``=``(655,` `500)`*, *`fov``=``45`*, *`background``=``'#ffffff'`*, *`clip_at``=``None`*, *`clip_plane_orientation``=``(0,` `0,` `-` `1)`*)\n\nIn an interactive notebook environment, opens an interactive 3D\nviewer of the scene.\n\nThe returned value of this method must be the last line of\nthe cell so that it is displayed. For example:\n```python\nfig = scene.preview()\n# ...\nfig\n```\n\n\nOr simply:\n```python\nscene.preview()\n```\n\n\nColor coding:\n\n- Green: Receiver\n- Blue: Transmitter\n\n\nControls:\n\n- Mouse left: Rotate\n- Scroll wheel: Zoom\n- Mouse right: Move\n\nInput\n\n- **paths** ([`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths) | <cite>None</cite>)  Simulated paths generated by\n[`compute_paths()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_paths) or <cite>None</cite>.\nIf <cite>None</cite>, only the scene is rendered.\nDefaults to <cite>None</cite>.\n- **show_paths** (*bool*)  If <cite>paths</cite> is not <cite>None</cite>, shows the paths.\nDefaults to <cite>True</cite>.\n- **show_devices** (*bool*)  If set to <cite>True</cite>, shows the radio devices.\nDefaults to <cite>True</cite>.\n- **show_orientations** (*bool*)  If <cite>show_devices</cite> is <cite>True</cite>, shows the radio devices orientations.\nDefaults to <cite>False</cite>.\n- **coverage_map** ([`CoverageMap`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.CoverageMap) | <cite>None</cite>)  An optional coverage map to overlay in the scene for visualization.\nDefaults to <cite>None</cite>.\n- **cm_tx** (*int | str*)  When <cite>coverage_map</cite> is specified, controls which of the transmitters\nto display the coverage map for. Either the transmitters name\nor index can be given.\nDefaults to <cite>0</cite>.\n- **cm_db_scale** (*bool*)  Use logarithmic scale for coverage map visualization, i.e. the\ncoverage values are mapped with:\n$y = 10 \\cdot \\log_{10}(x)$.\nDefaults to <cite>True</cite>.\n- **cm_vmin, cm_vmax** (*floot | None*)  For coverage map visualization, defines the range of path gains that\nthe colormap covers.\nThese parameters should be provided in dB if `cm_db_scale` is\nset to <cite>True</cite>, or in linear scale otherwise.\nIf set to None, then covers the complete range.\nDefaults to <cite>None</cite>.\n- **resolution** (*[2], int*)  Size of the viewer figure.\nDefaults to <cite>[655, 500]</cite>.\n- **fov** (*float*)  Field of view, in degrees.\nDefaults to 45.\n- **background** (*str*)  Background color in hex format prefixed by #.\nDefaults to #ffffff (white).\n- **clip_at** (*float*)  If not <cite>None</cite>, the scene preview will be clipped (cut) by a plane\nwith normal orientation `clip_plane_orientation` and offset `clip_at`.\nThat means that everything *behind* the plane becomes invisible.\nThis allows visualizing the interior of meshes, such as buildings.\nDefaults to <cite>None</cite>.\n- **clip_plane_orientation** (*tuple[float, float, float]*)  Normal vector of the clipping plane.\nDefaults to (0,0,-1)."
"### render\n\n`sionna.rt.Scene.``render`(*`camera`*, *`paths``=``None`*, *`show_paths``=``True`*, *`show_devices``=``True`*, *`coverage_map``=``None`*, *`cm_tx``=``0`*, *`cm_vmin``=``None`*, *`cm_vmax``=``None`*, *`cm_show_color_bar``=``True`*, *`num_samples``=``512`*, *`resolution``=``(655,` `500)`*, *`fov``=``45`*)\n\nRenders the scene from the viewpoint of a camera or the interactive\nviewer\nInput\n\n- **camera** (str | [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera))  The name or instance of a [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera).\nIf an interactive viewer was opened with\n[`preview()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.preview), set to <cite>preview</cite> to use its\nviewpoint.\n- **paths** ([`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths) | <cite>None</cite>)  Simulated paths generated by\n[`compute_paths()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_paths) or <cite>None</cite>.\nIf <cite>None</cite>, only the scene is rendered.\nDefaults to <cite>None</cite>.\n- **show_paths** (*bool*)  If <cite>paths</cite> is not <cite>None</cite>, shows the paths.\nDefaults to <cite>True</cite>.\n- **show_devices** (*bool*)  If <cite>paths</cite> is not <cite>None</cite>, shows the radio devices.\nDefaults to <cite>True</cite>.\n- **coverage_map** ([`CoverageMap`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.CoverageMap) | <cite>None</cite>)  An optional coverage map to overlay in the scene for visualization.\nDefaults to <cite>None</cite>.\n- **cm_tx** (*int | str*)  When <cite>coverage_map</cite> is specified, controls which of the transmitters\nto display the coverage map for. Either the transmitters name\nor index can be given.\nDefaults to <cite>0</cite>.\n- **cm_db_scale** (*bool*)  Use logarithmic scale for coverage map visualization, i.e. the\ncoverage values are mapped with:\n$y = 10 \\cdot \\log_{10}(x)$.\nDefaults to <cite>True</cite>.\n- **cm_vmin, cm_vmax** (*float | None*)  For coverage map visualization, defines the range of path gains that\nthe colormap covers.\nThese parameters should be provided in dB if `cm_db_scale` is\nset to <cite>True</cite>, or in linear scale otherwise.\nIf set to None, then covers the complete range.\nDefaults to <cite>None</cite>.\n- **cm_show_color_bar** (*bool*)  For coverage map visualization, show the color bar describing the\ncolor mapping used next to the rendering.\nDefaults to <cite>True</cite>.\n- **num_samples** (*int*)  Number of rays thrown per pixel.\nDefaults to 512.\n- **resolution** (*[2], int*)  Size of the rendered figure.\nDefaults to <cite>[655, 500]</cite>.\n- **fov** (*float*)  Field of view, in degrees.\nDefaults to 45.\n\n\nOutput\n\n`Figure`  Rendered image"
"### render_to_file\n\n`sionna.rt.Scene.``render_to_file`(*`camera`*, *`filename`*, *`paths``=``None`*, *`show_paths``=``True`*, *`show_devices``=``True`*, *`coverage_map``=``None`*, *`cm_tx``=``0`*, *`cm_db_scale``=``True`*, *`cm_vmin``=``None`*, *`cm_vmax``=``None`*, *`num_samples``=``512`*, *`resolution``=``(655,` `500)`*, *`fov``=``45`*)\n\nRenders the scene from the viewpoint of a camera or the interactive\nviewer, and saves the resulting image\nInput\n\n- **camera** (str | [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera))  The name or instance of a [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera).\nIf an interactive viewer was opened with\n[`preview()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.preview), set to <cite>preview</cite> to use its\nviewpoint.\n- **filename** (*str*)  Filename for saving the rendered image, e.g., my_scene.png\n- **paths** ([`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths) | <cite>None</cite>)  Simulated paths generated by\n[`compute_paths()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_paths) or <cite>None</cite>.\nIf <cite>None</cite>, only the scene is rendered.\nDefaults to <cite>None</cite>.\n- **show_paths** (*bool*)  If <cite>paths</cite> is not <cite>None</cite>, shows the paths.\nDefaults to <cite>True</cite>.\n- **show_devices** (*bool*)  If <cite>paths</cite> is not <cite>None</cite>, shows the radio devices.\nDefaults to <cite>True</cite>.\n- **coverage_map** ([`CoverageMap`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.CoverageMap) | <cite>None</cite>)  An optional coverage map to overlay in the scene for visualization.\nDefaults to <cite>None</cite>.\n- **cm_tx** (*int | str*)  When <cite>coverage_map</cite> is specified, controls which of the transmitters\nto display the coverage map for. Either the transmitters name\nor index can be given.\nDefaults to <cite>0</cite>.\n- **cm_db_scale** (*bool*)  Use logarithmic scale for coverage map visualization, i.e. the\ncoverage values are mapped with:\n$y = 10 \\cdot \\log_{10}(x)$.\nDefaults to <cite>True</cite>.\n- **cm_vmin, cm_vmax** (*float | None*)  For coverage map visualization, defines the range of path gains that\nthe colormap covers.\nThese parameters should be provided in dB if `cm_db_scale` is\nset to <cite>True</cite>, or in linear scale otherwise.\nIf set to None, then covers the complete range.\nDefaults to <cite>None</cite>.\n- **num_samples** (*int*)  Number of rays thrown per pixel.\nDefaults to 512.\n- **resolution** (*[2], int*)  Size of the rendered figure.\nDefaults to <cite>[655, 500]</cite>.\n- **fov** (*float*)  Field of view, in degrees.\nDefaults to 45."
"## Example Scenes\n\nSionna has several integrated scenes that are listed below.\nThey can be loaded and used as follows:\n```python\nscene = load_scene(sionna.rt.scene.etoile)\nscene.preview()\n```"
"### floor_wall\n\n`sionna.rt.scene.``floor_wall`\n\nExample scene containing a ground plane and a vertical wall\n\n\n([Blender file](https://drive.google.com/file/d/1djXBj3VYLT4_bQpmp4vR6o6agGmv_p1F/view?usp=share_link))"
"### simple_street_canyon\n\n`sionna.rt.scene.``simple_street_canyon`\n\nExample scene containing a few rectangular building blocks and a ground plane\n\n\n([Blender file](https://drive.google.com/file/d/1_1nsLtSC8cy1QfRHAN_JetT3rPP21tNb/view?usp=share_link))"
"### etoile\n\n`sionna.rt.scene.``etoile`\n\nExample scene containing the area around the Arc de Triomphe in Paris\nThe scene was created with data downloaded from [OpenStreetMap](https://www.openstreetmap.org) and\nthe help of [Blender](https://www.blender.org) and the [Blender-OSM](https://github.com/vvoovv/blender-osm)\nand [Mitsuba Blender](https://github.com/mitsuba-renderer/mitsuba-blender) add-ons.\nThe data is licensed under the [Open Data Commons Open Database License (ODbL)](https://openstreetmap.org/copyright).\n\n\n([Blender file](https://drive.google.com/file/d/1bamQ67lLGZHTfNmcVajQDmq2oiSY8FEn/view?usp=share_link))"
"### munich\n\n`sionna.rt.scene.``munich`\n\nExample scene containing the area around the Frauenkirche in Munich\nThe scene was created with data downloaded from [OpenStreetMap](https://www.openstreetmap.org) and\nthe help of [Blender](https://www.blender.org) and the [Blender-OSM](https://github.com/vvoovv/blender-osm)\nand [Mitsuba Blender](https://github.com/mitsuba-renderer/mitsuba-blender) add-ons.\nThe data is licensed under the [Open Data Commons Open Database License (ODbL)](https://openstreetmap.org/copyright).\n\n\n([Blender file](https://drive.google.com/file/d/15WrvMGrPWsoVKYvDG6Ab7btq-ktTCGR1/view?usp=share_link))"
"### simple_wedge\n\n`sionna.rt.scene.``simple_wedge`\n\nExample scene containing a wedge with a $90^{\\circ}$ opening angle\n\n\n([Blender file](https://drive.google.com/file/d/1RnJoYzXKkILMEmf-UVSsyjq-EowU6JRA/view?usp=share_link))"
"### simple_reflector\n\n`sionna.rt.scene.``simple_reflector`\n\nExample scene containing a metallic square\n\n\n([Blender file](https://drive.google.com/file/d/1iYPD11zAAMj0gNUKv_nv6QdLhOJcPpIa/view?usp=share_link))"
"### double_reflector\n\n`sionna.rt.scene.``double_reflector`\n\nExample scene containing two metallic squares\n\n\n([Blender file](https://drive.google.com/file/d/1K2ZUYHPPkrq9iUauJtInRu7x2r16D1zN/view?usp=share_link))"
"### triple_reflector\n\n`sionna.rt.scene.``triple_reflector`\n\nExample scene containing three metallic rectangles\n\n\n([Blender file](https://drive.google.com/file/d/1l95_0U2b3cEVtz3G8mQxuLxy8xiPsVID/view?usp=share_link))"
"### Box\n\n`sionna.rt.scene.``box`\n\nExample scene containing a metallic box\n\n\n([Blender file](https://drive.google.com/file/d/1pywetyKr0HBz3aSYpkmykGnjs_1JMsHY/view?usp=share_link))"
"## Paths\n\nA propagation path $i$ starts at a transmit antenna and ends at a receive antenna. It is described by\nits channel coefficient $a_i$ and delay $\\tau_i$, as well as the\nangles of departure $(\\theta_{\\text{T},i}, \\varphi_{\\text{T},i})$\nand arrival $(\\theta_{\\text{R},i}, \\varphi_{\\text{R},i})$.\nFor more detail, see the [Primer on Electromagnetics](../em_primer.html).\n\nIn Sionna, paths are computed with the help of the function [`compute_paths()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_paths) which returns an instance of\n[`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths). Paths can be visualized by providing them as arguments to the functions [`render()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.render),\n[`render_to_file()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.render_to_file), or [`preview()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.preview).\n\nChannel impulse responses (CIRs) can be obtained with [`cir()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths.cir) which can\nthen be used for link-level simulations. This is for example done in the [Sionna Ray Tracing Tutorial](../examples/Sionna_Ray_Tracing_Introduction.html)."
"### Paths\n\n`class` `sionna.rt.``Paths`[`[source]`](../_modules/sionna/rt/paths.html#Paths)\n\nStores the simulated propagation paths\n\nPaths are generated for the loaded scene using\n[`compute_paths()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_paths). Please refer to the\ndocumentation of this function for further details.\nThese paths can then be used to compute channel impulse responses:\n```python\npaths = scene.compute_paths()\na, tau = paths.cir()\n```\n\n\nwhere `scene` is the [`Scene`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene) loaded using\n[`load_scene()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.load_scene).\n\n`property` `a`\n\nPassband channel coefficients $a_i$ of each path as defined in [(26)](../em_primer.html#equation-h-final).\nType\n\n[batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths, num_time_steps], tf.complex\n\n\n`apply_doppler`(*`sampling_frequency`*, *`num_time_steps`*, *`tx_velocities``=``(0.0,` `0.0,` `0.0)`*, *`rx_velocities``=``(0.0,` `0.0,` `0.0)`*)[`[source]`](../_modules/sionna/rt/paths.html#Paths.apply_doppler)\n\nApply Doppler shifts corresponding to input transmitters and receivers\nvelocities.\n\nThis function replaces the last dimension of the tensor storing the\npaths coefficients [`a`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths.a), which stores the the temporal evolution of\nthe channel, with a dimension of size `num_time_steps` computed\naccording to the input velocities.\n\nTime evolution of the channel coefficients is simulated by computing the\nDoppler shift due to movements of the transmitter and receiver. If we denote by\n$\\mathbf{v}_{\\text{T}}\\in\\mathbb{R}^3$ and $\\mathbf{v}_{\\text{R}}\\in\\mathbb{R}^3$\nthe velocity vectors of the transmitter and receiver, respectively, the Doppler shifts are computed as\n\n$$\n\\begin{split}f_{\\text{T}, i} &= \\frac{\\hat{\\mathbf{r}}(\\theta_{\\text{T},i}, \\varphi_{\\text{T},i})^\\mathsf{T}\\mathbf{v}_{\\text{T}}}{\\lambda}\\qquad \\text{[Hz]}\\\\\nf_{\\text{R}, i} &= \\frac{\\hat{\\mathbf{r}}(\\theta_{\\text{R},i}, \\varphi_{\\text{R},i})^\\mathsf{T}\\mathbf{v}_{\\text{R}}}{\\lambda}\\qquad \\text{[Hz]}\\end{split}\n$$\n\nfor an arbitrary path $i$, where $(\\theta_{\\text{T},i}, \\varphi_{\\text{T},i})$ are the AoDs,\n$(\\theta_{\\text{R},i}, \\varphi_{\\text{R},i})$ are the AoAs, and $\\lambda$ is the wavelength.\nThis leads to the time-dependent path coefficient\n\n$$\na_i(t) = a_i e^{j2\\pi(f_{\\text{T}, i}+f_{\\text{R}, i})t}.\n$$\n\nNote that this model is only valid as long as the AoDs, AoAs, and path delay do not change.\n\nWhen this function is called multiple times, it overwrites the previous\ntime steps dimension.\nInput\n\n- **sampling_frequency** (*float*)  Frequency [Hz] at which the channel impulse response is sampled\n- **num_time_steps** (*int*)  Number of time steps.\n- **tx_velocities** ([batch_size, num_tx, 3] or broadcastable, tf.float | <cite>None</cite>)  Velocity vectors $(v_\\text{x}, v_\\text{y}, v_\\text{z})$ of all\ntransmitters [m/s].\nDefaults to <cite>[0,0,0]</cite>.\n- **rx_velocities** ([batch_size, num_tx, 3] or broadcastable, tf.float | <cite>None</cite>)  Velocity vectors $(v_\\text{x}, v_\\text{y}, v_\\text{z})$ of all\nreceivers [m/s].\nDefaults to <cite>[0,0,0]</cite>.\n\n\n`cir`(*`los``=``True`*, *`reflection``=``True`*, *`diffraction``=``True`*, *`scattering``=``True`*, *`num_paths``=``None`*)[`[source]`](../_modules/sionna/rt/paths.html#Paths.cir)\n\nReturns the baseband equivalent channel impulse response [(28)](../em_primer.html#equation-h-b)\nwhich can be used for link simulations by other Sionna components.\n\nThe baseband equivalent channel coefficients $a^{\\text{b}}_{i}$\nare computed as :\n\n$$\na^{\\text{b}}_{i} = a_{i} e^{-j2 \\pi f \\tau_{i}}\n$$\n\nwhere $i$ is the index of an arbitrary path, $a_{i}$\nis the passband path coefficient ([`a`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths.a)),\n$\\tau_{i}$ is the path delay ([`tau`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths.tau)),\nand $f$ is the carrier frequency.\n\nNote: For the paths of a given type to be returned (LoS, reflection, etc.), they\nmust have been previously computed by [`compute_paths()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_paths), i.e.,\nthe corresponding flags must have been set to <cite>True</cite>.\nInput\n\n- **los** (*bool*)  If set to <cite>False</cite>, LoS paths are not returned.\nDefaults to <cite>True</cite>.\n- **reflection** (*bool*)  If set to <cite>False</cite>, specular paths are not returned.\nDefaults to <cite>True</cite>.\n- **diffraction** (*bool*)  If set to <cite>False</cite>, diffracted paths are not returned.\nDefaults to <cite>True</cite>.\n- **scattering** (*bool*)  If set to <cite>False</cite>, scattered paths are not returned.\nDefaults to <cite>True</cite>.\n- **num_paths** (int or <cite>None</cite>)  All CIRs are either zero-padded or cropped to the largest\n`num_paths` paths.\nDefaults to <cite>None</cite> which means that no padding or cropping is done.\n\n\nOutput\n\n- **a** (*[batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths, num_time_steps], tf.complex*)  Path coefficients\n- **tau** (*[batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths] or [batch_size, num_rx, num_tx, max_num_paths], tf.float*)  Path delays\n\n\n`export`(*`filename`*)[`[source]`](../_modules/sionna/rt/paths.html#Paths.export)\n\nSaves the paths as an OBJ file for visualisation, e.g., in Blender\nInput\n\n**filename** (*str*)  Path and name of the file\n\n\n`from_dict`(*`data_dict`*)[`[source]`](../_modules/sionna/rt/paths.html#Paths.from_dict)\n\nSet the paths from a dictionnary which values are tensors\n\nThe format of the dictionnary is expected to be the same as the one\nreturned by [`to_dict()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths.to_dict).\nInput\n\n**data_dict** (<cite>dict</cite>)\n\n\n`property` `mask`\n\nSet to <cite>False</cite> for non-existent paths.\nWhen there are multiple transmitters or receivers, path counts may vary between links. This is used to identify non-existent paths.\nFor such paths, the channel coefficient is set to <cite>0</cite> and the delay to <cite>-1</cite>.\nType\n\n[batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths] or [batch_size, num_rx, num_tx, max_num_paths], tf.bool\n\n\n`property` `normalize_delays`\n\nSet to <cite>True</cite> to normalize path delays such that the first path\nbetween any pair of antennas of a transmitter and receiver arrives at\n`tau` `=` `0`. Defaults to <cite>True</cite>.\nType\n\nbool\n\n\n`property` `phi_r`\n\nAzimuth angles of arrival [rad]\nType\n\n[batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths] or [batch_size, num_rx, num_tx, max_num_paths], tf.float\n\n\n`property` `phi_t`\n\nAzimuth angles of departure [rad]\nType\n\n[batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths] or [batch_size, num_rx, num_tx, max_num_paths], tf.float\n\n\n`property` `reverse_direction`\n\nIf set to <cite>True</cite>, swaps receivers and transmitters\nType\n\nbool\n\n\n`property` `tau`\n\nPropagation delay $\\tau_i$ [s] of each path as defined in [(26)](../em_primer.html#equation-h-final).\nType\n\n[batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths] or [batch_size, num_rx, num_tx, max_num_paths], tf.float\n\n\n`property` `theta_r`\n\nZenith angles of arrival [rad]\nType\n\n[batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths] or [batch_size, num_rx, num_tx, max_num_paths], tf.float\n\n\n`property` `theta_t`\n\nZenith  angles of departure [rad]\nType\n\n[batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths] or [batch_size, num_rx, num_tx, max_num_paths], tf.float\n\n\n`to_dict`()[`[source]`](../_modules/sionna/rt/paths.html#Paths.to_dict)\n\nReturns the properties of the paths as a dictionnary which values are\ntensors\nOutput\n\n<cite>dict</cite>\n\n\n`property` `types`\n\nType of the paths:\n\n- 0 : LoS\n- 1 : Reflected\n- 2 : Diffracted\n- 3 : Scattered\n\nType\n\n[batch_size, max_num_paths], tf.int"
"## Coverage Maps\n\nA coverage map describes the received power from a specific transmitter at every point on a plane.\nIn other words, for a given transmitter, it associates every point on a surface  with the power that a receiver with\na specific orientation would observe at this point. A coverage map is not uniquely defined as it depends on\nthe transmit and receive arrays and their respective antenna patterns, the transmitter and receiver orientations, as well as\ntransmit precoding and receive combining vectors. Moreover, a coverage map is not continuous but discrete because the plane\nneeds to be quantized into small rectangular bins.\n\nIn Sionna, coverage maps are computed with the help of the function [`coverage_map()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.coverage_map) which returns an instance of\n[`CoverageMap`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.CoverageMap). They can be visualized by providing them either as arguments to the functions [`render()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.render),\n[`render_to_file()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.render_to_file), and [`preview()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.preview), or by using the class method [`show()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.CoverageMap.show).\n\nA very useful feature is [`sample_positions()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.CoverageMap.sample_positions) which allows sampling\nof random positions within the scene that have sufficient coverage from a specific transmitter.\nThis feature is used in the [Sionna Ray Tracing Tutorial](../examples/Sionna_Ray_Tracing_Introduction.html) to generate a dataset of channel impulse responses\nfor link-level simulations."
"### CoverageMap\n\n`class` `sionna.rt.``CoverageMap`[`[source]`](../_modules/sionna/rt/coverage_map.html#CoverageMap)\n\nStores the simulated coverage maps\n\nA coverage map is generated for the loaded scene for every transmitter using\n[`coverage_map()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.coverage_map). Please refer to the documentation of this function\nfor further details.\n\nAn instance of this class can be indexed like a tensor of rank three with\nshape `[num_tx,` `num_cells_y,` `num_cells_x]`, i.e.:\n```python\ncm = scene.coverage_map()\nprint(cm[0])      # prints the coverage map for transmitter 0\nprint(cm[0,1,2])  # prints the value of the cell (1,2) for transmitter 0\n```\n\n\nwhere `scene` is the [`Scene`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene) loaded using\n[`load_scene()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.load_scene).\n xample\n```python\nimport sionna\nfrom sionna.rt import load_scene, PlanarArray, Transmitter, Receiver\nscene = load_scene(sionna.rt.scene.munich)\n# Configure antenna array for all transmitters\nscene.tx_array = PlanarArray(num_rows=8,\n                          num_cols=2,\n                          vertical_spacing=0.7,\n                          horizontal_spacing=0.5,\n                          pattern=\"tr38901\",\n                          polarization=\"VH\")\n# Configure antenna array for all receivers\nscene.rx_array = PlanarArray(num_rows=1,\n                          num_cols=1,\n                          vertical_spacing=0.5,\n                          horizontal_spacing=0.5,\n                          pattern=\"dipole\",\n                          polarization=\"cross\")\n# Add a transmitters\ntx = Transmitter(name=\"tx\",\n              position=[8.5,21,30],\n              orientation=[0,0,0])\nscene.add(tx)\ntx.look_at([40,80,1.5])\n# Compute coverage map\ncm = scene.coverage_map(max_depth=8)\n# Show coverage map\ncm.show()\n```\n\n\n`as_tensor`()[`[source]`](../_modules/sionna/rt/coverage_map.html#CoverageMap.as_tensor)\n\nReturns the coverage map as a tensor\nOutput\n\n*[num_tx, num_cells_y, num_cells_x], tf.float*  The coverage map as a tensor\n\n\n`property` `cell_centers`\n\nGet the positions of the\ncenters of the cells in the global coordinate system\nType\n\n[num_cells_y, num_cells_x, 3], tf.float\n\n\n`property` `cell_size`\n\nGet the resolution of the coverage map, i.e., width\n(in the local X direction) and height (in the local Y direction) in\nof the cells of the coverage map\nType\n\n[2], tf.float\n\n\n`property` `center`\n\nGet the center of the coverage map\nType\n\n[3], tf.float\n\n\n`property` `num_cells_x`\n\nGet the number of cells along the local X-axis\nType\n\nint\n\n\n`property` `num_cells_y`\n\nGet the number of cells along the local Y-axis\nType\n\nint\n\n\n`property` `num_tx`\n\nGet the number of transmitters\nType\n\nint\n\n\n`property` `orientation`\n\nGet the orientation of the coverage map\nType\n\n[3], tf.float\n\n\n`sample_positions`(*`batch_size`*, *`tx``=``0`*, *`min_gain_db``=``None`*, *`max_gain_db``=``None`*, *`min_dist``=``None`*, *`max_dist``=``None`*, *`center_pos``=``False`*)[`[source]`](../_modules/sionna/rt/coverage_map.html#CoverageMap.sample_positions)\n\nSample random user positions from a coverage map\n\nFor a given coverage map, `batch_size` random positions are sampled\nsuch that the *expected*  path gain of this position is larger\nthan a given threshold `min_gain_db` or smaller than `max_gain_db`,\nrespectively.\nSimilarly, `min_dist` and `max_dist` define the minimum and maximum\ndistance of the random positions to the transmitter `tx`.\n\nNote that due to the quantization of the coverage map into cells it is\nnot guaranteed that all above parameters are exactly fulfilled for a\nreturned position. This stems from the fact that every\nindividual cell of the coverage map describes the expected *average*\nbehavior of the surface within this cell. For instance, it may happen\nthat half of the selected cell is shadowed and, thus, no path to the\ntransmitter exists but the average path gain is still larger than the\ngiven threshold. Please use `center_pos` = <cite>True</cite> to sample only\npositions from the cell centers.\n\nThe above figure shows an example for random positions between 220m and\n250m from the transmitter and a `max_gain_db` of -100 dB.\nKeep in mind that the transmitter can have a different height than the\ncoverage map which also contributes to this distance.\nFor example if the transmitter is located 20m above the surface of the\ncoverage map and a `min_dist` of 20m is selected, also positions\ndirectly below the transmitter are sampled.\nInput\n\n- **batch_size** (*int*)  Number of returned random positions\n- **min_gain_db** (*float | None*)  Minimum path gain [dB]. Positions are only sampled from cells where\nthe path gain is larger or equal to this value.\nIgnored if <cite>None</cite>.\nDefaults to <cite>None</cite>.\n- **max_gain_db** (*float | None*)  Maximum path gain [dB]. Positions are only sampled from cells where\nthe path gain is smaller or equal to this value.\nIgnored if <cite>None</cite>.\nDefaults to <cite>None</cite>.\n- **min_dist** (*float | None*)  Minimum distance [m] from transmitter for all random positions.\nIgnored if <cite>None</cite>.\nDefaults to <cite>None</cite>.\n- **max_dist** (*float | None*)  Maximum distance [m] from transmitter for all random positions.\nIgnored if <cite>None</cite>.\nDefaults to <cite>None</cite>.\n- **tx** (*int | str*)  Index or name of the transmitter from whose coverage map\npositions are sampled\n- **center_pos** (*bool*)  If <cite>True</cite>, all returned positions are sampled from the cell center\n(i.e., the grid of the coverage map). Otherwise, the positions are\nrandomly drawn from the surface of the cell.\nDefaults to <cite>False</cite>.\n\n\nOutput\n\n*[batch_size, 3], tf.float*  Random positions $(x,y,z)$ [m] that are in cells fulfilling the\nabove constraints w.r.t. distance and path gain\n\n\n`show`(*`tx``=``0`*, *`vmin``=``None`*, *`vmax``=``None`*, *`show_tx``=``True`*)[`[source]`](../_modules/sionna/rt/coverage_map.html#CoverageMap.show)\n\nVisualizes a coverage map\n\nThe position of the transmitter is indicated by a red + marker.\nInput\n\n- **tx** (*int | str*)  Index or name of the transmitter for which to show the coverage map\nDefaults to 0.\n- **vmin,vmax** (float | <cite>None</cite>)  Define the range of path gains that the colormap covers.\nIf set to <cite>None</cite>, then covers the complete range.\nDefaults to <cite>None</cite>.\n- **show_tx** (*bool*)  If set to <cite>True</cite>, then the position of the transmitter is shown.\nDefaults to <cite>True</cite>.\n\n\nOutput\n\n`Figure`  Figure showing the coverage map\n\n\n`property` `size`\n\nGet the size of the coverage map\nType\n\n[2], tf.float"
"## Cameras\n\nA [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) defines a position and view direction\nfor rendering the scene.\n\nThe [`cameras`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.cameras) property of the [`Scene`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene)\nlist all the cameras currently available for rendering. Cameras can be either\ndefined through the scene file or instantiated using the API.\nThe following code snippet shows how to load a scene and list the available\ncameras:\n```python\nscene = load_scene(sionna.rt.scene.munich)\nprint(scene.cameras)\nscene.render(\"scene-cam-0\") # Use the first camera of the scene for rendering\n```\n\n\nA new camera can be instantiated as follows:\n```python\ncam = Camera(\"mycam\", position=[200., 0.0, 50.])\nscene.add(cam)\ncam.look_at([0.0,0.0,0.0])\nscene.render(cam) # Render using the Camera instance\nscene.render(\"mycam\") # or using the name of the camera\n```"
"### Camera\n\n`class` `sionna.rt.``Camera`(*`name`*, *`position`*, *`orientation``=``[0.,` `0.,` `0.]`*, *`look_at``=``None`*)[`[source]`](../_modules/sionna/rt/camera.html#Camera)\n\nA camera defines a position and view direction for rendering the scene.\n\nIn its local coordinate system, a camera looks toward the positive X-axis\nwith the positive Z-axis being the upward direction.\nInput\n\n- **name** (*str*)  Name.\nCannot be <cite>preview</cite>, as it is reserved for the viewpoint of the\ninteractive viewer.\n- **position** (*[3], float*)  Position $(x,y,z)$ [m] as three-dimensional vector\n- **orientation** (*[3], float*)  Orientation $(\\alpha, \\beta, \\gamma)$ specified\nthrough three angles corresponding to a 3D rotation\nas defined in [(3)](../em_primer.html#equation-rotation).\nThis parameter is ignored if `look_at` is not <cite>None</cite>.\nDefaults to <cite>[0,0,0]</cite>.\n- **look_at** ([3], float | [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter) | [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver) | [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) | None)  A position or instance of [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter),\n[`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver), or [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) to look at.\nIf set to <cite>None</cite>, then `orientation` is used to orientate the camera.\n\n\n`look_at`(*`target`*)[`[source]`](../_modules/sionna/rt/camera.html#Camera.look_at)\n\nSets the orientation so that the camera looks at a position, radio\ndevice, or another camera.\n\nGiven a point $\\mathbf{x}\\in\\mathbb{R}^3$ with spherical angles\n$\\theta$ and $\\varphi$, the orientation of the camera\nwill be set equal to $(\\varphi, \\frac{\\pi}{2}-\\theta, 0.0)$.\nInput\n\n**target** ([3], float | [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter) | [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver) | [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) | str)  A position or the name or instance of a\n[`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter), [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver), or\n[`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) in the scene to look at.\n\n\n`property` `orientation`\n\nGet/set the orientation $(\\alpha, \\beta, \\gamma)$\nspecified through three angles corresponding to a 3D rotation\nas defined in [(3)](../em_primer.html#equation-rotation).\nType\n\n[3], float\n\n\n`property` `position`\n\nGet/set the position $(x,y,z)$ as three-dimensional\nvector\nType\n\n[3], float"
"## Scene Objects\n\nA scene is made of scene objects. Examples include cars, trees,\nbuildings, furniture, etc.\nA scene object is characterized by its geometry and material ([`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial))\nand implemented as an instance of the [`SceneObject`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.SceneObject) class.\n\nScene objects are uniquely identified by their name.\nTo access a scene object, the [`get()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.get) method of\n[`Scene`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene) may be used.\nFor example, the following code snippet shows how to load a scene and list its scene objects:\n```python\nscene = load_scene(sionna.rt.scene.munich)\nprint(scene.objects)\n```\n\n\nTo select an object, e.g., named <cite>Schrannenhalle-itu_metal</cite>, you can run:\n```python\nmy_object = scene.get(\"Schrannenhalle-itu_metal\")\n```\n\n\nYou can then set the [`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial)\nof `my_object` as follows:\n```python\nmy_object.radio_material = \"itu_wood\"\n```\n\n\nMost scene objects names have postfixes of the form -material_name. These are used during loading of a scene\nto assign a [`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial) to each of them. This [tutorial video](https://youtu.be/7xHLDxUaQ7c)\nexplains how you can assign radio materials to objects when you create your own scenes."
"### SceneObject\n\n`class` `sionna.rt.``SceneObject`[`[source]`](../_modules/sionna/rt/scene_object.html#SceneObject)\n\nEvery object in the scene is implemented by an instance of this class\n\n`property` `name`\n\nName\nType\n\nstr (read-only)\n\n\n`property` `radio_material`\n\nGet/set the radio material of the\nobject. Setting can be done by using either an instance of\n[`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial) or the material name (<cite>str</cite>).\nIf the radio material is not part of the scene, it will be added. This\ncan raise an error if a different radio material with the same name was\nalready added to the scene.\nType\n\n[`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial)"
"## Radio Materials\n\nA [`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial) contains everything that is needed to enable the simulation\nof the interaction of a radio wave with an object made of a particular material.\nMore precisely, it consists of the real-valued relative permittivity $\\varepsilon_r$,\nthe conductivity $\\sigma$, and the relative\npermeability $\\mu_r$. For more details, see [(7)](../em_primer.html#equation-epsilon), [(8)](../em_primer.html#equation-mu), [(9)](../em_primer.html#equation-eta).\nThese quantities can possibly depend on the frequency of the incident radio\nwave. Note that Sionna currently only allows non-magnetic materials with $\\mu_r=1$.\n\nAdditionally, a [`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial) can have an effective roughness (ER)\nassociated with it, leading to diffuse reflections (see, e.g., [[Degli-Esposti11]](../em_primer.html#degli-esposti11)).\nThe ER model requires a scattering coefficient $S\\in[0,1]$ [(37)](../em_primer.html#equation-scattering-coefficient),\na cross-polarization discrimination coefficient $K_x$ [(39)](../em_primer.html#equation-xpd), as well as a scattering pattern\n$f_\\text{s}(\\hat{\\mathbf{k}}_\\text{i}, \\hat{\\mathbf{k}}_\\text{s})$ [(40)](../em_primer.html#equation-lambertian-model)[(42)](../em_primer.html#equation-backscattering-model), such as the\n[`LambertianPattern`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.LambertianPattern) or [`DirectivePattern`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.DirectivePattern). The meaning of\nthese parameters is explained in [Scattering](../em_primer.html#scattering).\n\nSimilarly to scene objects ([`SceneObject`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.SceneObject)), all radio\nmaterials are uniquely identified by their name.\nFor example, specifying that a scene object named <cite>wall</cite> is made of the\nmaterial named <cite>itu-brick</cite> is done as follows:"
"```python\nobj = scene.get(\"wall\") # obj is a SceneObject\nobj.radio_material = \"itu_brick\" # \"wall\" is made of \"itu_brick\"\n```\n\n\nSionna provides the\n[ITU models of several materials](https://nvlabs.github.io/sionna/api/rt.html#provided-materials) whose properties\nare automatically updated according to the configured [`frequency`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.frequency).\nIt is also possible to\n[define custom radio materials](https://nvlabs.github.io/sionna/api/rt.html#custom-radio-materials).\n *Radio materials provided with Sionna**\n\nSionna provides the models of all of the materials defined in the ITU-R P.2040-2\nrecommendation [[ITUR_P2040_2]](https://nvlabs.github.io/sionna/api/rt.html#itur-p2040-2). These models are based on curve fitting to\nmeasurement results and assume non-ionized and non-magnetic materials\n($\\mu_r = 1$).\nFrequency dependence is modeled by\n\n$$\n\\begin{split}\\begin{align}\n   \\varepsilon_r &= a f_{\\text{GHz}}^b\\\\\n   \\sigma &= c f_{\\text{GHz}}^d\n\\end{align}\\end{split}\n$$\n\nwhere $f_{\\text{GHz}}$ is the frequency in GHz, and the constants\n$a$, $b$, $c$, and $d$ characterize the material.\nThe table below provides their values which are used in Sionna\n(from [[ITUR_P2040_2]](https://nvlabs.github.io/sionna/api/rt.html#itur-p2040-2)).\nNote that the relative permittivity $\\varepsilon_r$ and\nconductivity $\\sigma$ of all materials are updated automatically when\nthe frequency is set through the scenes property [`frequency`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.frequency).\nMoreover, by default, the scattering coefficient, $S$, of these materials is set to\n0, leading to no diffuse reflection.\n<table class=\"docutils align-default\">\n<colgroup>\n<col style=\"width: 25%\" />\n<col style=\"width: 17%\" />\n<col style=\"width: 15%\" />\n<col style=\"width: 14%\" />\n<col style=\"width: 9%\" />\n<col style=\"width: 21%\" />\n</colgroup>\n<tbody>\n<tr class=\"row-odd\"><td rowspan=\"2\">\nMaterial name</td>\n<td colspan=\"2\">\nReal part of relative permittivity</td>\n<td colspan=\"2\">\nConductivity [S/m]</td>\n<td rowspan=\"2\">\nFrequency range (GHz)</td>\n</tr>\n<tr class=\"row-even\"><td>\na</td>\n<td>\nb</td>\n<td>\nc</td>\n<td>\nd</td>\n</tr>\n<tr class=\"row-odd\"><td>\nvacuum</td>\n<td>\n1</td>\n<td>\n0</td>\n<td>\n0</td>\n<td>\n0</td>\n<td>\n0.001  100</td>\n</tr>\n<tr class=\"row-even\"><td>\nitu_concrete</td>\n<td>\n5.24</td>\n<td>\n0</td>\n<td>\n0.0462</td>\n<td>\n0.7822</td>\n<td>\n1  100</td>\n</tr>\n<tr class=\"row-odd\"><td>\nitu_brick</td>\n<td>\n3.91</td>\n<td>\n0</td>\n<td>\n0.0238</td>\n<td>\n0.16</td>\n<td>\n1  40</td>\n</tr>\n<tr class=\"row-even\"><td>\nitu_plasterboard</td>\n<td>\n2.73</td>\n<td>\n0</td>\n<td>\n0.0085</td>\n<td>\n0.9395</td>\n<td>\n1  100</td>\n</tr>\n<tr class=\"row-odd\"><td>\nitu_wood</td>\n<td>\n1.99</td>\n<td>\n0</td>\n<td>\n0.0047</td>\n<td>\n1.0718</td>\n<td>\n0.001  100</td>\n</tr>\n<tr class=\"row-even\"><td rowspan=\"2\">\nitu_glass</td>\n<td>\n6.31</td>\n<td>\n0</td>\n<td>\n0.0036</td>\n<td>\n1.3394</td>\n<td>\n0.1  100</td>\n</tr>\n<tr class=\"row-odd\"><td>\n5.79</td>\n<td>\n0</td>\n<td>\n0.0004</td>\n<td>\n1.658</td>\n<td>\n220  450</td>\n</tr>\n<tr class=\"row-even\"><td rowspan=\"2\">\nitu_ceiling_board</td>\n<td>\n1.48</td>\n<td>\n0</td>\n<td>\n0.0011</td>\n<td>\n1.0750</td>\n<td>\n1  100</td>\n</tr>\n<tr class=\"row-odd\"><td>\n1.52</td>\n<td>\n0</td>\n<td>\n0.0029</td>\n<td>\n1.029</td>\n<td>\n220  450</td>\n</tr>\n<tr class=\"row-even\"><td>\nitu_chipboard</td>\n<td>\n2.58</td>\n<td>\n0</td>\n<td>\n0.0217</td>\n<td>\n0.7800</td>\n<td>\n1  100</td>\n</tr>\n<tr class=\"row-odd\"><td>\nitu_plywood</td>\n<td>\n2.71</td>\n<td>\n0</td>\n<td>\n0.33</td>\n<td>\n0</td>\n<td>\n1  40</td>\n</tr>\n<tr class=\"row-even\"><td>\nitu_marble</td>\n<td>\n7.074</td>\n<td>\n0</td>\n<td>\n0.0055</td>\n<td>\n0.9262</td>\n<td>\n1  60</td>\n</tr>\n<tr class=\"row-odd\"><td>\nitu_floorboard</td>\n<td>\n3.66</td>\n<td>\n0</td>\n<td>\n0.0044</td>\n<td>\n1.3515</td>\n<td>\n50  100</td>\n</tr>\n<tr class=\"row-even\"><td>\nitu_metal</td>\n<td>\n1</td>\n<td>\n0</td>\n<td>\n$10^7$</td>\n<td>\n0</td>\n<td>\n1  100</td>\n</tr>\n<tr class=\"row-odd\"><td>\nitu_very_dry_ground</td>\n<td>\n3</td>\n<td>\n0</td>\n<td>\n0.00015</td>\n<td>\n2.52</td>\n<td>\n1  10</td>\n</tr>\n<tr class=\"row-even\"><td>\nitu_medium_dry_ground</td>\n<td>\n15</td>\n<td>\n-0.1</td>\n<td>\n0.035</td>\n<td>\n1.63</td>\n<td>\n1  10</td>\n</tr>\n<tr class=\"row-odd\"><td>\nitu_wet_ground</td>\n<td>\n30</td>\n<td>\n-0.4</td>\n<td>\n0.15</td>\n<td>\n1.30</td>\n<td>\n1  10</td>\n</tr>\n</tbody>\n</table>\n *Defining custom radio materials**\n\nCustom radio materials can be implemented using the\n[`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial) class by specifying a relative permittivity\n$\\varepsilon_r$ and conductivity $\\sigma$, as well as optional\nparameters related to diffuse scattering, such as the scattering coefficient $S$,\ncross-polarization discrimination coefficient $K_x$, and scattering pattern $f_\\text{s}(\\hat{\\mathbf{k}}_\\text{i}, \\hat{\\mathbf{k}}_\\text{s})$.\nNote that only non-magnetic materials with $\\mu_r=1$ are currently allowed.\nThe following code snippet shows how to create a custom radio material."
"```python\nload_scene() # Load empty scene\ncustom_material = RadioMaterial(\"my_material\",\n                                relative_permittivity=2.0,\n                                conductivity=5.0,\n                                scattering_coefficient=0.3,\n                                xpd_coefficient=0.1,\n                                scattering_pattern=LambertianPattern())\n```\n\n\nIt is also possible to define the properties of a material through a callback\nfunction that computes the material properties\n$(\\varepsilon_r, \\sigma)$ from the frequency:\n```python\ndef my_material_callback(f_hz):\n   relative_permittivity = compute_relative_permittivity(f_hz)\n   conductivity = compute_conductivity(f_hz)\n   return (relative_permittivity, conductivity)\ncustom_material = RadioMaterial(\"my_material\",\n                                frequency_update_callback=my_material_callback)\nscene.add(custom_material)\n```\n\n\nOnce defined, the custom material can be assigned to a [`SceneObject`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.SceneObject) using its name:\n```python\nobj = scene.get(\"my_object\") # obj is a SceneObject\nobj.radio_material = \"my_material\" # \"my_object\" is made of \"my_material\"\n```\n\n\nor the material instance:\n```python\nobj = scene.get(\"my_object\") # obj is a SceneObject\nobj.radio_material = custom_material # \"my_object\" is made of \"my_material\"\n```\n\n\nThe material parameters can be assigned to TensorFlow variables or tensors, such as\nthe output of a Keras layer defining a neural network. This allows one to make materials\ntrainable:\n```python\nmat = RadioMaterial(\"my_mat\",\n                    relative_permittivity= tf.Variable(2.1, dtype=tf.float32))\nmat.conductivity = tf.Variable(0.0, dtype=tf.float32)\n```"
"### RadioMaterial\n\n`class` `sionna.rt.``RadioMaterial`(*`name`*, *`relative_permittivity``=``1.0`*, *`conductivity``=``0.0`*, *`scattering_coefficient``=``0.0`*, *`xpd_coefficient``=``0.0`*, *`scattering_pattern``=``None`*, *`frequency_update_callback``=``None`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/radio_material.html#RadioMaterial)\n\nClass implementing a radio material\n\nA radio material is defined by its relative permittivity\n$\\varepsilon_r$ and conductivity $\\sigma$ (see [(9)](../em_primer.html#equation-eta)),\nas well as optional parameters related to diffuse scattering, such as the\nscattering coefficient $S$, cross-polarization discrimination\ncoefficient $K_x$, and scattering pattern $f_\\text{s}(\\hat{\\mathbf{k}}_\\text{i}, \\hat{\\mathbf{k}}_\\text{s})$.\n\nWe assume non-ionized and non-magnetic materials, and therefore the\npermeability $\\mu$ of the material is assumed to be equal\nto the permeability of vacuum i.e., $\\mu_r=1.0$.\n\nFor frequency-dependent materials, it is possible to\nspecify a callback function `frequency_update_callback` that computes\nthe material properties $(\\varepsilon_r, \\sigma)$ from the\nfrequency. If a callback function is specified, the material properties\ncannot be set and the values specified at instantiation are ignored.\nThe callback should return <cite>-1</cite> for both the relative permittivity and\nthe conductivity if these are not defined for the given carrier frequency.\n\nThe material properties can be assigned to a TensorFlow variable or\ntensor. In the latter case, the tensor could be the output of a callable,\nsuch as a Keras layer implementing a neural network. In the former case, it\ncould be set to a trainable variable:\n```python\nmat = RadioMaterial(\"my_mat\")\nmat.conductivity = tf.Variable(0.0, dtype=tf.float32)\n```\n\nParameters\n\n- **name** (*str*)  Unique name of the material\n- **relative_permittivity** (float | <cite>None</cite>)  Relative permittivity of the material.\nMust be larger or equal to 1.\nDefaults to 1. Ignored if `frequency_update_callback`\nis provided.\n- **conductivity** (float | <cite>None</cite>)  Conductivity of the material [S/m].\nMust be non-negative.\nDefaults to 0.\nIgnored if `frequency_update_callback`\nis provided.\n- **scattering_coefficient** (*float*)  Scattering coefficient $S\\in[0,1]$ as defined in\n[(37)](../em_primer.html#equation-scattering-coefficient).\nDefaults to 0.\n- **xpd_coefficient** (*float*)  Cross-polarization discrimination coefficient $K_x\\in[0,1]$ as\ndefined in [(39)](../em_primer.html#equation-xpd).\nOnly relevant if `scattering_coefficient`>0.\nDefaults to 0.\n- **scattering_pattern** (*ScatteringPattern*)  `ScatteringPattern` to be applied.\nOnly relevant if `scattering_coefficient`>0.\nDefaults to <cite>None</cite>, which implies a [`LambertianPattern`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.LambertianPattern).\n- **frequency_update_callback** (callable | <cite>None</cite>)\nAn optional callable object used to obtain the material parameters\nfrom the scenes [`frequency`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.frequency).\nThis callable must take as input the frequency [Hz] and\nmust return the material properties as a tuple:\n\n`(relative_permittivity,` `conductivity)`.\n\nIf set to <cite>None</cite>, the material properties are constant and equal\nto `relative_permittivity` and `conductivity`.\nDefaults to <cite>None</cite>.\n\n- **dtype** (*tf.complex64** or **tf.complex128*)  Datatype.\nDefaults to <cite>tf.complex64</cite>.\n\n\n`property` `complex_relative_permittivity`\n\nComplex relative permittivity\n$\\eta$ [(9)](../em_primer.html#equation-eta)\nType\n\ntf.complex (read-only)\n\n\n`property` `conductivity`\n\nGet/set the conductivity\n$\\sigma$ [S/m] [(9)](../em_primer.html#equation-eta)\nType\n\ntf.float\n\n\n`property` `frequency_update_callback`\n\nGet/set frequency update callback function\nType\n\ncallable\n\n\n`property` `is_used`\n\nIndicator if the material is used by at least one object of\nthe scene\nType\n\nbool\n\n\n`property` `name`\n\nName of the radio material\nType\n\nstr (read-only)\n\n\n`property` `relative_permeability`\n\nRelative permeability\n$\\mu_r$ [(8)](../em_primer.html#equation-mu).\nDefaults to 1.\nType\n\ntf.float (read-only)\n\n\n`property` `relative_permittivity`\n\nGet/set the relative permittivity\n$\\varepsilon_r$ [(9)](../em_primer.html#equation-eta)\nType\n\ntf.float\n\n\n`property` `scattering_coefficient`\n\nGet/set the scattering coefficient\n$S\\in[0,1]$ [(37)](../em_primer.html#equation-scattering-coefficient).\nType\n\ntf.float\n\n\n`property` `scattering_pattern`\n\nGet/set the ScatteringPattern.\nType\n\nScatteringPattern\n\n\n`property` `use_counter`\n\nNumber of scene objects using this material\nType\n\nint\n\n\n`property` `using_objects`\n\nIdentifiers of the objects using this\nmaterial\nType\n\n[num_using_objects], tf.int\n\n\n`property` `well_defined`\n\nGet if the material is well-defined\nType\n\nbool\n\n\n`property` `xpd_coefficient`\n\nGet/set the cross-polarization discrimination coefficient\n$K_x\\in[0,1]$ [(39)](../em_primer.html#equation-xpd).\nType\n\ntf.float"
"### ScatteringPattern\n\n`class` `sionna.rt.``LambertianPattern`(*`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/scattering_pattern.html#LambertianPattern)\n\nLambertian scattering model from [[Degli-Esposti07]](../em_primer.html#degli-esposti07) as given in [(40)](../em_primer.html#equation-lambertian-model)\nParameters\n\n**dtype** (*tf.complex64** or **tf.complex128*)  Datatype used for all computations.\nDefaults to <cite>tf.complex64</cite>.\n\nInput\n\n- **k_i** (*[batch_size, 3], dtype.real_dtype*)  Incoming directions\n- **k_s** (*[batch_size,3], dtype.real_dtype*)  Outgoing directions\n\n\nOutput\n\n**pattern** (*[batch_size], dtype.real_dtype*)  Scattering pattern\n\n\n xample\n```python\n>>> LambertianPattern().visualize()\n```\n\n\n`visualize`(*`k_i``=``(0.7071,` `0.0,` `-` `0.7071)`*, *`show_directions``=``False`*)\n\nVisualizes the scattering pattern\n\nIt is assumed that the surface normal points toward the\npositive z-axis.\nInput\n\n- **k_i** (*[3], array_like*)  Incoming direction\n- **show_directions** (*bool*)  If <cite>True</cite>, the incoming and specular reflection directions\nare shown.\nDefaults to <cite>False</cite>.\n\n\nOutput\n\n- `matplotlib.pyplot.Figure`  3D visualization of the scattering pattern\n- `matplotlib.pyplot.Figure`  Visualization of the incident plane cut through\nthe scattering pattern\n\n\n`class` `sionna.rt.``DirectivePattern`(*`alpha_r`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/scattering_pattern.html#DirectivePattern)\n\nDirective scattering model from [[Degli-Esposti07]](../em_primer.html#degli-esposti07) as given in [(41)](../em_primer.html#equation-directive-model)\nParameters\n\n- **alpha_r** (*int**, **[**1**,**2**,**...**]*)  Parameter related to the width of the scattering lobe in the\ndirection of the specular reflection.\n- **dtype** (*tf.complex64** or **tf.complex128*)  Datatype used for all computations.\nDefaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n- **k_i** (*[batch_size, 3], dtype.real_dtype*)  Incoming directions\n- **k_s** (*[batch_size,3], dtype.real_dtype*)  Outgoing directions\n\n\nOutput\n\n**pattern** (*[batch_size], dtype.real_dtype*)  Scattering pattern\n\n\n xample"
"```python\n>>> DirectivePattern(alpha_r=10).visualize()\n```\n\n\n`property` `alpha_r`\n\nGet/set `alpha_r`\nType\n\nbool\n\n\n`visualize`(*`k_i``=``(0.7071,` `0.0,` `-` `0.7071)`*, *`show_directions``=``False`*)\n\nVisualizes the scattering pattern\n\nIt is assumed that the surface normal points toward the\npositive z-axis.\nInput\n\n- **k_i** (*[3], array_like*)  Incoming direction\n- **show_directions** (*bool*)  If <cite>True</cite>, the incoming and specular reflection directions\nare shown.\nDefaults to <cite>False</cite>.\n\n\nOutput\n\n- `matplotlib.pyplot.Figure`  3D visualization of the scattering pattern\n- `matplotlib.pyplot.Figure`  Visualization of the incident plane cut through\nthe scattering pattern\n\n\n`class` `sionna.rt.``BackscatteringPattern`(*`alpha_r`*, *`alpha_i`*, *`lambda_`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/scattering_pattern.html#BackscatteringPattern)\n\nBackscattering model from [[Degli-Esposti07]](../em_primer.html#degli-esposti07) as given in [(42)](../em_primer.html#equation-backscattering-model)\n\nThe parameter `lambda_` can be assigned to a TensorFlow variable\nor tensor.  In the latter case, the tensor can be the output of a callable, such as\na Keras layer implementing a neural network.\nIn the former case, it can be set to a trainable variable:\n```python\nsp = BackscatteringPattern(alpha_r=3,\n                           alpha_i=5,\n                           lambda_=tf.Variable(0.3, dtype=tf.float32))\n```\n\nParameters\n\n- **alpha_r** (*int**, **[**1**,**2**,**...**]*)  Parameter related to the width of the scattering lobe in the\ndirection of the specular reflection.\n- **alpha_i** (*int**, **[**1**,**2**,**...**]*)  Parameter related to the width of the scattering lobe in the\nincoming direction.\n- **lambda** (*float**, **[**0**,**1**]*)  Parameter determining the percentage of the diffusely\nreflected energy in the lobe around the specular reflection.\n- **dtype** (*tf.complex64** or **tf.complex128*)  Datatype used for all computations.\nDefaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n- **k_i** (*[batch_size, 3], dtype.real_dtype*)  Incoming directions\n- **k_s** (*[batch_size,3], dtype.real_dtype*)  Outgoing directions\n\n\nOutput\n\n**pattern** (*[batch_size], dtype.real_dtype*)  Scattering pattern\n\n\n xample"
"```python\n>>> BackscatteringPattern(alpha_r=20, alpha_i=30, lambda_=0.7).visualize()\n```\n\n\n`property` `alpha_i`\n\nGet/set `alpha_i`\nType\n\nbool\n\n\n`property` `alpha_r`\n\nGet/set `alpha_r`\nType\n\nbool\n\n\n`property` `lambda_`\n\nGet/set `lambda_`\nType\n\nbool\n\n\n`visualize`(*`k_i``=``(0.7071,` `0.0,` `-` `0.7071)`*, *`show_directions``=``False`*)\n\nVisualizes the scattering pattern\n\nIt is assumed that the surface normal points toward the\npositive z-axis.\nInput\n\n- **k_i** (*[3], array_like*)  Incoming direction\n- **show_directions** (*bool*)  If <cite>True</cite>, the incoming and specular reflection directions\nare shown.\nDefaults to <cite>False</cite>.\n\n\nOutput\n\n- `matplotlib.pyplot.Figure`  3D visualization of the scattering pattern\n- `matplotlib.pyplot.Figure`  Visualization of the incident plane cut through\nthe scattering pattern"
"## Radio Devices\n\nA radio device refers to a [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter) or [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver) equipped\nwith an [`AntennaArray`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.AntennaArray) as specified by the [`Scene`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene)s properties\n[`tx_array`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.tx_array) and [`rx_array`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.rx_array), respectively.\n\nThe following code snippet shows how to instantiate a [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter)\nequipped with a $4 \\times 2$ [`PlanarArray`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.PlanarArray) with cross-polarized isotropic antennas:\n```python\n scene.tx_array = PlanarArray(num_rows=4,\n                              num_cols=2,\n                              vertical_spacing=0.5,\n                              horizontal_spacing=0.5,\n                              pattern=\"iso\",\n                              polarization=\"cross\")\n my_tx = Transmitter(name=\"my_tx\",\n                     position=(0,0,0),\n                     orientation=(0,0,0))\nscene.add(my_tx)\n```\n\n\nThe position $(x,y,z)$ and orientation $(\\alpha, \\beta, \\gamma)$ of a radio device\ncan be freely configured. The latter is specified through three angles corresponding to a 3D\nrotation as defined in [(3)](../em_primer.html#equation-rotation).\nBoth can be assigned to TensorFlow variables or tensors. In the latter case,\nthe tensor can be the output of a callable, such as a Keras layer implementing a neural network.\nIn the former case, it can be set to a trainable variable.\n\nRadio devices need to be explicitly added to the scene using the scenes method [`add()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.add)\nand can be removed from it using [`remove()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.remove):"
"```python\nscene = load_scene()\nscene.add(Transmitter(\"tx\", [10.0, 0.0, 1.5], [0.0,0.0,0.0]))\nscene.remove(\"tx\")\n```"
"### Transmitter\n\n`class` `sionna.rt.``Transmitter`(*`name`*, *`position`*, *`orientation``=``(0.0,` `0.0,` `0.0)`*, *`look_at``=``None`*, *`color``=``(0.16,` `0.502,` `0.725)`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/transmitter.html#Transmitter)\n\nClass defining a transmitter\n\nThe `position` and `orientation` properties can be assigned to a TensorFlow\nvariable or tensor. In the latter case, the tensor can be the output of a callable,\nsuch as a Keras layer implementing a neural network. In the former case, it\ncan be set to a trainable variable:\n```python\ntx = Transmitter(name=\"my_tx\",\n                 position=tf.Variable([0, 0, 0], dtype=tf.float32),\n                 orientation=tf.Variable([0, 0, 0], dtype=tf.float32))\n```\n\nParameters\n\n- **name** (*str*)  Name\n- **position** (*[**3**]**, **float*)  Position $(x,y,z)$ [m] as three-dimensional vector\n- **orientation** (*[**3**]**, **float*)  Orientation $(\\alpha, \\beta, \\gamma)$ [rad] specified\nthrough three angles corresponding to a 3D rotation\nas defined in [(3)](../em_primer.html#equation-rotation).\nThis parameter is ignored if `look_at` is not <cite>None</cite>.\nDefaults to [0,0,0].\n- **look_at** ([3], float | [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter) | [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver) | [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) | None)  A position or the instance of a [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter),\n[`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver), or [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) to look at.\nIf set to <cite>None</cite>, then `orientation` is used to orientate the device.\n- **color** (*[**3**]**, **float*)  Defines the RGB (red, green, blue) `color` parameter for the device as displayed in the previewer and renderer.\nEach RGB component must have a value within the range $\\in [0,1]$.\nDefaults to <cite>[0.160, 0.502, 0.725]</cite>.\n- **dtype** (*tf.complex*)  Datatype to be used in internal calculations.\nDefaults to <cite>tf.complex64</cite>.\n\n\n`property` `color`\n\nGet/set the the RGB (red, green, blue) color for the device as displayed in the previewer and renderer.\nEach RGB component must have a value within the range $\\in [0,1]$.\nType\n\n[3], float\n\n\n`look_at`(*`target`*)\n\nSets the orientation so that the x-axis points toward a\nposition, radio device, or camera.\n\nGiven a point $\\mathbf{x}\\in\\mathbb{R}^3$ with spherical angles\n$\\theta$ and $\\varphi$, the orientation of the radio device\nwill be set equal to $(\\varphi, \\frac{\\pi}{2}-\\theta, 0.0)$.\nInput\n\n**target** ([3], float | [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter) | [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver) | [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) | str)  A position or the name or instance of a\n[`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter), [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver), or\n[`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) in the scene to look at.\n\n\n`property` `name`\n\nName\nType\n\nstr (read-only)\n\n\n`property` `orientation`\n\nGet/set the orientation\nType\n\n[3], tf.float\n\n\n`property` `position`\n\nGet/set the position\nType\n\n[3], tf.float"
"### Receiver\n\n`class` `sionna.rt.``Receiver`(*`name`*, *`position`*, *`orientation``=``(0.0,` `0.0,` `0.0)`*, *`look_at``=``None`*, *`color``=``(0.153,` `0.682,` `0.375)`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/receiver.html#Receiver)\n\nClass defining a receiver\n\nThe `position` and `orientation` properties can be assigned to a TensorFlow\nvariable or tensor. In the latter case, the tensor can be the output of a callable,\nsuch as a Keras layer implementing a neural network. In the former case, it\ncan be set to a trainable variable:\n```python\nrx = Transmitter(name=\"my_rx\",\n                 position=tf.Variable([0, 0, 0], dtype=tf.float32),\n                 orientation=tf.Variable([0, 0, 0], dtype=tf.float32))\n```\n\nParameters\n\n- **name** (*str*)  Name\n- **position** (*[**3**]**, **float*)  Position $(x,y,z)$ as three-dimensional vector\n- **orientation** (*[**3**]**, **float*)  Orientation $(\\alpha, \\beta, \\gamma)$ [rad] specified\nthrough three angles corresponding to a 3D rotation\nas defined in [(3)](../em_primer.html#equation-rotation).\nThis parameter is ignored if `look_at` is not <cite>None</cite>.\nDefaults to [0,0,0].\n- **look_at** ([3], float | [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter) | [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver) | [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) | None)  A position or the instance of a [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter),\n[`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver), or [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) to look at.\nIf set to <cite>None</cite>, then `orientation` is used to orientate the device.\n- **color** (*[**3**]**, **float*)  Defines the RGB (red, green, blue) `color` parameter for the device as displayed in the previewer and renderer.\nEach RGB component must have a value within the range $\\in [0,1]$.\nDefaults to <cite>[0.153, 0.682, 0.375]</cite>.\n- **dtype** (*tf.complex*)  Datatype to be used in internal calculations.\nDefaults to <cite>tf.complex64</cite>.\n\n\n`property` `color`\n\nGet/set the the RGB (red, green, blue) color for the device as displayed in the previewer and renderer.\nEach RGB component must have a value within the range $\\in [0,1]$.\nType\n\n[3], float\n\n\n`look_at`(*`target`*)\n\nSets the orientation so that the x-axis points toward a\nposition, radio device, or camera.\n\nGiven a point $\\mathbf{x}\\in\\mathbb{R}^3$ with spherical angles\n$\\theta$ and $\\varphi$, the orientation of the radio device\nwill be set equal to $(\\varphi, \\frac{\\pi}{2}-\\theta, 0.0)$.\nInput\n\n**target** ([3], float | [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter) | [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver) | [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) | str)  A position or the name or instance of a\n[`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter), [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver), or\n[`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) in the scene to look at.\n\n\n`property` `name`\n\nName\nType\n\nstr (read-only)\n\n\n`property` `orientation`\n\nGet/set the orientation\nType\n\n[3], tf.float\n\n\n`property` `position`\n\nGet/set the position\nType\n\n[3], tf.float"
"## Antenna Arrays\n\nTransmitters ([`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter)) and receivers ([`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver)) are equipped with an [`AntennaArray`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.AntennaArray) that is composed of one or more antennas. All transmitters and all receivers share the same [`AntennaArray`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.AntennaArray) which can be set through the scene properties [`tx_array`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.tx_array) and [`rx_array`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.rx_array), respectively."
"### AntennaArray\n\n`class` `sionna.rt.``AntennaArray`(*`antenna`*, *`positions`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/antenna_array.html#AntennaArray)\n\nClass implementing an antenna array\n\nAn antenna array is composed of identical antennas that are placed\nat different positions. The `positions` parameter can be assigned\nto a TensorFlow variable or tensor.\n```python\narray = AntennaArray(antenna=Antenna(\"tr38901\", \"V\"),\n                     positions=tf.Variable([[0,0,0], [0, 1, 1]]))\n```\n\nParameters\n\n- **antenna** ([`Antenna`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Antenna))  Antenna instance\n- **positions** (*[**array_size**, **3**]**, **array_like*)  Array of relative positions $(x,y,z)$ [m] of each\nantenna (dual-polarized antennas are counted as a single antenna\nand share the same position).\nThe absolute position of the antennas is obtained by\nadding the position of the [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter)\nor [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver) using it.\n- **dtype** (*tf.complex64** or **tf.complex128*)  Data type used for all computations.\nDefaults to <cite>tf.complex64</cite>.\n\n\n`property` `antenna`\n\nGet/set the antenna\nType\n\n[`Antenna`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Antenna)\n\n\n`property` `array_size`\n\nNumber of antennas in the array.\nDual-polarized antennas are counted as a single antenna.\nType\n\nint (read-only)\n\n\n`property` `num_ant`\n\nNumber of linearly polarized antennas in the array.\nDual-polarized antennas are counted as two linearly polarized\nantennas.\nType\n\nint (read-only)\n\n\n`property` `positions`\n\nGet/set  array of relative positions\n$(x,y,z)$ [m] of each antenna (dual-polarized antennas are\ncounted as a single antenna and share the same position).\nType\n\n[array_size, 3], <cite>tf.float</cite>\n\n\n`rotated_positions`(*`orientation`*)[`[source]`](../_modules/sionna/rt/antenna_array.html#AntennaArray.rotated_positions)\n\nGet the antenna positions rotated according to `orientation`\nInput\n\n**orientation** (*[3], tf.float*)  Orientation $(\\alpha, \\beta, \\gamma)$ [rad] specified\nthrough three angles corresponding to a 3D rotation\nas defined in [(3)](../em_primer.html#equation-rotation).\n\nOutput\n\n*[array_size, 3]*  Rotated positions"
"### PlanarArray\n\n`class` `sionna.rt.``PlanarArray`(*`num_rows`*, *`num_cols`*, *`vertical_spacing`*, *`horizontal_spacing`*, *`pattern`*, *`polarization``=``None`*, *`polarization_model``=``2`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/antenna_array.html#PlanarArray)\n\nClass implementing a planar antenna array\n\nThe antennas are regularly spaced, located in the y-z plane, and\nnumbered column-first from the top-left to bottom-right corner.\nParameters\n\n- **num_rows** (*int*)  Number of rows\n- **num_cols** (*int*)  Number of columns\n- **vertical_spacing** (*float*)  Vertical antenna spacing [multiples of wavelength].\n- **horizontal_spacing** (*float*)  Horizontal antenna spacing [multiples of wavelength].\n- **pattern** (*str**, **callable**, or **length-2 sequence of callables*)  Antenna pattern. Either one of\n[iso, dipole, hw_dipole, tr38901],\nor a callable, or a length-2 sequence of callables defining\nantenna patterns. In the latter case, the antennas are dual\npolarized and each callable defines the antenna pattern\nin one of the two orthogonal polarization directions.\nAn antenna pattern is a callable that takes as inputs vectors of\nzenith and azimuth angles of the same length and returns for each\npair the corresponding zenith and azimuth patterns. See [(14)](../em_primer.html#equation-c) for\nmore detail.\n- **polarization** (*str** or **None*)  Type of polarization. For single polarization, must be V (vertical)\nor H (horizontal). For dual polarization, must be VH or cross.\nOnly needed if `pattern` is a string.\n- **polarization_model** (*int**, **one of** [**1**,**2**]*)  Polarization model to be used. Options <cite>1</cite> and <cite>2</cite>\nrefer to [`polarization_model_1()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.antenna.polarization_model_1)\nand [`polarization_model_2()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.antenna.polarization_model_2),\nrespectively.\nDefaults to <cite>2</cite>.\n- **dtype** (*tf.complex64** or **tf.complex128*)  Datatype used for all computations.\nDefaults to <cite>tf.complex64</cite>.\n\n\n xample"
"```python\narray = PlanarArray(8,4, 0.5, 0.5, \"tr38901\", \"VH\")\narray.show()\n```\n\n\n`property` `antenna`\n\nGet/set the antenna\nType\n\n[`Antenna`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Antenna)\n\n\n`property` `array_size`\n\nNumber of antennas in the array.\nDual-polarized antennas are counted as a single antenna.\nType\n\nint (read-only)\n\n\n`property` `num_ant`\n\nNumber of linearly polarized antennas in the array.\nDual-polarized antennas are counted as two linearly polarized\nantennas.\nType\n\nint (read-only)\n\n\n`property` `positions`\n\nGet/set  array of relative positions\n$(x,y,z)$ [m] of each antenna (dual-polarized antennas are\ncounted as a single antenna and share the same position).\nType\n\n[array_size, 3], <cite>tf.float</cite>\n\n\n`rotated_positions`(*`orientation`*)\n\nGet the antenna positions rotated according to `orientation`\nInput\n\n**orientation** (*[3], tf.float*)  Orientation $(\\alpha, \\beta, \\gamma)$ [rad] specified\nthrough three angles corresponding to a 3D rotation\nas defined in [(3)](../em_primer.html#equation-rotation).\n\nOutput\n\n*[array_size, 3]*  Rotated positions\n\n\n`show`()[`[source]`](../_modules/sionna/rt/antenna_array.html#PlanarArray.show)\n\nVisualizes the antenna array\n\nAntennas are depicted by markers that are annotated with the antenna\nnumber. The marker is not related to the polarization of an antenna.\nOutput\n\n`matplotlib.pyplot.Figure`  Figure depicting the antenna array"
"## Antennas\n\nWe refer the user to the section [Far Field of a Transmitting Antenna](../em_primer.html#far-field) for various useful definitions and background on antenna modeling.\nAn [`Antenna`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Antenna) can be single- or dual-polarized and has for each polarization direction a possibly different antenna pattern.\n\nAn antenna pattern is defined as a function $f:(\\theta,\\varphi)\\mapsto (C_\\theta(\\theta, \\varphi), C_\\varphi(\\theta, \\varphi))$\nthat maps a pair of zenith and azimuth angles to zenith and azimuth pattern values.\nYou can easily define your own pattern or use one of the predefined [patterns](https://nvlabs.github.io/sionna/api/rt.html#patterns) below.\n\nTransmitters ([`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter)) and receivers ([`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver)) are not equipped with an [`Antenna`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Antenna) but an [`AntennaArray`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.AntennaArray) that is composed of one or more antennas. All transmitters in a scene share the same [`AntennaArray`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.AntennaArray) which can be set through the scene property [`tx_array`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.tx_array). The same holds for all receivers whose [`AntennaArray`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.AntennaArray) can be set through [`rx_array`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.rx_array)."
"### Antenna\n\n`class` `sionna.rt.``Antenna`(*`pattern`*, *`polarization``=``None`*, *`polarization_model``=``2`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/antenna.html#Antenna)\n\nClass implementing an antenna\n\nCreates an antenna object with an either predefined or custom antenna\npattern. Can be single or dual polarized.\nParameters\n\n- **pattern** (*str**, **callable**, or **length-2 sequence of callables*)  Antenna pattern. Either one of\n[iso, dipole, hw_dipole, tr38901],\nor a callable, or a length-2 sequence of callables defining\nantenna patterns. In the latter case, the antenna is dual\npolarized and each callable defines the antenna pattern\nin one of the two orthogonal polarization directions.\nAn antenna pattern is a callable that takes as inputs vectors of\nzenith and azimuth angles of the same length and returns for each\npair the corresponding zenith and azimuth patterns.\n- **polarization** (*str** or **None*)  Type of polarization. For single polarization, must be V (vertical)\nor H (horizontal). For dual polarization, must be VH or cross.\nOnly needed if `pattern` is a string.\n- **polarization_model** (*int**, **one of** [**1**,**2**]*)  Polarization model to be used. Options <cite>1</cite> and <cite>2</cite>\nrefer to [`polarization_model_1()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.antenna.polarization_model_1)\nand [`polarization_model_2()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.antenna.polarization_model_2),\nrespectively.\nDefaults to <cite>2</cite>.\n- **dtype** (*tf.complex64** or **tf.complex128*)  Datatype used for all computations.\nDefaults to <cite>tf.complex64</cite>.\n\n\n xample\n```python\n>>> Antenna(\"tr38901\", \"VH\")\n```\n`property` `patterns`\n\nAntenna patterns for one or two\npolarization directions\nType\n\n<cite>list</cite>, <cite>callable</cite>"
"### compute_gain\n\n`sionna.rt.antenna.``compute_gain`(*`pattern`*)[`[source]`](../_modules/sionna/rt/antenna.html#compute_gain)\n\nComputes the directivity, gain, and radiation efficiency of an antenna pattern\n\nGiven a function $f:(\\theta,\\varphi)\\mapsto (C_\\theta(\\theta, \\varphi), C_\\varphi(\\theta, \\varphi))$\ndescribing an antenna pattern [(14)](../em_primer.html#equation-c), this function computes the gain $G$,\ndirectivity $D$, and radiation efficiency $\\eta_\\text{rad}=G/D$\n(see [(12)](../em_primer.html#equation-g) and text below).\nInput\n\n**pattern** (*callable*)  A callable that takes as inputs vectors of zenith and azimuth angles of the same\nlength and returns for each pair the corresponding zenith and azimuth patterns.\n\nOutput\n\n- **D** (*float*)  Directivity $D$\n- **G** (*float*)  Gain $G$\n- **eta_rad** (*float*)  Radiation efficiency $\\eta_\\text{rad}$\n\n\n xamples\n```python\n>>> compute_gain(tr38901_pattern)\n(<tf.Tensor: shape=(), dtype=float32, numpy=9.606758>,\n <tf.Tensor: shape=(), dtype=float32, numpy=6.3095527>,\n <tf.Tensor: shape=(), dtype=float32, numpy=0.65678275>)\n```"
"### visualize\n\n`sionna.rt.antenna.``visualize`(*`pattern`*)[`[source]`](../_modules/sionna/rt/antenna.html#visualize)\n\nVisualizes an antenna pattern\n\nThis function visualizes an antenna pattern with the help of three\nfigures showing the vertical and horizontal cuts as well as a\nthree-dimensional visualization of the antenna gain.\nInput\n\n**pattern** (*callable*)  A callable that takes as inputs vectors of zenith and azimuth angles\nof the same length and returns for each pair the corresponding zenith\nand azimuth patterns.\n\nOutput\n\n- `matplotlib.pyplot.Figure`  Vertical cut of the antenna gain\n- `matplotlib.pyplot.Figure`  Horizontal cut of the antenna gain\n- `matplotlib.pyplot.Figure`  3D visualization of the antenna gain\n\n\n xamples\n```python\n>>> fig_v, fig_h, fig_3d = visualize(hw_dipole_pattern)\n```"
"### dipole_pattern\n\n`sionna.rt.antenna.``dipole_pattern`(*`theta`*, *`phi`*, *`slant_angle``=``0.0`*, *`polarization_model``=``2`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/antenna.html#dipole_pattern)\n\nShort dipole pattern with linear polarizarion (Eq. 4-26a) [[Balanis97]](https://nvlabs.github.io/sionna/api/rt.html#balanis97)\nInput\n\n- **theta** (*array_like, float*)  Zenith angles wrapped within [0,pi] [rad]\n- **phi** (*array_like, float*)  Azimuth angles wrapped within [-pi, pi) [rad]\n- **slant_angle** (*float*)  Slant angle of the linear polarization [rad].\nA slant angle of zero means vertical polarization.\n- **polarization_model** (*int, one of [1,2]*)  Polarization model to be used. Options <cite>1</cite> and <cite>2</cite>\nrefer to [`polarization_model_1()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.antenna.polarization_model_1)\nand [`polarization_model_2()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.antenna.polarization_model_2),\nrespectively.\nDefaults to <cite>2</cite>.\n- **dtype** (*tf.complex64 or tf.complex128*)  Datatype.\nDefaults to <cite>tf.complex64</cite>.\n\n\nOutput\n\n- **c_theta** (*array_like, complex*)  Zenith pattern\n- **c_phi** (*array_like, complex*)  Azimuth pattern"
"### hw_dipole_pattern\n\n`sionna.rt.antenna.``hw_dipole_pattern`(*`theta`*, *`phi`*, *`slant_angle``=``0.0`*, *`polarization_model``=``2`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/antenna.html#hw_dipole_pattern)\n\nHalf-wavelength dipole pattern with linear polarizarion (Eq. 4-84) [[Balanis97]](https://nvlabs.github.io/sionna/api/rt.html#balanis97)\nInput\n\n- **theta** (*array_like, float*)  Zenith angles wrapped within [0,pi] [rad]\n- **phi** (*array_like, float*)  Azimuth angles wrapped within [-pi, pi) [rad]\n- **slant_angle** (*float*)  Slant angle of the linear polarization [rad].\nA slant angle of zero means vertical polarization.\n- **polarization_model** (*int, one of [1,2]*)  Polarization model to be used. Options <cite>1</cite> and <cite>2</cite>\nrefer to [`polarization_model_1()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.antenna.polarization_model_1)\nand [`polarization_model_2()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.antenna.polarization_model_2),\nrespectively.\nDefaults to <cite>2</cite>.\n- **dtype** (*tf.complex64 or tf.complex128*)  Datatype.\nDefaults to <cite>tf.complex64</cite>.\n\n\nOutput\n\n- **c_theta** (*array_like, complex*)  Zenith pattern\n- **c_phi** (*array_like, complex*)  Azimuth pattern"
"### iso_pattern\n\n`sionna.rt.antenna.``iso_pattern`(*`theta`*, *`phi`*, *`slant_angle``=``0.0`*, *`polarization_model``=``2`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/antenna.html#iso_pattern)\n\nIsotropic antenna pattern with linear polarizarion\nInput\n\n- **theta** (*array_like, float*)  Zenith angles wrapped within [0,pi] [rad]\n- **phi** (*array_like, float*)  Azimuth angles wrapped within [-pi, pi) [rad]\n- **slant_angle** (*float*)  Slant angle of the linear polarization [rad].\nA slant angle of zero means vertical polarization.\n- **polarization_model** (*int, one of [1,2]*)  Polarization model to be used. Options <cite>1</cite> and <cite>2</cite>\nrefer to [`polarization_model_1()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.antenna.polarization_model_1)\nand [`polarization_model_2()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.antenna.polarization_model_2),\nrespectively.\nDefaults to <cite>2</cite>.\n- **dtype** (*tf.complex64 or tf.complex128*)  Datatype.\nDefaults to <cite>tf.complex64</cite>.\n\n\nOutput\n\n- **c_theta** (*array_like, complex*)  Zenith pattern\n- **c_phi** (*array_like, complex*)  Azimuth pattern"
"### tr38901_pattern\n\n`sionna.rt.antenna.``tr38901_pattern`(*`theta`*, *`phi`*, *`slant_angle``=``0.0`*, *`polarization_model``=``2`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/antenna.html#tr38901_pattern)\n\nAntenna pattern from 3GPP TR 38.901 (Table 7.3-1) [[TR38901]](channel.wireless.html#tr38901)\nInput\n\n- **theta** (*array_like, float*)  Zenith angles wrapped within [0,pi] [rad]\n- **phi** (*array_like, float*)  Azimuth angles wrapped within [-pi, pi) [rad]\n- **slant_angle** (*float*)  Slant angle of the linear polarization [rad].\nA slant angle of zero means vertical polarization.\n- **polarization_model** (*int, one of [1,2]*)  Polarization model to be used. Options <cite>1</cite> and <cite>2</cite>\nrefer to [`polarization_model_1()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.antenna.polarization_model_1)\nand [`polarization_model_2()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.antenna.polarization_model_2),\nrespectively.\nDefaults to <cite>2</cite>.\n- **dtype** (*tf.complex64 or tf.complex128*)  Datatype.\nDefaults to <cite>tf.complex64</cite>.\n\n\nOutput\n\n- **c_theta** (*array_like, complex*)  Zenith pattern\n- **c_phi** (*array_like, complex*)  Azimuth pattern"
"### polarization_model_1\n\n`sionna.rt.antenna.``polarization_model_1`(*`c_theta`*, *`theta`*, *`phi`*, *`slant_angle`*)[`[source]`](../_modules/sionna/rt/antenna.html#polarization_model_1)\n\nModel-1 for polarized antennas from 3GPP TR 38.901\n\nTransforms a vertically polarized antenna pattern $\\tilde{C}_\\theta(\\theta, \\varphi)$\ninto a linearly polarized pattern whose direction\nis specified by a slant angle $\\zeta$. For example,\n$\\zeta=0$ and $\\zeta=\\pi/2$ correspond\nto vertical and horizontal polarization, respectively,\nand $\\zeta=\\pm \\pi/4$ to a pair of cross polarized\nantenna elements.\n\nThe transformed antenna pattern is given by (7.3-3) [[TR38901]](channel.wireless.html#tr38901):\n\n$$\n\\begin{split}\\begin{align}\n    \\begin{bmatrix}\n        C_\\theta(\\theta, \\varphi) \\\\\n        C_\\varphi(\\theta, \\varphi)\n    \\end{bmatrix} &= \\begin{bmatrix}\n     \\cos(\\psi) \\\\\n     \\sin(\\psi)\n    \\end{bmatrix} \\tilde{C}_\\theta(\\theta, \\varphi)\\\\\n    \\cos(\\psi) &= \\frac{\\cos(\\zeta)\\sin(\\theta)+\\sin(\\zeta)\\sin(\\varphi)\\cos(\\theta)}{\\sqrt{1-\\left(\\cos(\\zeta)\\cos(\\theta)-\\sin(\\zeta)\\sin(\\varphi)\\sin(\\theta)\\right)^2}} \\\\\n    \\sin(\\psi) &= \\frac{\\sin(\\zeta)\\cos(\\varphi)}{\\sqrt{1-\\left(\\cos(\\zeta)\\cos(\\theta)-\\sin(\\zeta)\\sin(\\varphi)\\sin(\\theta)\\right)^2}}\n\\end{align}\\end{split}\n$$\n\nInput\n\n- **c_tilde_theta** (*array_like, complex*)  Zenith pattern\n- **theta** (*array_like, float*)  Zenith angles wrapped within [0,pi] [rad]\n- **phi** (*array_like, float*)  Azimuth angles wrapped within [-pi, pi) [rad]\n- **slant_angle** (*float*)  Slant angle of the linear polarization [rad].\nA slant angle of zero means vertical polarization.\n\n\nOutput\n\n- **c_theta** (*array_like, complex*)  Zenith pattern\n- **c_phi** (*array_like, complex*)  Azimuth pattern"
"### polarization_model_2\n\n`sionna.rt.antenna.``polarization_model_2`(*`c`*, *`slant_angle`*)[`[source]`](../_modules/sionna/rt/antenna.html#polarization_model_2)\n\nModel-2 for polarized antennas from 3GPP TR 38.901\n\nTransforms a vertically polarized antenna pattern $\\tilde{C}_\\theta(\\theta, \\varphi)$\ninto a linearly polarized pattern whose direction\nis specified by a slant angle $\\zeta$. For example,\n$\\zeta=0$ and $\\zeta=\\pi/2$ correspond\nto vertical and horizontal polarization, respectively,\nand $\\zeta=\\pm \\pi/4$ to a pair of cross polarized\nantenna elements.\n\nThe transformed antenna pattern is given by (7.3-4/5) [[TR38901]](channel.wireless.html#tr38901):\n\n$$\n\\begin{split}\\begin{align}\n    \\begin{bmatrix}\n        C_\\theta(\\theta, \\varphi) \\\\\n        C_\\varphi(\\theta, \\varphi)\n    \\end{bmatrix} &= \\begin{bmatrix}\n     \\cos(\\zeta) \\\\\n     \\sin(\\zeta)\n    \\end{bmatrix} \\tilde{C}_\\theta(\\theta, \\varphi)\n\\end{align}\\end{split}\n$$\n\nInput\n\n- **c_tilde_theta** (*array_like, complex*)  Zenith pattern\n- **slant_angle** (*float*)  Slant angle of the linear polarization [rad].\nA slant angle of zero means vertical polarization.\n\n\nOutput\n\n- **c_theta** (*array_like, complex*)  Zenith pattern\n- **c_phi** (*array_like, complex*)  Azimuth pattern"
"### cross\n\n`sionna.rt.``cross`(*`u`*, *`v`*)[`[source]`](../_modules/sionna/rt/utils.html#cross)\n\nComputes the cross (or vector) product between u and v\nInput\n\n- **u** (*[,3]*)  First vector\n- **v** (*[,3]*)  Second vector\n\n\nOutput\n\n*[,3]*  Cross product between `u` and `v`"
"### dot\n\n`sionna.rt.``dot`(*`u`*, *`v`*, *`keepdim``=``False`*, *`clip``=``False`*)[`[source]`](../_modules/sionna/rt/utils.html#dot)\n\nComputes and the dot (or scalar) product between u and v\nInput\n\n- **u** (*[,3]*)  First vector\n- **v** (*[,3]*)  Second vector\n- **keepdim** (*bool*)  If <cite>True</cite>, keep the last dimension.\nDefaults to <cite>False</cite>.\n- **clip** (*bool*)  If <cite>True</cite>, clip output to [-1,1].\nDefaults to <cite>False</cite>.\n\n\nOutput\n\n*[,1] or []*  Dot product between `u` and `v`.\nThe last dimension is removed if `keepdim`\nis set to <cite>False</cite>."
"### normalize\n\n`sionna.rt.``normalize`(*`v`*)[`[source]`](../_modules/sionna/rt/utils.html#normalize)\n\nNormalizes `v` to unit norm\nInput\n\n**v** (*[,3], tf.float*)  Vector\n\nOutput\n\n- *[,3], tf.float*  Normalized vector\n- *[], tf.float*  Norm of the unnormalized vector"
"### phi_hat\n\n`sionna.rt.``phi_hat`(*`phi`*)[`[source]`](../_modules/sionna/rt/utils.html#phi_hat)\n\nComputes the spherical unit vector\n$\\hat{\\boldsymbol{\\varphi}}(\\theta, \\varphi)$\nas defined in [(1)](../em_primer.html#equation-spherical-vecs)\nInput\n\n**phi** (same shape as `theta`, tf.float)  Azimuth angles $\\varphi$ [rad]\n\nOutput\n\n**theta_hat** (`phi.shape` + [3], tf.float)  Vector $\\hat{\\boldsymbol{\\varphi}}(\\theta, \\varphi)$"
"### rotate\n\n`sionna.rt.``rotate`(*`p`*, *`angles`*)[`[source]`](../_modules/sionna/rt/utils.html#rotate)\n\nRotates points `p` by the `angles` according\nto the 3D rotation defined in [(3)](../em_primer.html#equation-rotation)\nInput\n\n- **p** (*[,3], tf.float*)  Points to rotate\n- **angles** (*[, 3]*)  Angles for the rotations [rad].\nThe last dimension corresponds to the angles\n$(\\alpha,\\beta,\\gamma)$ that define\nrotations about the axes $(z, y, x)$,\nrespectively.\n\n\nOutput\n\n*[,3]*  Rotated points `p`"
"### rotation_matrix\n\n`sionna.rt.``rotation_matrix`(*`angles`*)[`[source]`](../_modules/sionna/rt/utils.html#rotation_matrix)\n\nComputes rotation matrices as defined in [(3)](../em_primer.html#equation-rotation)\n\nThe closed-form expression in (7.1-4) [[TR38901]](channel.wireless.html#tr38901) is used.\nInput\n\n**angles** (*[,3], tf.float*)  Angles for the rotations [rad].\nThe last dimension corresponds to the angles\n$(\\alpha,\\beta,\\gamma)$ that define\nrotations about the axes $(z, y, x)$,\nrespectively.\n\nOutput\n\n*[,3,3], tf.float*  Rotation matrices"
"### rot_mat_from_unit_vecs\n\n`sionna.rt.``rot_mat_from_unit_vecs`(*`a`*, *`b`*)[`[source]`](../_modules/sionna/rt/utils.html#rot_mat_from_unit_vecs)\n\nComputes Rodrigues` rotation formula [(6)](../em_primer.html#equation-rodrigues-matrix)\nInput\n\n- **a** (*[,3], tf.float*)  First unit vector\n- **b** (*[,3], tf.float*)  Second unit vector\n\n\nOutput\n\n*[,3,3], tf.float*  Rodrigues rotation matrix"
"### r_hat\n\n`sionna.rt.``r_hat`(*`theta`*, *`phi`*)[`[source]`](../_modules/sionna/rt/utils.html#r_hat)\n\nComputes the spherical unit vetor $\\hat{\\mathbf{r}}(\\theta, \\phi)$\nas defined in [(1)](../em_primer.html#equation-spherical-vecs)\nInput\n\n- **theta** (*arbitrary shape, tf.float*)  Zenith angles $\\theta$ [rad]\n- **phi** (same shape as `theta`, tf.float)  Azimuth angles $\\varphi$ [rad]\n\n\nOutput\n\n**rho_hat** (`phi.shape` + [3], tf.float)  Vector $\\hat{\\mathbf{r}}(\\theta, \\phi)$  on unit sphere"
"### sample_points_on_hemisphere\n\n`sionna.rt.``sample_points_on_hemisphere`(*`normals`*, *`num_samples``=``1`*)[`[source]`](../_modules/sionna/rt/utils.html#sample_points_on_hemisphere)\n\nRandomly sample points on hemispheres defined by their normal vectors\nInput\n\n- **normals** (*[batch_size, 3], tf.float*)  Normal vectors defining hemispheres\n- **num_samples** (*int*)  Number of random samples to draw for each hemisphere\ndefined by its normal vector.\nDefaults to 1.\n\n\nOutput\n\n**points** (*[batch_size, num_samples, 3], tf.float or [batch_size, 3], tf.float if num_samples=1.*)  Random points on the hemispheres"
"### theta_hat\n\n`sionna.rt.``theta_hat`(*`theta`*, *`phi`*)[`[source]`](../_modules/sionna/rt/utils.html#theta_hat)\n\nComputes the spherical unit vector\n$\\hat{\\boldsymbol{\\theta}}(\\theta, \\varphi)$\nas defined in [(1)](../em_primer.html#equation-spherical-vecs)\nInput\n\n- **theta** (*arbitrary shape, tf.float*)  Zenith angles $\\theta$ [rad]\n- **phi** (same shape as `theta`, tf.float)  Azimuth angles $\\varphi$ [rad]\n\n\nOutput\n\n**theta_hat** (`phi.shape` + [3], tf.float)  Vector $\\hat{\\boldsymbol{\\theta}}(\\theta, \\varphi)$"
"### theta_phi_from_unit_vec\n\n`sionna.rt.``theta_phi_from_unit_vec`(*`v`*)[`[source]`](../_modules/sionna/rt/utils.html#theta_phi_from_unit_vec)\n\nComputes zenith and azimuth angles ($\\theta,\\varphi$)\nfrom unit-norm vectors as described in [(2)](../em_primer.html#equation-theta-phi)\nInput\n\n**v** (*[,3], tf.float*)  Tensor with unit-norm vectors in the last dimension\n\nOutput\n\n- **theta** (*[], tf.float*)  Zenith angles $\\theta$\n- **phi** (*[], tf.float*)  Azimuth angles $\\varphi$\n\n\nReferences:\nBalanis97([1](https://nvlabs.github.io/sionna/api/rt.html#id21),[2](https://nvlabs.github.io/sionna/api/rt.html#id22))\n<ol class=\"upperalpha simple\">\n- Balanis, Antenna Theory: Analysis and Design, 2nd Edition, John Wiley & Sons, 1997.\n</ol>\n\nITUR_P2040_2([1](https://nvlabs.github.io/sionna/api/rt.html#id16),[2](https://nvlabs.github.io/sionna/api/rt.html#id17))\n\nITU-R, Effects of building materials and structures on radiowave propagation above about 100 MHz, Recommendation ITU-R P.2040-2\n\n[SurfaceIntegral](https://nvlabs.github.io/sionna/api/rt.html#id2)\n\nWikipedia, [Surface integral](https://en.wikipedia.org/wiki/Surface_integral), accessed Jun. 22, 2023."

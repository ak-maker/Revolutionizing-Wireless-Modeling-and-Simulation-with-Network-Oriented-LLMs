"# Part 4: Toward Learned Receivers\n\nThis tutorial will guide you through Sionna, from its basic principles to the implementation of a point-to-point link with a 5G NR compliant code and a 3GPP channel model. You will also learn how to write custom trainable layers by implementing a state of the art neural receiver, and how to train and evaluate end-to-end communication systems.\n\nThe tutorial is structured in four notebooks:\n\n- Part I: Getting started with Sionna\n- Part II: Differentiable Communication Systems\n- Part III: Advanced Link-level Simulations\n- **Part IV: Toward Learned Receivers**\n\n\nThe [official documentation](https://nvlabs.github.io/sionna) provides key material on how to use Sionna and how its components are implemented."
"## Imports\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna as sn\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna as sn\n# Import TensorFlow and NumPy\nimport tensorflow as tf\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\nimport numpy as np\n# For saving complex Python data structures efficiently\nimport pickle\n# For plotting\n%matplotlib inline\nimport matplotlib.pyplot as plt\n# For the implementation of the neural receiver\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Layer, Conv2D, LayerNormalization\nfrom tensorflow.nn import relu\n```"
"## Simulation Parameters\n\n\n```python\n# Bit per channel use\nNUM_BITS_PER_SYMBOL = 2 # QPSK\n# Minimum value of Eb/N0 [dB] for simulations\nEBN0_DB_MIN = -3.0\n# Maximum value of Eb/N0 [dB] for simulations\nEBN0_DB_MAX = 5.0\n# How many examples are processed by Sionna in parallel\nBATCH_SIZE = 128\n# Coding rate\nCODERATE = 0.5\n# Define the number of UT and BS antennas\nNUM_UT = 1\nNUM_BS = 1\nNUM_UT_ANT = 1\nNUM_BS_ANT = 2\n# The number of transmitted streams is equal to the number of UT antennas\n# in both uplink and downlink\nNUM_STREAMS_PER_TX = NUM_UT_ANT\n# Create an RX-TX association matrix.\n# RX_TX_ASSOCIATION[i,j]=1 means that receiver i gets at least one stream\n# from transmitter j. Depending on the transmission direction (uplink or downlink),\n# the role of UT and BS can change.\n# For example, considering a system with 2 RX and 4 TX, the RX-TX\n# association matrix could be\n# [ [1 , 1, 0, 0],\n#   [0 , 0, 1, 1] ]\n# which indicates that the RX 0 receives from TX 0 and 1, and RX 1 receives from\n# TX 2 and 3.\n#\n# In this notebook, as we have only a single transmitter and receiver,\n# the RX-TX association matrix is simply:\nRX_TX_ASSOCIATION = np.array([[1]])\n# Instantiate a StreamManagement object\n# This determines which data streams are determined for which receiver.\n# In this simple setup, this is fairly easy. However, it can get more involved\n# for simulations with many transmitters and receivers.\nSTREAM_MANAGEMENT = sn.mimo.StreamManagement(RX_TX_ASSOCIATION, NUM_STREAMS_PER_TX)\nRESOURCE_GRID = sn.ofdm.ResourceGrid( num_ofdm_symbols=14,\n                                      fft_size=76,\n                                      subcarrier_spacing=30e3,\n                                      num_tx=NUM_UT,\n                                      num_streams_per_tx=NUM_STREAMS_PER_TX,\n                                      cyclic_prefix_length=6,\n                                      pilot_pattern=\"kronecker\",\n                                      pilot_ofdm_symbol_indices=[2,11])\n# Carrier frequency in Hz.\nCARRIER_FREQUENCY = 2.6e9\n# Antenna setting\nUT_ARRAY = sn.channel.tr38901.Antenna(  polarization=\"single\",\n                                        polarization_type=\"V\",\n                                        antenna_pattern=\"38.901\",\n                                        carrier_frequency=CARRIER_FREQUENCY)\nBS_ARRAY = sn.channel.tr38901.AntennaArray( num_rows=1,\n                                            num_cols=int(NUM_BS_ANT/2),\n                                            polarization=\"dual\",\n                                            polarization_type=\"cross\",\n                                            antenna_pattern=\"38.901\", # Try 'omni'\n                                            carrier_frequency=CARRIER_FREQUENCY)\n# Nominal delay spread in [s]. Please see the CDL documentation\n# about how to choose this value.\nDELAY_SPREAD = 100e-9\n# The `direction` determines if the UT or BS is transmitting.\n# In the `uplink`, the UT is transmitting.\nDIRECTION = \"uplink\"\n# Suitable values are [\"A\", \"B\", \"C\", \"D\", \"E\"]\nCDL_MODEL = \"C\"\n# UT speed [m/s]. BSs are always assumed to be fixed.\n# The direction of travel will chosen randomly within the x-y plane.\nSPEED = 10.0\n# Configure a channel impulse reponse (CIR) generator for the CDL model.\nCDL = sn.channel.tr38901.CDL(CDL_MODEL,\n                             DELAY_SPREAD,\n                             CARRIER_FREQUENCY,\n                             UT_ARRAY,\n                             BS_ARRAY,\n                             DIRECTION,\n                             min_speed=SPEED)\n```"
"## Implemention of an Advanced Neural Receiver\n\nWe will implement a state-of-the-art neural receiver that operates over the entire resource grid of received symbols.\n\nThe neural receiver computes LLRs on the coded bits from the received resource grid of frequency-domain baseband symbols.\n\n\nAs shown in the following figure, the neural receiver substitutes to the channel estimator, equalizer, and demapper.\n\n\nAs in [1] and [2], a neural receiver using residual convolutional layers is implemented.\n\nConvolutional layers are leveraged to efficienly process the 2D resource grid that is fed as an input to the neural receiver.\n\nResidual (skip) connections are used to avoid gradient vanishing [3].\n\nFor convenience, a Keras layer that implements a *residual block* is first defined. The Keras layer that implements the neural receiver is built by stacking such blocks. The following figure shows the architecture of the neural receiver.\n\n\n```python\nclass ResidualBlock(Layer):\n    def __init__(self):\n        super().__init__()\n        # Layer normalization is done over the last three dimensions: time, frequency, conv 'channels'\n        self._layer_norm_1 = LayerNormalization(axis=(-1, -2, -3))\n        self._conv_1 = Conv2D(filters=128,\n                              kernel_size=[3,3],\n                              padding='same',\n                              activation=None)\n        # Layer normalization is done over the last three dimensions: time, frequency, conv 'channels'\n        self._layer_norm_2 = LayerNormalization(axis=(-1, -2, -3))\n        self._conv_2 = Conv2D(filters=128,\n                              kernel_size=[3,3],\n                              padding='same',\n                              activation=None)\n    def call(self, inputs):\n        z = self._layer_norm_1(inputs)\n        z = relu(z)\n        z = self._conv_1(z)\n        z = self._layer_norm_2(z)\n        z = relu(z)\n        z = self._conv_2(z) # [batch size, num time samples, num subcarriers, num_channels]\n        # Skip connection\n        z = z + inputs\n        return z\nclass NeuralReceiver(Layer):\n    def __init__(self):\n        super().__init__()\n        # Input convolution\n        self._input_conv = Conv2D(filters=128,\n                                  kernel_size=[3,3],\n                                  padding='same',\n                                  activation=None)\n        # Residual blocks\n        self._res_block_1 = ResidualBlock()\n        self._res_block_2 = ResidualBlock()\n        self._res_block_3 = ResidualBlock()\n        self._res_block_4 = ResidualBlock()\n        # Output conv\n        self._output_conv = Conv2D(filters=NUM_BITS_PER_SYMBOL,\n                                   kernel_size=[3,3],\n                                   padding='same',\n                                   activation=None)\n    def call(self, inputs):\n        y, no = inputs\n        # Assuming a single receiver, remove the num_rx dimension\n        y = tf.squeeze(y, axis=1)\n        # Feeding the noise power in log10 scale helps with the performance\n        no = sn.utils.log10(no)\n        # Stacking the real and imaginary components of the different antennas along the 'channel' dimension\n        y = tf.transpose(y, [0, 2, 3, 1]) # Putting antenna dimension last\n        no = sn.utils.insert_dims(no, 3, 1)\n        no = tf.tile(no, [1, y.shape[1], y.shape[2], 1])\n        # z : [batch size, num ofdm symbols, num subcarriers, 2*num rx antenna + 1]\n        z = tf.concat([tf.math.real(y),\n                       tf.math.imag(y),\n                       no], axis=-1)\n        # Input conv\n        z = self._input_conv(z)\n        # Residual blocks\n        z = self._res_block_1(z)\n        z = self._res_block_2(z)\n        z = self._res_block_3(z)\n        z = self._res_block_4(z)\n        # Output conv\n        z = self._output_conv(z)\n        # Reshape the input to fit what the resource grid demapper is expected\n        z = sn.utils.insert_dims(z, 2, 1)\n        return z\n```"
"The task of the receiver is to jointly solve, for each resource element, `NUM_BITS_PER_SYMBOL` binary classification problems in order to reconstruct the transmitted bits. Therefore, a natural choice for the loss function is the *binary cross-entropy* (BCE) applied to each bit and to each received symbol.\n\n*Remark:* The LLRs computed by the demapper are *logits* on the transmitted bits, and can therefore be used as-is to compute the BCE without any additional processing. *Remark 2:* The BCE is closely related to an achieveable information rate for bit-interleaved coded modulation systems [4,5]\n\nThe next cell defines an end-to-end communication system using the neural receiver layer.\n\nAt initialization, the paramater `training` indicates if the system is instantiated to be trained (`True`) or evaluated (`False`).\n\nIf the system is instantiated to be trained, the outer encoder and decoder are not used as they are not required for training. Moreover, the estimated BCE is returned. This significantly reduces the computational complexity of training.\n\nIf the system is instantiated to be evaluated, the outer encoder and decoder are used, and the transmited information and corresponding LLRs are returned.\n\n\n```python\nclass OFDMSystemNeuralReceiver(Model): # Inherits from Keras Model\n    def __init__(self, training):\n        super().__init__() # Must call the Keras model initializer\n        self.training = training\n        n = int(RESOURCE_GRID.num_data_symbols*NUM_BITS_PER_SYMBOL) # Number of coded bits\n        k = int(n*CODERATE) # Number of information bits\n        self.k = k\n        self.n = n\n        # The binary source will create batches of information bits\n        self.binary_source = sn.utils.BinarySource()\n        # The encoder maps information bits to coded bits\n        self.encoder = sn.fec.ldpc.LDPC5GEncoder(k, n)\n        # The mapper maps blocks of information bits to constellation symbols\n        self.mapper = sn.mapping.Mapper(\"qam\", NUM_BITS_PER_SYMBOL)\n        # The resource grid mapper maps symbols onto an OFDM resource grid\n        self.rg_mapper = sn.ofdm.ResourceGridMapper(RESOURCE_GRID)\n        # Frequency domain channel\n        self.channel = sn.channel.OFDMChannel(CDL, RESOURCE_GRID, add_awgn=True, normalize_channel=True, return_channel=False)\n        # Neural receiver\n        self.neural_receiver = NeuralReceiver()\n        # Used to extract data-carrying resource elements\n        self.rg_demapper = sn.ofdm.ResourceGridDemapper(RESOURCE_GRID, STREAM_MANAGEMENT)\n        # The decoder provides hard-decisions on the information bits\n        self.decoder = sn.fec.ldpc.LDPC5GDecoder(self.encoder, hard_out=True)\n        # Loss function\n        self.bce = tf.keras.losses.BinaryCrossentropy(from_logits=True) # Loss function\n    @tf.function # Graph execution to speed things up\n    def __call__(self, batch_size, ebno_db):\n        no = sn.utils.ebnodb2no(ebno_db, num_bits_per_symbol=NUM_BITS_PER_SYMBOL, coderate=CODERATE, resource_grid=RESOURCE_GRID)\n        # The neural receiver is expected no to have shape [batch_size].\n        if len(no.shape) == 0:\n            no = tf.fill([batch_size], no)\n        # Transmitter\n        # Outer coding is only performed if not training\n        if self.training:\n            codewords = self.binary_source([batch_size, NUM_UT, NUM_UT_ANT, self.n])\n        else:\n            bits = self.binary_source([batch_size, NUM_UT, NUM_UT_ANT, self.k])\n            codewords = self.encoder(bits)\n        x = self.mapper(codewords)\n        x_rg = self.rg_mapper(x)\n        # Channel\n        y = self.channel([x_rg, no])\n        # Receiver\n        llr = self.neural_receiver([y, no])\n        llr = self.rg_demapper(llr) # Extract data-carrying resource elements. The other LLrs are discarded\n        llr = tf.reshape(llr, [batch_size, NUM_UT, NUM_UT_ANT, self.n]) # Reshape the LLRs to fit what the outer decoder is expected\n        if self.training:\n            loss = self.bce(codewords, llr)\n            return loss\n        else:\n            bits_hat = self.decoder(llr)\n            return bits, bits_hat\n```"
"## Training the Neural Receiver\n\nThe next cell implements a training loop of `NUM_TRAINING_ITERATIONS` iterations.\n\nAt each iteration: - A batch of SNRs $E_b/N_0$ is sampled - A forward pass through the end-to-end system is performed within a gradient tape - The gradients are computed using the gradient tape, and applied using the Adam optimizer - A progress bar is periodically updated to follow the progress of training\n\nAfter training, the weights of the models are saved in a file using [pickle](https://docs.python.org/3/library/pickle.html).\n\n```python\n[ ]:\n```\n\n```python\n# Set a seed for reproducibility\ntf.random.set_seed(1)\n# Number of iterations used for training\nNUM_TRAINING_ITERATIONS = 100000\n# Instantiating the end-to-end model for training\nmodel = OFDMSystemNeuralReceiver(training=True)\n# Adam optimizer (SGD variant)\noptimizer = tf.keras.optimizers.Adam()\n# Training loop\nfor i in range(NUM_TRAINING_ITERATIONS):\n    # Sample a batch of SNRs.\n    ebno_db = tf.random.uniform(shape=[BATCH_SIZE], minval=EBN0_DB_MIN, maxval=EBN0_DB_MAX)\n    # Forward pass\n    with tf.GradientTape() as tape:\n        loss = model(BATCH_SIZE, ebno_db)\n    # Computing and applying gradients\n    weights = model.trainable_weights\n    grads = tape.gradient(loss, weights)\n    optimizer.apply_gradients(zip(grads, weights))\n    # Print progress\n    if i % 100 == 0:\n        print(f\"{i}/{NUM_TRAINING_ITERATIONS}  Loss: {loss:.2E}\", end=\"\\r\")\n# Save the weightsin a file\nweights = model.get_weights()\nwith open('weights-ofdm-neuralrx', 'wb') as f:\n    pickle.dump(weights, f)\n```"
"## Benchmarking the Neural Receiver\n\nWe evaluate the trained model and benchmark it against the previously introduced baselines.\n\nWe first define and evaluate the baselines.\n\n\n```python\nclass OFDMSystem(Model): # Inherits from Keras Model\n    def __init__(self, perfect_csi):\n        super().__init__() # Must call the Keras model initializer\n        self.perfect_csi = perfect_csi\n        n = int(RESOURCE_GRID.num_data_symbols*NUM_BITS_PER_SYMBOL) # Number of coded bits\n        k = int(n*CODERATE) # Number of information bits\n        self.k = k\n        # The binary source will create batches of information bits\n        self.binary_source = sn.utils.BinarySource()\n        # The encoder maps information bits to coded bits\n        self.encoder = sn.fec.ldpc.LDPC5GEncoder(k, n)\n        # The mapper maps blocks of information bits to constellation symbols\n        self.mapper = sn.mapping.Mapper(\"qam\", NUM_BITS_PER_SYMBOL)\n        # The resource grid mapper maps symbols onto an OFDM resource grid\n        self.rg_mapper = sn.ofdm.ResourceGridMapper(RESOURCE_GRID)\n        # Frequency domain channel\n        self.channel = sn.channel.OFDMChannel(CDL, RESOURCE_GRID, add_awgn=True, normalize_channel=True, return_channel=True)\n        # The LS channel estimator will provide channel estimates and error variances\n        self.ls_est = sn.ofdm.LSChannelEstimator(RESOURCE_GRID, interpolation_type=\"nn\")\n        # The LMMSE equalizer will provide soft symbols together with noise variance estimates\n        self.lmmse_equ = sn.ofdm.LMMSEEqualizer(RESOURCE_GRID, STREAM_MANAGEMENT)\n        # The demapper produces LLR for all coded bits\n        self.demapper = sn.mapping.Demapper(\"app\", \"qam\", NUM_BITS_PER_SYMBOL)\n        # The decoder provides hard-decisions on the information bits\n        self.decoder = sn.fec.ldpc.LDPC5GDecoder(self.encoder, hard_out=True)\n    @tf.function # Graph execution to speed things up\n    def __call__(self, batch_size, ebno_db):\n        no = sn.utils.ebnodb2no(ebno_db, num_bits_per_symbol=NUM_BITS_PER_SYMBOL, coderate=CODERATE, resource_grid=RESOURCE_GRID)\n        # Transmitter\n        bits = self.binary_source([batch_size, NUM_UT, RESOURCE_GRID.num_streams_per_tx, self.k])\n        codewords = self.encoder(bits)\n        x = self.mapper(codewords)\n        x_rg = self.rg_mapper(x)\n        # Channel\n        y, h_freq = self.channel([x_rg, no])\n        # Receiver\n        if self.perfect_csi:\n            h_hat, err_var = h_freq, 0.\n        else:\n            h_hat, err_var = self.ls_est ([y, no])\n        x_hat, no_eff = self.lmmse_equ([y, h_hat, err_var, no])\n        llr = self.demapper([x_hat, no_eff])\n        bits_hat = self.decoder(llr)\n        return bits, bits_hat\n```"
"```python\nber_plots = sn.utils.PlotBER(\"Advanced neural receiver\")\nbaseline_ls = OFDMSystem(False)\nber_plots.simulate(baseline_ls,\n                  ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 20),\n                  batch_size=BATCH_SIZE,\n                  num_target_block_errors=100, # simulate until 100 block errors occured\n                  legend=\"Baseline: LS Estimation\",\n                  soft_estimates=True,\n                  max_mc_iter=100, # run 100 Monte-Carlo simulations (each with batch_size samples)\n                  show_fig=False);\nbaseline_pcsi = OFDMSystem(True)\nber_plots.simulate(baseline_pcsi,\n                  ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 20),\n                  batch_size=BATCH_SIZE,\n                  num_target_block_errors=100, # simulate until 100 block errors occured\n                  legend=\"Baseline: Perfect CSI\",\n                  soft_estimates=True,\n                  max_mc_iter=100, # run 100 Monte-Carlo simulations (each with batch_size samples)\n                  show_fig=False);\n```\n\n\n```python\nWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\nInstructions for updating:\nThe `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -3.0 | 3.6894e-01 | 1.0000e+00 |       43069 |      116736 |          128 |         128 |         7.7 |reached target block errors\n   -2.579 | 3.5806e-01 | 1.0000e+00 |       41799 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -2.158 | 3.4527e-01 | 1.0000e+00 |       40305 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -1.737 | 3.3213e-01 | 1.0000e+00 |       38771 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -1.316 | 3.2260e-01 | 1.0000e+00 |       37659 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -0.895 | 3.0787e-01 | 1.0000e+00 |       35940 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -0.474 | 2.9344e-01 | 1.0000e+00 |       34255 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -0.053 | 2.7841e-01 | 1.0000e+00 |       32501 |      116736 |          128 |         128 |         0.2 |reached target block errors\n    0.368 | 2.6109e-01 | 1.0000e+00 |       30479 |      116736 |          128 |         128 |         0.2 |reached target block errors\n    0.789 | 2.4077e-01 | 1.0000e+00 |       28107 |      116736 |          128 |         128 |         0.2 |reached target block errors\n    1.211 | 2.2460e-01 | 1.0000e+00 |       26219 |      116736 |          128 |         128 |         0.2 |reached target block errors\n    1.632 | 1.9116e-01 | 1.0000e+00 |       22315 |      116736 |          128 |         128 |         0.2 |reached target block errors\n    2.053 | 1.5909e-01 | 1.0000e+00 |       18572 |      116736 |          128 |         128 |         0.2 |reached target block errors\n    2.474 | 9.3930e-02 | 8.6719e-01 |       10965 |      116736 |          111 |         128 |         0.2 |reached target block errors\n    2.895 | 2.1987e-02 | 3.8281e-01 |        7700 |      350208 |          147 |         384 |         0.5 |reached target block errors\n    3.316 | 1.5316e-03 | 4.2352e-02 |        3397 |     2217984 |          103 |        2432 |         2.9 |reached target block errors\n    3.737 | 1.1607e-04 | 1.6406e-03 |        1355 |    11673600 |           21 |       12800 |        15.5 |reached max iter\n    4.158 | 0.0000e+00 | 0.0000e+00 |           0 |    11673600 |            0 |       12800 |        15.5 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 4.2 dB.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -3.0 | 2.1695e-01 | 1.0000e+00 |       25326 |      116736 |          128 |         128 |         3.4 |reached target block errors\n   -2.579 | 1.9826e-01 | 1.0000e+00 |       23144 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -2.158 | 1.7926e-01 | 1.0000e+00 |       20926 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -1.737 | 1.3810e-01 | 1.0000e+00 |       16121 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -1.316 | 7.1966e-02 | 8.7500e-01 |        8401 |      116736 |          112 |         128 |         0.2 |reached target block errors\n   -0.895 | 1.6267e-02 | 3.6719e-01 |        5697 |      350208 |          141 |         384 |         0.5 |reached target block errors\n   -0.474 | 6.2963e-04 | 2.8181e-02 |        2058 |     3268608 |          101 |        3584 |         4.3 |reached target block errors\n   -0.053 | 4.5916e-05 | 8.5938e-04 |         536 |    11673600 |           11 |       12800 |        15.4 |reached max iter\n    0.368 | 2.9126e-05 | 1.5625e-04 |         340 |    11673600 |            2 |       12800 |        15.4 |reached max iter\n    0.789 | 1.5676e-05 | 7.8125e-05 |         183 |    11673600 |            1 |       12800 |        15.4 |reached max iter\n    1.211 | 0.0000e+00 | 0.0000e+00 |           0 |    11673600 |            0 |       12800 |        15.5 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 1.2 dB.\n\n```"
"We then instantiate and evaluate the end-to-end system equipped with the neural receiver.\n\n\n```python\n# Instantiating the end-to-end model for evaluation\nmodel_neuralrx = OFDMSystemNeuralReceiver(training=False)\n# Run one inference to build the layers and loading the weights\nmodel_neuralrx(tf.constant(1, tf.int32), tf.constant(10.0, tf.float32))\nwith open('weights-ofdm-neuralrx', 'rb') as f:\n    weights = pickle.load(f)\n    model_neuralrx.set_weights(weights)\n```\n\n```python\n# Computing and plotting BER\nber_plots.simulate(model_neuralrx,\n                  ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 20),\n                  batch_size=BATCH_SIZE,\n                  num_target_block_errors=100,\n                  legend=\"Neural Receiver\",\n                  soft_estimates=True,\n                  max_mc_iter=100,\n                  show_fig=True);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -3.0 | 2.2083e-01 | 1.0000e+00 |       25779 |      116736 |          128 |         128 |         0.3 |reached target block errors\n   -2.579 | 2.0480e-01 | 1.0000e+00 |       23907 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -2.158 | 1.8219e-01 | 1.0000e+00 |       21268 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -1.737 | 1.4852e-01 | 1.0000e+00 |       17338 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -1.316 | 9.0503e-02 | 9.4531e-01 |       10565 |      116736 |          121 |         128 |         0.2 |reached target block errors\n   -0.895 | 2.2251e-02 | 4.4922e-01 |        5195 |      233472 |          115 |         256 |         0.3 |reached target block errors\n   -0.474 | 1.7106e-03 | 6.4303e-02 |        2596 |     1517568 |          107 |        1664 |         2.2 |reached target block errors\n   -0.053 | 1.4828e-04 | 3.2812e-03 |        1731 |    11673600 |           42 |       12800 |        16.6 |reached max iter\n    0.368 | 6.3305e-05 | 6.2500e-04 |         739 |    11673600 |            8 |       12800 |        16.5 |reached max iter\n    0.789 | 8.6520e-06 | 1.5625e-04 |         101 |    11673600 |            2 |       12800 |        16.5 |reached max iter\n    1.211 | 4.2832e-07 | 7.8125e-05 |           5 |    11673600 |            1 |       12800 |        16.6 |reached max iter\n    1.632 | 0.0000e+00 | 0.0000e+00 |           0 |    11673600 |            0 |       12800 |        16.5 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 1.6 dB.\n\n```"
"## Conclusion\n\nWe hope you are excited about Sionna - there is much more to be discovered:\n\n- TensorBoard debugging available\n- Scaling to multi-GPU simulation is simple\n- See the [available tutorials](https://nvlabs.github.io/sionna/tutorials.html) for more examples\n\n\nAnd if something is still missing - the project is open-source: you can modify, add, and extend any component at any time.\n\nTo get started you can use the `pip` installer:\n\n```python\n[ ]:\n```\n\n```python\n!pip install sionna\n```"
"## References\n\n[1] [M. Honkala, D. Korpi and J. M. J. Huttunen, DeepRx: Fully Convolutional Deep Learning Receiver, in IEEE Transactions on Wireless Communications, vol.20, no. 6, pp.3925-3940, June 2021, doi: 10.1109/TWC.2021.3054520](https://ieeexplore.ieee.org/abstract/document/9345504).\n\n[2] [F. Ait Aoudia and J. Hoydis, End-to-end Learning for OFDM: From Neural Receivers to Pilotless Communication, in IEEE Transactions on Wireless Communications, doi: 10.1109/TWC.2021.3101364](https://ieeexplore.ieee.org/abstract/document/9508784).\n\n[3] [Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Deep Residual Learning for Image Recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp.770-778](https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html)\n[3] [Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Deep Residual Learning for Image Recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp.770-778](https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html)\n[3] [Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Deep Residual Learning for Image Recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp.770-778](https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html)"

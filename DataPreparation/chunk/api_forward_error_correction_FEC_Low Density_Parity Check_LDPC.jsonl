"# Low-Density Parity-Check (LDPC)\n\nThe low-density parity-check (LDPC) code module supports 5G compliant LDPC codes and allows iterative belief propagation (BP) decoding.\nFurther, the module supports rate-matching for 5G and provides a generic linear encoder.\n\nThe following code snippets show how to setup and run a rate-matched 5G compliant LDPC encoder and a corresponding belief propagation (BP) decoder.\n\nFirst, we need to create instances of [`LDPC5GEncoder`](https://nvlabs.github.io/sionna/api/fec.ldpc.html#sionna.fec.ldpc.encoding.LDPC5GEncoder) and [`LDPC5GDecoder`](https://nvlabs.github.io/sionna/api/fec.ldpc.html#sionna.fec.ldpc.decoding.LDPC5GDecoder):\n```python\nencoder = LDPC5GEncoder(k                 = 100, # number of information bits (input)\n                        n                 = 200) # number of codeword bits (output)\n\ndecoder = LDPC5GDecoder(encoder           = encoder,\n                        num_iter          = 20, # number of BP iterations\n                        return_infobits   = True)\n```\n\n\nNow, the encoder and decoder can be used by:\n```python\n# --- encoder ---\n# u contains the information bits to be encoded and has shape [...,k].\n# c contains the polar encoded codewords and has shape [...,n].\nc = encoder(u)\n# --- decoder ---\n# llr contains the log-likelihood ratios from the demapper and has shape [...,n].\n# u_hat contains the estimated information bits and has shape [...,k].\nu_hat = decoder(llr)\n```"
"### LDPC5GEncoder\n\n`class` `sionna.fec.ldpc.encoding.``LDPC5GEncoder`(*`k`*, *`n`*, *`num_bits_per_symbol``=``None`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/ldpc/encoding.html#LDPC5GEncoder)\n\n5G NR LDPC Encoder following the 3GPP NR Initiative [[3GPPTS38212_LDPC]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#gppts38212-ldpc)\nincluding rate-matching.\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **k** (*int*)  Defining the number of information bit per codeword.\n- **n** (*int*)  Defining the desired codeword length.\n- **num_bits_per_symbol** (*int** or **None*)  Defining the number of bits per QAM symbol. If this parameter is\nexplicitly provided, the codeword will be interleaved after\nrate-matching as specified in Sec. 5.4.2.2 in [[3GPPTS38212_LDPC]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#gppts38212-ldpc).\n- **dtype** (*tf.DType*)  Defaults to <cite>tf.float32</cite>. Defines the output datatype of the layer\n(internal precision remains <cite>tf.uint8</cite>).\n\n\nInput\n\n**inputs** (*[,k], tf.float32*)  2+D tensor containing the information bits to be\nencoded.\n\nOutput\n\n*[,n], tf.float32*  2+D tensor of same shape as inputs besides last dimension has\nchanged to <cite>n</cite> containing the encoded codeword bits.\n\nAttributes\n\n- **k** (*int*)  Defining the number of information bit per codeword.\n- **n** (*int*)  Defining the desired codeword length.\n- **coderate** (*float*)  Defining the coderate r= `k` / `n`.\n- **n_ldpc** (*int*)  An integer defining the total codeword length (before\npunturing) of the lifted parity-check matrix.\n- **k_ldpc** (*int*)  An integer defining the total information bit length\n(before zero removal) of the lifted parity-check matrix. Gap to\n`k` must be filled with so-called filler bits.\n- **num_bits_per_symbol** (*int or None.*)  Defining the number of bits per QAM symbol. If this parameter is\nexplicitly provided, the codeword will be interleaved after\nrate-matching as specified in Sec. 5.4.2.2 in [[3GPPTS38212_LDPC]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#gppts38212-ldpc).\n- **out_int** (*[n], ndarray of int*)  Defining the rate-matching output interleaver sequence.\n- **out_int_inv** (*[n], ndarray of int*)  Defining the inverse rate-matching output interleaver sequence.\n- **_check_input** (*bool*)  A boolean that indicates whether the input vector\nduring call of the layer should be checked for consistency (i.e.,\nbinary).\n- **_bg** (*str*)  Denoting the selected basegraph (either <cite>bg1</cite> or <cite>bg2</cite>).\n- **_z** (*int*)  Denoting the lifting factor.\n- **_i_ls** (*int*)  Defining which version of the basegraph to load.\nCan take values between 0 and 7.\n- **_k_b** (*int*)  Defining the number of <cite>information bit columns</cite> in the\nbasegraph. Determined by the code design procedure in\n[[3GPPTS38212_LDPC]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#gppts38212-ldpc).\n- **_bm** (*ndarray*)  An ndarray defining the basegraph.\n- **_pcm** (*sp.sparse.csr_matrix*)  A sparse matrix of shape <cite>[k_ldpc-n_ldpc, n_ldpc]</cite>\ncontaining the sparse parity-check matrix.\n\n\nRaises\n\n- **AssertionError**  If `k` is not <cite>int</cite>.\n- **AssertionError**  If `n` is not <cite>int</cite>.\n- **ValueError**  If `code_length` is not supported.\n- **ValueError**  If <cite>dtype</cite> is not supported.\n- **ValueError**  If `inputs` contains other values than <cite>0</cite> or <cite>1</cite>.\n- **InvalidArgumentError**  When rank(`inputs`)<2.\n- **InvalidArgumentError**  When shape of last dim is not `k`.\n\n\n**Note**\n\nAs specified in [[3GPPTS38212_LDPC]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#gppts38212-ldpc), the encoder also performs\npuncturing and shortening. Thus, the corresponding decoder needs to\n<cite>invert</cite> these operations, i.e., must be compatible with the 5G\nencoding scheme.\n\n`property` `coderate`\n\nCoderate of the LDPC code after rate-matching.\n\n\n`generate_out_int`(*`n`*, *`num_bits_per_symbol`*)[`[source]`](../_modules/sionna/fec/ldpc/encoding.html#LDPC5GEncoder.generate_out_int)\n\nGenerates LDPC output interleaver sequence as defined in\nSec 5.4.2.2 in [[3GPPTS38212_LDPC]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#gppts38212-ldpc).\nParameters\n\n- **n** (*int*)  Desired output sequence length.\n- **num_bits_per_symbol** (*int*)  Number of symbols per QAM symbol, i.e., the modulation order.\n- **Outputs**\n- **-------**\n- **(****perm_seq**  Tuple:\n- **perm_seq_inv****)**  Tuple:\n- **perm_seq** (*ndarray of length n*)  Containing the permuted indices.\n- **perm_seq_inv** (*ndarray of length n*)  Containing the inverse permuted indices.\n\n\n**Note**\n\nThe interleaver pattern depends on the modulation order and helps to\nreduce dependencies in bit-interleaved coded modulation (BICM) schemes.\n\n\n`property` `k`\n\nNumber of input information bits.\n\n\n`property` `k_ldpc`\n\nNumber of LDPC information bits after rate-matching.\n\n\n`property` `n`\n\nNumber of output codeword bits.\n\n\n`property` `n_ldpc`\n\nNumber of LDPC codeword bits before rate-matching.\n\n\n`property` `num_bits_per_symbol`\n\nModulation order used for the rate-matching output interleaver.\n\n\n`property` `out_int`\n\nOutput interleaver sequence as defined in 5.4.2.2.\n\n\n`property` `out_int_inv`\n\nInverse output interleaver sequence as defined in 5.4.2.2.\n\n\n`property` `pcm`\n\nParity-check matrix for given code parameters.\n\n\n`property` `z`\n\nLifting factor of the basegraph."
"### LDPCBPDecoder\n\n`class` `sionna.fec.ldpc.decoding.``LDPCBPDecoder`(*`pcm`*, *`trainable``=``False`*, *`cn_type``=``'boxplus-phi'`*, *`hard_out``=``True`*, *`track_exit``=``False`*, *`num_iter``=``20`*, *`stateful``=``False`*, *`output_dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/ldpc/decoding.html#LDPCBPDecoder)\n\nIterative belief propagation decoder for low-density parity-check (LDPC)\ncodes and other <cite>codes on graphs</cite>.\n\nThis class defines a generic belief propagation decoder for decoding\nwith arbitrary parity-check matrices. It can be used to iteratively\nestimate/recover the transmitted codeword (or information bits) based on the\nLLR-values of the received noisy codeword observation.\n\nThe decoder implements the flooding SPA algorithm [[Ryan]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#ryan), i.e., all nodes\nare updated in a parallel fashion. Different check node update functions are\navailable\n<ol class=\"arabic\">\n- <cite>boxplus</cite>\n\n$$\ny_{j \\to i} = 2 \\operatorname{tanh}^{-1} \\left( \\prod_{i' \\in \\mathcal{N}_(j) \\setminus i} \\operatorname{tanh} \\left( \\frac{x_{i' \\to j}}{2} \\right) \\right)\n$$\n\n- <cite>boxplus-phi</cite>\n\n$$\ny_{j \\to i} = \\alpha_{j \\to i} \\cdot \\phi \\left( \\sum_{i' \\in \\mathcal{N}_(j) \\setminus i} \\phi \\left( |x_{i' \\to j}|\\right) \\right)\n$$\n\nwith $\\phi(x)=-\\operatorname{log}(\\operatorname{tanh} \\left(\\frac{x}{2}) \\right)$\n\n- <cite>minsum</cite>\n\n$$\n\\qquad y_{j \\to i} = \\alpha_{j \\to i} \\cdot {min}_{i' \\in \\mathcal{N}_(j) \\setminus i} \\left(|x_{i' \\to j}|\\right)\n$$\n\n</ol>\n\nwhere $y_{j \\to i}$ denotes the message from check node (CN) *j* to\nvariable node (VN) *i* and $x_{i \\to j}$ from VN *i* to CN *j*,\nrespectively. Further, $\\mathcal{N}_(j)$ denotes all indices of\nconnected VNs to CN *j* and\n\n$$\n\\alpha_{j \\to i} = \\prod_{i' \\in \\mathcal{N}_(j) \\setminus i} \\operatorname{sign}(x_{i' \\to j})\n$$\n\nis the sign of the outgoing message. For further details we refer to\n[[Ryan]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#ryan).\n\nNote that for full 5G 3GPP NR compatibility, the correct puncturing and\nshortening patterns must be applied (cf. [[Richardson]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#richardson) for details), this\ncan be done by `LDPC5GEncoder` and\n[`LDPC5GDecoder`](https://nvlabs.github.io/sionna/api/fec.ldpc.html#sionna.fec.ldpc.decoding.LDPC5GDecoder), respectively.\n\nIf required, the decoder can be made trainable and is fully differentiable\nby following the concept of <cite>weighted BP</cite> [[Nachmani]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#nachmani) as shown in Fig. 1\nleading to\n\n$$\ny_{j \\to i} = 2 \\operatorname{tanh}^{-1} \\left( \\prod_{i' \\in \\mathcal{N}_(j) \\setminus i} \\operatorname{tanh} \\left( \\frac{\\textcolor{red}{w_{i' \\to j}} \\cdot x_{i' \\to j}}{2} \\right) \\right)\n$$\n\nwhere $w_{i \\to j}$ denotes the trainable weight of message $x_{i \\to j}$.\nPlease note that the training of some check node types may be not supported.\n ig. 5 Fig. 1: Weighted BP as proposed in [[Nachmani]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#nachmani).\n\nFor numerical stability, the decoder applies LLR clipping of\n+/- 20 to the input LLRs.\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **pcm** (*ndarray*)  An ndarray of shape <cite>[n-k, n]</cite> defining the parity-check matrix\nconsisting only of <cite>0</cite> or <cite>1</cite> entries. Can be also of type <cite>scipy.\nsparse.csr_matrix</cite> or <cite>scipy.sparse.csc_matrix</cite>.\n- **trainable** (*bool*)  Defaults to False. If True, every outgoing variable node message is\nscaled with a trainable scalar.\n- **cn_type** (*str*)  A string defaults to boxplus-phi. One of\n{<cite>boxplus</cite>, <cite>boxplus-phi</cite>, <cite>minsum</cite>} where\nboxplus implements the single-parity-check APP decoding rule.\nboxplus-phi implements the numerical more stable version of\nboxplus [[Ryan]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#ryan).\nminsum implements the min-approximation of the CN\nupdate rule [[Ryan]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#ryan).\n- **hard_out** (*bool*)  Defaults to True. If True, the decoder provides hard-decided\ncodeword bits instead of soft-values.\n- **track_exit** (*bool*)  Defaults to False. If True, the decoder tracks EXIT\ncharacteristics. Note that this requires the all-zero\nCW as input.\n- **num_iter** (*int*)  Defining the number of decoder iteration (no early stopping used at\nthe moment!).\n- **stateful** (*bool*)  Defaults to False. If True, the internal VN messages `msg_vn`\nfrom the last decoding iteration are returned, and `msg_vn` or\n<cite>None</cite> needs to be given as a second input when calling the decoder.\nThis is required for iterative demapping and decoding.\n- **output_dtype** (*tf.DType*)  Defaults to tf.float32. Defines the output datatype of the layer\n(internal precision remains tf.float32).\n\n\nInput\n\n- **llrs_ch or (llrs_ch, msg_vn)**  Tensor or Tuple (only required if `stateful` is True):\n- **llrs_ch** (*[,n], tf.float32*)  2+D tensor containing the channel logits/llr values.\n- **msg_vn** (*None or RaggedTensor, tf.float32*)  Ragged tensor of VN messages.\nRequired only if `stateful` is True.\n\n\nOutput\n\n- *[,n], tf.float32*  2+D Tensor of same shape as `inputs` containing\nbit-wise soft-estimates (or hard-decided bit-values) of all\ncodeword bits.\n- *RaggedTensor, tf.float32:*  Tensor of VN messages.\nReturned only if `stateful` is set to True.\n\n\nAttributes\n\n- **pcm** (*ndarray*)  An ndarray of shape <cite>[n-k, n]</cite> defining the parity-check matrix\nconsisting only of <cite>0</cite> or <cite>1</cite> entries. Can be also of type <cite>scipy.\nsparse.csr_matrix</cite> or <cite>scipy.sparse.csc_matrix</cite>.\n- **num_cns** (*int*)  Defining the number of check nodes.\n- **num_vns** (*int*)  Defining the number of variable nodes.\n- **num_edges** (*int*)  Defining the total number of edges.\n- **trainable** (*bool*)  If True, the decoder uses trainable weights.\n- **_atanh_clip_value** (*float*)  Defining the internal clipping value before the atanh is applied\n(relates to the CN update).\n- **_cn_type** (*str*)  Defining the CN update function type.\n- **_cn_update**  A function defining the CN update.\n- **_hard_out** (*bool*)  If True, the decoder outputs hard-decided bits.\n- **_cn_con** (*ndarray*)  An ndarray of shape <cite>[num_edges]</cite> defining all edges from check\nnode perspective.\n- **_vn_con** (*ndarray*)  An ndarray of shape <cite>[num_edges]</cite> defining all edges from variable\nnode perspective.\n- **_vn_mask_tf** (*tf.float32*)  A ragged Tensor of shape <cite>[num_vns, None]</cite> defining the incoming\nmessage indices per VN. The second dimension is ragged and depends\non the node degree.\n- **_cn_mask_tf** (*tf.float32*)  A ragged Tensor of shape <cite>[num_cns, None]</cite> defining the incoming\nmessage indices per CN. The second dimension is ragged and depends\non the node degree.\n- **_ind_cn** (*ndarray*)  An ndarray of shape <cite>[num_edges]</cite> defining the permutation index to\nrearrange messages from variable into check node perspective.\n- **_ind_cn_inv** (*ndarray*)  An ndarray of shape <cite>[num_edges]</cite> defining the permutation index to\nrearrange messages from check into variable node perspective.\n- **_vn_row_splits** (*ndarray*)  An ndarray of shape <cite>[num_vns+1]</cite> defining the row split positions\nof a 1D vector consisting of all edges messages. Used to build a\nragged Tensor of incoming VN messages.\n- **_cn_row_splits** (*ndarray*)  An ndarray of shape <cite>[num_cns+1]</cite> defining the row split positions\nof a 1D vector consisting of all edges messages. Used to build a\nragged Tensor of incoming CN messages.\n- **_edge_weights** (*tf.float32*)  A Tensor of shape <cite>[num_edges]</cite> defining a (trainable) weight per\noutgoing VN message.\n\n\nRaises\n\n- **ValueError**  If the shape of `pcm` is invalid or contains other values than\n    <cite>0</cite> or <cite>1</cite> or dtype is not <cite>tf.float32</cite>.\n- **ValueError**  If `num_iter` is not an integer greater (or equal) <cite>0</cite>.\n- **ValueError**  If `output_dtype` is not\n    {tf.float16, tf.float32, tf.float64}.\n- **ValueError**  If `inputs` is not of shape <cite>[batch_size, n]</cite>.\n- **InvalidArgumentError**  When rank(`inputs`)<2."
"### Note\n\nAs decoding input logits\n$\\operatorname{log} \\frac{p(x=1)}{p(x=0)}$ are\nassumed for compatibility with the learning framework, but internally\nlog-likelihood ratios (LLRs) with definition $\\operatorname{log} \\frac{p(x=0)}{p(x=1)}$ are used.\n\nThe decoder is not (particularly) optimized for quasi-cyclic (QC) LDPC\ncodes and, thus, supports arbitrary parity-check matrices.\n\nThe decoder is implemented by using ragged Tensors [[TF_ragged]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#tf-ragged) to\naccount for arbitrary node degrees. To avoid a performance degradation\ncaused by a severe indexing overhead, the batch-dimension is shifted to\nthe last dimension during decoding.\n\nIf the decoder is made trainable [[Nachmani]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#nachmani), for performance\nimprovements only variable to check node messages are scaled as the VN\noperation is linear and, thus, would not increase the expressive power\nof the weights.\n\n`property` `edge_weights`\n\nTrainable weights of the BP decoder.\n\n\n`property` `has_weights`\n\nIndicates if decoder has trainable weights.\n\n\n`property` `ie_c`\n\nExtrinsic mutual information at check node.\n\n\n`property` `ie_v`\n\nExtrinsic mutual information at variable node.\n\n\n`property` `llr_max`\n\nMax LLR value used for internal calculations and rate-matching.\n\n\n`property` `num_cns`\n\nNumber of check nodes.\n\n\n`property` `num_edges`\n\nNumber of edges in decoding graph.\n\n\n`property` `num_iter`\n\nNumber of decoding iterations.\n\n\n`property` `num_vns`\n\nNumber of variable nodes.\n\n\n`property` `output_dtype`\n\nOutput dtype of decoder.\n\n\n`property` `pcm`\n\nParity-check matrix of LDPC code.\n\n\n`show_weights`(*`size``=``7`*)[`[source]`](../_modules/sionna/fec/ldpc/decoding.html#LDPCBPDecoder.show_weights)\n\nShow histogram of trainable weights.\nInput\n\n**size** (*float*)  Figure size of the matplotlib figure."
"### LDPC5GDecoder\n\n`class` `sionna.fec.ldpc.decoding.``LDPC5GDecoder`(*`encoder`*, *`trainable``=``False`*, *`cn_type``=``'boxplus-phi'`*, *`hard_out``=``True`*, *`track_exit``=``False`*, *`return_infobits``=``True`*, *`prune_pcm``=``True`*, *`num_iter``=``20`*, *`stateful``=``False`*, *`output_dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/ldpc/decoding.html#LDPC5GDecoder)\n\n(Iterative) belief propagation decoder for 5G NR LDPC codes.\n\nInherits from [`LDPCBPDecoder`](https://nvlabs.github.io/sionna/api/fec.ldpc.html#sionna.fec.ldpc.decoding.LDPCBPDecoder) and provides\na wrapper for 5G compatibility, i.e., automatically handles puncturing and\nshortening according to [[3GPPTS38212_LDPC]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#gppts38212-ldpc).\n\nNote that for full 5G 3GPP NR compatibility, the correct puncturing and\nshortening patterns must be applied and, thus, the encoder object is\nrequired as input.\n\nIf required the decoder can be made trainable and is differentiable\n(the training of some check node types may be not supported) following the\nconcept of weighted BP [[Nachmani]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#nachmani).\n\nFor numerical stability, the decoder applies LLR clipping of\n+/- 20 to the input LLRs.\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **encoder** ()  An instance of [`LDPC5GEncoder`](https://nvlabs.github.io/sionna/api/fec.ldpc.html#sionna.fec.ldpc.encoding.LDPC5GEncoder)\ncontaining the correct code parameters.\n- **trainable** (*bool*)  Defaults to False. If True, every outgoing variable node message is\nscaled with a trainable scalar.\n- **cn_type** (*str*)  A string defaults to boxplus-phi. One of\n{<cite>boxplus</cite>, <cite>boxplus-phi</cite>, <cite>minsum</cite>} where\nboxplus implements the single-parity-check APP decoding rule.\nboxplus-phi implements the numerical more stable version of\nboxplus [[Ryan]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#ryan).\nminsum implements the min-approximation of the CN\nupdate rule [[Ryan]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#ryan).\n- **hard_out** (*bool*)  Defaults to True. If True, the decoder provides hard-decided\ncodeword bits instead of soft-values.\n- **track_exit** (*bool*)  Defaults to False. If True, the decoder tracks EXIT characteristics.\nNote that this requires the all-zero CW as input.\n- **return_infobits** (*bool*)  Defaults to True. If True, only the <cite>k</cite> info bits (soft or\nhard-decided) are returned. Otherwise all <cite>n</cite> positions are\nreturned.\n- **prune_pcm** (*bool*)  Defaults to True. If True, all punctured degree-1 VNs and\nconnected check nodes are removed from the decoding graph (see\n[[Cammerer]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#cammerer) for details). Besides numerical differences, this should\nyield the same decoding result but improved the decoding throughput\nand reduces the memory footprint.\n- **num_iter** (*int*)  Defining the number of decoder iteration (no early stopping used at\nthe moment!).\n- **stateful** (*bool*)  Defaults to False. If True, the internal VN messages `msg_vn`\nfrom the last decoding iteration are returned, and `msg_vn` or\n<cite>None</cite> needs to be given as a second input when calling the decoder.\nThis is required for iterative demapping and decoding.\n- **output_dtype** (*tf.DType*)  Defaults to tf.float32. Defines the output datatype of the layer\n(internal precision remains tf.float32).\n\n\nInput\n\n- **llrs_ch or (llrs_ch, msg_vn)**  Tensor or Tuple (only required if `stateful` is True):\n- **llrs_ch** (*[,n], tf.float32*)  2+D tensor containing the channel logits/llr values.\n- **msg_vn** (*None or RaggedTensor, tf.float32*)  Ragged tensor of VN messages.\nRequired only if `stateful` is True.\n\n\nOutput\n\n- *[,n] or [,k], tf.float32*  2+D Tensor of same shape as `inputs` containing\nbit-wise soft-estimates (or hard-decided bit-values) of all\ncodeword bits. If `return_infobits` is True, only the <cite>k</cite>\ninformation bits are returned.\n- *RaggedTensor, tf.float32:*  Tensor of VN messages.\nReturned only if `stateful` is set to True.\n\n\nRaises\n\n- **ValueError**  If the shape of `pcm` is invalid or contains other\n    values than <cite>0</cite> or <cite>1</cite>.\n- **AssertionError**  If `trainable` is not <cite>bool</cite>.\n- **AssertionError**  If `track_exit` is not <cite>bool</cite>.\n- **AssertionError**  If `hard_out` is not <cite>bool</cite>.\n- **AssertionError**  If `return_infobits` is not <cite>bool</cite>.\n- **AssertionError**  If `encoder` is not an instance of\n    [`LDPC5GEncoder`](https://nvlabs.github.io/sionna/api/fec.ldpc.html#sionna.fec.ldpc.encoding.LDPC5GEncoder).\n- **ValueError**  If `output_dtype` is not {tf.float16, tf.float32, tf.\n    float64}.\n- **ValueError**  If `inputs` is not of shape <cite>[batch_size, n]</cite>.\n- **ValueError**  If `num_iter` is not an integer greater (or equal) <cite>0</cite>.\n- **InvalidArgumentError**  When rank(`inputs`)<2.\n\n\n**Note**\n\nAs decoding input logits\n$\\operatorname{log} \\frac{p(x=1)}{p(x=0)}$ are assumed for\ncompatibility with the learning framework, but\ninternally llrs with definition\n$\\operatorname{log} \\frac{p(x=0)}{p(x=1)}$ are used.\n\nThe decoder is not (particularly) optimized for Quasi-cyclic (QC) LDPC\ncodes and, thus, supports arbitrary parity-check matrices.\n\nThe decoder is implemented by using ragged Tensors [[TF_ragged]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#tf-ragged) to\naccount for arbitrary node degrees. To avoid a performance degradation\ncaused by a severe indexing overhead, the batch-dimension is shifted to\nthe last dimension during decoding.\n\nIf the decoder is made trainable [[Nachmani]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#nachmani), for performance\nimprovements only variable to check node messages are scaled as the VN\noperation is linear and, thus, would not increase the expressive power\nof the weights.\n\n`property` `encoder`\n\nLDPC Encoder used for rate-matching/recovery.\n\n\nReferences:\nPfister\n\nJ. Hou, P. H. Siegel, L. B. Milstein, and H. D. Pfister,\nCapacity-approaching bandwidth-efficient coded modulation schemes\nbased on low-density parity-check codes, IEEE Trans. Inf. Theory,\nSep. 2003.\n\n3GPPTS38212_LDPC([1](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id1),[2](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id2),[3](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id3),[4](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id4),[5](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id5),[6](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id6),[7](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id16))\n\nETSI 3GPP TS 38.212 5G NR Multiplexing and channel\ncoding, v.16.5.0, 2021-03.\n\nRyan([1](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id7),[2](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id8),[3](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id12),[4](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id13),[5](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id18),[6](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id19))\n\nW. Ryan, An Introduction to LDPC codes, CRC Handbook for\nCoding and Signal Processing for Recording Systems, 2004.\n\nTF_ragged([1](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id14),[2](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id21))\n\n[https://www.tensorflow.org/guide/ragged_tensor](https://www.tensorflow.org/guide/ragged_tensor)\n\n[Richardson](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id9)\n\nT. Richardson and S. Kudekar. Design of low-density\nparity-check codes for 5G new radio, IEEE Communications\nMagazine 56.3, 2018.\n\nNachmani([1](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id10),[2](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id11),[3](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id15),[4](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id17),[5](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id22))\n\nE. Nachmani, Y. Beery, and D. Burshtein. Learning to\ndecode linear codes using deep learning, IEEE Annual Allerton\nConference on Communication, Control, and Computing (Allerton),\n2016.\n\n[Cammerer](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id20)\n\nS. Cammerer, M. Ebada, A. Elkelesh, and S. ten Brink.\nSparse graphs for belief propagation decoding of polar codes.\nIEEE International Symposium on Information Theory (ISIT), 2018."

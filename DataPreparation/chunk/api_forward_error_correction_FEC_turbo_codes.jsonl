"# Turbo Codes\n\nThis module supports encoding and decoding of Turbo codes [[Berrou]](https://nvlabs.github.io/sionna/api/fec.turbo.html#berrou), e.g., as\nused in the LTE wireless standard. The convolutional component encoders and\ndecoders are composed of the [`ConvEncoder`](fec.conv.html#sionna.fec.conv.ConvEncoder) and\n[`BCJRDecoder`](fec.conv.html#sionna.fec.conv.BCJRDecoder) layers, respectively.\n\nPlease note that various notations are used in literature to represent the\ngenerator polynomials for the underlying convolutional codes. For simplicity,\n[`TurboEncoder`](https://nvlabs.github.io/sionna/api/fec.turbo.html#sionna.fec.turbo.TurboEncoder) only accepts the binary\nformat, i.e., <cite>10011</cite>, for the generator polynomial which corresponds to the\npolynomial $1 + D^3 + D^4$.\n\nThe following code snippet shows how to set-up a rate-1/3, constraint-length-4 [`TurboEncoder`](https://nvlabs.github.io/sionna/api/fec.turbo.html#sionna.fec.turbo.TurboEncoder) and the corresponding [`TurboDecoder`](https://nvlabs.github.io/sionna/api/fec.turbo.html#sionna.fec.turbo.TurboDecoder).\nYou can find further examples in the [Channel Coding Tutorial Notebook](../examples/5G_Channel_Coding_Polar_vs_LDPC_Codes.html).\n\nSetting-up:\n```python\nencoder = TurboEncoder(constraint_length=4, # Desired constraint length of the polynomials\n                       rate=1/3,  # Desired rate of Turbo code\n                       terminate=True) # Terminate the constituent convolutional encoders to all-zero state\n# or\nencoder = TurboEncoder(gen_poly=gen_poly, # Generator polynomials to use in the underlying convolutional encoders\n                       rate=1/3, # Rate of the desired Turbo code\n                       terminate=False) # Do not terminate the constituent convolutional encoders\n# the decoder can be initialized with a reference to the encoder\ndecoder = TurboDecoder(encoder,\n                       num_iter=6, # Number of iterations between component BCJR decoders\n                       algorithm=\"map\", # can be also \"maxlog\"\n                       hard_out=True) # hard_decide output\n```"
"Running the encoder / decoder:\n```python\n# --- encoder ---\n# u contains the information bits to be encoded and has shape [...,k].\n# c contains the turbo encoded codewords and has shape [...,n], where n=k/rate when terminate is False.\nc = encoder(u)\n# --- decoder ---\n# llr contains the log-likelihood ratio values from the de-mapper and has shape [...,n].\n# u_hat contains the estimated information bits and has shape [...,k].\nu_hat = decoder(llr)\n```"
"## Turbo Encoding\n\n`class` `sionna.fec.turbo.``TurboEncoder`(*`gen_poly``=``None`*, *`constraint_length``=``3`*, *`rate``=``1` `/` `3`*, *`terminate``=``False`*, *`interleaver_type``=``'3GPP'`*, *`output_dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/turbo/encoding.html#TurboEncoder)\n\nPerforms encoding of information bits to a Turbo code codeword [[Berrou]](https://nvlabs.github.io/sionna/api/fec.turbo.html#berrou).\nImplements the standard Turbo code framework [[Berrou]](https://nvlabs.github.io/sionna/api/fec.turbo.html#berrou): Two identical\nrate-1/2 convolutional encoders [`ConvEncoder`](fec.conv.html#sionna.fec.conv.ConvEncoder)\nare combined to produce a rate-1/3 Turbo code. Further,\npuncturing to attain a rate-1/2 Turbo code is supported.\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **gen_poly** (*tuple*)  Tuple of strings with each string being a 0,1 sequence. If\n<cite>None</cite>, `constraint_length` must be provided.\n- **constraint_length** (*int*)  Valid values are between 3 and 6 inclusive. Only required if\n`gen_poly` is <cite>None</cite>.\n- **rate** (*float*)  Valid values are 1/3 and 1/2. Note that `rate` here denotes\nthe <cite>design</cite> rate of the Turbo code. If `terminate` is <cite>True</cite>, a\nsmall rate-loss occurs.\n- **terminate** (*boolean*)  Underlying convolutional encoders are terminated to all zero state\nif <cite>True</cite>. If terminated, the true rate of the code is slightly lower\nthan `rate`.\n- **interleaver_type** (*str*)  Valid values are <cite>3GPP</cite> or <cite>random</cite>. Determines the choice of\nthe interleaver to interleave the message bits before input to the\nsecond convolutional encoder. If <cite>3GPP</cite>, the Turbo code interleaver\nfrom the 3GPP LTE standard [[3GPPTS36212_Turbo]](https://nvlabs.github.io/sionna/api/fec.turbo.html#gppts36212-turbo) is used. If <cite>random</cite>,\na random interleaver is used.\n- **output_dtype** (*tf.DType*)  Defaults to <cite>tf.float32</cite>. Defines the output datatype of the layer.\n\n\nInput\n\n**inputs** (*[,k], tf.float32*)  2+D tensor of information bits where <cite>k</cite> is the information length\n\nOutput\n\n<cite>[,k/rate]</cite>, tf.float32  2+D tensor where <cite>rate</cite> is provided as input\nparameter. The output is the encoded codeword for the input\ninformation tensor. When `terminate` is <cite>True</cite>, the effective rate\nof the Turbo code is slightly less than `rate`.\n\n\n**Note**\n\nVarious notations are used in literature to represent the generator\npolynomials for convolutional codes. For simplicity\n[`TurboEncoder`](https://nvlabs.github.io/sionna/api/fec.turbo.html#sionna.fec.turbo.TurboEncoder) only\naccepts the binary format, i.e., <cite>10011</cite>, for the `gen_poly` argument\nwhich corresponds to the polynomial $1 + D^3 + D^4$.\n\nNote that Turbo codes require the underlying convolutional encoders\nto be recursive systematic encoders. Only then the channel output\nfrom the systematic part of the first encoder can be used to decode\nthe second encoder.\n\nAlso note that `constraint_length` and `memory` are two different\nterms often used to denote the strength of the convolutional code. In\nthis sub-package we use `constraint_length`. For example, the polynomial\n<cite>10011</cite> has a `constraint_length` of 5, however its `memory` is\nonly 4.\n\nWhen `terminate` is <cite>True</cite>, the true rate of the Turbo code is\nslightly lower than `rate`. It can be computed as\n$\\frac{k}{\\frac{k}{r}+\\frac{4\\mu}{3r}}$ where <cite>r</cite> denotes\n`rate` and $\\mu$ is the `constraint_length` - 1. For example, in\n3GPP, `constraint_length` = 4, `terminate` = <cite>True</cite>, for\n`rate` = 1/3, true rate is equal to  $\\frac{k}{3k+12}$ .\n\n`property` `coderate`\n\nRate of the code used in the encoder\n\n\n`property` `constraint_length`\n\nConstraint length of the encoder\n\n\n`property` `gen_poly`\n\nGenerator polynomial used by the encoder\n\n\n`property` `k`\n\nNumber of information bits per codeword\n\n\n`property` `n`\n\nNumber of codeword bits\n\n\n`property` `punct_pattern`\n\nPuncturing pattern for the Turbo codeword\n\n\n`property` `terminate`\n\nIndicates if the convolutional encoders are terminated\n\n\n`property` `trellis`\n\nTrellis object used during encoding"
"## Turbo Decoding\n\n`class` `sionna.fec.turbo.``TurboDecoder`(*`encoder``=``None`*, *`gen_poly``=``None`*, *`rate``=``1` `/` `3`*, *`constraint_length``=``None`*, *`interleaver``=``'3GPP'`*, *`terminate``=``False`*, *`num_iter``=``6`*, *`hard_out``=``True`*, *`algorithm``=``'map'`*, *`output_dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/turbo/decoding.html#TurboDecoder)\n\nTurbo code decoder based on BCJR component decoders [[Berrou]](https://nvlabs.github.io/sionna/api/fec.turbo.html#berrou).\nTakes as input LLRs and returns LLRs or hard decided bits, i.e., an\nestimate of the information tensor.\n\nThis decoder is based on the [`BCJRDecoder`](fec.conv.html#sionna.fec.conv.BCJRDecoder)\nand, thus, internally instantiates two\n[`BCJRDecoder`](fec.conv.html#sionna.fec.conv.BCJRDecoder) layers.\n\nThe class inherits from the Keras layer class and can be used as layer in\na Keras model.\nParameters\n\n- **encoder** ([`TurboEncoder`](https://nvlabs.github.io/sionna/api/fec.turbo.html#sionna.fec.turbo.TurboEncoder))  If `encoder` is provided as input, the following input parameters\nare not required and will be ignored: <cite>gen_poly</cite>, <cite>rate</cite>,\n<cite>constraint_length</cite>, <cite>terminate</cite>, <cite>interleaver</cite>. They will be inferred\nfrom the `encoder` object itself.\nIf `encoder` is <cite>None</cite>, the above parameters must be provided\nexplicitly.\n- **gen_poly** (*tuple*)  Tuple of strings with each string being a 0, 1 sequence. If <cite>None</cite>,\n`rate` and `constraint_length` must be provided.\n- **rate** (*float*)  Rate of the Turbo code. Valid values are 1/3 and 1/2. Note that\n`gen_poly`, if provided, is used to encode the underlying\nconvolutional code, which traditionally has rate 1/2.\n- **constraint_length** (*int*)  Valid values are between 3 and 6 inclusive. Only required if\n`encoder` and `gen_poly` are <cite>None</cite>.\n- **interleaver** (*str*)  <cite>3GPP</cite> or <cite>Random</cite>. If <cite>3GPP</cite>, the internal interleaver for Turbo\ncodes as specified in [[3GPPTS36212_Turbo]](https://nvlabs.github.io/sionna/api/fec.turbo.html#gppts36212-turbo) will be used. Only required\nif `encoder` is <cite>None</cite>.\n- **terminate** (*bool*)  If <cite>True</cite>, the two underlying convolutional encoders are assumed\nto have terminated to all zero state.\n- **num_iter** (*int*)  Number of iterations for the Turbo decoding to run. Each iteration of\nTurbo decoding entails one BCJR decoder for each of the underlying\nconvolutional code components.\n- **hard_out** (*boolean*)  Defaults to <cite>True</cite> and indicates whether to output hard or soft\ndecisions on the decoded information vector. <cite>True</cite> implies a hard-\ndecoded information vector of 0/1s is output. <cite>False</cite> implies\ndecoded LLRs of the information is output.\n- **algorithm** (*str*)  Defaults to <cite>map</cite>. Indicates the implemented BCJR algorithm,\nwhere <cite>map</cite> denotes the exact MAP algorithm, <cite>log</cite> indicates the\nexact MAP implementation, but in log-domain, and\n<cite>maxlog</cite> indicates the approximated MAP implementation in log-domain,\nwhere $\\log(e^{a}+e^{b}) \\sim \\max(a,b)$.\n- **output_dtype** (*tf.DType*)  Defaults to <cite>tf.float32</cite>. Defines the output datatype of the layer.\n\n\nInput\n\n**inputs** (*tf.float32*)  2+D tensor of shape <cite>[,n]</cite> containing the (noisy) channel\noutput symbols where <cite>n</cite> is the codeword length\n\nOutput\n\n*tf.float32*  2+D tensor of shape <cite>[,coderate*n]</cite> containing the estimates of the\ninformation bit tensor\n\n\n**Note**\n\nFor decoding, input <cite>logits</cite> defined as\n$\\operatorname{log} \\frac{p(x=1)}{p(x=0)}$ are assumed for\ncompatibility with the rest of Sionna. Internally,\nlog-likelihood ratios (LLRs) with definition\n$\\operatorname{log} \\frac{p(x=0)}{p(x=1)}$ are used.\n\n`property` `coderate`\n\nRate of the code used in the encoder\n\n\n`property` `constraint_length`\n\nConstraint length of the encoder\n\n\n`depuncture`(*`y`*)[`[source]`](../_modules/sionna/fec/turbo/decoding.html#TurboDecoder.depuncture)\n\nGiven a tensor <cite>y</cite> of shape <cite>[batch, n]</cite>, depuncture() scatters <cite>y</cite>\nelements into shape <cite>[batch, 3*rate*n]</cite> where the\nextra elements are filled with 0.\n\nFor e.g., if input is <cite>y</cite>, rate is 1/2 and\n<cite>punct_pattern</cite> is [1, 1, 0, 1, 0, 1], then the\noutput is [y[0], y[1], 0., y[2], 0., y[3], y[4], y[5], 0.,  ,].\n\n\n`property` `gen_poly`\n\nGenerator polynomial used by the encoder\n\n\n`property` `k`\n\nNumber of information bits per codeword\n\n\n`property` `n`\n\nNumber of codeword bits\n\n\n`property` `trellis`\n\nTrellis object used during encoding"
"### TurboTermination\n\n`class` `sionna.fec.turbo.``TurboTermination`(*`constraint_length`*, *`conv_n``=``2`*, *`num_conv_encs``=``2`*, *`num_bit_streams``=``3`*)[`[source]`](../_modules/sionna/fec/turbo/utils.html#TurboTermination)\n\nTermination object, handles the transformation of termination bits from\nthe convolutional encoders to a Turbo codeword. Similarly, it handles the\ntransformation of channel symbols corresponding to the termination of a\nTurbo codeword to the underlying convolutional codewords.\nParameters\n\n- **constraint_length** (*int*)  Constraint length of the convolutional encoder used in the Turbo code.\nNote that the memory of the encoder is `constraint_length` - 1.\n- **conv_n** (*int*)  Number of output bits for one state transition in the underlying\nconvolutional encoder\n- **num_conv_encs** (*int*)  Number of parallel convolutional encoders used in the Turbo code\n- **num_bit_streams** (*int*)  Number of output bit streams from Turbo code\n\n\n`get_num_term_syms`()[`[source]`](../_modules/sionna/fec/turbo/utils.html#TurboTermination.get_num_term_syms)\n\nComputes the number of termination symbols for the Turbo\ncode based on the underlying convolutional code parameters,\nprimarily the memory $\\mu$.\nNote that it is assumed that one Turbo symbol implies\n`num_bitstreams` bits.\nInput\n\n**None**\n\nOutput\n\n**turbo_term_syms** (*int*)  Total number of termination symbols for the Turbo Code. One\nsymbol equals `num_bitstreams` bits.\n\n\n`term_bits_turbo2conv`(*`term_bits`*)[`[source]`](../_modules/sionna/fec/turbo/utils.html#TurboTermination.term_bits_turbo2conv)\n\nThis method splits the termination symbols from a Turbo codeword\nto the termination symbols corresponding to the two convolutional\nencoders, respectively.\n\nLets assume $\\mu=4$ and the underlying convolutional encoders\nare systematic and rate-1/2, for demonstration purposes.\n\nLet `term_bits` tensor, corresponding to the termination symbols of\nthe Turbo codeword be as following:\n\n$y = [x_1(K), z_1(K), x_1(K+1), z_1(K+1), x_1(K+2), z_1(K+2)$,\n$x_1(K+3), z_1(K+3), x_2(K), z_2(K), x_2(K+1), z_2(K+1),$\n$x_2(K+2), z_2(K+2), x_2(K+3), z_2(K+3), 0, 0]$\n\nThe two termination tensors corresponding to the convolutional encoders\nare:\n$y[0,..., 2\\mu]$, $y[2\\mu,..., 4\\mu]$. The output from this method is a tuple of two tensors, each of\nsize $2\\mu$ and shape $[\\mu,2]$.\n\n$[[x_1(K), z_1(K)]$,\n\n$[x_1(K+1), z_1(K+1)]$,\n\n$[x_1(K+2, z_1(K+2)]$,\n\n$[x_1(K+3), z_1(K+3)]]$\n\nand\n\n$[[x_2(K), z_2(K)],$\n\n$[x_2(K+1), z_2(K+1)]$,\n\n$[x_2(K+2), z_2(K+2)]$,\n\n$[x_2(K+3), z_2(K+3)]]$\nInput\n\n**term_bits** (*tf.float32*)  Channel output of the Turbo codeword, corresponding to the\ntermination part\n\nOutput\n\n*tf.float32*  Two tensors of channel outputs, corresponding to encoders 1 and 2,\nrespectively\n\n\n`termbits_conv2turbo`(*`term_bits1`*, *`term_bits2`*)[`[source]`](../_modules/sionna/fec/turbo/utils.html#TurboTermination.termbits_conv2turbo)\n\nThis method merges `term_bits1` and `term_bits2`, termination\nbit streams from the two convolutional encoders, to a bit stream\ncorresponding to the Turbo codeword.\n\nLet `term_bits1` and `term_bits2` be:\n\n$[x_1(K), z_1(K), x_1(K+1), z_1(K+1),..., x_1(K+\\mu-1),z_1(K+\\mu-1)]$\n\n$[x_2(K), z_2(K), x_2(K+1), z_2(K+1),..., x_2(K+\\mu-1), z_2(K+\\mu-1)]$\n\nwhere $x_i, z_i$ are the systematic and parity bit streams\nrespectively for a rate-1/2 convolutional encoder i, for i = 1, 2.\n\nIn the example output below, we assume $\\mu=4$ to demonstrate zero\npadding at the end. Zero padding is done such that the total length is\ndivisible by `num_bitstreams` (defaults to  3) which is the number of\nTurbo bit streams.\n\nAssume `num_bitstreams` = 3. Then number of termination symbols for\nthe TurboEncoder is $\\lceil \\frac{2*conv\\_n*\\mu}{3} \\rceil$:\n\n$[x_1(K), z_1(K), x_1(K+1)]$\n\n$[z_1(K+1), x_1(K+2, z_1(K+2)]$\n\n$[x_1(K+3), z_1(K+3), x_2(K)]$\n\n$[z_2(K), x_2(K+1), z_2(K+1)]$\n\n$[x_2(K+2), z_2(K+2), x_2(K+3)]$\n\n$[z_2(K+3), 0, 0]$\n\nTherefore, the output from this method is a single dimension vector\nwhere all Turbo symbols are concatenated together.\n\n$[x_1(K), z_1(K), x_1(K+1), z_1(K+1), x_1(K+2, z_1(K+2), x_1(K+3),$\n\n$z_1(K+3), x_2(K),z_2(K), x_2(K+1), z_2(K+1), x_2(K+2), z_2(K+2),$\n\n$x_2(K+3), z_2(K+3), 0, 0]$\nInput\n\n- **term_bits1** (*tf.int32*)  2+D Tensor containing termination bits from convolutional encoder 1\n- **term_bits2** (*tf.int32*)  2+D Tensor containing termination bits from convolutional encoder 2\n\n\nOutput\n\n*tf.int32*  1+D tensor of termination bits. The output is obtained by\nconcatenating the inputs and then adding right zero-padding if\nneeded."
"### polynomial_selector\n\n`sionna.fec.turbo.utils.``polynomial_selector`(*`constraint_length`*)[`[source]`](../_modules/sionna/fec/turbo/utils.html#polynomial_selector)\n\nReturns the generator polynomials for rate-1/2 convolutional codes\nfor a given `constraint_length`.\nInput\n\n**constraint_length** (*int*)  An integer defining the desired constraint length of the encoder.\nThe memory of the encoder is `constraint_length` - 1.\n\nOutput\n\n**gen_poly** (*tuple*)  Tuple of strings with each string being a 0,1 sequence where\neach polynomial is represented in binary form.\n\n\n**Note**\n\nPlease note that the polynomials are optimized for rsc codes and are\nnot necessarily the same as used in the polynomial selector\n[`polynomial_selector`](fec.conv.html#sionna.fec.conv.utils.polynomial_selector) of the\nconvolutional codes."
"### puncture_pattern\n\n`sionna.fec.turbo.utils.``puncture_pattern`(*`turbo_coderate`*, *`conv_coderate`*)[`[source]`](../_modules/sionna/fec/turbo/utils.html#puncture_pattern)\n\nThis method returns puncturing pattern such that the\nTurbo code has rate `turbo_coderate` given the underlying\nconvolutional encoder is of rate `conv_coderate`.\nInput\n\n- **turbo_coderate** (*float*)  Desired coderate of the Turbo code\n- **conv_coderate** (*float*)  Coderate of the underlying convolutional encoder\n\n\nOutput\n\n*tf.bool*  2D tensor indicating the positions to be punctured.\n\n\nReferences:\nBerrou([1](https://nvlabs.github.io/sionna/api/fec.turbo.html#id1),[2](https://nvlabs.github.io/sionna/api/fec.turbo.html#id2),[3](https://nvlabs.github.io/sionna/api/fec.turbo.html#id3),[4](https://nvlabs.github.io/sionna/api/fec.turbo.html#id5))\n<ol class=\"upperalpha simple\" start=\"3\">\n- Berrou, A. Glavieux, P. Thitimajshima, Near Shannon limit error-correcting coding and decoding: Turbo-codes, IEEE ICC, 1993.\n</ol>\n\n3GPPTS36212_Turbo([1](https://nvlabs.github.io/sionna/api/fec.turbo.html#id4),[2](https://nvlabs.github.io/sionna/api/fec.turbo.html#id6))\n\nETSI 3GPP TS 36.212 Evolved Universal Terrestrial\nRadio Access (EUTRA); Multiplexing and channel coding, v.15.3.0, 2018-09."

"# Mobility in Sionna RT\n\nThis notebook explains different ways in which the effects of mobility can be simulated with Sionnas [ray tracing (RT) module](https://nvlabs.github.io/sionna/api/rt.html). In particular, you will\n\n- Use the `position` and `orientation` properties to move scene objects\n- Understand the `velocity` property of scene objects and their impact on the Doppler shift\n- Learn how to use the `apply_dopper` method of a `Paths` object"
"## Background Information\n\nThere are two ways in which we can simulate the impact of movement of scene objects on the channel impulse response. The first consists in moving the desired objects in small steps along a trajectory and recomputing the propagation paths for each step. While this approach is the most accurate, it comes at the cost of high computational complexity. As we will see later in this notebook, this approach is fortunately not necessary when the lengths of the considered trajectories are small, i.e., not\nmore than a few wavelengths. In this case, we can compute the time evolution of the channel impulse response using the second approach which is based on the experienced Doppler shifts of all propagation paths. It is very fast and leads to very accurate predictions in many cases.\n\nIn order to compute the Doppler shift for a specific path as shown in the figure below, Sionna RT relies on the [velocity vectors](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.SceneObject.velocity) of the scene objects.\n\n\nWhile traveling from the transmitter to the receiver, the path undergoes $n$ scattering processes, such as reflection, diffuse scattering, or diffraction. The object on which lies the $i$th scattering point has the velocity vector $\\mathbf{v}_i$ and the outgoing ray direction at this point is denoted $\\hat{\\mathbf{k}}_i$. The first and last point correspond to the transmitter and receiver, respectively.\n\nThe Doppler shift $f_\\Delta$ for this path can be computed as (see the [documentation](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths.apply_doppler) of `Paths.apply_doppler()`)\n\n\\begin{align}\nf_\\Delta = \\frac{1}{\\lambda}\\left[\\mathbf{v}_{0}^\\mathsf{T}\\hat{\\mathbf{k}}_0 - \\mathbf{v}_{n+1}^\\mathsf{T}\\hat{\\mathbf{k}}_n + \\sum_{i=1}^n \\mathbf{v}_{i}^\\mathsf{T}\\left(\\hat{\\mathbf{k}}_i-\\hat{\\mathbf{k}}_{i-1} \\right) \\right] \\qquad \\text{[Hz]}\n\\end{align}\n\nwhere $\\lambda$ is the wavelength, and then be used to compute the time evolution of the path coefficient `Paths.a` as\n\n\\begin{align}\na(t) = a e^{j2\\pi f_\\Delta t}.\n\\end{align}"
"## GPU Configuration and Imports\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Colab does currently not support the latest version of ipython.\n# Thus, the preview does not work in Colab. However, whenever possible we\n# strongly recommend to use the scene preview mode.\ntry: # detect if the notebook runs in Colab\n    import google.colab\n    colab_compat = True # deactivate preview\nexcept:\n    colab_compat = False\nresolution = [480,320] # increase for higher quality of renderings\n# Allows to exit cell execution in Jupyter\nclass ExitCell(Exception):\n    def _render_traceback_(self):\n        pass\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n# For more details, see https://www.tensorflow.org/guide/gpu\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\ntf.random.set_seed(1) # Set global random seed for reproducibility\n```\n\n```python\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sionna.rt import load_scene, PlanarArray, Transmitter, Receiver, Camera\nfrom sionna.rt.utils import r_hat\nfrom sionna.ofdm import ResourceGrid\nfrom sionna.channel.utils import subcarrier_frequencies, cir_to_ofdm_channel\nfrom sionna.constants import SPEED_OF_LIGHT\n```"
"## Controlling Position and Orientation of Scene Objects\n\nEvery object in a scene has a `position` and `orientation` property that can be inspected and modified. To see this, let us load a scene consisting of a simple street canyon and a few cars.\n\n\n```python\nscene = load_scene(sionna.rt.scene.simple_street_canyon_with_cars)\nscene.add(Camera(\"cam\", position=[50,0,130], look_at=[10,0,0]))\nif colab_compat:\n    scene.render(camera=\"cam\", num_samples=512);\n    raise ExitCell\nscene.preview()\n```\n\n\nThe list of all scene objects can be accessed as follows:\n\n\n```python\nscene.objects\n```\n\n```python\n{'building_1': <sionna.rt.scene_object.SceneObject at 0x7f10cd1182e0>,\n 'building_2': <sionna.rt.scene_object.SceneObject at 0x7f10f2196fb0>,\n 'building_3': <sionna.rt.scene_object.SceneObject at 0x7f10f21962c0>,\n 'building_4': <sionna.rt.scene_object.SceneObject at 0x7f10f2197e20>,\n 'building_5': <sionna.rt.scene_object.SceneObject at 0x7f10f2197e50>,\n 'building_6': <sionna.rt.scene_object.SceneObject at 0x7f10f2197f40>,\n 'car_1': <sionna.rt.scene_object.SceneObject at 0x7f10f2197f70>,\n 'car_2': <sionna.rt.scene_object.SceneObject at 0x7f10f2197fa0>,\n 'car_3': <sionna.rt.scene_object.SceneObject at 0x7f10f2197fd0>,\n 'car_4': <sionna.rt.scene_object.SceneObject at 0x7f10f2197c10>,\n 'car_5': <sionna.rt.scene_object.SceneObject at 0x7f10f2197a60>,\n 'car_6': <sionna.rt.scene_object.SceneObject at 0x7f10f2197b20>,\n 'car_7': <sionna.rt.scene_object.SceneObject at 0x7f10f21979d0>,\n 'car_8': <sionna.rt.scene_object.SceneObject at 0x7f10f2195c90>,\n 'floor': <sionna.rt.scene_object.SceneObject at 0x7f10f2197a30>}\n```"
"Let us now inspect the position and orientation of one of the cars:\n\n\n```python\ncar_2 = scene.get(\"car_2\")\nprint(\"Position: \", car_2.position.numpy())\nprint(\"Orientation: \", car_2.orientation.numpy())\n```\n\n\n```python\nPosition:  [25.         5.5999994  0.7500001]\nOrientation:  [0. 0. 0.]\n```\n\n\nThe position of an object corresponds to the center of its axis-aligned bounding box. By default, the orientation of every scene object is `[0,0,0]`. We can now change the position and orientation of the car as follows:\n\n\n```python\n# Move the car 10m along the y-axis\ncar_2.position += [0, 10, 0]\n# And rotate it by 90 degree around the z-axis\ncar_2.orientation = [np.pi/2, 0, 0]\nif colab_compat:\n    scene.render(camera=\"cam\", num_samples=512);\n    raise ExitCell\nscene.preview(); # You do not need to open a new preview, the preview above will update\n```\n\n\nNext, we will visualize coverage maps for different positions of the cars in the scene, assuming that one of the cars is equipped with a transmit antenna:\n\n\n```python\nscene = load_scene(sionna.rt.scene.simple_street_canyon_with_cars)\nscene.add(Camera(\"cam\", position=[50,0,130], look_at=[10,0,0]))\n# Configure a transmitter that is located at the front of \"car_2\"\nscene.add(Transmitter(\"tx\", position=[22.7, 5.6, 0.75], orientation=[np.pi,0,0]))\nscene.tx_array = PlanarArray(1,1,0.5,0.5,\"tr38901\",\"V\")\nscene.rx_array = scene.tx_array\n# Move cars along straight lines for a couple of steps\ndisplacement_vec = [10, 0, 0]\nnum_displacements = 2\nfor _ in range(num_displacements+1):\n    # Compute and render a coverage map at 0.5m above the ground\n    cm = scene.coverage_map(num_samples=10e6,\n                            max_depth=5,\n                            diffraction=True,\n                            cm_center=[0,0,0.5],\n                            cm_orientation=[0,0,0],\n                            cm_size=[186,121],\n                            cm_cell_size=[2,2])\n    scene.render(\"cam\", coverage_map=cm)\n    # Move TX to next position\n    scene.get(\"tx\").position -= displacement_vec\n    # Move cars driving in -x direction\n    for j in range(1,6):\n        scene.get(f\"car_{j}\").position -= displacement_vec\n    # Move cars driving in x direction\n    for j in range(6,9):\n        scene.get(f\"car_{j}\").position += displacement_vec\n```"
"## Time Evolution of Channels Via Doppler Shift\n\nIn the previous section, we have seen how the position and orientation of objects in a scene can be modified. However, if we want to model the evolution of channels over very short time horizons, this approach becomes impractical. An alternative, consists in assigning to all moving objects a velocity vector $\\mathbf{v}_i\\in\\mathbb{R}^3$ based on which path-wise Doppler shifts can be computed. Let us now load a simple scene with a single reflector and modify its velocity.\n\n\n```python\n# Load scene with a single reflector\nscene = load_scene(sionna.rt.scene.simple_reflector)\n# Inspect the velocity of this object\nprint(\"Velocity vector: \", scene.get(\"reflector\").velocity.numpy())\n# Update velocity vector\nscene.get(\"reflector\").velocity = [0, 0, -20]\nprint(\"Velocity vector after update: \", scene.get(\"reflector\").velocity.numpy())\n```\n\n\n```python\nVelocity vector:  [0. 0. 0.]\nVelocity vector after update:  [  0.   0. -20.]\n```\n\n\nNext, we will add a transmitter and receiver to the scene and compute the propagation paths:\n\n\n```python\n# Configure arrays for all transmitters and receivers in the scene\nscene.tx_array = PlanarArray(1,1,0.5,0.5,\"iso\",\"V\")\nscene.rx_array = scene.tx_array\n# Add a transmitter and a receiver\nscene.add(Transmitter(\"tx\", [-25,0.1,50]))\nscene.add(Receiver(\"rx\",    [ 25,0.1,50]))\n# Compute paths\npaths = scene.compute_paths(max_depth=1)\npaths.normalize_delays = False # Do not normalize the delays such that the first path arrives at tau=0\n# Visualize the scene and propagation paths\nif colab_compat:\n    scene.add(Camera(\"cam\", position=[0, 100, 50], look_at=[0,0,30]))\n    scene.render(paths=paths, camera=\"cam\", num_samples=512);\n    raise ExitCell\nscene.preview(paths=paths)\n```\n\n\nEvery path has a property `Paths.doppler` that corresponds to the aggregated Doppler shift due to the movement of objects it intersects. This property does not account for the additional Doppler shifts caused by possible movements of the transmitter and receiver."
"```python\nprint(\"Path type (0=LoS, 1=Specular reflection): \", paths.types.numpy())\nprint(\"Doppler shifts (Hz): \", paths.doppler.numpy())\n```\n\n\n```python\nPath type (0=LoS, 1=Specular reflection):  [[0 1]]\nDoppler shifts (Hz):  [[[[   0.      -417.68832]]]]\n```"
"### Example: Delay-Doppler Spectrum\n\nWe will now use the Doppler shifts to compute a time-varying channel impulse response and estimate its Delay-Doppler spectrum. To this end, we assume that 1024 subsequent symbols of an OFDM system with 1024 subcarriers can be observed, assuming a subcarrier spacing of 30kHz. This will define the following resolutions in the delay and Doppler domains:\n\n\n```python\nrg = ResourceGrid(num_ofdm_symbols=1024,\n                  fft_size=1024,\n                  subcarrier_spacing=30e3)\ndelay_resolution = rg.ofdm_symbol_duration/rg.fft_size\nprint(\"Delay   resolution (ns): \", int(delay_resolution/1e-9))\ndoppler_resolution = rg.subcarrier_spacing/rg.num_ofdm_symbols\nprint(\"Doppler resolution (Hz): \", int(doppler_resolution))\n```\n\n\n```python\nDelay   resolution (ns):  32\nDoppler resolution (Hz):  29\n```\n\n\nIn addition to the velocity of the reflector, we also assume that the transmitter is moving. Its velocity vector will be provided during the call of the `apply_doppler()` function.\n\n\n```python\n# Compute time evolution of the channel impulse response\ntx_velocity = [30,0,0]\npaths.apply_doppler(sampling_frequency=1/rg.ofdm_symbol_duration,\n                    num_time_steps=rg.num_ofdm_symbols,\n                    tx_velocities=tx_velocity)\n\n### Compute the Delay-Doppler spectrum\n# Determine subcarrier frequencies\nfrequencies = subcarrier_frequencies(rg.fft_size, rg.subcarrier_spacing)\n# Squeeze useless dimensions\n# [num_time_steps, fft_size]\nh = tf.squeeze(cir_to_ofdm_channel(frequencies, *paths.cir(), normalize=True))\n# Apply an FFTshift to bring subcarriers in the\n# correct order for an IFFT\nh = np.fft.fftshift(h, axes=1)\n# Apply IFFT to subcarrier dimension to\n# convert frequency to delay domain\nh_delay = np.fft.ifft(h, axis=1)/np.sqrt(rg.fft_size)\n# Apply FFT to time-step dimension to\n# convert time to Doppler domain\nh_delay_doppler = np.fft.fft(h_delay, axis=0)/np.sqrt(rg.fft_size)\n# Apply FFTShift to bring Doppler dimension in the correct\n# order for visualization\nh_delay_doppler = np.fft.fftshift(h_delay_doppler, axes=0)\n# Compute meshgrid for visualization of the Delay-Doppler spectrum\ndoppler_bins = np.arange(-rg.num_ofdm_symbols/2*doppler_resolution,\n                          rg.num_ofdm_symbols/2*doppler_resolution,\n                         doppler_resolution)\ndelay_bins = np.arange(0,\n                       rg.fft_size*delay_resolution,\n                       delay_resolution) / 1e-9\nx, y = np.meshgrid(delay_bins, doppler_bins)\n# Visualize Delay-Doppler spectrum\nfig = plt.figure(figsize=(8, 10))\nax = fig.add_subplot(111, projection='3d')\n# We only visualize the relevant part of the spectrum\noffset = 20\nx_start = int(rg.fft_size/2)-offset\nx_end = int(rg.fft_size/2)+offset\ny_start = 0\ny_end = offset\nx_grid = x[x_start:x_end,y_start:y_end]\ny_grid = y[x_start:x_end,y_start:y_end]\nz_grid = np.abs(h_delay_doppler[x_start:x_end,y_start:y_end])\nsurf = ax.plot_surface(x_grid,\n                       y_grid,\n                       z_grid,\n                       cmap='viridis', edgecolor='none')\nax.set_xlabel('Delay (ns)')\nax.set_ylabel('Doppler (Hz)')\nax.set_zlabel('Magnitude');\nax.zaxis.labelpad=2\nax.view_init(elev=53, azim=-32)\nax.set_title(\"Delay-Doppler Spectrum\");\n```"
"As expected, we can observe two peaks in the Delay-Doppler spectrum above. The first at a delay of around 160ns, and the second at a delay of approximately 370ns. The respective Doppler shifts are around 350Hz and -260Hz.\n\nNext, we will compute the exact Doppler shifts based on the equation provided in the [Background Information](https://nvlabs.github.io/sionna/examples/Sionna_Ray_Tracing_Mobility.html#Background-Information) that should match the peaks in the Delay-Doppler spectrum.\n\n\n```python\n# Compute outgoing directions for the LoS and reflected path\nk_t_los = r_hat(paths.theta_t[0,0,0,0], paths.phi_t[0,0,0,0])\nk_t_ref = r_hat(paths.theta_t[0,0,0,1], paths.phi_t[0,0,0,1])\n# Compute the Doppler shifts due to movement of the transmitter\ndoppler_tx_los = np.sum(k_t_los*tx_velocity)/scene.wavelength\ndoppler_tx_ref = np.sum(k_t_ref*tx_velocity)/scene.wavelength\n# Compute the overall Doppler shifts\ndoppler_los = doppler_tx_los + paths.doppler[0,0,0,0]\ndoppler_ref = doppler_tx_ref + paths.doppler[0,0,0,1]\nprint(\"Delay - LoS Path (ns) :\", paths.tau[0,0,0,0].numpy()/1e-9)\nprint(\"Doppler - LoS Path (Hz) :\", doppler_los.numpy())\nprint(\"Delay - Reflected Path (ns) :\", paths.tau[0,0,0,1].numpy()/1e-9)\nprint(\"Doppler - Reflected Path (Hz) :\", doppler_ref.numpy())\n```\n\n\n```python\nDelay - LoS Path (ns) : 166.78205838616122\nDoppler - LoS Path (Hz) : 350.2423\nDelay - Reflected Path (ns) : 372.93600030352536\nDoppler - Reflected Path (Hz) : -261.05524\n```"
"## Comparison of Doppler- vs Position-based Time Evolution\n\nWe will now compare a time-varying channel frequency impulse response generated by the application of Doppler shifts against another one obtained by physically moving objects in a scene and retracing the paths.\n\nThe same scene as in the first section will be used where a transmitter is placed on a moving car. However, we now also place a receiver on another car and assume that all cars in the scene are moving along a linear trajectory.\n\n\n```python\nscene = load_scene(sionna.rt.scene.simple_street_canyon_with_cars)\nscene.add(Camera(\"cam\", position=[50,0,130], look_at=[10,0,0]))\n# Parameters for ray tracing\nmax_depth = 3\ndiffraction = True\n# TX and RX have directional antennas\nscene.tx_array = PlanarArray(1,1,0.5,0.5,\"tr38901\",\"V\")\nscene.rx_array = scene.tx_array\n# TX and RX are installed at the front of two different cars.\n# The directive antennas ensure that paths reaching an antenna from the back are close to zero.\nscene.add(Transmitter(\"tx\", position=[22.7, 5.6, 0.75], orientation=[np.pi,0,0]))\nscene.add(Receiver(\"rx\", position=[-27.8,-4.9, 0.75]))\n# Configure an OFDM resource grid\nrg = ResourceGrid(num_ofdm_symbols=128,\n                  fft_size=1024,\n                  subcarrier_spacing=30e3)\nfrequencies = subcarrier_frequencies(rg.fft_size, rg.subcarrier_spacing)\n# Define a velocity vector and the corresponding displacement over the duration\n# of one OFDM symbol\nvelocity_vec = np.array([10,0,0])\ndisplacement_vec = velocity_vec*rg.ofdm_symbol_duration\n# Assign velocity vector to cars driving in -x direction\nfor j in range(1,6):\n    scene.get(f\"car_{j}\").velocity = -velocity_vec\n# Assign velocity vector to cars driving in x direction\nfor j in range(6,9):\n    scene.get(f\"car_{j}\").velocity = velocity_vec\n# Compute paths and apply Doppler shift for time evolution\npaths = scene.compute_paths(max_depth=max_depth, diffraction=diffraction)\npaths.normalize_delays = False\npaths.apply_doppler(sampling_frequency=1/rg.ofdm_symbol_duration,\n                    num_time_steps=rg.num_ofdm_symbols,\n                    tx_velocities=-velocity_vec,\n                    rx_velocities=velocity_vec)\n# Compute the corresponding channel frequency responses\nh_dop = tf.squeeze(cir_to_ofdm_channel(frequencies, *paths.cir()))\n# Visualize the scene and propagation paths\nif colab_compat:\n    scene.render(paths=paths, camera=\"cam\", num_samples=512);\n    raise ExitCell\nscene.preview(paths=paths)\n```"
"In the next cell, we compute a sequence of channel frequency responses by moving all cars as well as the transmitter and receiver in the scene. After each step, propagation paths are traced and the corresponding channel frequency response is computed.\n\n\n```python\npaths = scene.compute_paths(max_depth=max_depth, diffraction=diffraction)\npaths.normalize_delays = False\n# Reshape to [1, num_subcarriers]\nh_sim = tf.reshape(cir_to_ofdm_channel(frequencies, *paths.cir()), [1, -1])\nfor i in range(rg.num_ofdm_symbols-1):\n    # Move TX and RX to next position\n    scene.get(\"tx\").position -= displacement_vec\n    scene.get(\"rx\").position += displacement_vec\n    # Move cars driving in -x direction to the next position\n    for j in range(1,6):\n        scene.get(f\"car_{j}\").position -= displacement_vec\n    # Move cars driving in +x direction to the next position\n    for j in range(6,9):\n        scene.get(f\"car_{j}\").position += displacement_vec\n    # Compute channel frequency response\n    paths = scene.compute_paths(max_depth=max_depth, diffraction=diffraction)\n    paths.normalize_delays = False\n    h = tf.reshape(cir_to_ofdm_channel(frequencies, *paths.cir()), [1, -1])\n    # Concatenate along the time dimensions\n    h_sim = tf.concat([h_sim, h], axis=0)\n```\n\n\nNext, we visualize the the time evolution of a few subcarriers as well as some snapshots of the full channel frequency response.\n\n\n```python\nsubcarriers = np.arange(0, 1024, 256)\ntimesteps =  np.arange(0, 128, 32)\nfig, axs = plt.subplots(2, 4, figsize=(18, 7))\nfor i,j in enumerate(subcarriers):\n    axs[0,i].plot(np.arange(rg.num_ofdm_symbols), np.abs(h_sim[:,j]))\n    axs[0,i].plot(np.arange(rg.num_ofdm_symbols), np.abs(h_dop[:,j]), \"--\")\n    axs[0,i].set_xlabel(\"Timestep\")\n    axs[0,i].set_ylabel(r\"$|h(f,t)|$\")\n    axs[0,i].set_title(f\"Subcarrier {j}\")\n    axs[0,i].legend([\"Movement\", \"Doppler\"])\n\nfor i,j in enumerate(timesteps):\n    axs[1,i].plot(np.arange(rg.fft_size), np.abs(h_sim[j,:]))\n    axs[1,i].plot(np.arange(rg.fft_size), np.abs(h_dop[j,:]), \"--\")\n    axs[1,i].set_xlabel(\"Subcarrier\")\n    axs[1,i].set_ylabel(r\"$|h(f,t)|$\")\n    axs[1,i].set_title(f\"Timestep {j}\")\n    axs[1,i].legend([\"Movement\", \"Doppler\"])\nplt.tight_layout()\nplt.show()\n```"
"From the figures above, we can see that there is until time step 80 no noticeable difference between the Doppler-based channel evolution and the one based on physically moving objects. At time step 80, some paths (diss-)appear and the Doppler-based time-evolution becomes less accurate."
"## Summary\n\nWe have discussed two different ways to simulate mobility in Sionna RT. One can either move objects in a scene and recompute paths or compute the time evolution of channels synthetically based on the Doppler shifts that are obtained from velocity vectors of the scene objects.\n\nThe former approach is computationally intensive but accurate while the latter is much faster but only accurate over short time spans during which the scene objects have moved very short distances.\n\nBoth approaches can be combined to simulate mobility over longer periods of time.\n\nWe hope you enjoyed our dive into the simulation of mobility with Sionna RT. You may also want to explore our other [tutorials](https://nvlabs.github.io/sionna/tutorials.html#ray-tracing).We hope you enjoyed our dive into the simulation of mobility with Sionna RT. You may also want to explore our other [tutorials](https://nvlabs.github.io/sionna/tutorials.html#ray-tracing).We hope you enjoyed our dive into the simulation of mobility with Sionna RT. You may also want to explore our other [tutorials](https://nvlabs.github.io/sionna/tutorials.html#ray-tracing).We hope you enjoyed our dive into the simulation of mobility with Sionna RT. You may also want to explore our other [tutorials](https://nvlabs.github.io/sionna/tutorials.html#ray-tracing)."

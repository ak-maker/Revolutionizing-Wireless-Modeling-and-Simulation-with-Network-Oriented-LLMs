"# 5G NR\n\nThis module provides layers and functions to support simulations of\n5G NR compliant features, in particular, the physical uplink shared channel (PUSCH). It provides implementations of a subset of the physical layer functionalities as described in the 3GPP specifications [[3GPP38211]](https://nvlabs.github.io/sionna/api/nr.html#gpp38211), [[3GPP38212]](https://nvlabs.github.io/sionna/api/nr.html#gpp38212), and [[3GPP38214]](https://nvlabs.github.io/sionna/api/nr.html#gpp38214).\n\nThe best way to discover this modules components is by having a look at the [5G NR PUSCH Tutorial](../examples/5G_NR_PUSCH.html).\n\nThe following code snippet shows how you can make standard-compliant\nsimulations of the 5G NR PUSCH with a few lines of code:\n```python\n# Create a PUSCH configuration with default settings\npusch_config = PUSCHConfig()\n# Instantiate a PUSCHTransmitter from the PUSCHConfig\npusch_transmitter = PUSCHTransmitter(pusch_config)\n# Create a PUSCHReceiver using the PUSCHTransmitter\npusch_receiver = PUSCHReceiver(pusch_transmitter)\n# AWGN channel\nchannel = AWGN()\n# Simulate transmissions over the AWGN channel\nbatch_size = 16\nno = 0.1 # Noise variance\nx, b = pusch_transmitter(batch_size) # Generate transmit signal and info bits\ny = channel([x, no]) # Simulate channel output\nb_hat = pusch_receiver([x, no]) # Recover the info bits\n# Compute BER\nprint(\"BER:\", compute_ber(b, b_hat).numpy())\n```\n\n\nThe [`PUSCHTransmitter`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHTransmitter) and [`PUSCHReceiver`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHReceiver) provide high-level abstractions of all required processing blocks. You can easily modify them according to your needs."
"### CarrierConfig\n\n`class` `sionna.nr.``CarrierConfig`(*`**``kwargs`*)[`[source]`](../_modules/sionna/nr/carrier_config.html#CarrierConfig)\n\nThe CarrierConfig objects sets parameters for a specific OFDM numerology,\nas described in Section 4 [[3GPP38211]](https://nvlabs.github.io/sionna/api/nr.html#gpp38211).\n\nAll configurable properties can be provided as keyword arguments during the\ninitialization or changed later.\n xample\n```python\n>>> carrier_config = CarrierConfig(n_cell_id=41)\n>>> carrier_config.subcarrier_spacing = 30\n```\n`property` `cyclic_prefix`\n\nCyclic prefix length\n\nThe option normal corresponds to 14 OFDM symbols per slot, while\nextended corresponds to 12 OFDM symbols. The latter option is\nonly possible with a <cite>subcarrier_spacing</cite> of 60 kHz.\nType\n\nstr, normal (default) | extended\n\n\n`property` `cyclic_prefix_length`\n\nCyclic prefix length\n$N_{\\text{CP},l}^{\\mu} \\cdot T_{\\text{c}}$ [s]\nType\n\nfloat, read-only\n\n\n`property` `frame_duration`\n\nDuration of a frame\n$T_\\text{f}$ [s]\nType\n\nfloat, 10e-3 (default), read-only\n\n\n`property` `frame_number`\n\nSystem frame number $n_\\text{f}$\nType\n\nint, 0 (default), [0,,1023]\n\n\n`property` `kappa`\n\nThe constant\n$\\kappa = T_\\text{s}/T_\\text{c}$\nType\n\nfloat, 64, read-only\n\n\n`property` `mu`\n\nSubcarrier\nspacing configuration, $\\Delta f = 2^\\mu 15$ kHz\nType\n\nint, 0 (default) | 1 | 2 | 3 | 4 | 5 | 6, read-only\n\n\n`property` `n_cell_id`\n\nPhysical layer cell identity\n$N_\\text{ID}^\\text{cell}$\nType\n\nint, 1 (default) | [0,,1007]\n\n\n`property` `n_size_grid`\n\nNumber of resource blocks in the\ncarrier resource grid $N^{\\text{size},\\mu}_{\\text{grid},x}$\nType\n\nint, 4 (default) | [1,,275]\n\n\n`property` `n_start_grid`\n\nStart of resource grid relative to\ncommon resource block (CRB) 0\n$N^{\\text{start},\\mu}_{\\text{grid},x}$\nType\n\nint, 0 (default) | [0,,2199]\n\n\n`property` `num_slots_per_frame`\n\nNumber\nof slots per frame $N_\\text{slot}^{\\text{frame},\\mu}$\n\nDepends on the <cite>subcarrier_spacing</cite>.\nType\n\nint, 10 (default) | 20 | 40 | 80 | 160 | 320 | 640, read-only\n\n\n`property` `num_slots_per_subframe`\n\nNumber of\nslots per subframe $N_\\text{slot}^{\\text{subframe},\\mu}$\n\nDepends on the <cite>subcarrier_spacing</cite>.\nType\n\nint, 1 (default) | 2 | 4 | 8 | 16 | 32 | 64, read-only\n\n\n`property` `num_symbols_per_slot`\n\nNumber of OFDM symbols per slot\n$N_\\text{symb}^\\text{slot}$\n\nConfigured through the <cite>cyclic_prefix</cite>.\nType\n\nint, 14 (default) | 12, read-only\n\n\n`property` `slot_number`\n\nSlot number within a frame\n$n^\\mu_{s,f}$\nType\n\nint, 0 (default), [0,,num_slots_per_frame]\n\n\n`property` `sub_frame_duration`\n\nDuration of a subframe\n$T_\\text{sf}$ [s]\nType\n\nfloat, 1e-3 (default), read-only\n\n\n`property` `subcarrier_spacing`\n\nSubcarrier\nspacing $\\Delta f$ [kHz]\nType\n\nfloat, 15 (default) | 30 | 60 | 120 | 240 | 480 | 960\n\n\n`property` `t_c`\n\nSampling time $T_\\text{c}$ for\nsubcarrier spacing 480kHz.\nType\n\nfloat, 0.509e-9 [s], read-only\n\n\n`property` `t_s`\n\nSampling time $T_\\text{s}$ for\nsubcarrier spacing 15kHz.\nType\n\nfloat, 32.552e-9 [s], read-only"
"### LayerMapper\n\n`class` `sionna.nr.``LayerMapper`(*`num_layers``=``1`*, *`verbose``=``False`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/nr/layer_mapping.html#LayerMapper)\n\nPerforms MIMO layer mapping of modulated symbols to layers as defined in\n[[3GPP38211]](https://nvlabs.github.io/sionna/api/nr.html#gpp38211).\n\nThe LayerMapper supports PUSCH and PDSCH channels and follows the procedure\nas defined in Sec. 6.3.1.3 and Sec. 7.3.1.3 in [[3GPP38211]](https://nvlabs.github.io/sionna/api/nr.html#gpp38211), respectively.\n\nAs specified in Tab. 7.3.1.3.-1 [[3GPP38211]](https://nvlabs.github.io/sionna/api/nr.html#gpp38211), the LayerMapper expects two\ninput streams for multiplexing if more than 4 layers are active (only\nrelevant for PDSCH).\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **num_layers** (*int**, **1** (**default**) **|** [**1**,**...**,**8**]*)  Number of MIMO layers. If\n`num_layers` >=4, a list of two inputs is expected.\n- **verbose** (*bool**, **False** (**default**)*)  If True, additional parameters are printed.\n\n\nInput\n\n**inputs** (*[,n], or [[,n1], [,n2]], tf.complex*)  2+D tensor containing the sequence of symbols to be mapped. If\n`num_layers` >=4, a list of two inputs is expected and <cite>n1</cite>/<cite>n2</cite>\nmust be chosen as defined in Tab. 7.3.1.3.-1 [[3GPP38211]](https://nvlabs.github.io/sionna/api/nr.html#gpp38211).\n\nOutput\n\n*[,num_layers, n/num_layers], tf.complex*  2+D tensor containing the sequence of symbols mapped to the MIMO\nlayers.\n\n\n`property` `num_codewords`\n\nNumber of input codewords for layer mapping. Can be either 1 or 2.\n\n\n`property` `num_layers`\n\nNumber of MIMO layers\n\n\n`property` `num_layers0`\n\nNumber of layers for first codeword (only relevant for\n<cite>num_codewords</cite> =2)\n\n\n`property` `num_layers1`\n\nNumber of layers for second codeword (only relevant for\n<cite>num_codewords</cite> =2)"
"### LayerDemapper\n\n`class` `sionna.nr.``LayerDemapper`(*`layer_mapper`*, *`num_bits_per_symbol``=``1`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/nr/layer_mapping.html#LayerDemapper)\n\nDemaps MIMO layers to coded transport block(s) by following Sec. 6.3.1.3\nand Sec. 7.3.1.3 in [[3GPP38211]](https://nvlabs.github.io/sionna/api/nr.html#gpp38211).\n\nThis layer must be associated to a [`LayerMapper`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.LayerMapper) and\nperforms the inverse operation.\n\nIt is assumed that `num_bits_per_symbol` consecutive LLRs belong to\na single symbol position. This allows to apply the LayerDemapper after\ndemapping symbols to LLR values.\n\nIf the layer mapper is configured for dual codeword transmission, a list of\nboth transport block streams is returned.\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **layer_mapper** ([`LayerMapper`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.LayerMapper))  Associated LayerMapper.\n- **num_bits_per_symbol** (*int**, **1** (**default**)*)  Modulation order. Defines how many consecutive LLRs are associated\nto the same symbol position.\n\n\nInput\n\n**inputs** (*[,num_layers, n/num_layers], tf.float*)  2+D tensor containing MIMO layer data sequences.\n\nOutput\n\n*[,n], or [[,n1], [,n2]], tf.float*  2+D tensor containing the sequence of bits after layer demapping.\nIf `num_codewords` =2, a list of two transport blocks is returned.\n\n\n**Note**\n\nAs it is more convenient to apply the layer demapper after demapping\nsymbols to LLRs, this layer groups the input sequence into groups of\n`num_bits_per_symbol` LLRs before restoring the original symbol sequence.\nThis behavior can be deactivated by setting `num_bits_per_symbol` =1."
"### PUSCHConfig\n\n`class` `sionna.nr.``PUSCHConfig`(*`carrier_config``=``None`*, *`pusch_dmrs_config``=``None`*, *`tb_config``=``None`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/nr/pusch_config.html#PUSCHConfig)\n\nThe PUSCHConfig objects sets parameters for a physical uplink shared\nchannel (PUSCH), as described in Sections 6.3 and 6.4 [[3GPP38211]](https://nvlabs.github.io/sionna/api/nr.html#gpp38211).\n\nAll configurable properties can be provided as keyword arguments during the\ninitialization or changed later.\nParameters\n\n- **carrier_config** ([`CarrierConfig`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.CarrierConfig) or <cite>None</cite>)  An instance of [`CarrierConfig`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.CarrierConfig). If <cite>None</cite>, a\n[`CarrierConfig`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.CarrierConfig) instance with default settings\nwill be created.\n- **pusch_dmrs_config** ([`PUSCHDMRSConfig`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHDMRSConfig) or <cite>None</cite>)  An instance of [`PUSCHDMRSConfig`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHDMRSConfig). If <cite>None</cite>, a\n[`PUSCHDMRSConfig`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHDMRSConfig) instance with default settings\nwill be created.\n\n\n xample\n```python\n>>> pusch_config = PUSCHConfig(mapping_type=\"B\")\n>>> pusch_config.dmrs.config_type = 2\n>>> pusch_config.carrier.subcarrier_spacing = 30\n```\n`c_init`(*`l`*)[`[source]`](../_modules/sionna/nr/pusch_config.html#PUSCHConfig.c_init)\n\nCompute RNG initialization $c_\\text{init}$ as in Section 6.4.1.1.1.1 [[3GPP38211]](https://nvlabs.github.io/sionna/api/nr.html#gpp38211)\nInput\n\n**l** (*int*)  OFDM symbol index relative to a reference $l$\n\nOutput\n\n**c_init** (*int*)  RNG initialization value\n\n\n`property` `carrier`\n\nCarrier configuration\nType\n\n[`CarrierConfig`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.CarrierConfig)\n\n\n`property` `dmrs`\n\nPUSCH DMRS configuration\nType\n\n[`PUSCHDMRSConfig`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHDMRSConfig)\n\n\n`property` `dmrs_grid`\n\nEmpty\nresource grid for each DMRS port, filled with DMRS signals\n\nThis property returns for each configured DMRS port an empty\nresource grid filled with DMRS signals as defined in\nSection 6.4.1.1 [3GPP38211]. Not all possible options are implemented,\ne.g., frequency hopping and transform precoding are not available.\n\nThis property provides the *unprecoded* DMRS for each configured DMRS port.\nPrecoding might be applied to map the DMRS to the antenna ports. However,\nin this case, the number of DMRS ports cannot be larger than the number of\nlayers.\nType\n\ncomplex, [num_dmrs_ports, num_subcarriers, num_symbols_per_slot], read-only\n\n\n`property` `dmrs_mask`\n\nMasked\nresource elements in the resource grid. <cite>True</cite> corresponds to\nresource elements on which no data is transmitted.\nType\n\nbool, [num_subcarriers, num_symbols_per_slot], read-only\n\n\n`property` `dmrs_symbol_indices`\n\nIndices of DMRS symbols within a slot\nType\n\nlist, int, read-only\n\n\n`property` `frequency_hopping`\n\nFrequency hopping configuration\nType\n\nstr, neither (default), read-only\n\n\n`property` `l_bar`\n\nList of possible values of\n$\\bar{l}$ used for DMRS generation\n\nDefined in Tables 6.4.1.1.3-3 and 6.4.1.1.3-4 [[3GPP38211]](https://nvlabs.github.io/sionna/api/nr.html#gpp38211).\nType\n\nlist, elements in [0,,11], read-only\n\n\n`property` `mapping_type`\n\nMapping type\nType\n\nstring, A (default) | B\n\n\n`property` `n_rnti`\n\nRadio network temporary identifier\n$n_\\text{RNTI}$\nType\n\nint, 1 (default), [0,,65535]\n\n\n`property` `n_size_bwp`\n\nNumber of resource blocks in the\nbandwidth part (BWP) $N^{\\text{size},\\mu}_{\\text{BWP},i}$\n\nIf set to <cite>None</cite>, the property\n[`n_size_grid`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.CarrierConfig.n_size_grid) of\n<cite>carrier</cite> will be used.\nType\n\nint, None (default), [1,,275]\n\n\n`property` `n_start_bwp`\n\nStart of BWP relative to\ncommon resource block (CRB) 0\n$N^{\\text{start},\\mu}_{\\text{BWP},i}$\nType\n\nint, 0 (default) | [0,,2199]\n\n\n`property` `num_antenna_ports`\n\nNumber of antenna ports\n\nMust be larger than or equal to\n[`num_layers`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHConfig.num_layers).\nType\n\nint, 1 (default) | 2 | 4\n\n\n`property` `num_coded_bits`\n\nNumber of coded bits that fit into one PUSCH slot.\nType\n\nint, read-only\n\n\n`property` `num_layers`\n\nNumber of transmission layers\n$\\nu$\n\nMust be smaller than or equal to\n[`num_antenna_ports`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHConfig.num_antenna_ports).\nType\n\nint, 1 (default) | 2 | 3 | 4\n\n\n`property` `num_ov`\n\nNumber of unused resource elements due to additional overhead as specified by higher layer.\nType\n\nint, 0 (default), read-only\n\n\n`property` `num_res_per_prb`\n\nNumber of resource elements per PRB\navailable for data\nType\n\nint, read-only\n\n\n`property` `num_resource_blocks`\n\nNumber of allocated resource blocks for the\nPUSCH transmissions.\nType\n\nint, read-only\n\n\n`property` `num_subcarriers`\n\nNumber of allocated subcarriers for the\nPUSCH transmissions\nType\n\nint, read-only\n\n\n`property` `precoding`\n\nPUSCH\ntransmission scheme\nType\n\nstr, non-codebook (default), codebook\n\n\n`property` `precoding_matrix`\n\nPrecoding matrix\n$\\mathbf{W}$ as defined in\nTables 6.3.1.5-1 to 6.3.1.5-7 [[3GPP38211]](https://nvlabs.github.io/sionna/api/nr.html#gpp38211).\n\nOnly relevant if `precoding`\nis codebook.\nType\n\nnd_array, complex, [num_antenna_ports, numLayers]\n\n\n`show`()[`[source]`](../_modules/sionna/nr/pusch_config.html#PUSCHConfig.show)\n\nPrint all properties of the PUSCHConfig and children\n\n\n`property` `symbol_allocation`\n\nPUSCH symbol allocation\n\nThe first elements denotes the start of the symbol allocation.\nThe second denotes the positive number of allocated OFDM symbols.\nFor <cite>mapping_type</cite> A, the first element must be zero.\nFor <cite>mapping_type</cite> B, the first element must be in\n[0,,13]. The second element must be such that the index\nof the last allocated OFDM symbol is not larger than 13\n(for normal cyclic prefix) or 11 (for extended cyclic prefix).\nType\n\n2-tuple, int, [0, 14] (default)\n\n\n`property` `tb`\n\nTransport block configuration\nType\n\n[`TBConfig`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.TBConfig)\n\n\n`property` `tb_size`\n\nTransport block size, i.e., how many information bits can be encoded into a slot for the given slot configuration.\nType\n\nint, read-only\n\n\n`property` `tpmi`\n\nTransmit precoding matrix indicator\n\nThe allowed value depends on the number of layers and\nthe number of antenna ports according to Table 6.3.1.5-1\nuntil Table 6.3.1.5-7 [[3GPP38211]](https://nvlabs.github.io/sionna/api/nr.html#gpp38211).\nType\n\nint,  0 (default) | [0,,27]\n\n\n`property` `transform_precoding`\n\nUse transform precoding\nType\n\nbool, False (default)"
"### PUSCHDMRSConfig\n\n`class` `sionna.nr.``PUSCHDMRSConfig`(*`**``kwargs`*)[`[source]`](../_modules/sionna/nr/pusch_dmrs_config.html#PUSCHDMRSConfig)\n\nThe PUSCHDMRSConfig objects sets parameters related to the generation\nof demodulation reference signals (DMRS) for a physical uplink shared\nchannel (PUSCH), as described in Section 6.4.1.1 [[3GPP38211]](https://nvlabs.github.io/sionna/api/nr.html#gpp38211).\n\nAll configurable properties can be provided as keyword arguments during the\ninitialization or changed later.\n xample\n```python\n>>> dmrs_config = PUSCHDMRSConfig(config_type=2)\n>>> dmrs_config.additional_position = 1\n```\n`property` `additional_position`\n\nMaximum number of additional DMRS positions\n\nThe actual number of used DMRS positions depends on\nthe length of the PUSCH symbol allocation.\nType\n\nint, 0 (default) | 1 | 2 | 3\n\n\n`property` `allowed_dmrs_ports`\n\nList of nominal antenna\nports\n\nThe maximum number of allowed antenna ports <cite>max_num_dmrs_ports</cite>\ndepends on the DMRS <cite>config_type</cite> and <cite>length</cite>. It can be\nequal to 4, 6, 8, or 12.\nType\n\nlist, [0,,max_num_dmrs_ports-1], read-only\n\n\n`property` `beta`\n\nRatio of PUSCH energy per resource element\n(EPRE) to DMRS EPRE $\\beta^{\\text{DMRS}}_\\text{PUSCH}$\nTable 6.2.2-1 [[3GPP38214]](https://nvlabs.github.io/sionna/api/nr.html#gpp38214)\nType\n\nfloat, read-only\n\n\n`property` `cdm_groups`\n\nList of CDM groups\n$\\lambda$ for all ports\nin the <cite>dmrs_port_set</cite> as defined in\nTable 6.4.1.1.3-1 or 6.4.1.1.3-2 [[3GPP38211]](https://nvlabs.github.io/sionna/api/nr.html#gpp38211)\n\nDepends on the <cite>config_type</cite>.\nType\n\nlist, elements in [0,1,2], read-only\n\n\n`property` `config_type`\n\nDMRS configuration type\n\nThe configuration type determines the frequency density of\nDMRS signals. With configuration type 1, six subcarriers per PRB are\nused for each antenna port, with configuration type 2, four\nsubcarriers are used.\nType\n\nint, 1 (default) | 2\n\n\n`property` `deltas`\n\nList of delta (frequency)\nshifts $\\Delta$ for all ports in the <cite>port_set</cite> as defined in\nTable 6.4.1.1.3-1 or 6.4.1.1.3-2 [[3GPP38211]](https://nvlabs.github.io/sionna/api/nr.html#gpp38211)\n\nDepends on the <cite>config_type</cite>.\nType\n\nlist, elements in [0,1,2,4], read-only\n\n\n`property` `dmrs_port_set`\n\nList of used DMRS antenna ports\n\nThe elements in this list must all be from the list of\n<cite>allowed_dmrs_ports</cite> which depends on the <cite>config_type</cite> as well as\nthe <cite>length</cite>. If set to <cite>[]</cite>, the port set will be equal to\n[0,,num_layers-1], where\n[`num_layers`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHConfig.num_layers) is a property of the\nparent [`PUSCHConfig`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHConfig) instance.\nType\n\nlist, [] (default) | [0,,11]\n\n\n`property` `length`\n\nNumber of front-loaded DMRS symbols\nA value of 1 corresponds to single-symbol DMRS, a value\nof 2 corresponds to double-symbol DMRS.\nType\n\nint, 1 (default) | 2\n\n\n`property` `n_id`\n\nScrambling\nidentities\n\nDefines the scrambling identities $N_\\text{ID}^0$ and\n$N_\\text{ID}^1$ as a 2-tuple of integers. If <cite>None</cite>,\nthe property [`n_cell_id`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.CarrierConfig.n_cell_id) of the\n[`CarrierConfig`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.CarrierConfig) is used.\nType\n\n2-tuple, None (default), [[0,,65535], [0,,65535]]\n\n\n`property` `n_scid`\n\nDMRS scrambling initialization\n$n_\\text{SCID}$\nType\n\nint, 0 (default) | 1\n\n\n`property` `num_cdm_groups_without_data`\n\nNumber of CDM groups without data\n\nThis parameter controls how many REs are available for data\ntransmission in a DMRS symbol. It should be greater or equal to\nthe maximum configured number of CDM groups. A value of\n1 corresponds to CDM group 0, a value of 2 corresponds to\nCDM groups 0 and 1, and a value of 3 corresponds to\nCDM groups 0, 1, and 2.\nType\n\nint, 2 (default) | 1 | 3\n\n\n`property` `type_a_position`\n\nPosition of first DMRS OFDM symbol\n\nDefines the position of the first DMRS symbol within a slot.\nThis parameter only applies if the property\n[`mapping_type`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHConfig.mapping_type) of\n[`PUSCHConfig`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHConfig) is equal to A.\nType\n\nint, 2 (default) | 3\n\n\n`property` `w_f`\n\nFrequency weight vectors\n$w_f(k')$ for all ports in the port set as defined in\nTable 6.4.1.1.3-1 or 6.4.1.1.3-2 [[3GPP38211]](https://nvlabs.github.io/sionna/api/nr.html#gpp38211)\nType\n\nmatrix, elements in [-1,1], read-only\n\n\n`property` `w_t`\n\nTime weight vectors\n$w_t(l')$ for all ports in the port set as defined in\nTable 6.4.1.1.3-1 or 6.4.1.1.3-2 [[3GPP38211]](https://nvlabs.github.io/sionna/api/nr.html#gpp38211)\nType\n\nmatrix, elements in [-1,1], read-only"
"### PUSCHLSChannelEstimator\n\n`class` `sionna.nr.``PUSCHLSChannelEstimator`(*`resource_grid`*, *`dmrs_length`*, *`dmrs_additional_position`*, *`num_cdm_groups_without_data`*, *`interpolation_type``=``'nn'`*, *`interpolator``=``None`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/nr/pusch_channel_estimation.html#PUSCHLSChannelEstimator)\n\nLayer implementing least-squares (LS) channel estimation for NR PUSCH Transmissions.\n\nAfter LS channel estimation at the pilot positions, the channel estimates\nand error variances are interpolated accross the entire resource grid using\na specified interpolation function.\n\nThe implementation is similar to that of [`LSChannelEstimator`](ofdm.html#sionna.ofdm.LSChannelEstimator).\nHowever, it additional takes into account the separation of streams in the same CDM group\nas defined in [`PUSCHDMRSConfig`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHDMRSConfig). This is done through\nfrequency and time averaging of adjacent LS channel estimates.\nParameters\n\n- **resource_grid** ()  An instance of [`ResourceGrid`](ofdm.html#sionna.ofdm.ResourceGrid)\n- **dmrs_length** (*int**, **[**1**,**2**]*)  Length of DMRS symbols. See [`PUSCHDMRSConfig`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHDMRSConfig).\n- **dmrs_additional_position** (*int**, **[**0**,**1**,**2**,**3**]*)  Number of additional DMRS symbols.\nSee [`PUSCHDMRSConfig`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHDMRSConfig).\n- **num_cdm_groups_without_data** (*int**, **[**1**,**2**,**3**]*)  Number of CDM groups masked for data transmissions.\nSee [`PUSCHDMRSConfig`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHDMRSConfig).\n- **interpolation_type** (*One of** [**\"nn\"**, **\"lin\"**, **\"lin_time_avg\"**]**, **string*)  The interpolation method to be used.\nIt is ignored if `interpolator` is not <cite>None</cite>.\nAvailable options are [`NearestNeighborInterpolator`](ofdm.html#sionna.ofdm.NearestNeighborInterpolator) (<cite>nn</cite>)\nor [`LinearInterpolator`](ofdm.html#sionna.ofdm.LinearInterpolator) without (<cite>lin</cite>) or with\naveraging across OFDM symbols (<cite>lin_time_avg</cite>).\nDefaults to nn.\n- **interpolator** ()  An instance of [`BaseChannelInterpolator`](ofdm.html#sionna.ofdm.BaseChannelInterpolator),\nsuch as [`LMMSEInterpolator`](ofdm.html#sionna.ofdm.LMMSEInterpolator),\nor <cite>None</cite>. In the latter case, the interpolator specified\nby `interpolation_type` is used.\nOtherwise, the `interpolator` is used and `interpolation_type`\nis ignored.\nDefaults to <cite>None</cite>.\n- **dtype** (*tf.Dtype*)  Datatype for internal calculations and the output dtype.\nDefaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n- **(y, no)**  Tuple:\n- **y** (*[batch_size, num_rx, num_rx_ant, num_ofdm_symbols,fft_size], tf.complex*)  Observed resource grid\n- **no** (*[batch_size, num_rx, num_rx_ant] or only the first n>=0 dims, tf.float*)  Variance of the AWGN\n\n\nOutput\n\n- **h_ls** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols,fft_size], tf.complex*)  Channel estimates across the entire resource grid for all\ntransmitters and streams\n- **err_var** (Same shape as `h_ls`, tf.float)  Channel estimation error variance across the entire resource grid\nfor all transmitters and streams"
"### PUSCHPilotPattern\n\n`class` `sionna.nr.``PUSCHPilotPattern`(*`pusch_configs`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/nr/pusch_pilot_pattern.html#PUSCHPilotPattern)\n\nClass defining a pilot pattern for NR PUSCH.\n\nThis class defines a [`PilotPattern`](ofdm.html#sionna.ofdm.PilotPattern)\nthat is used to configure an OFDM [`ResourceGrid`](ofdm.html#sionna.ofdm.ResourceGrid).\n\nFor every transmitter, a separte [`PUSCHConfig`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHConfig)\nneeds to be provided from which the pilot pattern will be created.\nParameters\n\n- **pusch_configs** (instance or list of [`PUSCHConfig`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHConfig))  PUSCH Configurations according to which the pilot pattern\nwill created. One configuration is needed for each transmitter.\n- **dtype** (*tf.Dtype*)  Defines the datatype for internal calculations and the output\ndtype. Defaults to <cite>tf.complex64</cite>.\n\n\n`property` `mask`\n\nMask of the pilot pattern\n\n\n`property` `normalize`\n\nReturns or sets the flag indicating if the pilots\nare normalized or not\n\n\n`property` `num_data_symbols`\n\nNumber of data symbols per transmit stream.\n\n\n`property` `num_effective_subcarriers`\n\nNumber of effectvie subcarriers\n\n\n`property` `num_ofdm_symbols`\n\nNumber of OFDM symbols\n\n\n`property` `num_pilot_symbols`\n\nNumber of pilot symbols per transmit stream.\n\n\n`property` `num_streams_per_tx`\n\nNumber of streams per transmitter\n\n\n`property` `num_tx`\n\nNumber of transmitters\n\n\n`property` `pilots`\n\nReturns or sets the possibly normalized tensor of pilot symbols.\nIf pilots are normalized, the normalization will be applied\nafter new values for pilots have been set. If this is\nnot the desired behavior, turn normalization off.\n\n\n`show`(*`tx_ind``=``None`*, *`stream_ind``=``None`*, *`show_pilot_ind``=``False`*)\n\nVisualizes the pilot patterns for some transmitters and streams.\nInput\n\n- **tx_ind** (*list, int*)  Indicates the indices of transmitters to be included.\nDefaults to <cite>None</cite>, i.e., all transmitters included.\n- **stream_ind** (*list, int*)  Indicates the indices of streams to be included.\nDefaults to <cite>None</cite>, i.e., all streams included.\n- **show_pilot_ind** (*bool*)  Indicates if the indices of the pilot symbols should be shown.\n\n\nOutput\n\n**list** (*matplotlib.figure.Figure*)  List of matplot figure objects showing each the pilot pattern\nfrom a specific transmitter and stream.\n\n\n`property` `trainable`\n\nReturns if pilots are trainable or not"
"### PUSCHPrecoder\n\n`class` `sionna.nr.``PUSCHPrecoder`(*`precoding_matrices`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/nr/pusch_precoder.html#PUSCHPrecoder)\n\nPrecodes a batch of modulated symbols mapped onto a resource grid\nfor PUSCH transmissions. Each transmitter is assumed to have its\nown precoding matrix.\nParameters\n\n- **precoding_matrices** (*list**, **[**num_tx**, **num_antenna_ports**, **num_layers**]** tf.complex*)  List of precoding matrices, one for each transmitter.\nAll precoding matrices must have the same shape.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**]*)  Dtype of inputs and outputs. Defaults to tf.complex64.\n\n\nInput\n\n*[batch_size, num_tx, num_layers, num_symbols_per_slot, num_subcarriers]*  Batch of resource grids to be precoded\n\nOutput\n\n*[batch_size, num_tx, num_antenna_ports, num_symbols_per_slot, num_subcarriers]*  Batch of precoded resource grids"
"### PUSCHReceiver\n\n`class` `sionna.nr.``PUSCHReceiver`(*`pusch_transmitter`*, *`channel_estimator``=``None`*, *`mimo_detector``=``None`*, *`tb_decoder``=``None`*, *`return_tb_crc_status``=``False`*, *`stream_management``=``None`*, *`input_domain``=``'freq'`*, *`l_min``=``None`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/nr/pusch_receiver.html#PUSCHReceiver)\n\nThis layer implements a full receiver for batches of 5G NR PUSCH slots sent\nby multiple transmitters. Inputs can be in the time or frequency domain.\nPerfect channel state information can be optionally provided.\nDifferent channel estimatiors, MIMO detectors, and transport decoders\ncan be configured.\n\nThe layer combines multiple processing blocks into a single layer\nas shown in the following figure. Blocks with dashed lines are\noptional and depend on the configuration.\n\n\nIf the `input_domain` equals time, the inputs $\\mathbf{y}$ are first\ntransformed to resource grids with the [`OFDMDemodulator`](ofdm.html#sionna.ofdm.OFDMDemodulator).\nThen channel estimation is performed, e.g., with the help of the\n[`PUSCHLSChannelEstimator`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHLSChannelEstimator). If `channel_estimator`\nis chosen to be perfect, this step is skipped and the input $\\mathbf{h}$\nis used instead.\nNext, MIMO detection is carried out with an arbitrary [`OFDMDetector`](ofdm.html#sionna.ofdm.OFDMDetector).\nThe resulting LLRs for each layer are then combined to transport blocks\nwith the help of the [`LayerDemapper`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.LayerDemapper).\nFinally, the transport blocks are decoded with the [`TBDecoder`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.TBDecoder).\nParameters\n\n- **pusch_transmitter** ([`PUSCHTransmitter`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHTransmitter))  Transmitter used for the generation of the transmit signals\n- **channel_estimator** ([`BaseChannelEstimator`](ofdm.html#sionna.ofdm.BaseChannelEstimator), perfect, or <cite>None</cite>)  Channel estimator to be used.\nIf <cite>None</cite>, the [`PUSCHLSChannelEstimator`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHLSChannelEstimator) with\nlinear interpolation is used.\nIf perfect, no channel estimation is performed and the channel state information\n`h` must be provided as additional input.\nDefaults to <cite>None</cite>.\n- **mimo_detector** ([`OFDMDetector`](ofdm.html#sionna.ofdm.OFDMDetector) or <cite>None</cite>)  MIMO Detector to be used.\nIf <cite>None</cite>, the [`LinearDetector`](ofdm.html#sionna.ofdm.LinearDetector) with\nLMMSE detection is used.\nDefaults to <cite>None</cite>.\n- **tb_decoder** ([`TBDecoder`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.TBDecoder) or <cite>None</cite>)  Transport block decoder to be used.\nIf <cite>None</cite>, the [`TBDecoder`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.TBDecoder) with its\ndefault settings is used.\nDefaults to <cite>None</cite>.\n- **return_tb_crc_status** (*bool*)  If <cite>True</cite>, the status of the transport block CRC is returned\nas additional output.\nDefaults to <cite>False</cite>.\n- **stream_management** ([`StreamManagement`](mimo.html#sionna.mimo.StreamManagement) or <cite>None</cite>)  Stream management configuration to be used.\nIf <cite>None</cite>, it is assumed that there is a single receiver\nwhich decodes all streams of all transmitters.\nDefaults to <cite>None</cite>.\n- **input_domain** (*str**, **one of** [**\"freq\"**, **\"time\"**]*)  Domain of the input signal.\nDefaults to freq.\n- **l_min** (int or <cite>None</cite>)  Smallest time-lag for the discrete complex baseband channel.\nOnly needed if `input_domain` equals time.\nDefaults to <cite>None</cite>.\n- **dtype** (*tf.Dtype*)  Datatype for internal calculations and the output dtype.\nDefaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n- **(y, h, no)**  Tuple:\n- **y** (*[batch size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex or [batch size, num_rx, num_rx_ant, num_time_samples + l_max - l_min], tf.complex*)  Frequency- or time-domain input signal\n- **h** (*[batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_ofdm_symbols, num_subcarriers], tf.complex or [batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_time_samples + l_max - l_min, l_max - l_min + 1], tf.complex*)  Perfect channel state information in either frequency or time domain\n(depending on `input_domain`) to be used for detection.\nOnly required if `channel_estimator` equals perfect.\n- **no** (*[batch_size, num_rx, num_rx_ant] or only the first n>=0 dims, tf.float*)  Variance of the AWGN\n\n\nOutput\n\n- **b_hat** (*[batch_size, num_tx, tb_size], tf.float*)  Decoded information bits\n- **tb_crc_status** (*[batch_size, num_tx], tf.bool*)  Transport block CRC status\n\n\n xample"
"```python\n>>> pusch_config = PUSCHConfig()\n>>> pusch_transmitter = PUSCHTransmitter(pusch_config)\n>>> pusch_receiver = PUSCHReceiver(pusch_transmitter)\n>>> channel = AWGN()\n>>> x, b = pusch_transmitter(16)\n>>> no = 0.1\n>>> y = channel([x, no])\n>>> b_hat = pusch_receiver([x, no])\n>>> compute_ber(b, b_hat)\n<tf.Tensor: shape=(), dtype=float64, numpy=0.0>\n```\n`property` `resource_grid`\n\nOFDM resource grid underlying the PUSCH transmissions"
"### PUSCHTransmitter\n\n`class` `sionna.nr.``PUSCHTransmitter`(*`pusch_configs`*, *`return_bits``=``True`*, *`output_domain``=``'freq'`*, *`dtype``=``tf.complex64`*, *`verbose``=``False`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/nr/pusch_transmitter.html#PUSCHTransmitter)\n\nThis layer generates batches of 5G NR PUSCH slots for multiple transmitters\nwith random or provided payloads. Frequency- or time-domain outputs can be generated.\n\nIt combines multiple processing blocks into a single layer\nas shown in the following figure. Blocks with dashed lines are\noptional and depend on the configuration.\n\n\nInformation bits $\\mathbf{b}$ that are either randomly generated or\nprovided as input are encoded into a transport block by the [`TBEncoder`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.TBEncoder).\nThe encoded bits are then mapped to QAM constellation symbols by the [`Mapper`](mapping.html#sionna.mapping.Mapper).\nThe [`LayerMapper`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.LayerMapper) splits the modulated symbols into different layers\nwhich are then mapped onto OFDM resource grids by the [`ResourceGridMapper`](ofdm.html#sionna.ofdm.ResourceGridMapper).\nIf precoding is enabled in the [`PUSCHConfig`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHConfig), the resource grids\nare further precoded so that there is one for each transmitter and antenna port.\nIf `output_domain` equals freq, these are the outputs $\\mathbf{x}$.\nIf `output_domain` is chosen to be time, the resource grids are transformed into\ntime-domain signals by the [`OFDMModulator`](ofdm.html#sionna.ofdm.OFDMModulator).\nParameters\n\n- **pusch_configs** (instance or list of [`PUSCHConfig`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHConfig))  PUSCH Configurations according to which the resource grid and pilot pattern\nwill created. One configuration is needed for each transmitter.\n- **return_bits** (*bool*)  If set to <cite>True</cite>, the layer generates random information bits\nto be transmitted and returns them together with the transmit signal.\nDefaults to <cite>True</cite>.\n- **output_domain** (*str**, **one of** [**\"freq\"**, **\"time\"**]*)  The domain of the output. Defaults to freq.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**]*)  Dtype of inputs and outputs. Defaults to tf.complex64.\n- **verbose** (*bool*)  If <cite>True</cite>, additional parameters are printed during initialization.\nDefaults to <cite>False</cite>.\n\n\nInput\n\n- **One of**\n- **batch_size** (*int*)  Batch size of random transmit signals to be generated,\nif `return_bits` is <cite>True</cite>.\n- **b** (*[batch_size, num_tx, tb_size], tf.float*)  Information bits to be transmitted,\nif `return_bits` is <cite>False</cite>.\n\n\nOutput\n\n- **x** (*[batch size, num_tx, num_tx_ant, num_ofdm_symbols, fft_size], tf.complex or [batch size, num_tx, num_tx_ant, num_time_samples], tf.complex*)  Transmit signal in either frequency or time domain, depending on `output_domain`.\n- **b** (*[batch_size, num_tx, tb_size], tf.float*)  Transmitted information bits.\nOnly returned if `return_bits` is <cite>True</cite>.\n\n\n xample"
"```python\n>>> pusch_config = PUSCHConfig()\n>>> pusch_transmitter = PUSCHTransmitter(pusch_config)\n>>> x, b = pusch_transmitter(16)\n>>> print(\"Shape of x:\", x.shape)\nShape of x: (16, 1, 1, 14, 48)\n>>> print(\"Shape of b:\", b.shape)\nShape of b: (16, 1, 1352)\n```\n`property` `pilot_pattern`\n\nAggregate pilot pattern of all transmitters\n\n\n`property` `resource_grid`\n\nOFDM resource grid underlying the PUSCH transmissions\n\n\n`show`()[`[source]`](../_modules/sionna/nr/pusch_transmitter.html#PUSCHTransmitter.show)\n\nPrint all properties of the PUSCHConfig and children"
"### TBConfig\n\n`class` `sionna.nr.``TBConfig`(*`**``kwargs`*)[`[source]`](../_modules/sionna/nr/tb_config.html#TBConfig)\n\nThe TBConfig objects sets parameters related to the transport block\nencoding, as described in TS 38.214 [[3GPP38214]](https://nvlabs.github.io/sionna/api/nr.html#gpp38214).\n\nAll configurable properties can be provided as keyword arguments during the\ninitialization or changed later.\n\nThe TBConfig is configured by selecting the modulation and coding scheme\n(MCS) tables and index.\n xample\n```python\n>>> tb_config = TBConfig(mcs_index=13)\n>>> tb_config.mcs_table = 3\n>>> tb_config.channel_type = \"PUSCH\"\n>>> tb_config.show()\n```\n\n\nThe following tables provide an overview of the corresponding coderates and\nmodulation orders.\n<table class=\"docutils align-center\" id=\"id46\">\n<caption>Table 1 MCS Index Table 1 (Table 5.1.3.1-1 in [[3GPP38214]](https://nvlabs.github.io/sionna/api/nr.html#gpp38214))</caption>\n<colgroup>\n<col style=\"width: 22%\" />\n<col style=\"width: 23%\" />\n<col style=\"width: 29%\" />\n<col style=\"width: 26%\" />\n</colgroup>\n<thead>\n<tr class=\"row-odd\"><th class=\"head\">\nMCS Index\n$I_{MCS}$\n</th>\n<th class=\"head\">\nModulation Order\n$Q_m$\n</th>\n<th class=\"head\">\nTarget Coderate\n$R\\times[1024]$\n</th>\n<th class=\"head\">\nSpectral Efficiency\n\n</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"row-even\"><td>\n0</td>\n<td>\n2</td>\n<td>\n120</td>\n<td>\n0.2344</td>\n</tr>\n<tr class=\"row-odd\"><td>\n1</td>\n<td>\n2</td>\n<td>\n157</td>\n<td>\n0.3066</td>\n</tr>\n<tr class=\"row-even\"><td>\n2</td>\n<td>\n2</td>\n<td>\n193</td>\n<td>\n0.3770</td>\n</tr>\n<tr class=\"row-odd\"><td>\n3</td>\n<td>\n2</td>\n<td>\n251</td>\n<td>\n0.4902</td>\n</tr>\n<tr class=\"row-even\"><td>\n4</td>\n<td>\n2</td>\n<td>\n308</td>\n<td>\n0.6016</td>\n</tr>\n<tr class=\"row-odd\"><td>\n5</td>\n<td>\n2</td>\n<td>\n379</td>\n<td>\n0.7402</td>\n</tr>\n<tr class=\"row-even\"><td>\n6</td>\n<td>\n2</td>\n<td>\n449</td>\n<td>\n0.8770</td>\n</tr>\n<tr class=\"row-odd\"><td>\n7</td>\n<td>\n2</td>\n<td>\n526</td>\n<td>\n1.0273</td>\n</tr>\n<tr class=\"row-even\"><td>\n8</td>\n<td>\n2</td>\n<td>\n602</td>\n<td>\n1.1758</td>\n</tr>\n<tr class=\"row-odd\"><td>\n9</td>\n<td>\n2</td>\n<td>\n679</td>\n<td>\n1.3262</td>\n</tr>\n<tr class=\"row-even\"><td>\n10</td>\n<td>\n4</td>\n<td>\n340</td>\n<td>\n1.3281</td>\n</tr>\n<tr class=\"row-odd\"><td>\n11</td>\n<td>\n4</td>\n<td>\n378</td>\n<td>\n1.4766</td>\n</tr>\n<tr class=\"row-even\"><td>\n12</td>\n<td>\n4</td>\n<td>\n434</td>\n<td>\n1.6953</td>\n</tr>\n<tr class=\"row-odd\"><td>\n13</td>\n<td>\n4</td>\n<td>\n490</td>\n<td>\n1.9141</td>\n</tr>\n<tr class=\"row-even\"><td>\n14</td>\n<td>\n4</td>\n<td>\n553</td>\n<td>\n2.1602</td>\n</tr>\n<tr class=\"row-odd\"><td>\n15</td>\n<td>\n4</td>\n<td>\n616</td>\n<td>\n2.4063</td>\n</tr>\n<tr class=\"row-even\"><td>\n16</td>\n<td>\n4</td>\n<td>\n658</td>\n<td>\n2.5703</td>\n</tr>\n<tr class=\"row-odd\"><td>\n17</td>\n<td>\n6</td>\n<td>\n438</td>\n<td>\n2.5664</td>\n</tr>\n<tr class=\"row-even\"><td>\n18</td>\n<td>\n6</td>\n<td>\n466</td>\n<td>\n2.7305</td>\n</tr>\n<tr class=\"row-odd\"><td>\n19</td>\n<td>\n6</td>\n<td>\n517</td>\n<td>\n3.0293</td>\n</tr>\n<tr class=\"row-even\"><td>\n20</td>\n<td>\n6</td>\n<td>\n567</td>\n<td>\n3.3223</td>\n</tr>\n<tr class=\"row-odd\"><td>\n21</td>\n<td>\n6</td>\n<td>\n616</td>\n<td>\n3.6094</td>\n</tr>\n<tr class=\"row-even\"><td>\n22</td>\n<td>\n6</td>\n<td>\n666</td>\n<td>\n3.9023</td>\n</tr>\n<tr class=\"row-odd\"><td>\n23</td>\n<td>\n6</td>\n<td>\n719</td>\n<td>\n4.2129</td>\n</tr>\n<tr class=\"row-even\"><td>\n24</td>\n<td>\n6</td>\n<td>\n772</td>\n<td>\n4.5234</td>\n</tr>\n<tr class=\"row-odd\"><td>\n25</td>\n<td>\n6</td>\n<td>\n822</td>\n<td>\n4.8164</td>\n</tr>\n<tr class=\"row-even\"><td>\n26</td>\n<td>\n6</td>\n<td>\n873</td>\n<td>\n5.1152</td>\n</tr>\n<tr class=\"row-odd\"><td>\n27</td>\n<td>\n6</td>\n<td>\n910</td>\n<td>\n5.3320</td>\n</tr>\n<tr class=\"row-even\"><td>\n28</td>\n<td>\n6</td>\n<td>\n948</td>\n<td>\n5.5547</td>\n</tr>\n</tbody>\n</table>\n<table class=\"docutils align-center\" id=\"id47\">\n<caption>Table 2 MCS Index Table 2 (Table 5.1.3.1-2 in [[3GPP38214]](https://nvlabs.github.io/sionna/api/nr.html#gpp38214))</caption>\n<colgroup>\n<col style=\"width: 22%\" />\n<col style=\"width: 23%\" />\n<col style=\"width: 29%\" />\n<col style=\"width: 26%\" />\n</colgroup>\n<thead>\n<tr class=\"row-odd\"><th class=\"head\">\nMCS Index\n$I_{MCS}$\n</th>\n<th class=\"head\">\nModulation Order\n$Q_m$\n</th>\n<th class=\"head\">\nTarget Coderate\n$R\\times[1024]$\n</th>\n<th class=\"head\">\nSpectral Efficiency\n\n</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"row-even\"><td>\n0</td>\n<td>\n2</td>\n<td>\n120</td>\n<td>\n0.2344</td>\n</tr>\n<tr class=\"row-odd\"><td>\n1</td>\n<td>\n2</td>\n<td>\n193</td>\n<td>\n0.3770</td>\n</tr>\n<tr class=\"row-even\"><td>\n2</td>\n<td>\n2</td>\n<td>\n308</td>\n<td>\n0.6016</td>\n</tr>\n<tr class=\"row-odd\"><td>\n3</td>\n<td>\n2</td>\n<td>\n449</td>\n<td>\n0.8770</td>\n</tr>\n<tr class=\"row-even\"><td>\n4</td>\n<td>\n2</td>\n<td>\n602</td>\n<td>\n1.1758</td>\n</tr>\n<tr class=\"row-odd\"><td>\n5</td>\n<td>\n4</td>\n<td>\n378</td>\n<td>\n1.4766</td>\n</tr>\n<tr class=\"row-even\"><td>\n6</td>\n<td>\n4</td>\n<td>\n434</td>\n<td>\n1.6953</td>\n</tr>\n<tr class=\"row-odd\"><td>\n7</td>\n<td>\n4</td>\n<td>\n490</td>\n<td>\n1.9141</td>\n</tr>\n<tr class=\"row-even\"><td>\n8</td>\n<td>\n4</td>\n<td>\n553</td>\n<td>\n2.1602</td>\n</tr>\n<tr class=\"row-odd\"><td>\n9</td>\n<td>\n4</td>\n<td>\n616</td>\n<td>\n2.4063</td>\n</tr>\n<tr class=\"row-even\"><td>\n10</td>\n<td>\n4</td>\n<td>\n658</td>\n<td>\n2.5703</td>\n</tr>\n<tr class=\"row-odd\"><td>\n11</td>\n<td>\n6</td>\n<td>\n466</td>\n<td>\n2.7305</td>\n</tr>\n<tr class=\"row-even\"><td>\n12</td>\n<td>\n6</td>\n<td>\n517</td>\n<td>\n3.0293</td>\n</tr>\n<tr class=\"row-odd\"><td>\n13</td>\n<td>\n6</td>\n<td>\n567</td>\n<td>\n3.3223</td>\n</tr>\n<tr class=\"row-even\"><td>\n14</td>\n<td>\n6</td>\n<td>\n616</td>\n<td>\n3.6094</td>\n</tr>\n<tr class=\"row-odd\"><td>\n15</td>\n<td>\n6</td>\n<td>\n666</td>\n<td>\n3.9023</td>\n</tr>\n<tr class=\"row-even\"><td>\n16</td>\n<td>\n6</td>\n<td>\n719</td>\n<td>\n4.2129</td>\n</tr>\n<tr class=\"row-odd\"><td>\n17</td>\n<td>\n6</td>\n<td>\n772</td>\n<td>\n4.5234</td>\n</tr>\n<tr class=\"row-even\"><td>\n18</td>\n<td>\n6</td>\n<td>\n822</td>\n<td>\n4.8164</td>\n</tr>\n<tr class=\"row-odd\"><td>\n19</td>\n<td>\n6</td>\n<td>\n873</td>\n<td>\n5.1152</td>\n</tr>\n<tr class=\"row-even\"><td>\n20</td>\n<td>\n8</td>\n<td>\n682.5</td>\n<td>\n5.3320</td>\n</tr>\n<tr class=\"row-odd\"><td>\n21</td>\n<td>\n8</td>\n<td>\n711</td>\n<td>\n5.5547</td>\n</tr>\n<tr class=\"row-even\"><td>\n22</td>\n<td>\n8</td>\n<td>\n754</td>\n<td>\n5.8906</td>\n</tr>\n<tr class=\"row-odd\"><td>\n23</td>\n<td>\n8</td>\n<td>\n797</td>\n<td>\n6.2266</td>\n</tr>\n<tr class=\"row-even\"><td>\n24</td>\n<td>\n8</td>\n<td>\n841</td>\n<td>\n6.5703</td>\n</tr>\n<tr class=\"row-odd\"><td>\n25</td>\n<td>\n8</td>\n<td>\n885</td>\n<td>\n6.9141</td>\n</tr>\n<tr class=\"row-even\"><td>\n26</td>\n<td>\n8</td>\n<td>\n916.5</td>\n<td>\n7.1602</td>\n</tr>\n<tr class=\"row-odd\"><td>\n27</td>\n<td>\n8</td>\n<td>\n948</td>\n<td>\n7.4063</td>\n</tr>\n</tbody>\n</table>\n<table class=\"docutils align-center\" id=\"id48\">\n<caption>Table 3 MCS Index Table 3 (Table 5.1.3.1-3 in [[3GPP38214]](https://nvlabs.github.io/sionna/api/nr.html#gpp38214))</caption>\n<colgroup>\n<col style=\"width: 22%\" />\n<col style=\"width: 23%\" />\n<col style=\"width: 29%\" />\n<col style=\"width: 26%\" />\n</colgroup>\n<thead>\n<tr class=\"row-odd\"><th class=\"head\">\nMCS Index\n$I_{MCS}$\n</th>\n<th class=\"head\">\nModulation Order\n$Q_m$\n</th>\n<th class=\"head\">\nTarget Coderate\n$R\\times[1024]$\n</th>\n<th class=\"head\">\nSpectral Efficiency\n\n</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"row-even\"><td>\n0</td>\n<td>\n2</td>\n<td>\n30</td>\n<td>\n0.0586</td>\n</tr>\n<tr class=\"row-odd\"><td>\n1</td>\n<td>\n2</td>\n<td>\n40</td>\n<td>\n0.0781</td>\n</tr>\n<tr class=\"row-even\"><td>\n2</td>\n<td>\n2</td>\n<td>\n50</td>\n<td>\n0.0977</td>\n</tr>\n<tr class=\"row-odd\"><td>\n3</td>\n<td>\n2</td>\n<td>\n64</td>\n<td>\n0.1250</td>\n</tr>\n<tr class=\"row-even\"><td>\n4</td>\n<td>\n2</td>\n<td>\n78</td>\n<td>\n0.1523</td>\n</tr>\n<tr class=\"row-odd\"><td>\n5</td>\n<td>\n2</td>\n<td>\n99</td>\n<td>\n0.1934</td>\n</tr>\n<tr class=\"row-even\"><td>\n6</td>\n<td>\n2</td>\n<td>\n120</td>\n<td>\n0.2344</td>\n</tr>\n<tr class=\"row-odd\"><td>\n7</td>\n<td>\n2</td>\n<td>\n157</td>\n<td>\n0.3066</td>\n</tr>\n<tr class=\"row-even\"><td>\n8</td>\n<td>\n2</td>\n<td>\n193</td>\n<td>\n0.3770</td>\n</tr>\n<tr class=\"row-odd\"><td>\n9</td>\n<td>\n2</td>\n<td>\n251</td>\n<td>\n0.4902</td>\n</tr>\n<tr class=\"row-even\"><td>\n10</td>\n<td>\n2</td>\n<td>\n308</td>\n<td>\n0.6016</td>\n</tr>\n<tr class=\"row-odd\"><td>\n11</td>\n<td>\n2</td>\n<td>\n379</td>\n<td>\n0.7402</td>\n</tr>\n<tr class=\"row-even\"><td>\n12</td>\n<td>\n2</td>\n<td>\n449</td>\n<td>\n0.8770</td>\n</tr>\n<tr class=\"row-odd\"><td>\n13</td>\n<td>\n2</td>\n<td>\n526</td>\n<td>\n1.0273</td>\n</tr>\n<tr class=\"row-even\"><td>\n14</td>\n<td>\n2</td>\n<td>\n602</td>\n<td>\n1.1758</td>\n</tr>\n<tr class=\"row-odd\"><td>\n15</td>\n<td>\n4</td>\n<td>\n340</td>\n<td>\n1.3281</td>\n</tr>\n<tr class=\"row-even\"><td>\n16</td>\n<td>\n4</td>\n<td>\n378</td>\n<td>\n1.4766</td>\n</tr>\n<tr class=\"row-odd\"><td>\n17</td>\n<td>\n4</td>\n<td>\n434</td>\n<td>\n1.6953</td>\n</tr>\n<tr class=\"row-even\"><td>\n18</td>\n<td>\n4</td>\n<td>\n490</td>\n<td>\n1.9141</td>\n</tr>\n<tr class=\"row-odd\"><td>\n19</td>\n<td>\n4</td>\n<td>\n553</td>\n<td>\n2.1602</td>\n</tr>\n<tr class=\"row-even\"><td>\n20</td>\n<td>\n4</td>\n<td>\n616</td>\n<td>\n2.4063</td>\n</tr>\n<tr class=\"row-odd\"><td>\n21</td>\n<td>\n6</td>\n<td>\n438</td>\n<td>\n2.5564</td>\n</tr>\n<tr class=\"row-even\"><td>\n22</td>\n<td>\n6</td>\n<td>\n466</td>\n<td>\n2.7305</td>\n</tr>\n<tr class=\"row-odd\"><td>\n23</td>\n<td>\n6</td>\n<td>\n517</td>\n<td>\n3.0293</td>\n</tr>\n<tr class=\"row-even\"><td>\n24</td>\n<td>\n6</td>\n<td>\n567</td>\n<td>\n3.3223</td>\n</tr>\n<tr class=\"row-odd\"><td>\n25</td>\n<td>\n6</td>\n<td>\n616</td>\n<td>\n3.6094</td>\n</tr>\n<tr class=\"row-even\"><td>\n26</td>\n<td>\n6</td>\n<td>\n666</td>\n<td>\n3.9023</td>\n</tr>\n<tr class=\"row-odd\"><td>\n27</td>\n<td>\n6</td>\n<td>\n719</td>\n<td>\n4.2129</td>\n</tr>\n<tr class=\"row-even\"><td>\n28</td>\n<td>\n6</td>\n<td>\n772</td>\n<td>\n4.5234</td>\n</tr>\n</tbody>\n</table>\n<table class=\"docutils align-center\" id=\"id49\">\n<caption>Table 4 MCS Index Table 4 (Table 5.1.3.1-4 in [[3GPP38214]](https://nvlabs.github.io/sionna/api/nr.html#gpp38214))</caption>\n<colgroup>\n<col style=\"width: 22%\" />\n<col style=\"width: 23%\" />\n<col style=\"width: 29%\" />\n<col style=\"width: 26%\" />\n</colgroup>\n<thead>\n<tr class=\"row-odd\"><th class=\"head\">\nMCS Index\n$I_{MCS}$\n</th>\n<th class=\"head\">\nModulation Order\n$Q_m$\n</th>\n<th class=\"head\">\nTarget Coderate\n$R\\times[1024]$\n</th>\n<th class=\"head\">\nSpectral Efficiency\n\n</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"row-even\"><td>\n0</td>\n<td>\n2</td>\n<td>\n120</td>\n<td>\n0.2344</td>\n</tr>\n<tr class=\"row-odd\"><td>\n1</td>\n<td>\n2</td>\n<td>\n193</td>\n<td>\n0.3770</td>\n</tr>\n<tr class=\"row-even\"><td>\n2</td>\n<td>\n2</td>\n<td>\n449</td>\n<td>\n0.8770</td>\n</tr>\n<tr class=\"row-odd\"><td>\n3</td>\n<td>\n4</td>\n<td>\n378</td>\n<td>\n1.4766</td>\n</tr>\n<tr class=\"row-even\"><td>\n4</td>\n<td>\n4</td>\n<td>\n490</td>\n<td>\n1.9141</td>\n</tr>\n<tr class=\"row-odd\"><td>\n5</td>\n<td>\n4</td>\n<td>\n616</td>\n<td>\n2.4063</td>\n</tr>\n<tr class=\"row-even\"><td>\n6</td>\n<td>\n6</td>\n<td>\n466</td>\n<td>\n2.7305</td>\n</tr>\n<tr class=\"row-odd\"><td>\n7</td>\n<td>\n6</td>\n<td>\n517</td>\n<td>\n3.0293</td>\n</tr>\n<tr class=\"row-even\"><td>\n8</td>\n<td>\n6</td>\n<td>\n567</td>\n<td>\n3.3223</td>\n</tr>\n<tr class=\"row-odd\"><td>\n9</td>\n<td>\n6</td>\n<td>\n616</td>\n<td>\n3.6094</td>\n</tr>\n<tr class=\"row-even\"><td>\n10</td>\n<td>\n6</td>\n<td>\n666</td>\n<td>\n3.9023</td>\n</tr>\n<tr class=\"row-odd\"><td>\n11</td>\n<td>\n6</td>\n<td>\n719</td>\n<td>\n4.2129</td>\n</tr>\n<tr class=\"row-even\"><td>\n12</td>\n<td>\n6</td>\n<td>\n772</td>\n<td>\n4.5234</td>\n</tr>\n<tr class=\"row-odd\"><td>\n13</td>\n<td>\n6</td>\n<td>\n822</td>\n<td>\n4.8154</td>\n</tr>\n<tr class=\"row-even\"><td>\n14</td>\n<td>\n6</td>\n<td>\n873</td>\n<td>\n5.1152</td>\n</tr>\n<tr class=\"row-odd\"><td>\n15</td>\n<td>\n8</td>\n<td>\n682.5</td>\n<td>\n5.3320</td>\n</tr>\n<tr class=\"row-even\"><td>\n16</td>\n<td>\n8</td>\n<td>\n711</td>\n<td>\n5.5547</td>\n</tr>\n<tr class=\"row-odd\"><td>\n17</td>\n<td>\n8</td>\n<td>\n754</td>\n<td>\n5.8906</td>\n</tr>\n<tr class=\"row-even\"><td>\n18</td>\n<td>\n8</td>\n<td>\n797</td>\n<td>\n6.2266</td>\n</tr>\n<tr class=\"row-odd\"><td>\n19</td>\n<td>\n8</td>\n<td>\n841</td>\n<td>\n6.5703</td>\n</tr>\n<tr class=\"row-even\"><td>\n20</td>\n<td>\n8</td>\n<td>\n885</td>\n<td>\n6.9141</td>\n</tr>\n<tr class=\"row-odd\"><td>\n21</td>\n<td>\n8</td>\n<td>\n916.5</td>\n<td>\n7.1602</td>\n</tr>\n<tr class=\"row-even\"><td>\n22</td>\n<td>\n8</td>\n<td>\n948</td>\n<td>\n7.4063</td>\n</tr>\n<tr class=\"row-odd\"><td>\n23</td>\n<td>\n10</td>\n<td>\n805.5</td>\n<td>\n7.8662</td>\n</tr>\n<tr class=\"row-even\"><td>\n24</td>\n<td>\n10</td>\n<td>\n853</td>\n<td>\n8.3301</td>\n</tr>\n<tr class=\"row-odd\"><td>\n25</td>\n<td>\n10</td>\n<td>\n900.5</td>\n<td>\n8.7939</td>\n</tr>\n<tr class=\"row-even\"><td>\n26</td>\n<td>\n10</td>\n<td>\n948</td>\n<td>\n9.2578</td>\n</tr>\n</tbody>\n</table>\n\n`property` `channel_type`\n\n5G NR physical channel type. Valid choices are PDSCH and PUSCH.\n\n\n`check_config`()[`[source]`](../_modules/sionna/nr/tb_config.html#TBConfig.check_config)\n\nTest if configuration is valid\n\n\n`property` `mcs_index`\n\nModulation and coding scheme (MCS) index (denoted as $I_{MCS}$\nin [[3GPP38214]](https://nvlabs.github.io/sionna/api/nr.html#gpp38214))\n\n\n`property` `mcs_table`\n\nIndicates which MCS table from [[3GPP38214]](https://nvlabs.github.io/sionna/api/nr.html#gpp38214) to use. Starts with 1.\n\n\n`property` `n_id`\n\nData scrambling initialization\n$n_\\text{ID}$. Data Scrambling ID related to cell id and\nprovided by higher layer. If <cite>None</cite>, the\n[`PUSCHConfig`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHConfig) will automatically set\n$n_\\text{ID}=N_\\text{ID}^{cell}$.\nType\n\nint, None (default), [0, 1023]\n\n\n`property` `num_bits_per_symbol`\n\nModulation order as defined by the selected MCS\nType\n\nint, read-only\n\n\n`property` `target_coderate`\n\nTarget coderate of the TB as defined by the selected\nMCS\nType\n\nfloat, read-only\n\n\n`property` `tb_scaling`\n\nTB scaling factor for PDSCH as\ndefined in [[3GPP38214]](https://nvlabs.github.io/sionna/api/nr.html#gpp38214) Tab. 5.1.3.2-2.\nType\n\nfloat, 1. (default), read-only"
"### TBEncoder\n\n`class` `sionna.nr.``TBEncoder`(*`target_tb_size`*, *`num_coded_bits`*, *`target_coderate`*, *`num_bits_per_symbol`*, *`num_layers=1`*, *`n_rnti=1`*, *`n_id=1`*, *`channel_type=\"PUSCH\"`*, *`codeword_index=0`*, *`use_scrambler=True`*, *`verbose=False`*, *`output_dtype=tf.float32`*, *`**kwargs`*)[`[source]`](../_modules/sionna/nr/tb_encoder.html#TBEncoder)\n\n5G NR transport block (TB) encoder as defined in TS 38.214\n[[3GPP38214]](https://nvlabs.github.io/sionna/api/nr.html#gpp38214) and TS 38.211 [[3GPP38211]](https://nvlabs.github.io/sionna/api/nr.html#gpp38211)\n\nThe transport block (TB) encoder takes as input a <cite>transport block</cite> of\ninformation bits and generates a sequence of codewords for transmission.\nFor this, the information bit sequence is segmented into multiple codewords,\nprotected by additional CRC checks and FEC encoded. Further, interleaving\nand scrambling is applied before a codeword concatenation generates the\nfinal bit sequence. Fig. 1 provides an overview of the TB encoding\nprocedure and we refer the interested reader to [[3GPP38214]](https://nvlabs.github.io/sionna/api/nr.html#gpp38214) and\n[[3GPP38211]](https://nvlabs.github.io/sionna/api/nr.html#gpp38211) for further details.\n ig. 10 Fig. 1: Overview TB encoding (CB CRC does not always apply).\n\nIf `n_rnti` and `n_id` are given as list, the TBEncoder encodes\n<cite>num_tx = len(</cite> `n_rnti` <cite>)</cite> parallel input streams with different\nscrambling sequences per user.\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **target_tb_size** (*int*)  Target transport block size, i.e., how many information bits are\nencoded into the TB. Note that the effective TB size can be\nslightly different due to quantization. If required, zero padding\nis internally applied.\n- **num_coded_bits** (*int*)  Number of coded bits after TB encoding.\n- **target_coderate** (*float*)  Target coderate.\n- **num_bits_per_symbol** (*int*)  Modulation order, i.e., number of bits per QAM symbol.\n- **num_layers** (*int**, **1** (**default**) **|** [**1**,**...**,**8**]*)  Number of transmission layers.\n- **n_rnti** (*int** or **list of ints**, **1** (**default**) **|** [**0**,**...**,**65335**]*)  RNTI identifier provided by higher layer. Defaults to 1 and must be\nin range <cite>[0, 65335]</cite>. Defines a part of the random seed of the\nscrambler. If provided as list, every list entry defines the RNTI\nof an independent input stream.\n- **n_id** (*int** or **list of ints**, **1** (**default**) **|** [**0**,**...**,**1023**]*)  Data scrambling ID $n_\\text{ID}$ related to cell id and\nprovided by higher layer.\nDefaults to 1 and must be in range <cite>[0, 1023]</cite>. If provided as\nlist, every list entry defines the scrambling id of an independent\ninput stream.\n- **channel_type** (*str**, **\"PUSCH\"** (**default**) **| \"PDSCH\"*)  Can be either PUSCH or PDSCH.\n- **codeword_index** (*int**, **0** (**default**) **| 1*)  Scrambler can be configured for two codeword transmission.\n`codeword_index` can be either 0 or 1. Must be 0 for\n`channel_type` = PUSCH.\n- **use_scrambler** (*bool**, **True** (**default**)*)  If False, no data scrambling is applied (non standard-compliant).\n- **verbose** (*bool**, **False** (**default**)*)  If <cite>True</cite>, additional parameters are printed during initialization.\n- **dtype** (*tf.float32** (**default**)*)  Defines the datatype for internal calculations and the output dtype.\n\n\nInput\n\n**inputs** (*[,target_tb_size] or [,num_tx,target_tb_size], tf.float*)  2+D tensor containing the information bits to be encoded. If\n`n_rnti` and `n_id` are a list of size <cite>num_tx</cite>, the input must\nbe of shape <cite>[,num_tx,target_tb_size]</cite>.\n\nOutput\n\n*[,num_coded_bits], tf.float*  2+D tensor containing the sequence of the encoded codeword bits of\nthe transport block.\n\n\n**Note**\n\nThe parameters `tb_size` and `num_coded_bits` can be derived by the\n`calculate_tb_size()` function or\nby accessing the corresponding [`PUSCHConfig`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHConfig) attributes.\n\n`property` `cb_crc_encoder`\n\nCB CRC encoder. <cite>None</cite> if no CB CRC is applied.\n\n\n`property` `coderate`\n\nEffective coderate of the TB after rate-matching including overhead\nfor the CRC.\n\n\n`property` `cw_lengths`\n\nEach list element defines the codeword length of each of the\ncodewords after LDPC encoding and rate-matching. The total number of\ncoded bits is $\\sum$ <cite>cw_lengths</cite>.\n\n\n`property` `k`\n\nNumber of input information bits. Equals <cite>tb_size</cite> except for zero\npadding of the last positions if the `target_tb_size` is quantized.\n\n\n`property` `k_padding`\n\nNumber of zero padded bits at the end of the TB.\n\n\n`property` `ldpc_encoder`\n\nLDPC encoder used for TB encoding.\n\n\n`property` `n`\n\nTotal number of output bits.\n\n\n`property` `num_cbs`\n\nNumber code blocks.\n\n\n`property` `num_tx`\n\nNumber of independent streams\n\n\n`property` `output_perm_inv`\n\nInverse interleaver pattern for output bit interleaver.\n\n\n`property` `scrambler`\n\nScrambler used for TB scrambling. <cite>None</cite> if no scrambler is used.\n\n\n`property` `tb_crc_encoder`\n\nTB CRC encoder\n\n\n`property` `tb_size`\n\nEffective number of information bits per TB.\nNote that (if required) internal zero padding can be applied to match\nthe request exact `target_tb_size`."
"### TBDecoder\n\n`class` `sionna.nr.``TBDecoder`(*`encoder`*, *`num_bp_iter``=``20`*, *`cn_type``=``'boxplus-phi'`*, *`output_dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/nr/tb_decoder.html#TBDecoder)\n\n5G NR transport block (TB) decoder as defined in TS 38.214\n[[3GPP38214]](https://nvlabs.github.io/sionna/api/nr.html#gpp38214).\n\nThe transport block decoder takes as input a sequence of noisy channel\nobservations and reconstructs the corresponding <cite>transport block</cite> of\ninformation bits. The detailed procedure is described in TS 38.214\n[[3GPP38214]](https://nvlabs.github.io/sionna/api/nr.html#gpp38214) and TS 38.211 [[3GPP38211]](https://nvlabs.github.io/sionna/api/nr.html#gpp38211).\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **encoder** ([`TBEncoder`](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.TBEncoder))  Associated transport block encoder used for encoding of the signal.\n- **num_bp_iter** (*int**, **20** (**default**)*)  Number of BP decoder iterations\n- **cn_type** (*str**, **\"boxplus-phi\"** (**default**) **| \"boxplus\" | \"minsum\"*)  The check node processing function of the LDPC BP decoder.\nOne of {<cite>boxplus</cite>, <cite>boxplus-phi</cite>, <cite>minsum</cite>} where\nboxplus implements the single-parity-check APP decoding rule.\nboxplus-phi implements the numerical more stable version of\nboxplus [[Ryan]](fec.ldpc.html#ryan).\nminsum implements the min-approximation of the CN update rule\n[[Ryan]](fec.ldpc.html#ryan).\n- **output_dtype** (*tf.float32** (**default**)*)  Defines the datatype for internal calculations and the output dtype.\n\n\nInput\n\n**inputs** (*[,num_coded_bits], tf.float*)  2+D tensor containing channel logits/llr values of the (noisy)\nchannel observations.\n\nOutput\n\n- **b_hat** (*[,target_tb_size], tf.float*)  2+D tensor containing hard decided bit estimates of all information\nbits of the transport block.\n- **tb_crc_status** (*[], tf.bool*)  Transport block CRC status indicating if a transport block was\n(most likely) correctly recovered. Note that false positives are\npossible.\n\n\n`property` `k`\n\nNumber of input information bits. Equals TB size.\n\n\n`property` `n`\n\nTotal number of output codeword bits.\n\n\n`property` `tb_size`\n\nNumber of information bits per TB."
"### calculate_tb_size\n\n`sionna.nr.utils.``calculate_tb_size`(*`modulation_order`*, *`target_coderate`*, *`target_tb_size``=``None`*, *`num_coded_bits``=``None`*, *`num_prbs``=``None`*, *`num_ofdm_symbols``=``None`*, *`num_dmrs_per_prb``=``None`*, *`num_layers``=``1`*, *`num_ov``=``0`*, *`tb_scaling``=``1.0`*, *`verbose``=``True`*)[`[source]`](../_modules/sionna/nr/utils.html#calculate_tb_size)\n\nCalculates transport block (TB) size for given system parameters.\n\nThis function follows the basic procedure as defined in TS 38.214 Sec.\n5.1.3.2 and Sec. 6.1.4.2 [[3GPP38214]](https://nvlabs.github.io/sionna/api/nr.html#gpp38214).\nParameters\n\n- **modulation_order** (*int*)  Modulation order, i.e., number of bits per QAM symbol.\n- **target_coderate** (*float*)  Target coderate.\n- **target_tb_size** (*None** (**default**) **| int*)  Target transport block size, i.e., how many information bits can be\nencoded into a slot for the given slot configuration. If provided,\n`num_prbs`, `num_ofdm_symbols` and `num_dmrs_per_prb` will be\nignored.\n- **num_coded_bits** (*None** (**default**) **| int*)  How many coded bits can be fit into a given slot. If provided,\n`num_prbs`, `num_ofdm_symbols` and `num_dmrs_per_prb` will be\nignored.\n- **num_prbs** (*None** (**default**) **| int*)  Total number of allocated PRBs per OFDM symbol where 1 PRB equals 12\nsubcarriers.\n- **num_ofdm_symbols** (*None** (**default**) **| int*)  Number of OFDM symbols allocated for transmission. Cannot be larger\nthan 14.\n- **num_dmrs_per_prb** (*None** (**default**) **| int*)  Number of DMRS (i.e., pilot) symbols per PRB that are NOT used for data\ntransmission. Sum over all `num_ofdm_symbols` OFDM symbols.\n- **num_layers** (*int**, **1** (**default**)*)  Number of MIMO layers.\n- **num_ov** (*int**, **0** (**default**)*)  Number of unused resource elements due to additional\noverhead as specified by higher layer.\n- **tb_scaling** (*float**, **0.25 | 0.5 | 1** (**default**)*)  TB scaling factor for PDSCH as defined in TS 38.214 Tab. 5.1.3.2-2.\nValid choices are 0.25, 0.5 and 1.0.\n- **verbose** (*bool**, **False** (**default**)*)  If True, additional information will be printed.\n\n\nReturns\n\n\n- *(tb_size, cb_size, num_cbs, cw_length, tb_crc_length, cb_crc_length, cw_lengths)*  Tuple:\n- **tb_size** (*int*)  Transport block size, i.e., how many information bits can be encoded\ninto a slot for the given slot configuration.\n- **cb_size** (*int*)  Code block (CB) size. Determines the number of\ninformation bits (including TB/CB CRC parity bits) per codeword.\n- **num_cbs** (*int*)  Number of code blocks. Determines into how many CBs the TB is segmented.\n- **cw_lengths** (*list of ints*)  Each list element defines the codeword length of each of the `num_cbs`\ncodewords after LDPC encoding and rate-matching. The total number of\ncoded bits is $\\sum$ `cw_lengths`.\n- **tb_crc_length** (*int*)  Length of the TB CRC.\n- **cb_crc_length** (*int*)  Length of each CB CRC.\n\n\n**Note**\n\nDue to rounding, `cw_lengths` (=length of each codeword after encoding),\ncan be slightly different within a transport block. Thus,\n`cw_lengths` is given as a list of ints where each list elements denotes\nthe number of codeword bits of the corresponding codeword after\nrate-matching."
"### generate_prng_seq\n\n`sionna.nr.utils.``generate_prng_seq`(*`length`*, *`c_init`*)[`[source]`](../_modules/sionna/nr/utils.html#generate_prng_seq)\n\nImplements pseudo-random sequence generator as defined in Sec. 5.2.1\nin [[3GPP38211]](https://nvlabs.github.io/sionna/api/nr.html#gpp38211) based on a length-31 Gold sequence.\nParameters\n\n- **length** (*int*)  Desired output sequence length.\n- **c_init** (*int*)  Initialization sequence of the PRNG. Must be in the range of 0 to\n$2^{32}-1$.\n\n\nOutput\n\n[`length`], ndarray of 0s and 1s  Containing the scrambling sequence.\n\n\n**Note**\n\nThe initialization sequence `c_init` is application specific and is\nusually provided be higher layer protocols."
"### select_mcs\n\n`sionna.nr.utils.``select_mcs`(*`mcs_index`*, *`table_index``=``1`*, *`channel_type``=``'PUSCH'`*, *`transform_precoding``=``False`*, *`pi2bpsk``=``False`*, *`verbose``=``False`*)[`[source]`](../_modules/sionna/nr/utils.html#select_mcs)\n\nSelects modulation and coding scheme (MCS) as specified in TS 38.214 [[3GPP38214]](https://nvlabs.github.io/sionna/api/nr.html#gpp38214).\n\nImplements MCS tables as defined in [[3GPP38214]](https://nvlabs.github.io/sionna/api/nr.html#gpp38214) for PUSCH and PDSCH.\nParameters\n\n- **mcs_index** (*int|** [**0**,**...**,**28**]*)  MCS index (denoted as $I_{MCS}$ in [[3GPP38214]](https://nvlabs.github.io/sionna/api/nr.html#gpp38214)).\n- **table_index** (*int**, **1** (**default**) **| 2 | 3 | 4*)  Indicates which MCS table from [[3GPP38214]](https://nvlabs.github.io/sionna/api/nr.html#gpp38214) to use. Starts with index 1.\n- **channel_type** (*str**, **\"PUSCH\"** (**default**) **| \"PDSCH\"*)  5G NR physical channel type. Valid choices are PDSCH and PUSCH.\n- **transform_precoding** (*bool**, **False** (**default**)*)  If True, the MCS tables as described in Sec. 6.1.4.1\nin [[3GPP38214]](https://nvlabs.github.io/sionna/api/nr.html#gpp38214) are applied. Only relevant for PUSCH.\n- **pi2bpsk** (*bool**, **False** (**default**)*)  If True, the higher-layer parameter <cite>tp-pi2BPSK</cite> as\ndescribed in Sec. 6.1.4.1 in [[3GPP38214]](https://nvlabs.github.io/sionna/api/nr.html#gpp38214) is applied. Only relevant\nfor PUSCH.\n- **verbose** (*bool**, **False** (**default**)*)  If True, additional information will be printed.\n\n\nReturns\n\n\n- *(modulation_order, target_rate)*  Tuple:\n- **modulation_order** (*int*)  Modulation order, i.e., number of bits per symbol.\n- **target_rate** (*float*)  Target coderate.\n\n\nReferences:\n3GPP38211([1](https://nvlabs.github.io/sionna/api/nr.html#id1),[2](https://nvlabs.github.io/sionna/api/nr.html#id4),[3](https://nvlabs.github.io/sionna/api/nr.html#id5),[4](https://nvlabs.github.io/sionna/api/nr.html#id6),[5](https://nvlabs.github.io/sionna/api/nr.html#id7),[6](https://nvlabs.github.io/sionna/api/nr.html#id8),[7](https://nvlabs.github.io/sionna/api/nr.html#id9),[8](https://nvlabs.github.io/sionna/api/nr.html#id10),[9](https://nvlabs.github.io/sionna/api/nr.html#id11),[10](https://nvlabs.github.io/sionna/api/nr.html#id12),[11](https://nvlabs.github.io/sionna/api/nr.html#id13),[12](https://nvlabs.github.io/sionna/api/nr.html#id14),[13](https://nvlabs.github.io/sionna/api/nr.html#id15),[14](https://nvlabs.github.io/sionna/api/nr.html#id17),[15](https://nvlabs.github.io/sionna/api/nr.html#id18),[16](https://nvlabs.github.io/sionna/api/nr.html#id19),[17](https://nvlabs.github.io/sionna/api/nr.html#id20),[18](https://nvlabs.github.io/sionna/api/nr.html#id30),[19](https://nvlabs.github.io/sionna/api/nr.html#id32),[20](https://nvlabs.github.io/sionna/api/nr.html#id35),[21](https://nvlabs.github.io/sionna/api/nr.html#id39))\n\n3GPP TS 38.211. NR; Physical channels and modulation.\n\n[3GPP38212](https://nvlabs.github.io/sionna/api/nr.html#id2)\n\n3GPP TS 38.212. NR; Multiplexing and channel coding\n\n3GPP38214([1](https://nvlabs.github.io/sionna/api/nr.html#id3),[2](https://nvlabs.github.io/sionna/api/nr.html#id16),[3](https://nvlabs.github.io/sionna/api/nr.html#id21),[4](https://nvlabs.github.io/sionna/api/nr.html#id22),[5](https://nvlabs.github.io/sionna/api/nr.html#id23),[6](https://nvlabs.github.io/sionna/api/nr.html#id24),[7](https://nvlabs.github.io/sionna/api/nr.html#id25),[8](https://nvlabs.github.io/sionna/api/nr.html#id26),[9](https://nvlabs.github.io/sionna/api/nr.html#id27),[10](https://nvlabs.github.io/sionna/api/nr.html#id28),[11](https://nvlabs.github.io/sionna/api/nr.html#id29),[12](https://nvlabs.github.io/sionna/api/nr.html#id31),[13](https://nvlabs.github.io/sionna/api/nr.html#id33),[14](https://nvlabs.github.io/sionna/api/nr.html#id34),[15](https://nvlabs.github.io/sionna/api/nr.html#id38),[16](https://nvlabs.github.io/sionna/api/nr.html#id40),[17](https://nvlabs.github.io/sionna/api/nr.html#id41),[18](https://nvlabs.github.io/sionna/api/nr.html#id42),[19](https://nvlabs.github.io/sionna/api/nr.html#id43),[20](https://nvlabs.github.io/sionna/api/nr.html#id44),[21](https://nvlabs.github.io/sionna/api/nr.html#id45))\n\n3GPP TS 38.214. NR; Physical layer procedures for data."
"# Discrete\n\nThis module provides layers and functions that implement channel\nmodels with discrete input/output alphabets.\n\nAll channel models support binary inputs $x \\in \\{0, 1\\}$ and <cite>bipolar</cite>\ninputs $x \\in \\{-1, 1\\}$, respectively. In the later case, it is assumed\nthat each <cite>0</cite> is mapped to <cite>-1</cite>.\n\nThe channels can either return discrete values or log-likelihood ratios (LLRs).\nThese LLRs describe the channel transition probabilities\n$L(y|X=1)=L(X=1|y)+L_a(X=1)$ where $L_a(X=1)=\\operatorname{log} \\frac{P(X=1)}{P(X=0)}$ depends only on the <cite>a priori</cite> probability of $X=1$. These LLRs equal the <cite>a posteriori</cite> probability if $P(X=1)=P(X=0)=0.5$.\n\nFurther, the channel reliability parameter $p_b$ can be either a scalar\nvalue or a tensor of any shape that can be broadcasted to the input. This\nallows for the efficient implementation of\nchannels with non-uniform error probabilities.\n\nThe channel models are based on the <cite>Gumble-softmax trick</cite> [[GumbleSoftmax]](https://nvlabs.github.io/sionna/api/channel.discrete.html#gumblesoftmax) to\nensure differentiability of the channel w.r.t. to the channel reliability\nparameter. Please see [[LearningShaping]](https://nvlabs.github.io/sionna/api/channel.discrete.html#learningshaping) for further details.\n\nSetting-up:\n```python\n>>> bsc = BinarySymmetricChannel(return_llrs=False, bipolar_input=False)\n```\n\n\nRunning:\n```python\n>>> x = tf.zeros((128,)) # x is the channel input\n>>> pb = 0.1 # pb is the bit flipping probability\n>>> y = bsc((x, pb))\n```"
"## BinaryMemorylessChannel\n\n`class` `sionna.channel.``BinaryMemorylessChannel`(*`return_llrs``=``False`*, *`bipolar_input``=``False`*, *`llr_max``=``100.`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/channel/discrete_channel.html#BinaryMemorylessChannel)\n\nDiscrete binary memory less channel with (possibly) asymmetric bit flipping\nprobabilities.\n\nInputs bits are flipped with probability $p_\\text{b,0}$ and\n$p_\\text{b,1}$, respectively.\n\nThis layer supports binary inputs ($x \\in \\{0, 1\\}$) and <cite>bipolar</cite>\ninputs ($x \\in \\{-1, 1\\}$).\n\nIf activated, the channel directly returns log-likelihood ratios (LLRs)\ndefined as\n\n$$\n\\begin{split}\\ell =\n\\begin{cases}\n    \\operatorname{log} \\frac{p_{b,1}}{1-p_{b,0}}, \\qquad \\text{if} \\, y=0 \\\\\n    \\operatorname{log} \\frac{1-p_{b,1}}{p_{b,0}}, \\qquad \\text{if} \\, y=1 \\\\\n\\end{cases}\\end{split}\n$$\n\nThe error probability $p_\\text{b}$ can be either scalar or a\ntensor (broadcastable to the shape of the input). This allows\ndifferent erasure probabilities per bit position. In any case, its last\ndimension must be of length 2 and is interpreted as $p_\\text{b,0}$ and\n$p_\\text{b,1}$.\n\nThis class inherits from the Keras <cite>Layer</cite> class and can be used as layer in\na Keras model.\nParameters\n\n- **return_llrs** (*bool*)  Defaults to <cite>False</cite>. If <cite>True</cite>, the layer returns log-likelihood ratios\ninstead of binary values based on `pb`.\n- **bipolar_input** (*bool**, **False*)  Defaults to <cite>False</cite>. If <cite>True</cite>, the expected input is given as\n$\\{-1,1\\}$ instead of $\\{0,1\\}$.\n- **llr_max** (*tf.float*)  Defaults to 100. Defines the clipping value of the LLRs.\n- **dtype** (*tf.DType*)  Defines the datatype for internal calculations and the output\ndtype. Defaults to <cite>tf.float32</cite>.\n\n\nInput\n\n- **(x, pb)**  Tuple:\n- **x** (*[,n], tf.float32*)  Input sequence to the channel consisting of binary values $\\{0,1\\}\n${-1,1}`, respectively.\n- **pb** (*[,2], tf.float32*)  Error probability. Can be a tuple of two scalars or of any\nshape that can be broadcasted to the shape of `x`. It has an\nadditional last dimension which is interpreted as $p_\\text{b,0}$\nand $p_\\text{b,1}$.\n\n\nOutput\n\n*[,n], tf.float32*  Output sequence of same length as the input `x`. If\n`return_llrs` is <cite>False</cite>, the output is ternary where a <cite>-1</cite> and\n<cite>0</cite> indicate an erasure for the binary and bipolar input,\nrespectively.\n\n\n`property` `llr_max`\n\nMaximum value used for LLR calculations.\n\n\n`property` `temperature`\n\nTemperature for Gumble-softmax trick."
"## BinarySymmetricChannel\n\n`class` `sionna.channel.``BinarySymmetricChannel`(*`return_llrs``=``False`*, *`bipolar_input``=``False`*, *`llr_max``=``100.`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/channel/discrete_channel.html#BinarySymmetricChannel)\n\nDiscrete binary symmetric channel which randomly flips bits with probability\n$p_\\text{b}$.\n\nThis layer supports binary inputs ($x \\in \\{0, 1\\}$) and <cite>bipolar</cite>\ninputs ($x \\in \\{-1, 1\\}$).\n\nIf activated, the channel directly returns log-likelihood ratios (LLRs)\ndefined as\n\n$$\n\\begin{split}\\ell =\n\\begin{cases}\n    \\operatorname{log} \\frac{p_{b}}{1-p_{b}}, \\qquad \\text{if}\\, y=0 \\\\\n    \\operatorname{log} \\frac{1-p_{b}}{p_{b}}, \\qquad \\text{if}\\, y=1 \\\\\n\\end{cases}\\end{split}\n$$\n\nwhere $y$ denotes the binary output of the channel.\n\nThe bit flipping probability $p_\\text{b}$ can be either a scalar or  a\ntensor (broadcastable to the shape of the input). This allows\ndifferent bit flipping probabilities per bit position.\n\nThis class inherits from the Keras <cite>Layer</cite> class and can be used as layer in\na Keras model.\nParameters\n\n- **return_llrs** (*bool*)  Defaults to <cite>False</cite>. If <cite>True</cite>, the layer returns log-likelihood ratios\ninstead of binary values based on `pb`.\n- **bipolar_input** (*bool**, **False*)  Defaults to <cite>False</cite>. If <cite>True</cite>, the expected input is given as {-1,1}\ninstead of {0,1}.\n- **llr_max** (*tf.float*)  Defaults to 100. Defines the clipping value of the LLRs.\n- **dtype** (*tf.DType*)  Defines the datatype for internal calculations and the output\ndtype. Defaults to <cite>tf.float32</cite>.\n\n\nInput\n\n- **(x, pb)**  Tuple:\n- **x** (*[,n], tf.float32*)  Input sequence to the channel.\n- **pb** (*tf.float32*)  Bit flipping probability. Can be a scalar or of any shape that\ncan be broadcasted to the shape of `x`.\n\n\nOutput\n\n*[,n], tf.float32*  Output sequence of same length as the input `x`. If\n`return_llrs` is <cite>False</cite>, the output is binary and otherwise\nsoft-values are returned."
"## BinaryErasureChannel\n\n`class` `sionna.channel.``BinaryErasureChannel`(*`return_llrs``=``False`*, *`bipolar_input``=``False`*, *`llr_max``=``100.`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/channel/discrete_channel.html#BinaryErasureChannel)\n\nBinary erasure channel (BEC) where a bit is either correctly received\nor erased.\n\nIn the binary erasure channel, bits are always correctly received or erased\nwith erasure probability $p_\\text{b}$.\n\nThis layer supports binary inputs ($x \\in \\{0, 1\\}$) and <cite>bipolar</cite>\ninputs ($x \\in \\{-1, 1\\}$).\n\nIf activated, the channel directly returns log-likelihood ratios (LLRs)\ndefined as\n\n$$\n\\begin{split}\\ell =\n\\begin{cases}\n    -\\infty, \\qquad \\text{if} \\, y=0 \\\\\n    0, \\qquad \\quad \\,\\, \\text{if} \\, y=? \\\\\n    \\infty, \\qquad \\quad \\text{if} \\, y=1 \\\\\n\\end{cases}\\end{split}\n$$\n\nThe erasure probability $p_\\text{b}$ can be either a scalar or a\ntensor (broadcastable to the shape of the input). This allows\ndifferent erasure probabilities per bit position.\n\nPlease note that the output of the BEC is ternary. Hereby, <cite>-1</cite> indicates an\nerasure for the binary configuration and <cite>0</cite> for the bipolar mode,\nrespectively.\n\nThis class inherits from the Keras <cite>Layer</cite> class and can be used as layer in\na Keras model.\nParameters\n\n- **return_llrs** (*bool*)  Defaults to <cite>False</cite>. If <cite>True</cite>, the layer returns log-likelihood ratios\ninstead of binary values based on `pb`.\n- **bipolar_input** (*bool**, **False*)  Defaults to <cite>False</cite>. If <cite>True</cite>, the expected input is given as {-1,1}\ninstead of {0,1}.\n- **llr_max** (*tf.float*)  Defaults to 100. Defines the clipping value of the LLRs.\n- **dtype** (*tf.DType*)  Defines the datatype for internal calculations and the output\ndtype. Defaults to <cite>tf.float32</cite>.\n\n\nInput\n\n- **(x, pb)**  Tuple:\n- **x** (*[,n], tf.float32*)  Input sequence to the channel.\n- **pb** (*tf.float32*)  Erasure probability. Can be a scalar or of any shape that can be\nbroadcasted to the shape of `x`.\n\n\nOutput\n\n*[,n], tf.float32*  Output sequence of same length as the input `x`. If\n`return_llrs` is <cite>False</cite>, the output is ternary where each <cite>-1</cite>\nand each <cite>0</cite> indicate an erasure for the binary and bipolar input,\nrespectively."
"## BinaryZChannel\n\n`class` `sionna.channel.``BinaryZChannel`(*`return_llrs``=``False`*, *`bipolar_input``=``False`*, *`llr_max``=``100.`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/channel/discrete_channel.html#BinaryZChannel)\n\nLayer that implements the binary Z-channel.\n\nIn the Z-channel, transmission errors only occur for the transmission of\nsecond input element (i.e., if a <cite>1</cite> is transmitted) with error probability\nprobability $p_\\text{b}$ but the first element is always correctly\nreceived.\n\nThis layer supports binary inputs ($x \\in \\{0, 1\\}$) and <cite>bipolar</cite>\ninputs ($x \\in \\{-1, 1\\}$).\n\nIf activated, the channel directly returns log-likelihood ratios (LLRs)\ndefined as\n\n$$\n\\begin{split}\\ell =\n\\begin{cases}\n    \\operatorname{log} \\left( p_b \\right), \\qquad \\text{if} \\, y=0 \\\\\n    \\infty, \\qquad \\qquad \\text{if} \\, y=1 \\\\\n\\end{cases}\\end{split}\n$$\n\nassuming equal probable inputs $P(X=0) = P(X=1) = 0.5$.\n\nThe error probability $p_\\text{b}$ can be either a scalar or a\ntensor (broadcastable to the shape of the input). This allows\ndifferent error probabilities per bit position.\n\nThis class inherits from the Keras <cite>Layer</cite> class and can be used as layer in\na Keras model.\nParameters\n\n- **return_llrs** (*bool*)  Defaults to <cite>False</cite>. If <cite>True</cite>, the layer returns log-likelihood ratios\ninstead of binary values based on `pb`.\n- **bipolar_input** (*bool**, **False*)  Defaults to <cite>False</cite>. If True, the expected input is given as {-1,1}\ninstead of {0,1}.\n- **llr_max** (*tf.float*)  Defaults to 100. Defines the clipping value of the LLRs.\n- **dtype** (*tf.DType*)  Defines the datatype for internal calculations and the output\ndtype. Defaults to <cite>tf.float32</cite>.\n\n\nInput\n\n- **(x, pb)**  Tuple:\n- **x** (*[,n], tf.float32*)  Input sequence to the channel.\n- **pb** (*tf.float32*)  Error probability. Can be a scalar or of any shape that can be\nbroadcasted to the shape of `x`.\n\n\nOutput\n\n*[,n], tf.float32*  Output sequence of same length as the input `x`. If\n`return_llrs` is <cite>False</cite>, the output is binary and otherwise\nsoft-values are returned.\n\n\nReferences:\n[GumbleSoftmax](https://nvlabs.github.io/sionna/api/channel.discrete.html#id1)\n<ol class=\"upperalpha simple\" start=\"5\">\n- Jang, G. Shixiang, and Ben Poole. <cite>Categorical reparameterization with gumbel-softmax,</cite> arXiv preprint arXiv:1611.01144 (2016).\n</ol>\n\n[LearningShaping](https://nvlabs.github.io/sionna/api/channel.discrete.html#id2)\n<ol class=\"upperalpha simple\" start=\"13\">\n- Stark, F. Ait Aoudia, and J. Hoydis. <cite>Joint learning of geometric and probabilistic constellation shaping,</cite> 2019 IEEE Globecom Workshops (GC Wkshps). IEEE, 2019.\n</ol>"
"# Optical\n\nThis module provides layers and functions that implement channel models for (fiber) optical communications.\nThe currently only available model is the split-step Fourier method ([`SSFM`](https://nvlabs.github.io/sionna/api/channel.optical.html#sionna.channel.SSFM), for dual- and\nsingle-polarization) that can be combined with an Erbium-doped amplifier ([`EDFA`](https://nvlabs.github.io/sionna/api/channel.optical.html#sionna.channel.EDFA)).\n\nThe following code snippets show how to setup and simulate the transmission\nover a single-mode fiber (SMF) by using the split-step Fourier method.\n```python\n# init fiber\nspan = sionna.channel.optical.SSFM(\n                              alpha=0.046,\n                              beta_2=-21.67,\n                              f_c=193.55e12,\n                              gamma=1.27,\n                              length=80,\n                              n_ssfm=200,\n                              n_sp=1.0,\n                              t_norm=1e-12,\n                              with_amplification=False,\n                              with_attenuation=True,\n                              with_dispersion=True,\n                              with_nonlinearity=True,\n                              dtype=tf.complex64)\n# init amplifier\namplifier = sionna.channel.optical.EDFA(\n                              g=4.0,\n                              f=2.0,\n                              f_c=193.55e12,\n                              dt=1.0e-12)\n@tf.function\ndef simulate_transmission(x, n_span):\n      y = x\n      # simulate n_span fiber spans\n      for _ in range(n_span):\n            # simulate single span\n            y = span(y)\n            # simulate amplifier\n            y = amplifier(y)\n      return y\n```\n\n\nRunning the channel model is done as follows:\n```python\n# x is the optical input signal, n_span the number of spans\ny = simulate_transmission(x, n_span)\n```\n\n\nFor further details, the tutorial [Optical Channel with Lumped Amplification](../examples/Optical_Lumped_Amplification_Channel.html)  provides more sophisticated examples of how to use this module.\n\nFor the purpose of the present document, the following symbols apply:\n<table class=\"docutils align-default\">\n<colgroup>\n<col style=\"width: 30%\" />\n<col style=\"width: 70%\" />\n</colgroup>\n<tbody>\n<tr class=\"row-odd\"><td>\n$T_\\text{norm}$</td>\n<td>\nTime normalization for the SSFM in $(\\text{s})$</td>\n</tr>\n<tr class=\"row-even\"><td>\n$L_\\text{norm}$</td>\n<td>\nDistance normalization the for SSFM in $(\\text{m})$</td>\n</tr>\n<tr class=\"row-odd\"><td>\n$W$</td>\n<td>\nBandwidth</td>\n</tr>\n<tr class=\"row-even\"><td>\n$\\alpha$</td>\n<td>\nAttenuation coefficient in $(1/L_\\text{norm})$</td>\n</tr>\n<tr class=\"row-odd\"><td>\n$\\beta_2$</td>\n<td>\nGroup velocity dispersion coeff. in $(T_\\text{norm}^2/L_\\text{norm})$</td>\n</tr>\n<tr class=\"row-even\"><td>\n$f_\\mathrm{c}$</td>\n<td>\nCarrier frequency in  $\\text{(Hz)}$</td>\n</tr>\n<tr class=\"row-odd\"><td>\n$\\gamma$</td>\n<td>\nNonlinearity coefficient in $(1/L_\\text{norm}/\\text{W})$</td>\n</tr>\n<tr class=\"row-even\"><td>\n$\\ell$</td>\n<td>\nFiber length in $(L_\\text{norm})$</td>\n</tr>\n<tr class=\"row-odd\"><td>\n$h$</td>\n<td>\nPlanck constant</td>\n</tr>\n<tr class=\"row-even\"><td>\n$N_\\mathrm{SSFM}$</td>\n<td>\nNumber of SSFM simulation steps</td>\n</tr>\n<tr class=\"row-odd\"><td>\n$n_\\mathrm{sp}$</td>\n<td>\nSpontaneous emission factor of Raman amplification</td>\n</tr>\n<tr class=\"row-even\"><td>\n$\\Delta_t$</td>\n<td>\nNormalized simulation time step in $(T_\\text{norm})$</td>\n</tr>\n<tr class=\"row-odd\"><td>\n$\\Delta_z$</td>\n<td>\nNormalized simulation step size in $(L_\\text{norm})$</td>\n</tr>\n<tr class=\"row-even\"><td>\n$G$</td>\n<td>\nAmplifier gain</td>\n</tr>\n<tr class=\"row-odd\"><td>\n$F$</td>\n<td>\nAmplifiers noise figure</td>\n</tr>\n<tr class=\"row-even\"><td>\n$\\rho_\\text{ASE}$</td>\n<td>\nNoise spectral density</td>\n</tr>\n<tr class=\"row-odd\"><td>\n$P$</td>\n<td>\nSignal power</td>\n</tr>\n<tr class=\"row-even\"><td>\n$\\hat{D}$</td>\n<td>\nLinear SSFM operator [[A2012]](https://nvlabs.github.io/sionna/api/channel.optical.html#a2012)</td>\n</tr>\n<tr class=\"row-odd\"><td>\n$\\hat{N}$</td>\n<td>\nNon-linear SSFM operator [[A2012]](https://nvlabs.github.io/sionna/api/channel.optical.html#a2012)</td>\n</tr>\n<tr class=\"row-even\"><td>\n$f_\\textrm{sim}$</td>\n<td>\nSimulation bandwidth</td>\n</tr>\n</tbody>\n</table>\n\n**Remark:** Depending on the exact simulation parameters, the SSFM algorithm may require `dtype=tf.complex128` for accurate simulation results. However, this may increase the simulation complexity significantly."
"## Split-step Fourier method\n\n`class` `sionna.channel.``SSFM`(*`alpha``=``0.046`*, *`beta_2``=``-` `21.67`*, *`f_c``=``193.55e12`*, *`gamma``=``1.27`*, *`half_window_length``=``0`*, *`length``=``80`*, *`n_ssfm``=``1`*, *`n_sp``=``1.0`*, *`sample_duration``=``1.0`*, *`t_norm``=``1e-12`*, *`with_amplification``=``False`*, *`with_attenuation``=``True`*, *`with_dispersion``=``True`*, *`with_manakov``=``False`*, *`with_nonlinearity``=``True`*, *`swap_memory``=``True`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/channel/optical/fiber.html#SSFM)\n\nLayer implementing the split-step Fourier method (SSFM)\n\nThe SSFM (first mentioned in [[HT1973]](https://nvlabs.github.io/sionna/api/channel.optical.html#ht1973)) numerically solves the generalized\nnonlinear Schrdinger equation (NLSE)\n\n$$\n\\frac{\\partial E(t,z)}{\\partial z}=-\\frac{\\alpha}{2} E(t,z)+j\\frac{\\beta_2}{2}\\frac{\\partial^2 E(t,z)}{\\partial t^2}-j\\gamma |E(t,z)|^2 E(t,z) + n(n_{\\text{sp}};\\,t,\\,z)\n$$\n\nfor an unpolarized (or single polarized) optical signal;\nor the Manakov equation (according to [[WMC1991]](https://nvlabs.github.io/sionna/api/channel.optical.html#wmc1991))\n\n$$\n\\frac{\\partial \\mathbf{E}(t,z)}{\\partial z}=-\\frac{\\alpha}{2} \\mathbf{E}(t,z)+j\\frac{\\beta_2}{2}\\frac{\\partial^2 \\mathbf{E}(t,z)}{\\partial t^2}-j\\gamma \\frac{8}{9}||\\mathbf{E}(t,z)||_2^2 \\mathbf{E}(t,z) + \\mathbf{n}(n_{\\text{sp}};\\,t,\\,z)\n$$\n\nfor dual polarization, with attenuation coefficient $\\alpha$, group\nvelocity dispersion parameters $\\beta_2$, and nonlinearity\ncoefficient $\\gamma$. The noise terms $n(n_{\\text{sp}};\\,t,\\,z)$\nand $\\mathbf{n}(n_{\\text{sp}};\\,t,\\,z)$, respectively, stem from\nan (optional) ideally distributed Raman amplification with\nspontaneous emission factor $n_\\text{sp}$. The optical signal\n$E(t,\\,z)$ has the unit $\\sqrt{\\text{W}}$. For the dual\npolarized case, $\\mathbf{E}(t,\\,z)=(E_x(t,\\,z), E_y(t,\\,z))$\nis a vector consisting of the signal components of both polarizations.\n\nThe symmetrized SSFM is applied according to Eq. (7) of [[FMF1976]](https://nvlabs.github.io/sionna/api/channel.optical.html#fmf1976) that\ncan be written as\n\n$$\nE(z+\\Delta_z,t) \\approx \\exp\\left(\\frac{\\Delta_z}{2}\\hat{D}\\right)\\exp\\left(\\int^{z+\\Delta_z}_z \\hat{N}(z')dz'\\right)\\exp\\left(\\frac{\\Delta_z}{2}\\hat{D}\\right)E(z,\\,t)\n$$\n\nwhere only the single-polarized case is shown. The integral is\napproximated by $\\Delta_z\\hat{N}$ with $\\hat{D}$ and\n$\\hat{N}$ denoting the linear and nonlinear SSFM operator,\nrespectively [[A2012]](https://nvlabs.github.io/sionna/api/channel.optical.html#a2012).\n\nAdditionally, ideally distributed Raman amplification may be applied, which\nis implemented as in [[MFFP2009]](https://nvlabs.github.io/sionna/api/channel.optical.html#mffp2009). Please note that the implemented\nRaman amplification currently results in a transparent fiber link. Hence,\nthe introduced gain cannot be parametrized.\n\nThe SSFM operates on normalized time $T_\\text{norm}$\n(e.g., $T_\\text{norm}=1\\,\\text{ps}=1\\cdot 10^{-12}\\,\\text{s}$) and\ndistance units $L_\\text{norm}$\n(e.g., $L_\\text{norm}=1\\,\\text{km}=1\\cdot 10^{3}\\,\\text{m}$).\nHence, all parameters as well as the signal itself have to be given with the\nsame unit prefix for the\nsame unit (e.g., always pico for time, or kilo for distance). Despite the normalization,\nthe SSFM is implemented with physical\nunits, which is different from the normalization, e.g., used for the\nnonlinear Fourier transform. For simulations, only $T_\\text{norm}$ has to be\nprovided.\n\nTo avoid reflections at the signal boundaries during simulation, a Hamming\nwindow can be applied in each SSFM-step, whose length can be\ndefined by `half_window_length`.\n xample\n\nSetting-up:"
"```python\n>>> ssfm = SSFM(\n>>>     alpha=0.046,\n>>>     beta_2=-21.67,\n>>>     f_c=193.55e12,\n>>>     gamma=1.27,\n>>>     half_window_length=100,\n>>>     length=80,\n>>>     n_ssfm=200,\n>>>     n_sp=1.0,\n>>>     t_norm=1e-12,\n>>>     with_amplification=False,\n>>>     with_attenuation=True,\n>>>     with_dispersion=True,\n>>>     with_manakov=False,\n>>>     with_nonlinearity=True)\n```\n\n\nRunning:\n```python\n>>> # x is the optical input signal\n>>> y = ssfm(x)\n```\n\nParameters\n\n- **alpha** (*float*)  Attenuation coefficient $\\alpha$ in $(1/L_\\text{norm})$.\nDefaults to 0.046.\n- **beta_2** (*float*)  Group velocity dispersion coefficient $\\beta_2$ in $(T_\\text{norm}^2/L_\\text{norm})$.\nDefaults to -21.67\n- **f_c** (*float*)  Carrier frequency $f_\\mathrm{c}$ in $(\\text{Hz})$.\nDefaults to 193.55e12.\n- **gamma** (*float*)  Nonlinearity coefficient $\\gamma$ in $(1/L_\\text{norm}/\\text{W})$.\nDefaults to 1.27.\n- **half_window_length** (*int*)  Half of the Hamming window length. Defaults to 0.\n- **length** (*float*)  Fiber length $\\ell$ in $(L_\\text{norm})$.\nDefaults to 80.0.\n- **n_ssfm** (*int | \"adaptive\"*)  Number of steps $N_\\mathrm{SSFM}$.\nSet to adaptive to use nonlinear-phase rotation to calculate\nthe step widths adaptively (maxmimum rotation can be set in phase_inc).\nDefaults to 1.\n- **n_sp** (*float*)  Spontaneous emission factor $n_\\mathrm{sp}$ of Raman amplification.\nDefaults to 1.0.\n- **sample_duration** (*float*)  Normalized time step $\\Delta_t$ in $(T_\\text{norm})$.\nDefaults to 1.0.\n- **t_norm** (*float*)  Time normalization $T_\\text{norm}$ in $(\\text{s})$.\nDefaults to 1e-12.\n- **with_amplification** (*bool*)  Enable ideal inline amplification and corresponding\nnoise. Defaults to <cite>False</cite>.\n- **with_attenuation** (*bool*)  Enable attenuation. Defaults to <cite>True</cite>.\n- **with_dispersion** (*bool*)  Apply chromatic dispersion. Defaults to <cite>True</cite>.\n- **with_manakov** (*bool*)  Considers axis [-2] as x- and y-polarization and calculates the\nnonlinear step as given by the Manakov equation. Defaults to <cite>False.</cite>\n- **with_nonlinearity** (*bool*)  Apply Kerr nonlinearity. Defaults to <cite>True</cite>.\n- **phase_inc** (*float*)  Maximum nonlinear-phase rotation in rad allowed during simulation.\nTo be used with `n_ssfm` = adaptive.\nDefaults to 1e-4.\n- **swap_memory** (*bool*)  Use CPU memory for while loop. Defaults to <cite>True</cite>.\n- **dtype** (*tf.complex*)  Defines the datatype for internal calculations and the output\ndtype. Defaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n**x** (*[,n] or [,2,n], tf.complex*)  Input signal in $(\\sqrt{\\text{W}})$. If `with_manakov` is <cite>True</cite>,\nthe second last dimension is interpreted as x- and y-polarization,\nrespectively.\n\nOutput\n\n**y** (Tensor with same shape as `x`, <cite>tf.complex</cite>)  Channel output"
"## Erbium-doped fiber amplifier\n\n`class` `sionna.channel.``EDFA`(*`g``=``4.0`*, *`f``=``7.0`*, *`f_c``=``193.55e12`*, *`dt``=``1e-12`*, *`with_dual_polarization``=``False`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/channel/optical/edfa.html#EDFA)\n\nLayer implementing a model of an Erbium-Doped Fiber Amplifier\n\nAmplifies the optical input signal by a given gain and adds\namplified spontaneous emission (ASE) noise.\n\nThe noise figure including the noise due to beating of signal and\nspontaneous emission is $F_\\mathrm{ASE,shot} =\\frac{\\mathrm{SNR}\n_\\mathrm{in}}{\\mathrm{SNR}_\\mathrm{out}}$,\nwhere ideally the detector is limited by shot noise only, and\n$\\text{SNR}$ is the signal-to-noise-ratio. Shot noise is\nneglected here but is required to derive the noise power of the amplifier, as\notherwise the input SNR is infinitely large. Hence, for the input SNR,\nit follows [[A2012]](https://nvlabs.github.io/sionna/api/channel.optical.html#a2012) that\n$\\mathrm{SNR}_\\mathrm{in}=\\frac{P}{2hf_cW}$, where $h$ denotes\nPlancks constant, $P$ is the signal power, and $W$ the\nconsidered bandwidth.\nThe output SNR is decreased by ASE noise induced by the amplification.\nNote that shot noise is applied after the amplifier and is hence not\namplified. It results that $\\mathrm{SNR}_\\mathrm{out}=\\frac{GP}{\\left\n(4\\rho_\\mathrm{ASE}+2hf_c\\right)W}$, where $G$ is the\nparametrized gain.\nHence, one can write the former equation as $F_\\mathrm{ASE,shot} = 2\nn_\\mathrm{sp} \\left(1-G^{-1}\\right) + G^{-1}$.\nDropping shot noise again results in $F = 2 n_\\mathrm{sp} \\left(1-G^\n{-1}\\right)=2 n_\\mathrm{sp} \\frac{G-1}{G}$.\n\nFor a transparent link, e.g., the required gain per span is $G =\n\\exp\\left(\\alpha \\ell \\right)$.\nThe spontaneous emission factor is $n_\\mathrm{sp}=\\frac{F}\n{2}\\frac{G}{G-1}$.\nAccording to [[A2012]](https://nvlabs.github.io/sionna/api/channel.optical.html#a2012) and [[EKWFG2010]](https://nvlabs.github.io/sionna/api/channel.optical.html#ekwfg2010) combined with [[BGT2000]](https://nvlabs.github.io/sionna/api/channel.optical.html#bgt2000) and [[GD1991]](https://nvlabs.github.io/sionna/api/channel.optical.html#gd1991),\nthe noise power spectral density of the EDFA per state of\npolarization is obtained as $\\rho_\\mathrm{ASE}^{(1)} = n_\\mathrm{sp}\\left\n(G-1\\right) h f_c=\\frac{1}{2}G F h f_c$.\nAt simulation frequency $f_\\mathrm{sim}$, the noise has a power of\n$P_\\mathrm{ASE}^{(1)}=\\sigma_\\mathrm{n,ASE}^2=2\\rho_\\mathrm{ASE}^{(1)}\n\\cdot f_\\mathrm{sim}$,\nwhere the factor $2$ accounts for the unpolarized noise (for dual\npolarization the factor is $1$ per polarization).\nHere, the notation $()^{(1)}$ means that this is the noise introduced by a\nsingle EDFA.\n\nThis class inherits from the Keras <cite>Layer</cite> class and can be used as layer in\na Keras model.\n xample\n\nSetting-up:"
"```python\n>>> edfa = EDFA(\n>>>     g=4.0,\n>>>     f=2.0,\n>>>     f_c=193.55e12,\n>>>     dt=1.0e-12,\n>>>     with_dual_polarization=False)\n```\n\n\nRunning:\n```python\n>>> # x is the optical input signal\n>>> y = EDFA(x)\n```\n\nParameters\n\n- **g** (*float*)  Amplifier gain (linear domain). Defaults to 4.0.\n- **f** (*float*)  Noise figure (linear domain). Defaults to 7.0.\n- **f_c** (*float*)  Carrier frequency $f_\\mathrm{c}$ in $(\\text{Hz})$.\nDefaults to 193.55e12.\n- **dt** (*float*)  Time step $\\Delta_t$ in $(\\text{s})$.\nDefaults to 1e-12.\n- **with_dual_polarization** (*bool*)  Considers axis [-2] as x- and y-polarization and applies the noise\nper polarization. Defaults to <cite>False</cite>.\n- **dtype** (*tf.complex*)  Defines the datatype for internal calculations and the output\ndtype. Defaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n**x** (*Tensor, tf.complex*)  Optical input signal\n\nOutput\n\n**y** (Tensor with same shape as `x`, `dtype`)  Amplifier output"
"### time_frequency_vector\n\n`sionna.channel.utils.``time_frequency_vector`(*`num_samples`*, *`sample_duration`*, *`dtype``=``tf.float32`*)[`[source]`](../_modules/sionna/channel/utils.html#time_frequency_vector)\n\nCompute the time and frequency vector for a given number of samples\nand duration per sample in normalized time unit.\n```python\n>>> t = tf.cast(tf.linspace(-n_min, n_max, num_samples), dtype) * sample_duration\n>>> f = tf.cast(tf.linspace(-n_min, n_max, num_samples), dtype) * 1/(sample_duration*num_samples)\n```\n\nInput\n\n- **num_samples** (*int*)  Number of samples\n- **sample_duration** (*float*)  Sample duration in normalized time\n- **dtype** (*tf.DType*)  Datatype to use for internal processing and output.\nDefaults to <cite>tf.float32</cite>.\n\n\nOutput\n\n- **t** ([`num_samples`], `dtype`)  Time vector\n- **f** ([`num_samples`], `dtype`)  Frequency vector\n\n\nReferences:\n[HT1973](https://nvlabs.github.io/sionna/api/channel.optical.html#id3)\n\nR. H. Hardin and F. D. Tappert,\nApplications of the Split-Step Fourier Method to the Numerical Solution of Nonlinear and Variable Coefficient Wave Equations.,\nSIAM Review Chronicles, Vol. 15, No. 2, Part 1, p 423, 1973.\n\n[FMF1976](https://nvlabs.github.io/sionna/api/channel.optical.html#id5)\n\nJ. A. Fleck, J. R. Morris, and M. D. Feit,\nTime-dependent Propagation of High Energy Laser Beams Through the Atmosphere,\nAppl. Phys., Vol. 10, pp 129160, 1976.\n\n[MFFP2009](https://nvlabs.github.io/sionna/api/channel.optical.html#id7)\n\nN. J. Muga, M. C. Fugihara, M. F. S. Ferreira, and A. N. Pinto,\nASE Noise Simulation in Raman Amplification Systems,\nConftele, 2009.\n\nA2012([1](https://nvlabs.github.io/sionna/api/channel.optical.html#id1),[2](https://nvlabs.github.io/sionna/api/channel.optical.html#id2),[3](https://nvlabs.github.io/sionna/api/channel.optical.html#id6),[4](https://nvlabs.github.io/sionna/api/channel.optical.html#id8),[5](https://nvlabs.github.io/sionna/api/channel.optical.html#id9))\n\nG. P. Agrawal,\nFiber-optic Communication Systems,\n4th ed. Wiley series in microwave and optical engineering 222. New York: Wiley, 2010.\n\n[EKWFG2010](https://nvlabs.github.io/sionna/api/channel.optical.html#id10)\n\nR. J. Essiambre, G. Kramer, P. J. Winzer, G. J. Foschini, and B. Goebel,\nCapacity Limits of Optical Fiber Networks,\nJournal of Lightwave Technology 28, No. 4, 2010.\n\n[BGT2000](https://nvlabs.github.io/sionna/api/channel.optical.html#id11)\n\nD. M. Baney, P. Gallion, and R. S. Tucker,\nTheory and Measurement Techniques for the Noise Figure of Optical Amplifiers,\nOptical Fiber Technology 6, No. 2, 2000.\n\n[GD1991](https://nvlabs.github.io/sionna/api/channel.optical.html#id12)\n\nC.R. Giles, and E. Desurvire,\nModeling Erbium-Doped Fiber Amplifiers,\nJournal of Lightwave Technology 9, No. 2, 1991.\n\n[WMC1991](https://nvlabs.github.io/sionna/api/channel.optical.html#id4)\n\nP. K. A. Wai, C. R. Menyuk, and H. H. Chen,\nStability of Solitons in Randomly Varying Birefringent Fibers,\nOptics Letters, No. 16, 1991."
"# Wireless\n\nThis module provides layers and functions that implement wireless channel models.\nModels currently available include [`AWGN`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.AWGN), [flat-fading](https://nvlabs.github.io/sionna/api/channel.wireless.html#flat-fading) with (optional) [`SpatialCorrelation`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.SpatialCorrelation), [`RayleighBlockFading`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.RayleighBlockFading), as well as models from the 3rd Generation Partnership Project (3GPP) [[TR38901]](https://nvlabs.github.io/sionna/api/channel.wireless.html#tr38901): [TDL](https://nvlabs.github.io/sionna/api/channel.wireless.html#tdl), [CDL](https://nvlabs.github.io/sionna/api/channel.wireless.html#cdl), [UMi](https://nvlabs.github.io/sionna/api/channel.wireless.html#umi), [UMa](https://nvlabs.github.io/sionna/api/channel.wireless.html#uma), and [RMa](https://nvlabs.github.io/sionna/api/channel.wireless.html#rma). It is also possible to [use externally generated CIRs](https://nvlabs.github.io/sionna/api/channel.wireless.html#external-datasets).\n\nApart from [flat-fading](https://nvlabs.github.io/sionna/api/channel.wireless.html#flat-fading), all of these models generate channel impulse responses (CIRs) that can then be used to\nimplement a channel transfer function in the [time domain](https://nvlabs.github.io/sionna/api/channel.wireless.html#time-domain) or\n[assuming an OFDM waveform](https://nvlabs.github.io/sionna/api/channel.wireless.html#ofdm-waveform).\n\nThis is achieved using the different functions, classes, and Keras layers which\noperate as shown in the figures below.\n ig. 7 Channel module architecture for time domain simulations.\n\n ig. 8 Channel module architecture for simulations assuming OFDM waveform.\n\nA channel model generate CIRs from which channel responses in the time domain\nor in the frequency domain are computed using the\n[`cir_to_time_channel()`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.cir_to_time_channel) or\n[`cir_to_ofdm_channel()`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.cir_to_ofdm_channel) functions, respectively.\nIf one does not need access to the raw CIRs, the\n[`GenerateTimeChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.GenerateTimeChannel) and\n[`GenerateOFDMChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.GenerateOFDMChannel) classes can be used to conveniently\nsample CIRs and generate channel responses in the desired domain.\n\nOnce the channel responses in the time or frequency domain are computed, they\ncan be applied to the channel input using the\n[`ApplyTimeChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.ApplyTimeChannel) or\n[`ApplyOFDMChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.ApplyOFDMChannel) Keras layers.\n\nThe following code snippets show how to setup and run a Rayleigh block fading\nmodel assuming an OFDM waveform, and without accessing the CIRs or\nchannel responses.\nThis is the easiest way to setup a channel model.\nSetting-up other models is done in a similar way, except for\n[`AWGN`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.AWGN) (see the [`AWGN`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.AWGN)\nclass documentation)."
"```python\nrayleigh = RayleighBlockFading(num_rx = 1,\n                               num_rx_ant = 32,\n                               num_tx = 4,\n                               num_tx_ant = 2)\nchannel  = OFDMChannel(channel_model = rayleigh,\n                       resource_grid = rg)\n```\n\n\nwhere `rg` is an instance of [`ResourceGrid`](ofdm.html#sionna.ofdm.ResourceGrid).\n\nRunning the channel model is done as follows:\n```python\n# x is the channel input\n# no is the noise variance\ny = channel([x, no])\n```\n\n\nTo use the time domain representation of the channel, one can use\n[`TimeChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.TimeChannel) instead of\n[`OFDMChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.OFDMChannel).\n\nIf access to the channel responses is needed, one can separate their\ngeneration from their application to the channel input by setting up the channel\nmodel as follows:\n```python\nrayleigh = RayleighBlockFading(num_rx = 1,\n                               num_rx_ant = 32,\n                               num_tx = 4,\n                               num_tx_ant = 2)\ngenerate_channel = GenerateOFDMChannel(channel_model = rayleigh,\n                                       resource_grid = rg)\napply_channel = ApplyOFDMChannel()\n```\n\n\nwhere `rg` is an instance of [`ResourceGrid`](ofdm.html#sionna.ofdm.ResourceGrid).\nRunning the channel model is done as follows:\n```python\n# Generate a batch of channel responses\nh = generate_channel(batch_size)\n# Apply the channel\n# x is the channel input\n# no is the noise variance\ny = apply_channel([x, h, no])\n```\n\n\nGenerating and applying the channel in the time domain can be achieved by using\n[`GenerateTimeChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.GenerateTimeChannel) and\n[`ApplyTimeChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.ApplyTimeChannel) instead of\n[`GenerateOFDMChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.GenerateOFDMChannel) and\n[`ApplyOFDMChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.ApplyOFDMChannel), respectively.\n\nTo access the CIRs, setting up the channel can be done as follows:"
"```python\nrayleigh = RayleighBlockFading(num_rx = 1,\n                               num_rx_ant = 32,\n                               num_tx = 4,\n                               num_tx_ant = 2)\napply_channel = ApplyOFDMChannel()\n```\n\n\nand running the channel model as follows:\n```python\ncir = rayleigh(batch_size)\nh = cir_to_ofdm_channel(frequencies, *cir)\ny = apply_channel([x, h, no])\n```\n\n\nwhere `frequencies` are the subcarrier frequencies in the baseband, which can\nbe computed using the [`subcarrier_frequencies()`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.subcarrier_frequencies) utility\nfunction.\n\nApplying the channel in the time domain can be done by using\n[`cir_to_time_channel()`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.cir_to_time_channel) and\n[`ApplyTimeChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.ApplyTimeChannel) instead of\n[`cir_to_ofdm_channel()`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.cir_to_ofdm_channel) and\n[`ApplyOFDMChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.ApplyOFDMChannel), respectively.\n\nFor the purpose of the present document, the following symbols apply:\n<table class=\"docutils align-default\">\n<colgroup>\n<col style=\"width: 24%\" />\n<col style=\"width: 76%\" />\n</colgroup>\n<tbody>\n<tr class=\"row-odd\"><td>\n$N_T (u)$</td>\n<td>\nNumber of transmitters (transmitter index)</td>\n</tr>\n<tr class=\"row-even\"><td>\n$N_R (v)$</td>\n<td>\nNumber of receivers (receiver index)</td>\n</tr>\n<tr class=\"row-odd\"><td>\n$N_{TA} (k)$</td>\n<td>\nNumber of antennas per transmitter (transmit antenna index)</td>\n</tr>\n<tr class=\"row-even\"><td>\n$N_{RA} (l)$</td>\n<td>\nNumber of antennas per receiver (receive antenna index)</td>\n</tr>\n<tr class=\"row-odd\"><td>\n$N_S (s)$</td>\n<td>\nNumber of OFDM symbols (OFDM symbol index)</td>\n</tr>\n<tr class=\"row-even\"><td>\n$N_F (n)$</td>\n<td>\nNumber of subcarriers (subcarrier index)</td>\n</tr>\n<tr class=\"row-odd\"><td>\n$N_B (b)$</td>\n<td>\nNumber of time samples forming the channel input (baseband symbol index)</td>\n</tr>\n<tr class=\"row-even\"><td>\n$L_{\\text{min}}$</td>\n<td>\nSmallest time-lag for the discrete complex baseband channel</td>\n</tr>\n<tr class=\"row-odd\"><td>\n$L_{\\text{max}}$</td>\n<td>\nLargest time-lag for the discrete complex baseband channel</td>\n</tr>\n<tr class=\"row-even\"><td>\n$M (m)$</td>\n<td>\nNumber of paths (clusters) forming a power delay profile (path index)</td>\n</tr>\n<tr class=\"row-odd\"><td>\n$\\tau_m(t)$</td>\n<td>\n$m^{th}$ path (cluster) delay at time step $t$</td>\n</tr>\n<tr class=\"row-even\"><td>\n$a_m(t)$</td>\n<td>\n$m^{th}$ path (cluster) complex coefficient at time step $t$</td>\n</tr>\n<tr class=\"row-odd\"><td>\n$\\Delta_f$</td>\n<td>\nSubcarrier spacing</td>\n</tr>\n<tr class=\"row-even\"><td>\n$W$</td>\n<td>\nBandwidth</td>\n</tr>\n<tr class=\"row-odd\"><td>\n$N_0$</td>\n<td>\nNoise variance</td>\n</tr>\n</tbody>\n</table>\n\nAll transmitters are equipped with $N_{TA}$ antennas and all receivers\nwith $N_{RA}$ antennas.\n\nA channel model, such as [`RayleighBlockFading`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.RayleighBlockFading) or\n[`UMi`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.tr38901.UMi), is used to generate for each link between\nantenna $k$ of transmitter $u$ and antenna $l$ of receiver\n$v$ a power delay profile\n$(a_{u, k, v, l, m}(t), \\tau_{u, v, m}), 0 \\leq m \\leq M-1$.\nThe delays are assumed not to depend on time $t$, and transmit and receive\nantennas $k$ and $l$.\nSuch a power delay profile corresponds to the channel impulse response\n\n$$\nh_{u, k, v, l}(t,\\tau) =\n\\sum_{m=0}^{M-1} a_{u, k, v, l,m}(t) \\delta(\\tau - \\tau_{u, v, m})\n$$\n\nwhere $\\delta(\\cdot)$ is the Dirac delta measure.\nFor example, in the case of Rayleigh block fading, the power delay profiles are\ntime-invariant and such that for every link $(u, k, v, l)$\n\n$$\n\\begin{split}\\begin{align}\n   M                     &= 1\\\\\n   \\tau_{u, v, 0}  &= 0\\\\\n   a_{u, k, v, l, 0}     &\\sim \\mathcal{CN}(0,1).\n\\end{align}\\end{split}\n$$\n\n3GPP channel models use the procedure depicted in [[TR38901]](https://nvlabs.github.io/sionna/api/channel.wireless.html#tr38901) to generate power\ndelay profiles. With these models, the power delay profiles are time-*variant*\nin the event of mobility."
"## AWGN\n\n`class` `sionna.channel.``AWGN`(*`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/channel/awgn.html#AWGN)\n\nAdd complex AWGN to the inputs with a certain variance.\n\nThis class inherits from the Keras <cite>Layer</cite> class and can be used as layer in\na Keras model.\n\nThis layer adds complex AWGN noise with variance `no` to the input.\nThe noise has variance `no/2` per real dimension.\nIt can be either a scalar or a tensor which can be broadcast to the shape\nof the input.\n xample\n\nSetting-up:\n```python\n>>> awgn_channel = AWGN()\n```\n\n\nRunning:\n```python\n>>> # x is the channel input\n>>> # no is the noise variance\n>>> y = awgn_channel((x, no))\n```\n\nParameters\n\n**dtype** (*Complex tf.DType*)  Defines the datatype for internal calculations and the output\ndtype. Defaults to <cite>tf.complex64</cite>.\n\nInput\n\n- **(x, no)**  Tuple:\n- **x** (*Tensor, tf.complex*)  Channel input\n- **no** (*Scalar or Tensor, tf.float*)  Scalar or tensor whose shape can be broadcast to the shape of `x`.\nThe noise power `no` is per complex dimension. If `no` is a\nscalar, noise of the same variance will be added to the input.\nIf `no` is a tensor, it must have a shape that can be broadcast to\nthe shape of `x`. This allows, e.g., adding noise of different\nvariance to each example in a batch. If `no` has a lower rank than\n`x`, then `no` will be broadcast to the shape of `x` by adding\ndummy dimensions after the last axis.\n\n\nOutput\n\n**y** (Tensor with same shape as `x`, tf.complex)  Channel output"
"### FlatFadingChannel\n\n`class` `sionna.channel.``FlatFadingChannel`(*`num_tx_ant`*, *`num_rx_ant`*, *`spatial_corr``=``None`*, *`add_awgn``=``True`*, *`return_channel``=``False`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/channel/flat_fading_channel.html#FlatFadingChannel)\n\nApplies random channel matrices to a vector input and adds AWGN.\n\nThis class combines [`GenerateFlatFadingChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.GenerateFlatFadingChannel) and\n[`ApplyFlatFadingChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.ApplyFlatFadingChannel) and computes the output of\na flat-fading channel with AWGN.\n\nFor a given batch of input vectors $\\mathbf{x}\\in\\mathbb{C}^{K}$,\nthe output is\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$ are randomly generated\nflat-fading channel matrices and\n$\\mathbf{n}\\in\\mathbb{C}^{M}\\sim\\mathcal{CN}(0, N_o\\mathbf{I})$\nis an AWGN vector that is optionally added.\n\nA [`SpatialCorrelation`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.SpatialCorrelation) can be configured and the\nchannel realizations optionally returned. This is useful to simulate\nreceiver algorithms with perfect channel knowledge.\nParameters\n\n- **num_tx_ant** (*int*)  Number of transmit antennas.\n- **num_rx_ant** (*int*)  Number of receive antennas.\n- **spatial_corr** (*, **None*)  An instance of [`SpatialCorrelation`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.SpatialCorrelation) or <cite>None</cite>.\nDefaults to <cite>None</cite>.\n- **add_awgn** (*bool*)  Indicates if AWGN noise should be added to the output.\nDefaults to <cite>True</cite>.\n- **return_channel** (*bool*)  Indicates if the channel realizations should be returned.\nDefaults  to <cite>False</cite>.\n- **dtype** (*tf.complex64**, **tf.complex128*)  The dtype of the output. Defaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n- **(x, no)**  Tuple or Tensor:\n- **x** (*[batch_size, num_tx_ant], tf.complex*)  Tensor of transmit vectors.\n- **no** (*Scalar of Tensor, tf.float*)  The noise power `no` is per complex dimension.\nOnly required if `add_awgn==True`.\nWill be broadcast to the dimensions of the channel output if needed.\nFor more details, see [`AWGN`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.AWGN).\n\n\nOutput\n\n- **(y, h)**  Tuple or Tensor:\n- **y** ([batch_size, num_rx_ant, num_tx_ant], `dtype`)  Channel output.\n- **h** ([batch_size, num_rx_ant, num_tx_ant], `dtype`)  Channel realizations. Will only be returned if\n`return_channel==True`.\n\n\n`property` `apply`\n\nCalls the internal [`ApplyFlatFadingChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.ApplyFlatFadingChannel).\n\n\n`property` `generate`\n\nCalls the internal [`GenerateFlatFadingChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.GenerateFlatFadingChannel).\n\n\n`property` `spatial_corr`\n\nThe [`SpatialCorrelation`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.SpatialCorrelation) to be used."
"### GenerateFlatFadingChannel\n\n`class` `sionna.channel.``GenerateFlatFadingChannel`(*`num_tx_ant`*, *`num_rx_ant`*, *`spatial_corr``=``None`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/channel/flat_fading_channel.html#GenerateFlatFadingChannel)\n\nGenerates tensors of flat-fading channel realizations.\n\nThis class generates batches of random flat-fading channel matrices.\nA spatial correlation can be applied.\nParameters\n\n- **num_tx_ant** (*int*)  Number of transmit antennas.\n- **num_rx_ant** (*int*)  Number of receive antennas.\n- **spatial_corr** (*, **None*)  An instance of [`SpatialCorrelation`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.SpatialCorrelation) or <cite>None</cite>.\nDefaults to <cite>None</cite>.\n- **dtype** (*tf.complex64**, **tf.complex128*)  The dtype of the output. Defaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n**batch_size** (*int*)  The batch size, i.e., the number of channel matrices to generate.\n\nOutput\n\n**h** ([batch_size, num_rx_ant, num_tx_ant], `dtype`)  Batch of random flat fading channel matrices.\n\n\n`property` `spatial_corr`\n\nThe [`SpatialCorrelation`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.SpatialCorrelation) to be used."
"### ApplyFlatFadingChannel\n\n`class` `sionna.channel.``ApplyFlatFadingChannel`(*`add_awgn``=``True`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/channel/flat_fading_channel.html#ApplyFlatFadingChannel)\n\nApplies given channel matrices to a vector input and adds AWGN.\n\nThis class applies a given tensor of flat-fading channel matrices\nto an input tensor. AWGN noise can be optionally added.\nMathematically, for channel matrices\n$\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$\nand input $\\mathbf{x}\\in\\mathbb{C}^{K}$, the output is\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{n}\\in\\mathbb{C}^{M}\\sim\\mathcal{CN}(0, N_o\\mathbf{I})$\nis an AWGN vector that is optionally added.\nParameters\n\n- **add_awgn** (*bool*)  Indicates if AWGN noise should be added to the output.\nDefaults to <cite>True</cite>.\n- **dtype** (*tf.complex64**, **tf.complex128*)  The dtype of the output. Defaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n- **(x, h, no)**  Tuple:\n- **x** (*[batch_size, num_tx_ant], tf.complex*)  Tensor of transmit vectors.\n- **h** (*[batch_size, num_rx_ant, num_tx_ant], tf.complex*)  Tensor of channel realizations. Will be broadcast to the\ndimensions of `x` if needed.\n- **no** (*Scalar or Tensor, tf.float*)  The noise power `no` is per complex dimension.\nOnly required if `add_awgn==True`.\nWill be broadcast to the shape of `y`.\nFor more details, see [`AWGN`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.AWGN).\n\n\nOutput\n\n**y** ([batch_size, num_rx_ant, num_tx_ant], `dtype`)  Channel output."
"### SpatialCorrelation\n\n`class` `sionna.channel.``SpatialCorrelation`[`[source]`](../_modules/sionna/channel/spatial_correlation.html#SpatialCorrelation)\n\nAbstract class that defines an interface for spatial correlation functions.\n\nThe [`FlatFadingChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.FlatFadingChannel) model can be configured with a\nspatial correlation model.\nInput\n\n**h** (*tf.complex*)  Tensor of arbitrary shape containing spatially uncorrelated\nchannel coefficients\n\nOutput\n\n**h_corr** (*tf.complex*)  Tensor of the same shape and dtype as `h` containing the spatially\ncorrelated channel coefficients."
"### KroneckerModel\n\n`class` `sionna.channel.``KroneckerModel`(*`r_tx``=``None`*, *`r_rx``=``None`*)[`[source]`](../_modules/sionna/channel/spatial_correlation.html#KroneckerModel)\n\nKronecker model for spatial correlation.\n\nGiven a batch of matrices $\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$,\n$\\mathbf{R}_\\text{tx}\\in\\mathbb{C}^{K\\times K}$, and\n$\\mathbf{R}_\\text{rx}\\in\\mathbb{C}^{M\\times M}$, this function\nwill generate the following output:\n\n$$\n\\mathbf{H}_\\text{corr} = \\mathbf{R}^{\\frac12}_\\text{rx} \\mathbf{H} \\mathbf{R}^{\\frac12}_\\text{tx}\n$$\n\nNote that $\\mathbf{R}_\\text{tx}\\in\\mathbb{C}^{K\\times K}$ and $\\mathbf{R}_\\text{rx}\\in\\mathbb{C}^{M\\times M}$\nmust be positive semi-definite, such as the ones generated by\n[`exp_corr_mat()`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.exp_corr_mat).\nParameters\n\n- **r_tx** (*[**...**, **K**, **K**]**, **tf.complex*)  Tensor containing the transmit correlation matrices. If\nthe rank of `r_tx` is smaller than that of the input `h`,\nit will be broadcast.\n- **r_rx** (*[**...**, **M**, **M**]**, **tf.complex*)  Tensor containing the receive correlation matrices. If\nthe rank of `r_rx` is smaller than that of the input `h`,\nit will be broadcast.\n\n\nInput\n\n**h** (*[, M, K], tf.complex*)  Tensor containing spatially uncorrelated\nchannel coeffficients.\n\nOutput\n\n**h_corr** (*[, M, K], tf.complex*)  Tensor containing the spatially\ncorrelated channel coefficients.\n\n\n`property` `r_rx`\n\nTensor containing the receive correlation matrices.\n\n**Note**\n\nIf you want to set this property in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat).\n\n\n`property` `r_tx`\n\nTensor containing the transmit correlation matrices.\n\n**Note**\n\nIf you want to set this property in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### PerColumnModel\n\n`class` `sionna.channel.``PerColumnModel`(*`r_rx`*)[`[source]`](../_modules/sionna/channel/spatial_correlation.html#PerColumnModel)\n\nPer-column model for spatial correlation.\n\nGiven a batch of matrices $\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$\nand correlation matrices $\\mathbf{R}_k\\in\\mathbb{C}^{M\\times M}, k=1,\\dots,K$,\nthis function will generate the output $\\mathbf{H}_\\text{corr}\\in\\mathbb{C}^{M\\times K}$,\nwith columns\n\n$$\n\\mathbf{h}^\\text{corr}_k = \\mathbf{R}^{\\frac12}_k \\mathbf{h}_k,\\quad k=1, \\dots, K\n$$\n\nwhere $\\mathbf{h}_k$ is the kth column of $\\mathbf{H}$.\nNote that all $\\mathbf{R}_k\\in\\mathbb{C}^{M\\times M}$ must\nbe positive semi-definite, such as the ones generated\nby [`one_ring_corr_mat()`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.one_ring_corr_mat).\n\nThis model is typically used to simulate a MIMO channel between multiple\nsingle-antenna users and a base station with multiple antennas.\nThe resulting SIMO channel for each user has a different spatial correlation.\nParameters\n\n**r_rx** (*[**...**, **M**, **M**]**, **tf.complex*)  Tensor containing the receive correlation matrices. If\nthe rank of `r_rx` is smaller than that of the input `h`,\nit will be broadcast. For a typically use of this model, `r_rx`\nhas shape [, K, M, M], i.e., a different correlation matrix for each\ncolumn of `h`.\n\nInput\n\n**h** (*[, M, K], tf.complex*)  Tensor containing spatially uncorrelated\nchannel coeffficients.\n\nOutput\n\n**h_corr** (*[, M, K], tf.complex*)  Tensor containing the spatially\ncorrelated channel coefficients.\n\n\n`property` `r_rx`\n\nTensor containing the receive correlation matrices.\n\n**Note**\n\nIf you want to set this property in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"## Channel model interface\n\n`class` `sionna.channel.``ChannelModel`[`[source]`](../_modules/sionna/channel/channel_model.html#ChannelModel)\n\nAbstract class that defines an interface for channel models.\n\nAny channel model which generates channel impulse responses must implement this interface.\nAll the channel models available in Sionna, such as [`RayleighBlockFading`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.RayleighBlockFading) or [`TDL`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.tr38901.TDL), implement this interface.\n\n*Remark:* Some channel models only require a subset of the input parameters.\nInput\n\n- **batch_size** (*int*)  Batch size\n- **num_time_steps** (*int*)  Number of time steps\n- **sampling_frequency** (*float*)  Sampling frequency [Hz]\n\n\nOutput\n\n- **a** (*[batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps], tf.complex*)  Path coefficients\n- **tau** (*[batch size, num_rx, num_tx, num_paths], tf.float*)  Path delays [s]"
"## Time domain channel\n\nThe model of the channel in the time domain assumes pulse shaping and receive\nfiltering are performed using a conventional sinc filter (see, e.g., [[Tse]](../em_primer.html#tse)).\nUsing sinc for transmit and receive filtering, the discrete-time domain received\nsignal at time step $b$ is\n\n$$\ny_{v, l, b} = \\sum_{u=0}^{N_{T}-1}\\sum_{k=0}^{N_{TA}-1}\n   \\sum_{\\ell = L_{\\text{min}}}^{L_{\\text{max}}}\n   \\bar{h}_{u, k, v, l, b, \\ell} x_{u, k, b-\\ell}\n   + w_{v, l, b}\n$$\n\nwhere $x_{u, k, b}$ is the baseband symbol transmitted by transmitter\n$u$ on antenna $k$ and at time step $b$,\n$w_{v, l, b} \\sim \\mathcal{CN}\\left(0,N_0\\right)$ the additive white\nGaussian noise, and $\\bar{h}_{u, k, v, l, b, \\ell}$ the channel filter tap\nat time step $b$ and for time-lag $\\ell$, which is given by\n\n$$\n\\bar{h}_{u, k, v, l, b, \\ell}\n= \\sum_{m=0}^{M-1} a_{u, k, v, l, m}\\left(\\frac{b}{W}\\right)\n   \\text{sinc}\\left( \\ell - W\\tau_{u, v, m} \\right).\n$$\n\n**Note**\n\nThe two parameters $L_{\\text{min}}$ and $L_{\\text{max}}$ control the smallest\nand largest time-lag for the discrete-time channel model, respectively.\nThey are set when instantiating [`TimeChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.TimeChannel),\n[`GenerateTimeChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.GenerateTimeChannel), and when calling the utility\nfunction [`cir_to_time_channel()`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.cir_to_time_channel).\nBecause the sinc filter is neither time-limited nor causal, the discrete-time\nchannel model is not causal. Therefore, ideally, one would set\n$L_{\\text{min}} = -\\infty$ and $L_{\\text{max}} = +\\infty$.\nIn practice, however, these two parameters need to be set to reasonable\nfinite values. Values for these two parameters can be computed using the\n[`time_lag_discrete_time_channel()`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.time_lag_discrete_time_channel) utility function from\na given bandwidth and maximum delay spread.\nThis function returns $-6$ for $L_{\\text{min}}$. $L_{\\text{max}}$ is computed\nfrom the specified bandwidth and maximum delay spread, which default value is\n$3 \\mu s$. These values for $L_{\\text{min}}$ and the maximum delay spread\nwere found to be valid for all the models available in Sionna when an RMS delay\nspread of 100ns is assumed."
"### TimeChannel\n\n`class` `sionna.channel.``TimeChannel`(*`channel_model`*, *`bandwidth`*, *`num_time_samples`*, *`maximum_delay_spread``=``3e-6`*, *`l_min``=``None`*, *`l_max``=``None`*, *`normalize_channel``=``False`*, *`add_awgn``=``True`*, *`return_channel``=``False`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/channel/time_channel.html#TimeChannel)\n\nGenerate channel responses and apply them to channel inputs in the time domain.\n\nThis class inherits from the Keras <cite>Layer</cite> class and can be used as layer\nin a Keras model.\n\nThe channel output consists of `num_time_samples` + `l_max` - `l_min`\ntime samples, as it is the result of filtering the channel input of length\n`num_time_samples` with the time-variant channel filter  of length\n`l_max` - `l_min` + 1. In the case of a single-input single-output link and given a sequence of channel\ninputs $x_0,\\cdots,x_{N_B}$, where $N_B$ is `num_time_samples`, this\nlayer outputs\n\n$$\ny_b = \\sum_{\\ell = L_{\\text{min}}}^{L_{\\text{max}}} x_{b-\\ell} \\bar{h}_{b,\\ell} + w_b\n$$\n\nwhere $L_{\\text{min}}$ corresponds `l_min`, $L_{\\text{max}}$ to `l_max`, $w_b$ to\nthe additive noise, and $\\bar{h}_{b,\\ell}$ to the\n$\\ell^{th}$ tap of the $b^{th}$ channel sample.\nThis layer outputs $y_b$ for $b$ ranging from $L_{\\text{min}}$ to\n$N_B + L_{\\text{max}} - 1$, and $x_{b}$ is set to 0 for $b < 0$ or $b \\geq N_B$.\nThe channel taps $\\bar{h}_{b,\\ell}$ are computed assuming a sinc filter\nis used for pulse shaping and receive filtering. Therefore, given a channel impulse response\n$(a_{m}(t), \\tau_{m}), 0 \\leq m \\leq M-1$, generated by the `channel_model`,\nthe channel taps are computed as follows:\n\n$$\n\\bar{h}_{b, \\ell}\n= \\sum_{m=0}^{M-1} a_{m}\\left(\\frac{b}{W}\\right)\n    \\text{sinc}\\left( \\ell - W\\tau_{m} \\right)\n$$\n\nfor $\\ell$ ranging from `l_min` to `l_max`, and where $W$ is\nthe `bandwidth`.\n\nFor multiple-input multiple-output (MIMO) links, the channel output is computed for each antenna of each receiver and by summing over all the antennas of all transmitters.\nParameters\n\n- **channel_model** ([`ChannelModel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.ChannelModel) object)  An instance of a [`ChannelModel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.ChannelModel), such as\n[`RayleighBlockFading`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.RayleighBlockFading) or\n[`UMi`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.tr38901.UMi).\n- **bandwidth** (*float*)  Bandwidth ($W$) [Hz]\n- **num_time_samples** (*int*)  Number of time samples forming the channel input ($N_B$)\n- **maximum_delay_spread** (*float*)  Maximum delay spread [s].\nUsed to compute the default value of `l_max` if `l_max` is set to\n<cite>None</cite>. If a value is given for `l_max`, this parameter is not used.\nIt defaults to 3us, which was found\nto be large enough to include most significant paths with all channel\nmodels included in Sionna assuming a nominal delay spread of 100ns.\n- **l_min** (*int*)  Smallest time-lag for the discrete complex baseband channel ($L_{\\text{min}}$).\nIf set to <cite>None</cite>, defaults to the value given by [`time_lag_discrete_time_channel()`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.time_lag_discrete_time_channel).\n- **l_max** (*int*)  Largest time-lag for the discrete complex baseband channel ($L_{\\text{max}}$).\nIf set to <cite>None</cite>, it is computed from `bandwidth` and `maximum_delay_spread`\nusing [`time_lag_discrete_time_channel()`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.time_lag_discrete_time_channel). If it is not set to <cite>None</cite>,\nthen the parameter `maximum_delay_spread` is not used.\n- **add_awgn** (*bool*)  If set to <cite>False</cite>, no white Gaussian noise is added.\nDefaults to <cite>True</cite>.\n- **normalize_channel** (*bool*)  If set to <cite>True</cite>, the channel is normalized over the block size\nto ensure unit average energy per time step. Defaults to <cite>False</cite>.\n- **return_channel** (*bool*)  If set to <cite>True</cite>, the channel response is returned in addition to the\nchannel output. Defaults to <cite>False</cite>.\n- **dtype** (*tf.DType*)  Complex datatype to use for internal processing and output.\nDefaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n- **(x, no) or x**  Tuple or Tensor:\n- **x** (*[batch size, num_tx, num_tx_ant, num_time_samples], tf.complex*)  Channel inputs\n- **no** (*Scalar or Tensor, tf.float*)  Scalar or tensor whose shape can be broadcast to the shape of the\nchannel outputs: [batch size, num_rx, num_rx_ant, num_time_samples].\nOnly required if `add_awgn` is set to <cite>True</cite>.\nThe noise power `no` is per complex dimension. If `no` is a scalar,\nnoise of the same variance will be added to the outputs.\nIf `no` is a tensor, it must have a shape that can be broadcast to\nthe shape of the channel outputs. This allows, e.g., adding noise of\ndifferent variance to each example in a batch. If `no` has a lower\nrank than the channel outputs, then `no` will be broadcast to the\nshape of the channel outputs by adding dummy dimensions after the last\naxis.\n\n\nOutput\n\n- **y** (*[batch size, num_rx, num_rx_ant, num_time_samples + l_max - l_min], tf.complex*)  Channel outputs\nThe channel output consists of `num_time_samples` + `l_max` - `l_min`\ntime samples, as it is the result of filtering the channel input of length\n`num_time_samples` with the time-variant channel filter  of length\n`l_max` - `l_min` + 1.\n- **h_time** (*[batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_time_samples + l_max - l_min, l_max - l_min + 1], tf.complex*)  (Optional) Channel responses. Returned only if `return_channel`\nis set to <cite>True</cite>.\nFor each batch example, `num_time_samples` + `l_max` - `l_min` time\nsteps of the channel realizations are generated to filter the channel input."
"### GenerateTimeChannel\n\n`class` `sionna.channel.``GenerateTimeChannel`(*`channel_model`*, *`bandwidth`*, *`num_time_samples`*, *`l_min`*, *`l_max`*, *`normalize_channel``=``False`*)[`[source]`](../_modules/sionna/channel/generate_time_channel.html#GenerateTimeChannel)\n\nGenerate channel responses in the time domain.\n\nFor each batch example, `num_time_samples` + `l_max` - `l_min` time steps of a\nchannel realization are generated by this layer.\nThese can be used to filter a channel input of length `num_time_samples` using the\n[`ApplyTimeChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.ApplyTimeChannel) layer.\n\nThe channel taps $\\bar{h}_{b,\\ell}$ (`h_time`) returned by this layer\nare computed assuming a sinc filter is used for pulse shaping and receive filtering.\nTherefore, given a channel impulse response\n$(a_{m}(t), \\tau_{m}), 0 \\leq m \\leq M-1$, generated by the `channel_model`,\nthe channel taps are computed as follows:\n\n$$\n\\bar{h}_{b, \\ell}\n= \\sum_{m=0}^{M-1} a_{m}\\left(\\frac{b}{W}\\right)\n    \\text{sinc}\\left( \\ell - W\\tau_{m} \\right)\n$$\n\nfor $\\ell$ ranging from `l_min` to `l_max`, and where $W$ is\nthe `bandwidth`.\nParameters\n\n- **channel_model** ([`ChannelModel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.ChannelModel) object)  An instance of a [`ChannelModel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.ChannelModel), such as\n[`RayleighBlockFading`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.RayleighBlockFading) or\n[`UMi`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.tr38901.UMi).\n- **bandwidth** (*float*)  Bandwidth ($W$) [Hz]\n- **num_time_samples** (*int*)  Number of time samples forming the channel input ($N_B$)\n- **l_min** (*int*)  Smallest time-lag for the discrete complex baseband channel ($L_{\\text{min}}$)\n- **l_max** (*int*)  Largest time-lag for the discrete complex baseband channel ($L_{\\text{max}}$)\n- **normalize_channel** (*bool*)  If set to <cite>True</cite>, the channel is normalized over the block size\nto ensure unit average energy per time step. Defaults to <cite>False</cite>.\n\n\nInput\n\n**batch_size** (*int*)  Batch size. Defaults to <cite>None</cite> for channel models that do not require this paranmeter.\n\nOutput\n\n**h_time** (*[batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_time_samples + l_max - l_min, l_max - l_min + 1], tf.complex*)  Channel responses.\nFor each batch example, `num_time_samples` + `l_max` - `l_min` time steps of a\nchannel realization are generated by this layer.\nThese can be used to filter a channel input of length `num_time_samples` using the\n[`ApplyTimeChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.ApplyTimeChannel) layer."
"### ApplyTimeChannel\n\n`class` `sionna.channel.``ApplyTimeChannel`(*`num_time_samples`*, *`l_tot`*, *`add_awgn``=``True`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/channel/apply_time_channel.html#ApplyTimeChannel)\n\nApply time domain channel responses `h_time` to channel inputs `x`,\nby filtering the channel inputs with time-variant channel responses.\n\nThis class inherits from the Keras <cite>Layer</cite> class and can be used as layer\nin a Keras model.\n\nFor each batch example, `num_time_samples` + `l_tot` - 1 time steps of a\nchannel realization are required to filter the channel inputs.\n\nThe channel output consists of `num_time_samples` + `l_tot` - 1\ntime samples, as it is the result of filtering the channel input of length\n`num_time_samples` with the time-variant channel filter  of length\n`l_tot`. In the case of a single-input single-output link and given a sequence of channel\ninputs $x_0,\\cdots,x_{N_B}$, where $N_B$ is `num_time_samples`, this\nlayer outputs\n\n$$\ny_b = \\sum_{\\ell = 0}^{L_{\\text{tot}}} x_{b-\\ell} \\bar{h}_{b,\\ell} + w_b\n$$\n\nwhere $L_{\\text{tot}}$ corresponds `l_tot`, $w_b$ to the additive noise, and\n$\\bar{h}_{b,\\ell}$ to the $\\ell^{th}$ tap of the $b^{th}$ channel sample.\nThis layer outputs $y_b$ for $b$ ranging from 0 to\n$N_B + L_{\\text{tot}} - 1$, and $x_{b}$ is set to 0 for $b \\geq N_B$.\n\nFor multiple-input multiple-output (MIMO) links, the channel output is computed for each antenna\nof each receiver and by summing over all the antennas of all transmitters.\nParameters\n\n- **num_time_samples** (*int*)  Number of time samples forming the channel input ($N_B$)\n- **l_tot** (*int*)  Length of the channel filter ($L_{\\text{tot}} = L_{\\text{max}} - L_{\\text{min}} + 1$)\n- **add_awgn** (*bool*)  If set to <cite>False</cite>, no white Gaussian noise is added.\nDefaults to <cite>True</cite>.\n- **dtype** (*tf.DType*)  Complex datatype to use for internal processing and output.\nDefaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n- **(x, h_time, no) or (x, h_time)**  Tuple:\n- **x** (*[batch size, num_tx, num_tx_ant, num_time_samples], tf.complex*)  Channel inputs\n- **h_time** (*[batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_time_samples + l_tot - 1, l_tot], tf.complex*)  Channel responses.\nFor each batch example, `num_time_samples` + `l_tot` - 1 time steps of a\nchannel realization are required to filter the channel inputs.\n- **no** (*Scalar or Tensor, tf.float*)  Scalar or tensor whose shape can be broadcast to the shape of the channel outputs: [batch size, num_rx, num_rx_ant, num_time_samples + l_tot - 1].\nOnly required if `add_awgn` is set to <cite>True</cite>.\nThe noise power `no` is per complex dimension. If `no` is a\nscalar, noise of the same variance will be added to the outputs.\nIf `no` is a tensor, it must have a shape that can be broadcast to\nthe shape of the channel outputs. This allows, e.g., adding noise of\ndifferent variance to each example in a batch. If `no` has a lower\nrank than the channel outputs, then `no` will be broadcast to the\nshape of the channel outputs by adding dummy dimensions after the\nlast axis.\n\n\nOutput\n\n**y** (*[batch size, num_rx, num_rx_ant, num_time_samples + l_tot - 1], tf.complex*)  Channel outputs.\nThe channel output consists of `num_time_samples` + `l_tot` - 1\ntime samples, as it is the result of filtering the channel input of length\n`num_time_samples` with the time-variant channel filter  of length\n`l_tot`."
"### cir_to_time_channel\n\n`sionna.channel.``cir_to_time_channel`(*`bandwidth`*, *`a`*, *`tau`*, *`l_min`*, *`l_max`*, *`normalize``=``False`*)[`[source]`](../_modules/sionna/channel/utils.html#cir_to_time_channel)\n\nCompute the channel taps forming the discrete complex-baseband\nrepresentation of the channel from the channel impulse response\n(`a`, `tau`).\n\nThis function assumes that a sinc filter is used for pulse shaping and receive\nfiltering. Therefore, given a channel impulse response\n$(a_{m}(t), \\tau_{m}), 0 \\leq m \\leq M-1$, the channel taps\nare computed as follows:\n\n$$\n\\bar{h}_{b, \\ell}\n= \\sum_{m=0}^{M-1} a_{m}\\left(\\frac{b}{W}\\right)\n    \\text{sinc}\\left( \\ell - W\\tau_{m} \\right)\n$$\n\nfor $\\ell$ ranging from `l_min` to `l_max`, and where $W$ is\nthe `bandwidth`.\nInput\n\n- **bandwidth** (*float*)  Bandwidth [Hz]\n- **a** (*[batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps], tf.complex*)  Path coefficients\n- **tau** (*[batch size, num_rx, num_tx, num_paths] or [batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths], tf.float*)  Path delays [s]\n- **l_min** (*int*)  Smallest time-lag for the discrete complex baseband channel ($L_{\\text{min}}$)\n- **l_max** (*int*)  Largest time-lag for the discrete complex baseband channel ($L_{\\text{max}}$)\n- **normalize** (*bool*)  If set to <cite>True</cite>, the channel is normalized over the block size\nto ensure unit average energy per time step. Defaults to <cite>False</cite>.\n\n\nOutput\n\n**hm** (*[batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_time_steps, l_max - l_min + 1], tf.complex*)  Channel taps coefficients"
"### time_to_ofdm_channel\n\n`sionna.channel.``time_to_ofdm_channel`(*`h_t`*, *`rg`*, *`l_min`*)[`[source]`](../_modules/sionna/channel/utils.html#time_to_ofdm_channel)\n\nCompute the channel frequency response from the discrete complex-baseband\nchannel impulse response.\n\nGiven a discrete complex-baseband channel impulse response\n$\\bar{h}_{b,\\ell}$, for $\\ell$ ranging from $L_\\text{min}\\le 0$\nto $L_\\text{max}$, the discrete channel frequency response is computed as\n\n$$\n\\hat{h}_{b,n} = \\sum_{k=0}^{L_\\text{max}} \\bar{h}_{b,k} e^{-j \\frac{2\\pi kn}{N}} + \\sum_{k=L_\\text{min}}^{-1} \\bar{h}_{b,k} e^{-j \\frac{2\\pi n(N+k)}{N}}, \\quad n=0,\\dots,N-1\n$$\n\nwhere $N$ is the FFT size and $b$ is the time step.\n\nThis function only produces one channel frequency response per OFDM symbol, i.e.,\nonly values of $b$ corresponding to the start of an OFDM symbol (after\ncyclic prefix removal) are considered.\nInput\n\n- **h_t** (*[num_time_steps,l_max-l_min+1], tf.complex*)  Tensor of discrete complex-baseband channel impulse responses\n- **resource_grid** ([`ResourceGrid`](ofdm.html#sionna.ofdm.ResourceGrid))  Resource grid\n- **l_min** (*int*)  Smallest time-lag for the discrete complex baseband\nchannel impulse response ($L_{\\text{min}}$)\n\n\nOutput\n\n**h_f** (*[,num_ofdm_symbols,fft_size], tf.complex*)  Tensor of discrete complex-baseband channel frequency responses\n\n\n**Note**\n\nNote that the result of this function is generally different from the\noutput of `cir_to_ofdm_channel()` because\nthe discrete complex-baseband channel impulse response is truncated\n(see `cir_to_time_channel()`). This effect\ncan be observed in the example below.\n xamples\n```python\n# Setup resource grid and channel model\ntf.random.set_seed(4)\nsm = StreamManagement(np.array([[1]]), 1)\nrg = ResourceGrid(num_ofdm_symbols=1,\n                  fft_size=1024,\n                  subcarrier_spacing=15e3)\ntdl = TDL(\"A\", 100e-9, 3.5e9)\n# Generate CIR\ncir = tdl(batch_size=1, num_time_steps=1, sampling_frequency=rg.bandwidth)\n# Generate OFDM channel from CIR\nfrequencies = subcarrier_frequencies(rg.fft_size, rg.subcarrier_spacing)\nh_freq = tf.squeeze(cir_to_ofdm_channel(frequencies, *cir, normalize=True))\n# Generate time channel from CIR\nl_min, l_max = time_lag_discrete_time_channel(rg.bandwidth)\nh_time = cir_to_time_channel(rg.bandwidth, *cir, l_min=l_min, l_max=l_max, normalize=True)\n# Generate OFDM channel from time channel\nh_freq_hat = tf.squeeze(time_to_ofdm_channel(h_time, rg, l_min))\n# Visualize results\nplt.figure()\nplt.plot(np.real(h_freq), \"-\")\nplt.plot(np.real(h_freq_hat), \"--\")\nplt.plot(np.imag(h_freq), \"-\")\nplt.plot(np.imag(h_freq_hat), \"--\")\nplt.xlabel(\"Subcarrier index\")\nplt.ylabel(r\"Channel frequency response\")\nplt.legend([\"OFDM Channel (real)\", \"OFDM Channel from time (real)\", \"OFDM Channel (imag)\", \"OFDM Channel from time (imag)\"])\n```"
"## Channel with OFDM waveform\n\nTo implement the channel response assuming an OFDM waveform, it is assumed that\nthe power delay profiles are invariant over the duration of an OFDM symbol.\nMoreover, it is assumed that the duration of the cyclic prefix (CP) equals at\nleast the maximum delay spread. These assumptions are common in the literature, as they\nenable modeling of the channel transfer function in the frequency domain as a\nsingle-tap channel.\n\nFor every link $(u, k, v, l)$ and resource element $(s,n)$,\nthe frequency channel response is obtained by computing the Fourier transform of\nthe channel response at the subcarrier frequencies, i.e.,\n\n$$\n\\begin{split}\\begin{align}\n\\widehat{h}_{u, k, v, l, s, n}\n   &= \\int_{-\\infty}^{+\\infty} h_{u, k, v, l}(s,\\tau) e^{-j2\\pi n \\Delta_f \\tau} d\\tau\\\\\n   &= \\sum_{m=0}^{M-1} a_{u, k, v, l, m}(s)\n   e^{-j2\\pi n \\Delta_f \\tau_{u, k, v, l, m}}\n\\end{align}\\end{split}\n$$\n\nwhere $s$ is used as time step to indicate that the channel response can\nchange from one OFDM symbol to the next in the event of mobility, even if it is\nassumed static over the duration of an OFDM symbol.\n\nFor every receive antenna $l$ of every receiver $v$, the\nreceived signal $y_{v, l, s, n}$ for resource element\n$(s, n)$ is computed by\n\n$$\ny_{v, l, s, n} = \\sum_{u=0}^{N_{T}-1}\\sum_{k=0}^{N_{TA}-1}\n   \\widehat{h}_{u, k, v, l, s, n} x_{u, k, s, n}\n   + w_{v, l, s, n}\n$$\n\nwhere $x_{u, k, s, n}$ is the baseband symbol transmitted by transmitter\n$u$ on antenna $k$ and resource element $(s, n)$, and\n$w_{v, l, s, n} \\sim \\mathcal{CN}\\left(0,N_0\\right)$ the additive white\nGaussian noise.\n\n**Note**\n\nThis model does not account for intersymbol interference (ISI) nor\nintercarrier interference (ICI). To model the ICI due to channel aging over\nthe duration of an OFDM symbol or the ISI due to a delay spread exceeding the\nCP duration, one would need to simulate the channel in the time domain.\nThis can be achieved by using the [`OFDMModulator`](ofdm.html#sionna.ofdm.OFDMModulator) and\n[`OFDMDemodulator`](ofdm.html#sionna.ofdm.OFDMDemodulator) layers, and the\n[time domain channel model](https://nvlabs.github.io/sionna/api/channel.wireless.html#time-domain).\nBy doing so, one performs inverse discrete Fourier transform (IDFT) on\nthe transmitter side and discrete Fourier transform (DFT) on the receiver side\non top of a single-carrier sinc-shaped waveform.\nThis is equivalent to\n[simulating the channel in the frequency domain](https://nvlabs.github.io/sionna/api/channel.wireless.html#ofdm-waveform) if no\nISI nor ICI is assumed, but allows the simulation of these effects in the\nevent of a non-stationary channel or long delay spreads.\nNote that simulating the channel in the time domain is typically significantly\nmore computationally demanding that simulating the channel in the frequency\ndomain."
"### OFDMChannel\n\n`class` `sionna.channel.``OFDMChannel`(*`channel_model`*, *`resource_grid`*, *`add_awgn``=``True`*, *`normalize_channel``=``False`*, *`return_channel``=``False`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/channel/ofdm_channel.html#OFDMChannel)\n\nGenerate channel frequency responses and apply them to channel inputs\nassuming an OFDM waveform with no ICI nor ISI.\n\nThis class inherits from the Keras <cite>Layer</cite> class and can be used as layer\nin a Keras model.\n\nFor each OFDM symbol $s$ and subcarrier $n$, the channel output is computed as follows:\n\n$$\ny_{s,n} = \\widehat{h}_{s, n} x_{s,n} + w_{s,n}\n$$\n\nwhere $y_{s,n}$ is the channel output computed by this layer,\n$\\widehat{h}_{s, n}$ the frequency channel response,\n$x_{s,n}$ the channel input `x`, and $w_{s,n}$ the additive noise.\n\nFor multiple-input multiple-output (MIMO) links, the channel output is computed for each antenna\nof each receiver and by summing over all the antennas of all transmitters.\n\nThe channel frequency response for the $s^{th}$ OFDM symbol and\n$n^{th}$ subcarrier is computed from a given channel impulse response\n$(a_{m}(t), \\tau_{m}), 0 \\leq m \\leq M-1$ generated by the `channel_model`\nas follows:\n\n$$\n\\widehat{h}_{s, n} = \\sum_{m=0}^{M-1} a_{m}(s) e^{-j2\\pi n \\Delta_f \\tau_{m}}\n$$\n\nwhere $\\Delta_f$ is the subcarrier spacing, and $s$ is used as time\nstep to indicate that the channel impulse response can change from one OFDM symbol to the\nnext in the event of mobility, even if it is assumed static over the duration\nof an OFDM symbol.\nParameters\n\n- **channel_model** ([`ChannelModel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.ChannelModel) object)  An instance of a [`ChannelModel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.ChannelModel) object, such as\n[`RayleighBlockFading`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.RayleighBlockFading) or\n[`UMi`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.tr38901.UMi).\n- **resource_grid** ([`ResourceGrid`](ofdm.html#sionna.ofdm.ResourceGrid))  Resource grid\n- **add_awgn** (*bool*)  If set to <cite>False</cite>, no white Gaussian noise is added.\nDefaults to <cite>True</cite>.\n- **normalize_channel** (*bool*)  If set to <cite>True</cite>, the channel is normalized over the resource grid\nto ensure unit average energy per resource element. Defaults to <cite>False</cite>.\n- **return_channel** (*bool*)  If set to <cite>True</cite>, the channel response is returned in addition to the\nchannel output. Defaults to <cite>False</cite>.\n- **dtype** (*tf.DType*)  Complex datatype to use for internal processing and output.\nDefaults to tf.complex64.\n\n\nInput\n\n- **(x, no) or x**  Tuple or Tensor:\n- **x** (*[batch size, num_tx, num_tx_ant, num_ofdm_symbols, fft_size], tf.complex*)  Channel inputs\n- **no** (*Scalar or Tensor, tf.float*)  Scalar or tensor whose shape can be broadcast to the shape of the\nchannel outputs:\n[batch size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size].\nOnly required if `add_awgn` is set to <cite>True</cite>.\nThe noise power `no` is per complex dimension. If `no` is a scalar,\nnoise of the same variance will be added to the outputs.\nIf `no` is a tensor, it must have a shape that can be broadcast to\nthe shape of the channel outputs. This allows, e.g., adding noise of\ndifferent variance to each example in a batch. If `no` has a lower\nrank than the channel outputs, then `no` will be broadcast to the\nshape of the channel outputs by adding dummy dimensions after the last\naxis.\n\n\nOutput\n\n- **y** (*[batch size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex*)  Channel outputs\n- **h_freq** (*[batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_ofdm_symbols, fft_size], tf.complex*)  (Optional) Channel frequency responses. Returned only if\n`return_channel` is set to <cite>True</cite>."
"### GenerateOFDMChannel\n\n`class` `sionna.channel.``GenerateOFDMChannel`(*`channel_model`*, *`resource_grid`*, *`normalize_channel``=``False`*)[`[source]`](../_modules/sionna/channel/generate_ofdm_channel.html#GenerateOFDMChannel)\n\nGenerate channel frequency responses.\nThe channel impulse response is constant over the duration of an OFDM symbol.\n\nGiven a channel impulse response\n$(a_{m}(t), \\tau_{m}), 0 \\leq m \\leq M-1$, generated by the `channel_model`,\nthe channel frequency response for the $s^{th}$ OFDM symbol and\n$n^{th}$ subcarrier is computed as follows:\n\n$$\n\\widehat{h}_{s, n} = \\sum_{m=0}^{M-1} a_{m}(s) e^{-j2\\pi n \\Delta_f \\tau_{m}}\n$$\n\nwhere $\\Delta_f$ is the subcarrier spacing, and $s$ is used as time\nstep to indicate that the channel impulse response can change from one OFDM symbol to the\nnext in the event of mobility, even if it is assumed static over the duration\nof an OFDM symbol.\nParameters\n\n- **channel_model** ([`ChannelModel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.ChannelModel) object)  An instance of a [`ChannelModel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.ChannelModel) object, such as\n[`RayleighBlockFading`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.RayleighBlockFading) or\n[`UMi`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.tr38901.UMi).\n- **resource_grid** ([`ResourceGrid`](ofdm.html#sionna.ofdm.ResourceGrid))  Resource grid\n- **normalize_channel** (*bool*)  If set to <cite>True</cite>, the channel is normalized over the resource grid\nto ensure unit average energy per resource element. Defaults to <cite>False</cite>.\n- **dtype** (*tf.DType*)  Complex datatype to use for internal processing and output.\nDefaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n**batch_size** (*int*)  Batch size. Defaults to <cite>None</cite> for channel models that do not require this paranmeter.\n\nOutput\n\n**h_freq** (*[batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_ofdm_symbols, num_subcarriers], tf.complex*)  Channel frequency responses"
"### ApplyOFDMChannel\n\n`class` `sionna.channel.``ApplyOFDMChannel`(*`add_awgn``=``True`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/channel/apply_ofdm_channel.html#ApplyOFDMChannel)\n\nApply single-tap channel frequency responses to channel inputs.\n\nThis class inherits from the Keras <cite>Layer</cite> class and can be used as layer\nin a Keras model.\n\nFor each OFDM symbol $s$ and subcarrier $n$, the single-tap channel\nis applied as follows:\n\n$$\ny_{s,n} = \\widehat{h}_{s, n} x_{s,n} + w_{s,n}\n$$\n\nwhere $y_{s,n}$ is the channel output computed by this layer,\n$\\widehat{h}_{s, n}$ the frequency channel response (`h_freq`),\n$x_{s,n}$ the channel input `x`, and $w_{s,n}$ the additive noise.\n\nFor multiple-input multiple-output (MIMO) links, the channel output is computed for each antenna\nof each receiver and by summing over all the antennas of all transmitters.\nParameters\n\n- **add_awgn** (*bool*)  If set to <cite>False</cite>, no white Gaussian noise is added.\nDefaults to <cite>True</cite>.\n- **dtype** (*tf.DType*)  Complex datatype to use for internal processing and output. Defaults to\n<cite>tf.complex64</cite>.\n\n\nInput\n\n- **(x, h_freq, no) or (x, h_freq)**  Tuple:\n- **x** (*[batch size, num_tx, num_tx_ant, num_ofdm_symbols, fft_size], tf.complex*)  Channel inputs\n- **h_freq** (*[batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_ofdm_symbols, fft_size], tf.complex*)  Channel frequency responses\n- **no** (*Scalar or Tensor, tf.float*)  Scalar or tensor whose shape can be broadcast to the shape of the\nchannel outputs:\n[batch size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size].\nOnly required if `add_awgn` is set to <cite>True</cite>.\nThe noise power `no` is per complex dimension. If `no` is a\nscalar, noise of the same variance will be added to the outputs.\nIf `no` is a tensor, it must have a shape that can be broadcast to\nthe shape of the channel outputs. This allows, e.g., adding noise of\ndifferent variance to each example in a batch. If `no` has a lower\nrank than the channel outputs, then `no` will be broadcast to the\nshape of the channel outputs by adding dummy dimensions after the\nlast axis.\n\n\nOutput\n\n**y** (*[batch size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex*)  Channel outputs"
"### cir_to_ofdm_channel\n\n`sionna.channel.``cir_to_ofdm_channel`(*`frequencies`*, *`a`*, *`tau`*, *`normalize``=``False`*)[`[source]`](../_modules/sionna/channel/utils.html#cir_to_ofdm_channel)\n\nCompute the frequency response of the channel at `frequencies`.\n\nGiven a channel impulse response\n$(a_{m}, \\tau_{m}), 0 \\leq m \\leq M-1$ (inputs `a` and `tau`),\nthe channel frequency response for the frequency $f$\nis computed as follows:\n\n$$\n\\widehat{h}(f) = \\sum_{m=0}^{M-1} a_{m} e^{-j2\\pi f \\tau_{m}}\n$$\n\nInput\n\n- **frequencies** (*[fft_size], tf.float*)  Frequencies at which to compute the channel response\n- **a** (*[batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps], tf.complex*)  Path coefficients\n- **tau** (*[batch size, num_rx, num_tx, num_paths] or [batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths], tf.float*)  Path delays\n- **normalize** (*bool*)  If set to <cite>True</cite>, the channel is normalized over the resource grid\nto ensure unit average energy per resource element. Defaults to <cite>False</cite>.\n\n\nOutput\n\n**h_f** (*[batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_time_steps, fft_size], tf.complex*)  Channel frequency responses at `frequencies`"
"## Rayleigh block fading\n\n`class` `sionna.channel.``RayleighBlockFading`(*`num_rx`*, *`num_rx_ant`*, *`num_tx`*, *`num_tx_ant`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/channel/rayleigh_block_fading.html#RayleighBlockFading)\n\nGenerate channel impulse responses corresponding to a Rayleigh block\nfading channel model.\n\nThe channel impulse responses generated are formed of a single path with\nzero delay and a normally distributed fading coefficient.\nAll time steps of a batch example share the same channel coefficient\n(block fading).\n\nThis class can be used in conjunction with the classes that simulate the\nchannel response in time or frequency domain, i.e.,\n[`OFDMChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.OFDMChannel),\n[`TimeChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.TimeChannel),\n[`GenerateOFDMChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.GenerateOFDMChannel),\n[`ApplyOFDMChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.ApplyOFDMChannel),\n[`GenerateTimeChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.GenerateTimeChannel),\n[`ApplyTimeChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.ApplyTimeChannel).\nParameters\n\n- **num_rx** (*int*)  Number of receivers ($N_R$)\n- **num_rx_ant** (*int*)  Number of antennas per receiver ($N_{RA}$)\n- **num_tx** (*int*)  Number of transmitters ($N_T$)\n- **num_tx_ant** (*int*)  Number of antennas per transmitter ($N_{TA}$)\n- **dtype** (*tf.DType*)  Complex datatype to use for internal processing and output.\nDefaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n- **batch_size** (*int*)  Batch size\n- **num_time_steps** (*int*)  Number of time steps\n\n\nOutput\n\n- **a** (*[batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths = 1, num_time_steps], tf.complex*)  Path coefficients\n- **tau** (*[batch size, num_rx, num_tx, num_paths = 1], tf.float*)  Path delays [s]"
"## 3GPP 38.901 channel models\n\nThe submodule `tr38901` implements 3GPP channel models from [[TR38901]](https://nvlabs.github.io/sionna/api/channel.wireless.html#tr38901).\n\nThe [CDL](https://nvlabs.github.io/sionna/api/channel.wireless.html#cdl), [UMi](https://nvlabs.github.io/sionna/api/channel.wireless.html#umi), [UMa](https://nvlabs.github.io/sionna/api/channel.wireless.html#uma), and [RMa](https://nvlabs.github.io/sionna/api/channel.wireless.html#rma)\nmodels require setting-up antenna models for the transmitters and\nreceivers. This is achieved using the\n[`PanelArray`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.tr38901.PanelArray) class.\n\nThe [UMi](https://nvlabs.github.io/sionna/api/channel.wireless.html#umi), [UMa](https://nvlabs.github.io/sionna/api/channel.wireless.html#uma), and [RMa](https://nvlabs.github.io/sionna/api/channel.wireless.html#rma) models require\nsetting-up a network topology, specifying, e.g., the user terminals (UTs) and\nbase stations (BSs) locations, the UTs velocities, etc.\n[Utility functions](https://nvlabs.github.io/sionna/api/channel.wireless.html#utility-functions) are available to help laying out\ncomplex topologies or to quickly setup simple but widely used topologies."
"### PanelArray\n\n`class` `sionna.channel.tr38901.``PanelArray`(*`num_rows_per_panel`*, *`num_cols_per_panel`*, *`polarization`*, *`polarization_type`*, *`antenna_pattern`*, *`carrier_frequency`*, *`num_rows``=``1`*, *`num_cols``=``1`*, *`panel_vertical_spacing``=``None`*, *`panel_horizontal_spacing``=``None`*, *`element_vertical_spacing``=``None`*, *`element_horizontal_spacing``=``None`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/channel/tr38901/antenna.html#PanelArray)\n\nAntenna panel array following the [[TR38901]](https://nvlabs.github.io/sionna/api/channel.wireless.html#tr38901) specification.\n\nThis class is used to create models of the panel arrays used by the\ntransmitters and receivers and that need to be specified when using the\n[CDL](https://nvlabs.github.io/sionna/api/channel.wireless.html#cdl), [UMi](https://nvlabs.github.io/sionna/api/channel.wireless.html#umi), [UMa](https://nvlabs.github.io/sionna/api/channel.wireless.html#uma), and [RMa](https://nvlabs.github.io/sionna/api/channel.wireless.html#rma)\nmodels.\n xample\n```python\n>>> array = PanelArray(num_rows_per_panel = 4,\n...                    num_cols_per_panel = 4,\n...                    polarization = 'dual',\n...                    polarization_type = 'VH',\n...                    antenna_pattern = '38.901',\n...                    carrier_frequency = 3.5e9,\n...                    num_cols = 2,\n...                    panel_horizontal_spacing = 3.)\n>>> array.show()\n```\n\nParameters\n\n- **num_rows_per_panel** (*int*)  Number of rows of elements per panel\n- **num_cols_per_panel** (*int*)  Number of columns of elements per panel\n- **polarization** (*str*)  Polarization, either single or dual\n- **polarization_type** (*str*)  Type of polarization. For single polarization, must be V or H.\nFor dual polarization, must be VH or cross.\n- **antenna_pattern** (*str*)  Element radiation pattern, either omni or 38.901\n- **carrier_frequency** (*float*)  Carrier frequency [Hz]\n- **num_rows** (*int*)  Number of rows of panels. Defaults to 1.\n- **num_cols** (*int*)  Number of columns of panels. Defaults to 1.\n- **panel_vertical_spacing** (<cite>None</cite> or float)  Vertical spacing of panels [multiples of wavelength].\nMust be greater than the panel width.\nIf set to <cite>None</cite> (default value), it is set to the panel width + 0.5.\n- **panel_horizontal_spacing** (<cite>None</cite> or float)  Horizontal spacing of panels [in multiples of wavelength].\nMust be greater than the panel height.\nIf set to <cite>None</cite> (default value), it is set to the panel height + 0.5.\n- **element_vertical_spacing** (<cite>None</cite> or float)  Element vertical spacing [multiple of wavelength].\nDefaults to 0.5 if set to <cite>None</cite>.\n- **element_horizontal_spacing** (<cite>None</cite> or float)  Element horizontal spacing [multiple of wavelength].\nDefaults to 0.5 if set to <cite>None</cite>.\n- **dtype** (*Complex tf.DType*)  Defines the datatype for internal calculations and the output\ndtype. Defaults to <cite>tf.complex64</cite>.\n\n\n`property` `ant_ind_pol1`\n\nIndices of antenna elements with the first polarization direction\n\n\n`property` `ant_ind_pol2`\n\nIndices of antenna elements with the second polarization direction.\nOnly defined with dual polarization.\n\n\n`property` `ant_pol1`\n\nField of an antenna element with the first polarization direction\n\n\n`property` `ant_pol2`\n\nField of an antenna element with the second polarization direction.\nOnly defined with dual polarization.\n\n\n`property` `ant_pos`\n\nPositions of the antennas\n\n\n`property` `ant_pos_pol1`\n\nPositions of the antenna elements with the first polarization\ndirection\n\n\n`property` `ant_pos_pol2`\n\nPositions of antenna elements with the second polarization direction.\nOnly defined with dual polarization.\n\n\n`property` `element_horizontal_spacing`\n\nHorizontal spacing between the antenna elements within a panel\n[multiple of wavelength]\n\n\n`property` `element_vertical_spacing`\n\nVertical spacing between the antenna elements within a panel\n[multiple of wavelength]\n\n\n`property` `num_ant`\n\nTotal number of antenna elements\n\n\n`property` `num_cols`\n\nNumber of columns of panels\n\n\n`property` `num_cols_per_panel`\n\nNumber of columns of elements per panel\n\n\n`property` `num_panels`\n\nNumber of panels\n\n\n`property` `num_panels_ant`\n\nNumber of antenna elements per panel\n\n\n`property` `num_rows`\n\nNumber of rows of panels\n\n\n`property` `num_rows_per_panel`\n\nNumber of rows of elements per panel\n\n\n`property` `panel_horizontal_spacing`\n\nHorizontal spacing between the panels [multiple of wavelength]\n\n\n`property` `panel_vertical_spacing`\n\nVertical spacing between the panels [multiple of wavelength]\n\n\n`property` `polarization`\n\nPolarization (single or dual)\n\n\n`property` `polarization_type`\n\nPolarization type. V or H for single polarization.\nVH or cross for dual polarization.\n\n\n`show`()[`[source]`](../_modules/sionna/channel/tr38901/antenna.html#PanelArray.show)\n\nShow the panel array geometry\n\n\n`show_element_radiation_pattern`()[`[source]`](../_modules/sionna/channel/tr38901/antenna.html#PanelArray.show_element_radiation_pattern)\n\nShow the radiation field of antenna elements forming the panel"
"### Antenna\n\n`class` `sionna.channel.tr38901.``Antenna`(*`polarization`*, *`polarization_type`*, *`antenna_pattern`*, *`carrier_frequency`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/channel/tr38901/antenna.html#Antenna)\n\nSingle antenna following the [[TR38901]](https://nvlabs.github.io/sionna/api/channel.wireless.html#tr38901) specification.\n\nThis class is a special case of [`PanelArray`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.tr38901.PanelArray),\nand can be used in lieu of it.\nParameters\n\n- **polarization** (*str*)  Polarization, either single or dual\n- **polarization_type** (*str*)  Type of polarization. For single polarization, must be V or H.\nFor dual polarization, must be VH or cross.\n- **antenna_pattern** (*str*)  Element radiation pattern, either omni or 38.901\n- **carrier_frequency** (*float*)  Carrier frequency [Hz]\n- **dtype** (*Complex tf.DType*)  Defines the datatype for internal calculations and the output\ndtype. Defaults to <cite>tf.complex64</cite>."
"### AntennaArray\n\n`class` `sionna.channel.tr38901.``AntennaArray`(*`num_rows`*, *`num_cols`*, *`polarization`*, *`polarization_type`*, *`antenna_pattern`*, *`carrier_frequency`*, *`vertical_spacing`*, *`horizontal_spacing`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/channel/tr38901/antenna.html#AntennaArray)\n\nAntenna array following the [[TR38901]](https://nvlabs.github.io/sionna/api/channel.wireless.html#tr38901) specification.\n\nThis class is a special case of [`PanelArray`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.tr38901.PanelArray),\nand can used in lieu of it.\nParameters\n\n- **num_rows** (*int*)  Number of rows of elements\n- **num_cols** (*int*)  Number of columns of elements\n- **polarization** (*str*)  Polarization, either single or dual\n- **polarization_type** (*str*)  Type of polarization. For single polarization, must be V or H.\nFor dual polarization, must be VH or cross.\n- **antenna_pattern** (*str*)  Element radiation pattern, either omni or 38.901\n- **carrier_frequency** (*float*)  Carrier frequency [Hz]\n- **vertical_spacing** (<cite>None</cite> or float)  Element vertical spacing [multiple of wavelength].\nDefaults to 0.5 if set to <cite>None</cite>.\n- **horizontal_spacing** (<cite>None</cite> or float)  Element horizontal spacing [multiple of wavelength].\nDefaults to 0.5 if set to <cite>None</cite>.\n- **dtype** (*Complex tf.DType*)  Defines the datatype for internal calculations and the output\ndtype. Defaults to <cite>tf.complex64</cite>."
"### Tapped delay line (TDL)\n\n`class` `sionna.channel.tr38901.``TDL`(*`model`*, *`delay_spread`*, *`carrier_frequency`*, *`num_sinusoids``=``20`*, *`los_angle_of_arrival``=``PI` `/` `4.`*, *`min_speed``=``0.`*, *`max_speed``=``None`*, *`num_rx_ant``=``1`*, *`num_tx_ant``=``1`*, *`spatial_corr_mat``=``None`*, *`rx_corr_mat``=``None`*, *`tx_corr_mat``=``None`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/channel/tr38901/tdl.html#TDL)\n\nTapped delay line (TDL) channel model from the 3GPP [[TR38901]](https://nvlabs.github.io/sionna/api/channel.wireless.html#tr38901) specification.\n\nThe power delay profiles (PDPs) are normalized to have a total energy of one.\n\nChannel coefficients are generated using a sum-of-sinusoids model [[SoS]](https://nvlabs.github.io/sionna/api/channel.wireless.html#sos).\nChannel aging is simulated in the event of mobility.\n\nIf a minimum speed and a maximum speed are specified such that the\nmaximum speed is greater than the minimum speed, then speeds are randomly\nand uniformly sampled from the specified interval for each link and each\nbatch example.\n\nThe TDL model only works for systems with a single transmitter and a single\nreceiver. The transmitter and receiver can be equipped with multiple\nantennas. Spatial correlation is simulated through filtering by specified\ncorrelation matrices.\n\nThe `spatial_corr_mat` parameter can be used to specify an arbitrary\nspatial correlation matrix. In particular, it can be used to model\ncorrelated cross-polarized transmit and receive antennas as follows\n(see, e.g., Annex G.2.3.2.1 [[TS38141-1]](https://nvlabs.github.io/sionna/api/channel.wireless.html#ts38141-1)):\n\n$$\n\\mathbf{R} = \\mathbf{R}_{\\text{rx}} \\otimes \\mathbf{\\Gamma} \\otimes \\mathbf{R}_{\\text{tx}}\n$$\n\nwhere $\\mathbf{R}$ is the spatial correlation matrix `spatial_corr_mat`,\n$\\mathbf{R}_{\\text{rx}}$ the spatial correlation matrix at the receiver\nwith same polarization, $\\mathbf{R}_{\\text{tx}}$ the spatial correlation\nmatrix at the transmitter with same polarization, and $\\mathbf{\\Gamma}$\nthe polarization correlation matrix. $\\mathbf{\\Gamma}$ is 1x1 for single-polarized\nantennas, 2x2 when only the transmit or receive antennas are cross-polarized, and 4x4 when\ntransmit and receive antennas are cross-polarized.\n\nIt is also possible not to specify `spatial_corr_mat`, but instead the correlation matrices\nat the receiver and transmitter, using the `rx_corr_mat` and `tx_corr_mat`\nparameters, respectively.\nThis can be useful when single polarized antennas are simulated, and it is also\nmore computationally efficient.\nThis is equivalent to setting `spatial_corr_mat` to :\n\n$$\n\\mathbf{R} = \\mathbf{R}_{\\text{rx}} \\otimes \\mathbf{R}_{\\text{tx}}\n$$\n\nwhere $\\mathbf{R}_{\\text{rx}}$ is the correlation matrix at the receiver\n`rx_corr_mat` and  $\\mathbf{R}_{\\text{tx}}$ the correlation matrix at\nthe transmitter `tx_corr_mat`.\n xample\n\nThe following code snippet shows how to setup a TDL channel model assuming\nan OFDM waveform:"
"```python\n>>> tdl = TDL(model = \"A\",\n...           delay_spread = 300e-9,\n...           carrier_frequency = 3.5e9,\n...           min_speed = 0.0,\n...           max_speed = 3.0)\n>>>\n>>> channel = OFDMChannel(channel_model = tdl,\n...                       resource_grid = rg)\n```\n\n\nwhere `rg` is an instance of [`ResourceGrid`](ofdm.html#sionna.ofdm.ResourceGrid).\n otes\n\nThe following tables from [[TR38901]](https://nvlabs.github.io/sionna/api/channel.wireless.html#tr38901) provide typical values for the delay\nspread.\n<table class=\"docutils align-default\">\n<colgroup>\n<col style=\"width: 58%\" />\n<col style=\"width: 42%\" />\n</colgroup>\n<thead>\n<tr class=\"row-odd\"><th class=\"head\">\nModel</th>\n<th class=\"head\">\nDelay spread [ns]</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"row-even\"><td>\nVery short delay spread</td>\n<td>\n$10$</td>\n</tr>\n<tr class=\"row-odd\"><td>\nShort short delay spread</td>\n<td>\n$10$</td>\n</tr>\n<tr class=\"row-even\"><td>\nNominal delay spread</td>\n<td>\n$100$</td>\n</tr>\n<tr class=\"row-odd\"><td>\nLong delay spread</td>\n<td>\n$300$</td>\n</tr>\n<tr class=\"row-even\"><td>\nVery long delay spread</td>\n<td>\n$1000$</td>\n</tr>\n</tbody>\n</table>\n<table class=\"docutils align-default\">\n<colgroup>\n<col style=\"width: 30%\" />\n<col style=\"width: 27%\" />\n<col style=\"width: 7%\" />\n<col style=\"width: 7%\" />\n<col style=\"width: 5%\" />\n<col style=\"width: 6%\" />\n<col style=\"width: 6%\" />\n<col style=\"width: 5%\" />\n<col style=\"width: 6%\" />\n</colgroup>\n<thead>\n<tr class=\"row-odd\"><th class=\"head\" colspan=\"2\" rowspan=\"2\">\nDelay spread [ns]</th>\n<th class=\"head\" colspan=\"7\">\nFrequency [GHz]</th>\n</tr>\n<tr class=\"row-even\"><th class=\"head\">\n2</th>\n<th class=\"head\">\n6</th>\n<th class=\"head\">\n15</th>\n<th class=\"head\">\n28</th>\n<th class=\"head\">\n39</th>\n<th class=\"head\">\n60</th>\n<th class=\"head\">\n70</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"row-odd\"><td rowspan=\"3\">\nIndoor office</td>\n<td>\nShort delay profile</td>\n<td>\n20</td>\n<td>\n16</td>\n<td>\n16</td>\n<td>\n16</td>\n<td>\n16</td>\n<td>\n16</td>\n<td>\n16</td>\n</tr>\n<tr class=\"row-even\"><td>\nNormal delay profile</td>\n<td>\n39</td>\n<td>\n30</td>\n<td>\n24</td>\n<td>\n20</td>\n<td>\n18</td>\n<td>\n16</td>\n<td>\n16</td>\n</tr>\n<tr class=\"row-odd\"><td>\nLong delay profile</td>\n<td>\n59</td>\n<td>\n53</td>\n<td>\n47</td>\n<td>\n43</td>\n<td>\n41</td>\n<td>\n38</td>\n<td>\n37</td>\n</tr>\n<tr class=\"row-even\"><td rowspan=\"3\">\nUMi Street-canyon</td>\n<td>\nShort delay profile</td>\n<td>\n65</td>\n<td>\n45</td>\n<td>\n37</td>\n<td>\n32</td>\n<td>\n30</td>\n<td>\n27</td>\n<td>\n26</td>\n</tr>\n<tr class=\"row-odd\"><td>\nNormal delay profile</td>\n<td>\n129</td>\n<td>\n93</td>\n<td>\n76</td>\n<td>\n66</td>\n<td>\n61</td>\n<td>\n55</td>\n<td>\n53</td>\n</tr>\n<tr class=\"row-even\"><td>\nLong delay profile</td>\n<td>\n634</td>\n<td>\n316</td>\n<td>\n307</td>\n<td>\n301</td>\n<td>\n297</td>\n<td>\n293</td>\n<td>\n291</td>\n</tr>\n<tr class=\"row-odd\"><td rowspan=\"3\">\nUMa</td>\n<td>\nShort delay profile</td>\n<td>\n93</td>\n<td>\n93</td>\n<td>\n85</td>\n<td>\n80</td>\n<td>\n78</td>\n<td>\n75</td>\n<td>\n74</td>\n</tr>\n<tr class=\"row-even\"><td>\nNormal delay profile</td>\n<td>\n363</td>\n<td>\n363</td>\n<td>\n302</td>\n<td>\n266</td>\n<td>\n249</td>\n<td>\n228</td>\n<td>\n221</td>\n</tr>\n<tr class=\"row-odd\"><td>\nLong delay profile</td>\n<td>\n1148</td>\n<td>\n1148</td>\n<td>\n955</td>\n<td>\n841</td>\n<td>\n786</td>\n<td>\n720</td>\n<td>\n698</td>\n</tr>\n<tr class=\"row-even\"><td rowspan=\"3\">\nRMa / RMa O2I</td>\n<td>\nShort delay profile</td>\n<td>\n32</td>\n<td>\n32</td>\n<td>\nN/A</td>\n<td>\nN/A</td>\n<td>\nN/A</td>\n<td>\nN/A</td>\n<td>\nN/A</td>\n</tr>\n<tr class=\"row-odd\"><td>\nNormal delay profile</td>\n<td>\n37</td>\n<td>\n37</td>\n<td>\nN/A</td>\n<td>\nN/A</td>\n<td>\nN/A</td>\n<td>\nN/A</td>\n<td>\nN/A</td>\n</tr>\n<tr class=\"row-even\"><td>\nLong delay profile</td>\n<td>\n153</td>\n<td>\n153</td>\n<td>\nN/A</td>\n<td>\nN/A</td>\n<td>\nN/A</td>\n<td>\nN/A</td>\n<td>\nN/A</td>\n</tr>\n<tr class=\"row-odd\"><td rowspan=\"2\">\nUMi / UMa O2I</td>\n<td>\nNormal delay profile</td>\n<td colspan=\"7\">\n242</td>\n</tr>\n<tr class=\"row-even\"><td>\nLong delay profile</td>\n<td colspan=\"7\">\n616</td>\n</tr>\n</tbody>\n</table>\nParameters\n\n- **model** (*str*)  TDL model to use. Must be one of A, B, C, D, E, A30, B100, or C300.\n- **delay_spread** (*float*)  RMS delay spread [s].\nFor the A30, B100, and C300 models, the delay spread must be set\nto 30ns, 100ns, and 300ns, respectively.\n- **carrier_frequency** (*float*)  Carrier frequency [Hz]\n- **num_sinusoids** (*int*)  Number of sinusoids for the sum-of-sinusoids model. Defaults to 20.\n- **los_angle_of_arrival** (*float*)  Angle-of-arrival for LoS path [radian]. Only used with LoS models.\nDefaults to $\\pi/4$.\n- **min_speed** (*float*)  Minimum speed [m/s]. Defaults to 0.\n- **max_speed** (*None** or **float*)  Maximum speed [m/s]. If set to <cite>None</cite>,\nthen `max_speed` takes the same value as `min_speed`.\nDefaults to <cite>None</cite>.\n- **num_rx_ant** (*int*)  Number of receive antennas.\nDefaults to 1.\n- **num_tx_ant** (*int*)  Number of transmit antennas.\nDefaults to 1.\n- **spatial_corr_mat** ([num_rx_ant*num_tx_ant,num_rx_ant*num_tx_ant], tf.complex or <cite>None</cite>)  Spatial correlation matrix.\nIf not set to <cite>None</cite>, then `rx_corr_mat` and `tx_corr_mat` are ignored and\nthis matrix is used for spatial correlation.\nIf set to <cite>None</cite> and `rx_corr_mat` and `tx_corr_mat` are also set to <cite>None</cite>,\nthen no correlation is applied.\nDefaults to <cite>None</cite>.\n- **rx_corr_mat** ([num_rx_ant,num_rx_ant], tf.complex or <cite>None</cite>)  Spatial correlation matrix for the receiver.\nIf set to <cite>None</cite> and `spatial_corr_mat` is also set to <cite>None</cite>, then no receive\ncorrelation is applied.\nDefaults to <cite>None</cite>.\n- **tx_corr_mat** ([num_tx_ant,num_tx_ant], tf.complex or <cite>None</cite>)  Spatial correlation matrix for the transmitter.\nIf set to <cite>None</cite> and `spatial_corr_mat` is also set to <cite>None</cite>, then no transmit\ncorrelation is applied.\nDefaults to <cite>None</cite>.\n- **dtype** (*Complex tf.DType*)  Defines the datatype for internal calculations and the output\ndtype. Defaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n- **batch_size** (*int*)  Batch size\n- **num_time_steps** (*int*)  Number of time steps\n- **sampling_frequency** (*float*)  Sampling frequency [Hz]\n\n\nOutput\n\n- **a** (*[batch size, num_rx = 1, num_rx_ant = 1, num_tx = 1, num_tx_ant = 1, num_paths, num_time_steps], tf.complex*)  Path coefficients\n- **tau** (*[batch size, num_rx = 1, num_tx = 1, num_paths], tf.float*)  Path delays [s]\n\n\n`property` `delay_spread`\n\nRMS delay spread [s]\n\n\n`property` `delays`\n\nPath delays [s]\n\n\n`property` `k_factor`\n\nK-factor in linear scale. Only available with LoS models.\n\n\n`property` `los`\n\n<cite>True</cite> if this is a LoS model. <cite>False</cite> otherwise.\n\n\n`property` `mean_power_los`\n\nLoS component power in linear scale.\nOnly available with LoS models.\n\n\n`property` `mean_powers`\n\nPath powers in linear scale\n\n\n`property` `num_clusters`\n\nNumber of paths ($M$)"
"### Clustered delay line (CDL)\n\n`class` `sionna.channel.tr38901.``CDL`(*`model`*, *`delay_spread`*, *`carrier_frequency`*, *`ut_array`*, *`bs_array`*, *`direction`*, *`min_speed``=``0.`*, *`max_speed``=``None`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/channel/tr38901/cdl.html#CDL)\n\nClustered delay line (CDL) channel model from the 3GPP [[TR38901]](https://nvlabs.github.io/sionna/api/channel.wireless.html#tr38901) specification.\n\nThe power delay profiles (PDPs) are normalized to have a total energy of one.\n\nIf a minimum speed and a maximum speed are specified such that the\nmaximum speed is greater than the minimum speed, then UTs speeds are\nrandomly and uniformly sampled from the specified interval for each link\nand each batch example.\n\nThe CDL model only works for systems with a single transmitter and a single\nreceiver. The transmitter and receiver can be equipped with multiple\nantennas.\n xample\n\nThe following code snippet shows how to setup a CDL channel model assuming\nan OFDM waveform:\n```python\n>>> # Panel array configuration for the transmitter and receiver\n>>> bs_array = PanelArray(num_rows_per_panel = 4,\n...                       num_cols_per_panel = 4,\n...                       polarization = 'dual',\n...                       polarization_type = 'cross',\n...                       antenna_pattern = '38.901',\n...                       carrier_frequency = 3.5e9)\n>>> ut_array = PanelArray(num_rows_per_panel = 1,\n...                       num_cols_per_panel = 1,\n...                       polarization = 'single',\n...                       polarization_type = 'V',\n...                       antenna_pattern = 'omni',\n...                       carrier_frequency = 3.5e9)\n>>> # CDL channel model\n>>> cdl = CDL(model = \"A\",\n>>>           delay_spread = 300e-9,\n...           carrier_frequency = 3.5e9,\n...           ut_array = ut_array,\n...           bs_array = bs_array,\n...           direction = 'uplink')\n>>> channel = OFDMChannel(channel_model = cdl,\n...                       resource_grid = rg)\n```"
"where `rg` is an instance of [`ResourceGrid`](ofdm.html#sionna.ofdm.ResourceGrid).\n otes\n\nThe following tables from [[TR38901]](https://nvlabs.github.io/sionna/api/channel.wireless.html#tr38901) provide typical values for the delay\nspread.\n<table class=\"docutils align-default\">\n<colgroup>\n<col style=\"width: 58%\" />\n<col style=\"width: 42%\" />\n</colgroup>\n<thead>\n<tr class=\"row-odd\"><th class=\"head\">\nModel</th>\n<th class=\"head\">\nDelay spread [ns]</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"row-even\"><td>\nVery short delay spread</td>\n<td>\n$10$</td>\n</tr>\n<tr class=\"row-odd\"><td>\nShort short delay spread</td>\n<td>\n$10$</td>\n</tr>\n<tr class=\"row-even\"><td>\nNominal delay spread</td>\n<td>\n$100$</td>\n</tr>\n<tr class=\"row-odd\"><td>\nLong delay spread</td>\n<td>\n$300$</td>\n</tr>\n<tr class=\"row-even\"><td>\nVery long delay spread</td>\n<td>\n$1000$</td>\n</tr>\n</tbody>\n</table>\n<table class=\"docutils align-default\">\n<colgroup>\n<col style=\"width: 30%\" />\n<col style=\"width: 27%\" />\n<col style=\"width: 7%\" />\n<col style=\"width: 7%\" />\n<col style=\"width: 5%\" />\n<col style=\"width: 6%\" />\n<col style=\"width: 6%\" />\n<col style=\"width: 5%\" />\n<col style=\"width: 6%\" />\n</colgroup>\n<thead>\n<tr class=\"row-odd\"><th class=\"head\" colspan=\"2\" rowspan=\"2\">\nDelay spread [ns]</th>\n<th class=\"head\" colspan=\"7\">\nFrequency [GHz]</th>\n</tr>\n<tr class=\"row-even\"><th class=\"head\">\n2</th>\n<th class=\"head\">\n6</th>\n<th class=\"head\">\n15</th>\n<th class=\"head\">\n28</th>\n<th class=\"head\">\n39</th>\n<th class=\"head\">\n60</th>\n<th class=\"head\">\n70</th>\n</tr>\n</thead>\n<tbody>\n<tr class=\"row-odd\"><td rowspan=\"3\">\nIndoor office</td>\n<td>\nShort delay profile</td>\n<td>\n20</td>\n<td>\n16</td>\n<td>\n16</td>\n<td>\n16</td>\n<td>\n16</td>\n<td>\n16</td>\n<td>\n16</td>\n</tr>\n<tr class=\"row-even\"><td>\nNormal delay profile</td>\n<td>\n39</td>\n<td>\n30</td>\n<td>\n24</td>\n<td>\n20</td>\n<td>\n18</td>\n<td>\n16</td>\n<td>\n16</td>\n</tr>\n<tr class=\"row-odd\"><td>\nLong delay profile</td>\n<td>\n59</td>\n<td>\n53</td>\n<td>\n47</td>\n<td>\n43</td>\n<td>\n41</td>\n<td>\n38</td>\n<td>\n37</td>\n</tr>\n<tr class=\"row-even\"><td rowspan=\"3\">\nUMi Street-canyon</td>\n<td>\nShort delay profile</td>\n<td>\n65</td>\n<td>\n45</td>\n<td>\n37</td>\n<td>\n32</td>\n<td>\n30</td>\n<td>\n27</td>\n<td>\n26</td>\n</tr>\n<tr class=\"row-odd\"><td>\nNormal delay profile</td>\n<td>\n129</td>\n<td>\n93</td>\n<td>\n76</td>\n<td>\n66</td>\n<td>\n61</td>\n<td>\n55</td>\n<td>\n53</td>\n</tr>\n<tr class=\"row-even\"><td>\nLong delay profile</td>\n<td>\n634</td>\n<td>\n316</td>\n<td>\n307</td>\n<td>\n301</td>\n<td>\n297</td>\n<td>\n293</td>\n<td>\n291</td>\n</tr>\n<tr class=\"row-odd\"><td rowspan=\"3\">\nUMa</td>\n<td>\nShort delay profile</td>\n<td>\n93</td>\n<td>\n93</td>\n<td>\n85</td>\n<td>\n80</td>\n<td>\n78</td>\n<td>\n75</td>\n<td>\n74</td>\n</tr>\n<tr class=\"row-even\"><td>\nNormal delay profile</td>\n<td>\n363</td>\n<td>\n363</td>\n<td>\n302</td>\n<td>\n266</td>\n<td>\n249</td>\n<td>\n228</td>\n<td>\n221</td>\n</tr>\n<tr class=\"row-odd\"><td>\nLong delay profile</td>\n<td>\n1148</td>\n<td>\n1148</td>\n<td>\n955</td>\n<td>\n841</td>\n<td>\n786</td>\n<td>\n720</td>\n<td>\n698</td>\n</tr>\n<tr class=\"row-even\"><td rowspan=\"3\">\nRMa / RMa O2I</td>\n<td>\nShort delay profile</td>\n<td>\n32</td>\n<td>\n32</td>\n<td>\nN/A</td>\n<td>\nN/A</td>\n<td>\nN/A</td>\n<td>\nN/A</td>\n<td>\nN/A</td>\n</tr>\n<tr class=\"row-odd\"><td>\nNormal delay profile</td>\n<td>\n37</td>\n<td>\n37</td>\n<td>\nN/A</td>\n<td>\nN/A</td>\n<td>\nN/A</td>\n<td>\nN/A</td>\n<td>\nN/A</td>\n</tr>\n<tr class=\"row-even\"><td>\nLong delay profile</td>\n<td>\n153</td>\n<td>\n153</td>\n<td>\nN/A</td>\n<td>\nN/A</td>\n<td>\nN/A</td>\n<td>\nN/A</td>\n<td>\nN/A</td>\n</tr>\n<tr class=\"row-odd\"><td rowspan=\"2\">\nUMi / UMa O2I</td>\n<td>\nNormal delay profile</td>\n<td colspan=\"7\">\n242</td>\n</tr>\n<tr class=\"row-even\"><td>\nLong delay profile</td>\n<td colspan=\"7\">\n616</td>\n</tr>\n</tbody>\n</table>\nParameters\n\n- **model** (*str*)  CDL model to use. Must be one of A, B, C, D or E.\n- **delay_spread** (*float*)  RMS delay spread [s].\n- **carrier_frequency** (*float*)  Carrier frequency [Hz].\n- **ut_array** ()  Panel array used by the UTs. All UTs share the same antenna array\nconfiguration.\n- **bs_array** ()  Panel array used by the Bs. All BSs share the same antenna array\nconfiguration.\n- **direction** (*str*)  Link direction. Must be either uplink or downlink.\n- **ut_orientation** (<cite>None</cite> or Tensor of shape [3], tf.float)  Orientation of the UT. If set to <cite>None</cite>, [$\\pi$, 0, 0] is used.\nDefaults to <cite>None</cite>.\n- **bs_orientation** (<cite>None</cite> or Tensor of shape [3], tf.float)  Orientation of the BS. If set to <cite>None</cite>, [0, 0, 0] is used.\nDefaults to <cite>None</cite>.\n- **min_speed** (*float*)  Minimum speed [m/s]. Defaults to 0.\n- **max_speed** (*None** or **float*)  Maximum speed [m/s]. If set to <cite>None</cite>,\nthen `max_speed` takes the same value as `min_speed`.\nDefaults to <cite>None</cite>.\n- **dtype** (*Complex tf.DType*)  Defines the datatype for internal calculations and the output\ndtype. Defaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n- **batch_size** (*int*)  Batch size\n- **num_time_steps** (*int*)  Number of time steps\n- **sampling_frequency** (*float*)  Sampling frequency [Hz]\n\n\nOutput\n\n- **a** (*[batch size, num_rx = 1, num_rx_ant, num_tx = 1, num_tx_ant, num_paths, num_time_steps], tf.complex*)  Path coefficients\n- **tau** (*[batch size, num_rx = 1, num_tx = 1, num_paths], tf.float*)  Path delays [s]\n\n\n`property` `delay_spread`\n\nRMS delay spread [s]\n\n\n`property` `delays`\n\nPath delays [s]\n\n\n`property` `k_factor`\n\nK-factor in linear scale. Only available with LoS models.\n\n\n`property` `los`\n\n<cite>True</cite> is this is a LoS model. <cite>False</cite> otherwise.\n\n\n`property` `num_clusters`\n\nNumber of paths ($M$)\n\n\n`property` `powers`\n\nPath powers in linear scale"
"### Urban microcell (UMi)\n\n`class` `sionna.channel.tr38901.``UMi`(*`carrier_frequency`*, *`o2i_model`*, *`ut_array`*, *`bs_array`*, *`direction`*, *`enable_pathloss``=``True`*, *`enable_shadow_fading``=``True`*, *`always_generate_lsp``=``False`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/channel/tr38901/umi.html#UMi)\n\nUrban microcell (UMi) channel model from 3GPP [[TR38901]](https://nvlabs.github.io/sionna/api/channel.wireless.html#tr38901) specification.\n\nSetting up a UMi model requires configuring the network topology, i.e., the\nUTs and BSs locations, UTs velocities, etc. This is achieved using the\n[`set_topology()`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.tr38901.UMi.set_topology) method. Setting a different\ntopology for each batch example is possible. The batch size used when setting up the network topology\nis used for the link simulations.\n\nThe following code snippet shows how to setup a UMi channel model operating\nin the frequency domain:\n```python\n>>> # UT and BS panel arrays\n>>> bs_array = PanelArray(num_rows_per_panel = 4,\n...                       num_cols_per_panel = 4,\n...                       polarization = 'dual',\n...                       polarization_type  = 'cross',\n...                       antenna_pattern = '38.901',\n...                       carrier_frequency = 3.5e9)\n>>> ut_array = PanelArray(num_rows_per_panel = 1,\n...                       num_cols_per_panel = 1,\n...                       polarization = 'single',\n...                       polarization_type = 'V',\n...                       antenna_pattern = 'omni',\n...                       carrier_frequency = 3.5e9)\n>>> # Instantiating UMi channel model\n>>> channel_model = UMi(carrier_frequency = 3.5e9,\n...                     o2i_model = 'low',\n...                     ut_array = ut_array,\n...                     bs_array = bs_array,\n...                     direction = 'uplink')\n>>> # Setting up network topology\n>>> # ut_loc: UTs locations\n>>> # bs_loc: BSs locations\n>>> # ut_orientations: UTs array orientations\n>>> # bs_orientations: BSs array orientations\n>>> # in_state: Indoor/outdoor states of UTs\n>>> channel_model.set_topology(ut_loc,\n...                            bs_loc,\n...                            ut_orientations,\n...                            bs_orientations,\n...                            ut_velocities,\n...                            in_state)\n>>> # Instanting the frequency domain channel\n>>> channel = OFDMChannel(channel_model = channel_model,\n...                       resource_grid = rg)\n```"
"where `rg` is an instance of [`ResourceGrid`](ofdm.html#sionna.ofdm.ResourceGrid).\nParameters\n\n- **carrier_frequency** (*float*)  Carrier frequency in Hertz\n- **o2i_model** (*str*)  Outdoor-to-indoor loss model for UTs located indoor.\nSet this parameter to low to use the low-loss model, or to high\nto use the high-loss model.\nSee section 7.4.3 of [[TR38901]](https://nvlabs.github.io/sionna/api/channel.wireless.html#tr38901) for details.\n- **rx_array** ()  Panel array used by the receivers. All receivers share the same\nantenna array configuration.\n- **tx_array** ()  Panel array used by the transmitters. All transmitters share the\nsame antenna array configuration.\n- **direction** (*str*)  Link direction. Either uplink or downlink.\n- **enable_pathloss** (*bool*)  If <cite>True</cite>, apply pathloss. Otherwise doesnt. Defaults to <cite>True</cite>.\n- **enable_shadow_fading** (*bool*)  If <cite>True</cite>, apply shadow fading. Otherwise doesnt.\nDefaults to <cite>True</cite>.\n- **always_generate_lsp** (*bool*)  If <cite>True</cite>, new large scale parameters (LSPs) are generated for every\nnew generation of channel impulse responses. Otherwise, always reuse\nthe same LSPs, except if the topology is changed. Defaults to\n<cite>False</cite>.\n- **dtype** (*Complex tf.DType*)  Defines the datatype for internal calculations and the output\ndtype. Defaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n- **num_time_steps** (*int*)  Number of time steps\n- **sampling_frequency** (*float*)  Sampling frequency [Hz]\n\n\nOutput\n\n- **a** (*[batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps], tf.complex*)  Path coefficients\n- **tau** (*[batch size, num_rx, num_tx, num_paths], tf.float*)  Path delays [s]\n\n\n`set_topology`(*`ut_loc``=``None`*, *`bs_loc``=``None`*, *`ut_orientations``=``None`*, *`bs_orientations``=``None`*, *`ut_velocities``=``None`*, *`in_state``=``None`*, *`los``=``None`*)\n\nSet the network topology.\n\nIt is possible to set up a different network topology for each batch\nexample. The batch size used when setting up the network topology\nis used for the link simulations.\n\nWhen calling this function, not specifying a parameter leads to the\nreuse of the previously given value. Not specifying a value that was not\nset at a former call rises an error.\nInput\n\n- **ut_loc** (*[batch size,num_ut, 3], tf.float*)  Locations of the UTs\n- **bs_loc** (*[batch size,num_bs, 3], tf.float*)  Locations of BSs\n- **ut_orientations** (*[batch size,num_ut, 3], tf.float*)  Orientations of the UTs arrays [radian]\n- **bs_orientations** (*[batch size,num_bs, 3], tf.float*)  Orientations of the BSs arrays [radian]\n- **ut_velocities** (*[batch size,num_ut, 3], tf.float*)  Velocity vectors of UTs\n- **in_state** (*[batch size,num_ut], tf.bool*)  Indoor/outdoor state of UTs. <cite>True</cite> means indoor and <cite>False</cite>\nmeans outdoor.\n- **los** (tf.bool or <cite>None</cite>)  If not <cite>None</cite> (default value), all UTs located outdoor are\nforced to be in LoS if `los` is set to <cite>True</cite>, or in NLoS\nif it is set to <cite>False</cite>. If set to <cite>None</cite>, the LoS/NLoS states\nof UTs is set following 3GPP specification [[TR38901]](https://nvlabs.github.io/sionna/api/channel.wireless.html#tr38901).\n\n\n**Note**\n\nIf you want to use this function in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat).\n\n\n`show_topology`(*`bs_index``=``0`*, *`batch_index``=``0`*)\n\nShows the network topology of the batch example with index\n`batch_index`.\n\nThe `bs_index` parameter specifies with respect to which BS the\nLoS/NLoS state of UTs is indicated.\nInput\n\n- **bs_index** (*int*)  BS index with respect to which the LoS/NLoS state of UTs is\nindicated. Defaults to 0.\n- **batch_index** (*int*)  Batch example for which the topology is shown. Defaults to 0."
"### Urban macrocell (UMa)\n\n`class` `sionna.channel.tr38901.``UMa`(*`carrier_frequency`*, *`o2i_model`*, *`ut_array`*, *`bs_array`*, *`direction`*, *`enable_pathloss``=``True`*, *`enable_shadow_fading``=``True`*, *`always_generate_lsp``=``False`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/channel/tr38901/uma.html#UMa)\n\nUrban macrocell (UMa) channel model from 3GPP [[TR38901]](https://nvlabs.github.io/sionna/api/channel.wireless.html#tr38901) specification.\n\nSetting up a UMa model requires configuring the network topology, i.e., the\nUTs and BSs locations, UTs velocities, etc. This is achieved using the\n[`set_topology()`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.tr38901.UMa.set_topology) method. Setting a different\ntopology for each batch example is possible. The batch size used when setting up the network topology\nis used for the link simulations.\n\nThe following code snippet shows how to setup an UMa channel model assuming\nan OFDM waveform:\n```python\n>>> # UT and BS panel arrays\n>>> bs_array = PanelArray(num_rows_per_panel = 4,\n...                       num_cols_per_panel = 4,\n...                       polarization = 'dual',\n...                       polarization_type = 'cross',\n...                       antenna_pattern = '38.901',\n...                       carrier_frequency = 3.5e9)\n>>> ut_array = PanelArray(num_rows_per_panel = 1,\n...                       num_cols_per_panel = 1,\n...                       polarization = 'single',\n...                       polarization_type = 'V',\n...                       antenna_pattern = 'omni',\n...                       carrier_frequency = 3.5e9)\n>>> # Instantiating UMa channel model\n>>> channel_model = UMa(carrier_frequency = 3.5e9,\n...                     o2i_model = 'low',\n...                     ut_array = ut_array,\n...                     bs_array = bs_array,\n...                     direction = 'uplink')\n>>> # Setting up network topology\n>>> # ut_loc: UTs locations\n>>> # bs_loc: BSs locations\n>>> # ut_orientations: UTs array orientations\n>>> # bs_orientations: BSs array orientations\n>>> # in_state: Indoor/outdoor states of UTs\n>>> channel_model.set_topology(ut_loc,\n...                            bs_loc,\n...                            ut_orientations,\n...                            bs_orientations,\n...                            ut_velocities,\n...                            in_state)\n>>> # Instanting the OFDM channel\n>>> channel = OFDMChannel(channel_model = channel_model,\n...                       resource_grid = rg)\n```"
"where `rg` is an instance of [`ResourceGrid`](ofdm.html#sionna.ofdm.ResourceGrid).\nParameters\n\n- **carrier_frequency** (*float*)  Carrier frequency in Hertz\n- **o2i_model** (*str*)  Outdoor-to-indoor loss model for UTs located indoor.\nSet this parameter to low to use the low-loss model, or to high\nto use the high-loss model.\nSee section 7.4.3 of [[TR38901]](https://nvlabs.github.io/sionna/api/channel.wireless.html#tr38901) for details.\n- **rx_array** ()  Panel array used by the receivers. All receivers share the same\nantenna array configuration.\n- **tx_array** ()  Panel array used by the transmitters. All transmitters share the\nsame antenna array configuration.\n- **direction** (*str*)  Link direction. Either uplink or downlink.\n- **enable_pathloss** (*bool*)  If <cite>True</cite>, apply pathloss. Otherwise doesnt. Defaults to <cite>True</cite>.\n- **enable_shadow_fading** (*bool*)  If <cite>True</cite>, apply shadow fading. Otherwise doesnt.\nDefaults to <cite>True</cite>.\n- **always_generate_lsp** (*bool*)  If <cite>True</cite>, new large scale parameters (LSPs) are generated for every\nnew generation of channel impulse responses. Otherwise, always reuse\nthe same LSPs, except if the topology is changed. Defaults to\n<cite>False</cite>.\n- **dtype** (*Complex tf.DType*)  Defines the datatype for internal calculations and the output\ndtype. Defaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n- **num_time_steps** (*int*)  Number of time steps\n- **sampling_frequency** (*float*)  Sampling frequency [Hz]\n\n\nOutput\n\n- **a** (*[batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps], tf.complex*)  Path coefficients\n- **tau** (*[batch size, num_rx, num_tx, num_paths], tf.float*)  Path delays [s]\n\n\n`set_topology`(*`ut_loc``=``None`*, *`bs_loc``=``None`*, *`ut_orientations``=``None`*, *`bs_orientations``=``None`*, *`ut_velocities``=``None`*, *`in_state``=``None`*, *`los``=``None`*)\n\nSet the network topology.\n\nIt is possible to set up a different network topology for each batch\nexample. The batch size used when setting up the network topology\nis used for the link simulations.\n\nWhen calling this function, not specifying a parameter leads to the\nreuse of the previously given value. Not specifying a value that was not\nset at a former call rises an error.\nInput\n\n- **ut_loc** (*[batch size,num_ut, 3], tf.float*)  Locations of the UTs\n- **bs_loc** (*[batch size,num_bs, 3], tf.float*)  Locations of BSs\n- **ut_orientations** (*[batch size,num_ut, 3], tf.float*)  Orientations of the UTs arrays [radian]\n- **bs_orientations** (*[batch size,num_bs, 3], tf.float*)  Orientations of the BSs arrays [radian]\n- **ut_velocities** (*[batch size,num_ut, 3], tf.float*)  Velocity vectors of UTs\n- **in_state** (*[batch size,num_ut], tf.bool*)  Indoor/outdoor state of UTs. <cite>True</cite> means indoor and <cite>False</cite>\nmeans outdoor.\n- **los** (tf.bool or <cite>None</cite>)  If not <cite>None</cite> (default value), all UTs located outdoor are\nforced to be in LoS if `los` is set to <cite>True</cite>, or in NLoS\nif it is set to <cite>False</cite>. If set to <cite>None</cite>, the LoS/NLoS states\nof UTs is set following 3GPP specification [[TR38901]](https://nvlabs.github.io/sionna/api/channel.wireless.html#tr38901).\n\n\n**Note**\n\nIf you want to use this function in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat).\n\n\n`show_topology`(*`bs_index``=``0`*, *`batch_index``=``0`*)\n\nShows the network topology of the batch example with index\n`batch_index`.\n\nThe `bs_index` parameter specifies with respect to which BS the\nLoS/NLoS state of UTs is indicated.\nInput\n\n- **bs_index** (*int*)  BS index with respect to which the LoS/NLoS state of UTs is\nindicated. Defaults to 0.\n- **batch_index** (*int*)  Batch example for which the topology is shown. Defaults to 0."
"### Rural macrocell (RMa)\n\n`class` `sionna.channel.tr38901.``RMa`(*`carrier_frequency`*, *`ut_array`*, *`bs_array`*, *`direction`*, *`enable_pathloss``=``True`*, *`enable_shadow_fading``=``True`*, *`always_generate_lsp``=``False`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/channel/tr38901/rma.html#RMa)\n\nRural macrocell (RMa) channel model from 3GPP [[TR38901]](https://nvlabs.github.io/sionna/api/channel.wireless.html#tr38901) specification.\n\nSetting up a RMa model requires configuring the network topology, i.e., the\nUTs and BSs locations, UTs velocities, etc. This is achieved using the\n[`set_topology()`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.tr38901.RMa.set_topology) method. Setting a different\ntopology for each batch example is possible. The batch size used when setting up the network topology\nis used for the link simulations.\n\nThe following code snippet shows how to setup an RMa channel model assuming\nan OFDM waveform:\n```python\n>>> # UT and BS panel arrays\n>>> bs_array = PanelArray(num_rows_per_panel = 4,\n...                       num_cols_per_panel = 4,\n...                       polarization = 'dual',\n...                       polarization_type = 'cross',\n...                       antenna_pattern = '38.901',\n...                       carrier_frequency = 3.5e9)\n>>> ut_array = PanelArray(num_rows_per_panel = 1,\n...                       num_cols_per_panel = 1,\n...                       polarization = 'single',\n...                       polarization_type = 'V',\n...                       antenna_pattern = 'omni',\n...                       carrier_frequency = 3.5e9)\n>>> # Instantiating RMa channel model\n>>> channel_model = RMa(carrier_frequency = 3.5e9,\n...                     ut_array = ut_array,\n...                     bs_array = bs_array,\n...                     direction = 'uplink')\n>>> # Setting up network topology\n>>> # ut_loc: UTs locations\n>>> # bs_loc: BSs locations\n>>> # ut_orientations: UTs array orientations\n>>> # bs_orientations: BSs array orientations\n>>> # in_state: Indoor/outdoor states of UTs\n>>> channel_model.set_topology(ut_loc,\n...                            bs_loc,\n...                            ut_orientations,\n...                            bs_orientations,\n...                            ut_velocities,\n...                            in_state)\n>>> # Instanting the OFDM channel\n>>> channel = OFDMChannel(channel_model = channel_model,\n...                       resource_grid = rg)\n```"
"where `rg` is an instance of [`ResourceGrid`](ofdm.html#sionna.ofdm.ResourceGrid).\nParameters\n\n- **carrier_frequency** (*float*)  Carrier frequency [Hz]\n- **rx_array** ()  Panel array used by the receivers. All receivers share the same\nantenna array configuration.\n- **tx_array** ()  Panel array used by the transmitters. All transmitters share the\nsame antenna array configuration.\n- **direction** (*str*)  Link direction. Either uplink or downlink.\n- **enable_pathloss** (*bool*)  If <cite>True</cite>, apply pathloss. Otherwise doesnt. Defaults to <cite>True</cite>.\n- **enable_shadow_fading** (*bool*)  If <cite>True</cite>, apply shadow fading. Otherwise doesnt.\nDefaults to <cite>True</cite>.\n- **average_street_width** (*float*)  Average street width [m]. Defaults to 5m.\n- **average_street_width**  Average building height [m]. Defaults to 20m.\n- **always_generate_lsp** (*bool*)  If <cite>True</cite>, new large scale parameters (LSPs) are generated for every\nnew generation of channel impulse responses. Otherwise, always reuse\nthe same LSPs, except if the topology is changed. Defaults to\n<cite>False</cite>.\n- **dtype** (*Complex tf.DType*)  Defines the datatype for internal calculations and the output\ndtype. Defaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n- **num_time_steps** (*int*)  Number of time steps\n- **sampling_frequency** (*float*)  Sampling frequency [Hz]\n\n\nOutput\n\n- **a** (*[batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps], tf.complex*)  Path coefficients\n- **tau** (*[batch size, num_rx, num_tx, num_paths], tf.float*)  Path delays [s]\n\n\n`set_topology`(*`ut_loc``=``None`*, *`bs_loc``=``None`*, *`ut_orientations``=``None`*, *`bs_orientations``=``None`*, *`ut_velocities``=``None`*, *`in_state``=``None`*, *`los``=``None`*)\n\nSet the network topology.\n\nIt is possible to set up a different network topology for each batch\nexample. The batch size used when setting up the network topology\nis used for the link simulations.\n\nWhen calling this function, not specifying a parameter leads to the\nreuse of the previously given value. Not specifying a value that was not\nset at a former call rises an error.\nInput\n\n- **ut_loc** (*[batch size,num_ut, 3], tf.float*)  Locations of the UTs\n- **bs_loc** (*[batch size,num_bs, 3], tf.float*)  Locations of BSs\n- **ut_orientations** (*[batch size,num_ut, 3], tf.float*)  Orientations of the UTs arrays [radian]\n- **bs_orientations** (*[batch size,num_bs, 3], tf.float*)  Orientations of the BSs arrays [radian]\n- **ut_velocities** (*[batch size,num_ut, 3], tf.float*)  Velocity vectors of UTs\n- **in_state** (*[batch size,num_ut], tf.bool*)  Indoor/outdoor state of UTs. <cite>True</cite> means indoor and <cite>False</cite>\nmeans outdoor.\n- **los** (tf.bool or <cite>None</cite>)  If not <cite>None</cite> (default value), all UTs located outdoor are\nforced to be in LoS if `los` is set to <cite>True</cite>, or in NLoS\nif it is set to <cite>False</cite>. If set to <cite>None</cite>, the LoS/NLoS states\nof UTs is set following 3GPP specification [[TR38901]](https://nvlabs.github.io/sionna/api/channel.wireless.html#tr38901).\n\n\n**Note**\n\nIf you want to use this function in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat).\n\n\n`show_topology`(*`bs_index``=``0`*, *`batch_index``=``0`*)\n\nShows the network topology of the batch example with index\n`batch_index`.\n\nThe `bs_index` parameter specifies with respect to which BS the\nLoS/NLoS state of UTs is indicated.\nInput\n\n- **bs_index** (*int*)  BS index with respect to which the LoS/NLoS state of UTs is\nindicated. Defaults to 0.\n- **batch_index** (*int*)  Batch example for which the topology is shown. Defaults to 0."
"## External datasets\n\n`class` `sionna.channel.``CIRDataset`(*`cir_generator`*, *`batch_size`*, *`num_rx`*, *`num_rx_ant`*, *`num_tx`*, *`num_tx_ant`*, *`num_paths`*, *`num_time_steps`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/channel/cir_dataset.html#CIRDataset)\n\nCreates a channel model from a dataset that can be used with classes such as\n[`TimeChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.TimeChannel) and [`OFDMChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.OFDMChannel).\nThe dataset is defined by a [generator](https://wiki.python.org/moin/Generators).\n\nThe batch size is configured when instantiating the dataset or through the [`batch_size`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.CIRDataset.batch_size) property.\nThe number of time steps (<cite>num_time_steps</cite>) and sampling frequency (<cite>sampling_frequency</cite>) can only be set when instantiating the dataset.\nThe specified values must be in accordance with the data.\n xample\n\nThe following code snippet shows how to use this class as a channel model.\n```python\n>>> my_generator = MyGenerator(...)\n>>> channel_model = sionna.channel.CIRDataset(my_generator,\n...                                           batch_size,\n...                                           num_rx,\n...                                           num_rx_ant,\n...                                           num_tx,\n...                                           num_tx_ant,\n...                                           num_paths,\n...                                           num_time_steps+l_tot-1)\n>>> channel = sionna.channel.TimeChannel(channel_model, bandwidth, num_time_steps)\n```\n\n\nwhere `MyGenerator` is a generator\n```python\n>>> class MyGenerator:\n...\n...     def __call__(self):\n...         ...\n...         yield a, tau\n```\n\n\nthat returns complex-valued path coefficients `a` with shape\n<cite>[num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps]</cite>\nand real-valued path delays `tau` (in second)\n<cite>[num_rx, num_tx, num_paths]</cite>.\nParameters\n\n- **cir_generator**  Generator that returns channel impulse responses `(a,` `tau)` where\n`a` is the tensor of channel coefficients of shape\n<cite>[num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps]</cite>\nand dtype `dtype`, and `tau` the tensor of path delays\nof shape  <cite>[num_rx, num_tx, num_paths]</cite> and dtype `dtype.`\n`real_dtype`.\n- **batch_size** (*int*)  Batch size\n- **num_rx** (*int*)  Number of receivers ($N_R$)\n- **num_rx_ant** (*int*)  Number of antennas per receiver ($N_{RA}$)\n- **num_tx** (*int*)  Number of transmitters ($N_T$)\n- **num_tx_ant** (*int*)  Number of antennas per transmitter ($N_{TA}$)\n- **num_paths** (*int*)  Number of paths ($M$)\n- **num_time_steps** (*int*)  Number of time steps\n- **dtype** (*tf.DType*)  Complex datatype to use for internal processing and output.\nDefaults to <cite>tf.complex64</cite>.\n\n\nOutput\n\n- **a** (*[batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps], tf.complex*)  Path coefficients\n- **tau** (*[batch size, num_rx, num_tx, num_paths], tf.float*)  Path delays [s]\n\n\n`property` `batch_size`\n\nBatch size"
"### subcarrier_frequencies\n\n`sionna.channel.``subcarrier_frequencies`(*`num_subcarriers`*, *`subcarrier_spacing`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/channel/utils.html#subcarrier_frequencies)\n\nCompute the baseband frequencies of `num_subcarrier` subcarriers spaced by\n`subcarrier_spacing`, i.e.,\n```python\n>>> # If num_subcarrier is even:\n>>> frequencies = [-num_subcarrier/2, ..., 0, ..., num_subcarrier/2-1] * subcarrier_spacing\n>>>\n>>> # If num_subcarrier is odd:\n>>> frequencies = [-(num_subcarrier-1)/2, ..., 0, ..., (num_subcarrier-1)/2] * subcarrier_spacing\n```\n\nInput\n\n- **num_subcarriers** (*int*)  Number of subcarriers\n- **subcarrier_spacing** (*float*)  Subcarrier spacing [Hz]\n- **dtype** (*tf.DType*)  Datatype to use for internal processing and output.\nIf a complex datatype is provided, the corresponding precision of\nreal components is used.\nDefaults to <cite>tf.complex64</cite> (<cite>tf.float32</cite>).\n\n\nOutput\n\n**frequencies** ([`num_subcarrier`], tf.float)  Baseband frequencies of subcarriers"
"### time_lag_discrete_time_channel\n\n`sionna.channel.``time_lag_discrete_time_channel`(*`bandwidth`*, *`maximum_delay_spread``=``3e-06`*)[`[source]`](../_modules/sionna/channel/utils.html#time_lag_discrete_time_channel)\n\nCompute the smallest and largest time-lag for the descrete complex baseband\nchannel, i.e., $L_{\\text{min}}$ and $L_{\\text{max}}$.\n\nThe smallest time-lag ($L_{\\text{min}}$) returned is always -6, as this value\nwas found small enough for all models included in Sionna.\n\nThe largest time-lag ($L_{\\text{max}}$) is computed from the `bandwidth`\nand `maximum_delay_spread` as follows:\n\n$$\nL_{\\text{max}} = \\lceil W \\tau_{\\text{max}} \\rceil + 6\n$$\n\nwhere $L_{\\text{max}}$ is the largest time-lag, $W$ the `bandwidth`,\nand $\\tau_{\\text{max}}$ the `maximum_delay_spread`.\n\nThe default value for the `maximum_delay_spread` is 3us, which was found\nto be large enough to include most significant paths with all channel models\nincluded in Sionna assuming a nominal delay spread of 100ns.\n\n**Note**\n\nThe values of $L_{\\text{min}}$ and $L_{\\text{max}}$ computed\nby this function are only recommended values.\n$L_{\\text{min}}$ and $L_{\\text{max}}$ should be set according to\nthe considered channel model. For OFDM systems, one also needs to be careful\nthat the effective length of the complex baseband channel is not larger than\nthe cyclic prefix length.\n\nInput\n\n- **bandwidth** (*float*)  Bandwith ($W$) [Hz]\n- **maximum_delay_spread** (*float*)  Maximum delay spread [s]. Defaults to 3us.\n\n\nOutput\n\n- **l_min** (*int*)  Smallest time-lag ($L_{\\text{min}}$) for the descrete complex baseband\nchannel. Set to -6, , as this value was found small enough for all models\nincluded in Sionna.\n- **l_max** (*int*)  Largest time-lag ($L_{\\text{max}}$) for the descrete complex baseband\nchannel"
"### deg_2_rad\n\n`sionna.channel.``deg_2_rad`(*`x`*)[`[source]`](../_modules/sionna/channel/utils.html#deg_2_rad)\n\nConvert degree to radian\nInput\n\n**x** (*Tensor*)  Angles in degree\n\nOutput\n\n**y** (*Tensor*)  Angles `x` converted to radian"
"### rad_2_deg\n\n`sionna.channel.``rad_2_deg`(*`x`*)[`[source]`](../_modules/sionna/channel/utils.html#rad_2_deg)\n\nConvert radian to degree\nInput\n\n**x** (*Tensor*)  Angles in radian\n\nOutput\n\n**y** (*Tensor*)  Angles `x` converted to degree"
"### wrap_angle_0_360\n\n`sionna.channel.``wrap_angle_0_360`(*`angle`*)[`[source]`](../_modules/sionna/channel/utils.html#wrap_angle_0_360)\n\nWrap `angle` to (0,360)\nInput\n\n**angle** (*Tensor*)  Input to wrap\n\nOutput\n\n**y** (*Tensor*)  `angle` wrapped to (0,360)"
"### drop_uts_in_sector\n\n`sionna.channel.``drop_uts_in_sector`(*`batch_size`*, *`num_ut`*, *`min_bs_ut_dist`*, *`isd`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/channel/utils.html#drop_uts_in_sector)\n\nUniformly sample UT locations from a sector.\n\nThe sector from which UTs are sampled is shown in the following figure.\nThe BS is assumed to be located at the origin (0,0) of the coordinate\nsystem.\n\n\nInput\n\n- **batch_size** (*int*)  Batch size\n- **num_ut** (*int*)  Number of UTs to sample per batch example\n- **min_bs_ut_dist** (*tf.float*)  Minimum BS-UT distance [m]\n- **isd** (*tf.float*)  Inter-site distance, i.e., the distance between two adjacent BSs [m]\n- **dtype** (*tf.DType*)  Datatype to use for internal processing and output.\nIf a complex datatype is provided, the corresponding precision of\nreal components is used.\nDefaults to <cite>tf.complex64</cite> (<cite>tf.float32</cite>).\n\n\nOutput\n\n**ut_loc** (*[batch_size, num_ut, 2], tf.float*)  UTs locations in the X-Y plan"
"### relocate_uts\n\n`sionna.channel.``relocate_uts`(*`ut_loc`*, *`sector_id`*, *`cell_loc`*)[`[source]`](../_modules/sionna/channel/utils.html#relocate_uts)\n\nRelocate the UTs by rotating them into the sector with index `sector_id`\nand transposing them to the cell centered on `cell_loc`.\n\n`sector_id` gives the index of the sector to which the UTs are\nrotated to. The picture below shows how the three sectors of a cell are\nindexed.\n\n ig. 9 Indexing of sectors\n\nIf `sector_id` is a scalar, then all UTs are relocated to the same\nsector indexed by `sector_id`.\nIf `sector_id` is a tensor, it should be broadcastable with\n[`batch_size`, `num_ut`], and give the sector in which each UT or\nbatch example is relocated to.\n\nWhen calling the function, `ut_loc` gives the locations of the UTs to\nrelocate, which are all assumed to be in sector with index 0, and in the\ncell centered on the origin (0,0).\nInput\n\n- **ut_loc** (*[batch_size, num_ut, 2], tf.float*)  UTs locations in the X-Y plan\n- **sector_id** (*Tensor broadcastable with [batch_size, num_ut], int*)  Indexes of the sector to which to relocate the UTs\n- **cell_loc** (*Tensor broadcastable with [batch_size, num_ut], tf.float*)  Center of the cell to which to transpose the UTs\n\n\nOutput\n\n**ut_loc** (*[batch_size, num_ut, 2], tf.float*)  Relocated UTs locations in the X-Y plan"
"### set_3gpp_scenario_parameters\n\n`sionna.channel.``set_3gpp_scenario_parameters`(*`scenario`*, *`min_bs_ut_dist``=``None`*, *`isd``=``None`*, *`bs_height``=``None`*, *`min_ut_height``=``None`*, *`max_ut_height``=``None`*, *`indoor_probability``=``None`*, *`min_ut_velocity``=``None`*, *`max_ut_velocity``=``None`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/channel/utils.html#set_3gpp_scenario_parameters)\n\nSet valid parameters for a specified 3GPP system level `scenario`\n(RMa, UMi, or UMa).\n\nIf a parameter is given, then it is returned. If it is set to <cite>None</cite>,\nthen a parameter valid according to the chosen scenario is returned\n(see [[TR38901]](https://nvlabs.github.io/sionna/api/channel.wireless.html#tr38901)).\nInput\n\n- **scenario** (*str*)  System level model scenario. Must be one of rma, umi, or uma.\n- **min_bs_ut_dist** (*None or tf.float*)  Minimum BS-UT distance [m]\n- **isd** (*None or tf.float*)  Inter-site distance [m]\n- **bs_height** (*None or tf.float*)  BS elevation [m]\n- **min_ut_height** (*None or tf.float*)  Minimum UT elevation [m]\n- **max_ut_height** (*None or tf.float*)  Maximum UT elevation [m]\n- **indoor_probability** (*None or tf.float*)  Probability of a UT to be indoor\n- **min_ut_velocity** (*None or tf.float*)  Minimum UT velocity [m/s]\n- **max_ut_velocity** (*None or tf.float*)  Maximim UT velocity [m/s]\n- **dtype** (*tf.DType*)  Datatype to use for internal processing and output.\nIf a complex datatype is provided, the corresponding precision of\nreal components is used.\nDefaults to <cite>tf.complex64</cite> (<cite>tf.float32</cite>).\n\n\nOutput\n\n- **min_bs_ut_dist** (*tf.float*)  Minimum BS-UT distance [m]\n- **isd** (*tf.float*)  Inter-site distance [m]\n- **bs_height** (*tf.float*)  BS elevation [m]\n- **min_ut_height** (*tf.float*)  Minimum UT elevation [m]\n- **max_ut_height** (*tf.float*)  Maximum UT elevation [m]\n- **indoor_probability** (*tf.float*)  Probability of a UT to be indoor\n- **min_ut_velocity** (*tf.float*)  Minimum UT velocity [m/s]\n- **max_ut_velocity** (*tf.float*)  Maximim UT velocity [m/s]"
"### gen_single_sector_topology\n\n`sionna.channel.``gen_single_sector_topology`(*`batch_size`*, *`num_ut`*, *`scenario`*, *`min_bs_ut_dist``=``None`*, *`isd``=``None`*, *`bs_height``=``None`*, *`min_ut_height``=``None`*, *`max_ut_height``=``None`*, *`indoor_probability``=``None`*, *`min_ut_velocity``=``None`*, *`max_ut_velocity``=``None`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/channel/utils.html#gen_single_sector_topology)\n\nGenerate a batch of topologies consisting of a single BS located at the\norigin and `num_ut` UTs randomly and uniformly dropped in a cell sector.\n\nThe following picture shows the sector from which UTs are sampled.\n\n\nUTs orientations are randomly and uniformly set, whereas the BS orientation\nis set such that the it is oriented towards the center of the sector.\n\nThe drop configuration can be controlled through the optional parameters.\nParameters set to <cite>None</cite> are set to valid values according to the chosen\n`scenario` (see [[TR38901]](https://nvlabs.github.io/sionna/api/channel.wireless.html#tr38901)).\n\nThe returned batch of topologies can be used as-is with the\n`set_topology()` method of the system level models, i.e.\n[`UMi`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.tr38901.UMi), [`UMa`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.tr38901.UMa),\nand [`RMa`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.tr38901.RMa).\n xample\n```python\n>>> # Create antenna arrays\n>>> bs_array = PanelArray(num_rows_per_panel = 4,\n...                      num_cols_per_panel = 4,\n...                      polarization = 'dual',\n...                      polarization_type = 'VH',\n...                      antenna_pattern = '38.901',\n...                      carrier_frequency = 3.5e9)\n>>>\n>>> ut_array = PanelArray(num_rows_per_panel = 1,\n...                       num_cols_per_panel = 1,\n...                       polarization = 'single',\n...                       polarization_type = 'V',\n...                       antenna_pattern = 'omni',\n...                       carrier_frequency = 3.5e9)\n>>> # Create channel model\n>>> channel_model = UMi(carrier_frequency = 3.5e9,\n...                     o2i_model = 'low',\n...                     ut_array = ut_array,\n...                     bs_array = bs_array,\n...                     direction = 'uplink')\n>>> # Generate the topology\n>>> topology = gen_single_sector_topology(batch_size = 100,\n...                                       num_ut = 4,\n...                                       scenario = 'umi')\n>>> # Set the topology\n>>> ut_loc, bs_loc, ut_orientations, bs_orientations, ut_velocities, in_state = topology\n>>> channel_model.set_topology(ut_loc,\n...                            bs_loc,\n...                            ut_orientations,\n...                            bs_orientations,\n...                            ut_velocities,\n...                            in_state)\n>>> channel_model.show_topology()\n```"
"Input\n\n- **batch_size** (*int*)  Batch size\n- **num_ut** (*int*)  Number of UTs to sample per batch example\n- **scenario** (*str*)  System leven model scenario. Must be one of rma, umi, or uma.\n- **min_bs_ut_dist** (*None or tf.float*)  Minimum BS-UT distance [m]\n- **isd** (*None or tf.float*)  Inter-site distance [m]\n- **bs_height** (*None or tf.float*)  BS elevation [m]\n- **min_ut_height** (*None or tf.float*)  Minimum UT elevation [m]\n- **max_ut_height** (*None or tf.float*)  Maximum UT elevation [m]\n- **indoor_probability** (*None or tf.float*)  Probability of a UT to be indoor\n- **min_ut_velocity** (*None or tf.float*)  Minimum UT velocity [m/s]\n- **max_ut_velocity** (*None or tf.float*)  Maximim UT velocity [m/s]\n- **dtype** (*tf.DType*)  Datatype to use for internal processing and output.\nIf a complex datatype is provided, the corresponding precision of\nreal components is used.\nDefaults to <cite>tf.complex64</cite> (<cite>tf.float32</cite>).\n\n\nOutput\n\n- **ut_loc** (*[batch_size, num_ut, 3], tf.float*)  UTs locations\n- **bs_loc** (*[batch_size, 1, 3], tf.float*)  BS location. Set to (0,0,0) for all batch examples.\n- **ut_orientations** (*[batch_size, num_ut, 3], tf.float*)  UTs orientations [radian]\n- **bs_orientations** (*[batch_size, 1, 3], tf.float*)  BS orientations [radian]. Oriented towards the center of the sector.\n- **ut_velocities** (*[batch_size, num_ut, 3], tf.float*)  UTs velocities [m/s]\n- **in_state** (*[batch_size, num_ut], tf.float*)  Indoor/outdoor state of UTs. <cite>True</cite> means indoor, <cite>False</cite> means\noutdoor."
"### gen_single_sector_topology_interferers\n\n`sionna.channel.``gen_single_sector_topology_interferers`(*`batch_size`*, *`num_ut`*, *`num_interferer`*, *`scenario`*, *`min_bs_ut_dist``=``None`*, *`isd``=``None`*, *`bs_height``=``None`*, *`min_ut_height``=``None`*, *`max_ut_height``=``None`*, *`indoor_probability``=``None`*, *`min_ut_velocity``=``None`*, *`max_ut_velocity``=``None`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/channel/utils.html#gen_single_sector_topology_interferers)\n\nGenerate a batch of topologies consisting of a single BS located at the\norigin, `num_ut` UTs randomly and uniformly dropped in a cell sector, and\n`num_interferer` interfering UTs randomly dropped in the adjacent cells.\n\nThe following picture shows how UTs are sampled\n\n\nUTs orientations are randomly and uniformly set, whereas the BS orientation\nis set such that it is oriented towards the center of the sector it\nserves.\n\nThe drop configuration can be controlled through the optional parameters.\nParameters set to <cite>None</cite> are set to valid values according to the chosen\n`scenario` (see [[TR38901]](https://nvlabs.github.io/sionna/api/channel.wireless.html#tr38901)).\n\nThe returned batch of topologies can be used as-is with the\n`set_topology()` method of the system level models, i.e.\n[`UMi`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.tr38901.UMi), [`UMa`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.tr38901.UMa),\nand [`RMa`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.tr38901.RMa).\n\nIn the returned `ut_loc`, `ut_orientations`, `ut_velocities`, and\n`in_state` tensors, the first `num_ut` items along the axis with index\n1 correspond to the served UTs, whereas the remaining `num_interferer`\nitems correspond to the interfering UTs.\n xample"
"```python\n>>> # Create antenna arrays\n>>> bs_array = PanelArray(num_rows_per_panel = 4,\n...                      num_cols_per_panel = 4,\n...                      polarization = 'dual',\n...                      polarization_type = 'VH',\n...                      antenna_pattern = '38.901',\n...                      carrier_frequency = 3.5e9)\n>>>\n>>> ut_array = PanelArray(num_rows_per_panel = 1,\n...                       num_cols_per_panel = 1,\n...                       polarization = 'single',\n...                       polarization_type = 'V',\n...                       antenna_pattern = 'omni',\n...                       carrier_frequency = 3.5e9)\n>>> # Create channel model\n>>> channel_model = UMi(carrier_frequency = 3.5e9,\n...                     o2i_model = 'low',\n...                     ut_array = ut_array,\n...                     bs_array = bs_array,\n...                     direction = 'uplink')\n>>> # Generate the topology\n>>> topology = gen_single_sector_topology_interferers(batch_size = 100,\n...                                                   num_ut = 4,\n...                                                   num_interferer = 4,\n...                                                   scenario = 'umi')\n>>> # Set the topology\n>>> ut_loc, bs_loc, ut_orientations, bs_orientations, ut_velocities, in_state = topology\n>>> channel_model.set_topology(ut_loc,\n...                            bs_loc,\n...                            ut_orientations,\n...                            bs_orientations,\n...                            ut_velocities,\n...                            in_state)\n>>> channel_model.show_topology()\n```\n\nInput\n\n- **batch_size** (*int*)  Batch size\n- **num_ut** (*int*)  Number of UTs to sample per batch example\n- **num_interferer** (*int*)  Number of interfeering UTs per batch example\n- **scenario** (*str*)  System leven model scenario. Must be one of rma, umi, or uma.\n- **min_bs_ut_dist** (*None or tf.float*)  Minimum BS-UT distance [m]\n- **isd** (*None or tf.float*)  Inter-site distance [m]\n- **bs_height** (*None or tf.float*)  BS elevation [m]\n- **min_ut_height** (*None or tf.float*)  Minimum UT elevation [m]\n- **max_ut_height** (*None or tf.float*)  Maximum UT elevation [m]\n- **indoor_probability** (*None or tf.float*)  Probability of a UT to be indoor\n- **min_ut_velocity** (*None or tf.float*)  Minimum UT velocity [m/s]\n- **max_ut_velocity** (*None or tf.float*)  Maximim UT velocity [m/s]\n- **dtype** (*tf.DType*)  Datatype to use for internal processing and output.\nIf a complex datatype is provided, the corresponding precision of\nreal components is used.\nDefaults to <cite>tf.complex64</cite> (<cite>tf.float32</cite>).\n\n\nOutput\n\n- **ut_loc** (*[batch_size, num_ut, 3], tf.float*)  UTs locations. The first `num_ut` items along the axis with index\n1 correspond to the served UTs, whereas the remaining\n`num_interferer` items correspond to the interfeering UTs.\n- **bs_loc** (*[batch_size, 1, 3], tf.float*)  BS location. Set to (0,0,0) for all batch examples.\n- **ut_orientations** (*[batch_size, num_ut, 3], tf.float*)  UTs orientations [radian]. The first `num_ut` items along the\naxis with index 1 correspond to the served UTs, whereas the\nremaining `num_interferer` items correspond to the interfeering\nUTs.\n- **bs_orientations** (*[batch_size, 1, 3], tf.float*)  BS orientation [radian]. Oriented towards the center of the sector.\n- **ut_velocities** (*[batch_size, num_ut, 3], tf.float*)  UTs velocities [m/s]. The first `num_ut` items along the axis\nwith index 1 correspond to the served UTs, whereas the remaining\n`num_interferer` items correspond to the interfeering UTs.\n- **in_state** (*[batch_size, num_ut], tf.float*)  Indoor/outdoor state of UTs. <cite>True</cite> means indoor, <cite>False</cite> means\noutdoor. The first `num_ut` items along the axis with\nindex 1 correspond to the served UTs, whereas the remaining\n`num_interferer` items correspond to the interfeering UTs."
"### exp_corr_mat\n\n`sionna.channel.``exp_corr_mat`(*`a`*, *`n`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/channel/utils.html#exp_corr_mat)\n\nGenerate exponential correlation matrices.\n\nThis function computes for every element $a$ of a complex-valued\ntensor $\\mathbf{a}$ the corresponding $n\\times n$ exponential\ncorrelation matrix $\\mathbf{R}(a,n)$, defined as (Eq. 1, [[MAL2018]](https://nvlabs.github.io/sionna/api/channel.wireless.html#mal2018)):\n\n$$\n\\begin{split}\\mathbf{R}(a,n)_{i,j} = \\begin{cases}\n            1 & \\text{if } i=j\\\\\n            a^{i-j}  & \\text{if } i>j\\\\\n            (a^\\star)^{j-i}  & \\text{if } j<i, j=1,\\dots,n\\\\\n          \\end{cases}\\end{split}\n$$\n\nwhere $|a|<1$ and $\\mathbf{R}\\in\\mathbb{C}^{n\\times n}$.\nInput\n\n- **a** (*[n_0, , n_k], tf.complex*)  A tensor of arbitrary rank whose elements\nhave an absolute value smaller than one.\n- **n** (*int*)  Number of dimensions of the output correlation matrices.\n- **dtype** (*tf.complex64, tf.complex128*)  The dtype of the output.\n\n\nOutput\n\n**R** (*[n_0, , n_k, n, n], tf.complex*)  A tensor of the same dtype as the input tensor $\\mathbf{a}$."
"### one_ring_corr_mat\n\n`sionna.channel.``one_ring_corr_mat`(*`phi_deg`*, *`num_ant`*, *`d_h``=``0.5`*, *`sigma_phi_deg``=``15`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/channel/utils.html#one_ring_corr_mat)\n\nGenerate covariance matrices from the one-ring model.\n\nThis function generates approximate covariance matrices for the\nso-called <cite>one-ring</cite> model (Eq. 2.24) [[BHS2017]](https://nvlabs.github.io/sionna/api/channel.wireless.html#bhs2017). A uniform\nlinear array (ULA) with uniform antenna spacing is assumed. The elements\nof the covariance matrices are computed as:\n\n$$\n\\mathbf{R}_{\\ell,m} =\n      \\exp\\left( j2\\pi d_\\text{H} (\\ell -m)\\sin(\\varphi) \\right)\n      \\exp\\left( -\\frac{\\sigma_\\varphi^2}{2}\n      \\left( 2\\pi d_\\text{H}(\\ell -m)\\cos(\\varphi) \\right)^2 \\right)\n$$\n\nfor $\\ell,m = 1,\\dots, M$, where $M$ is the number of antennas,\n$\\varphi$ is the angle of arrival, $d_\\text{H}$ is the antenna\nspacing in multiples of the wavelength,\nand $\\sigma^2_\\varphi$ is the angular standard deviation.\nInput\n\n- **phi_deg** (*[n_0, , n_k], tf.float*)  A tensor of arbitrary rank containing azimuth angles (deg) of arrival.\n- **num_ant** (*int*)  Number of antennas\n- **d_h** (*float*)  Antenna spacing in multiples of the wavelength. Defaults to 0.5.\n- **sigma_phi_deg** (*float*)  Angular standard deviation (deg). Defaults to 15 (deg). Values greater\nthan 15 should not be used as the approximation becomes invalid.\n- **dtype** (*tf.complex64, tf.complex128*)  The dtype of the output.\n\n\nOutput\n\n**R** ([n_0, , n_k, num_ant, nun_ant], <cite>dtype</cite>)  Tensor containing the covariance matrices of the desired dtype.\n\n\nReferences:\nTR38901([1](https://nvlabs.github.io/sionna/api/channel.wireless.html#id1),[2](https://nvlabs.github.io/sionna/api/channel.wireless.html#id2),[3](https://nvlabs.github.io/sionna/api/channel.wireless.html#id4),[4](https://nvlabs.github.io/sionna/api/channel.wireless.html#id5),[5](https://nvlabs.github.io/sionna/api/channel.wireless.html#id6),[6](https://nvlabs.github.io/sionna/api/channel.wireless.html#id7),[7](https://nvlabs.github.io/sionna/api/channel.wireless.html#id8),[8](https://nvlabs.github.io/sionna/api/channel.wireless.html#id11),[9](https://nvlabs.github.io/sionna/api/channel.wireless.html#id12),[10](https://nvlabs.github.io/sionna/api/channel.wireless.html#id13),[11](https://nvlabs.github.io/sionna/api/channel.wireless.html#id14),[12](https://nvlabs.github.io/sionna/api/channel.wireless.html#id15),[13](https://nvlabs.github.io/sionna/api/channel.wireless.html#id16),[14](https://nvlabs.github.io/sionna/api/channel.wireless.html#id17),[15](https://nvlabs.github.io/sionna/api/channel.wireless.html#id18),[16](https://nvlabs.github.io/sionna/api/channel.wireless.html#id19),[17](https://nvlabs.github.io/sionna/api/channel.wireless.html#id20),[18](https://nvlabs.github.io/sionna/api/channel.wireless.html#id21),[19](https://nvlabs.github.io/sionna/api/channel.wireless.html#id25),[20](https://nvlabs.github.io/sionna/api/channel.wireless.html#id26),[21](https://nvlabs.github.io/sionna/api/channel.wireless.html#id27))\n\n3GPP TR 38.901,\nStudy on channel model for frequencies from 0.5 to 100 GHz, Release 16.1\n\n[TS38141-1](https://nvlabs.github.io/sionna/api/channel.wireless.html#id10)\n\n3GPP TS 38.141-1\nBase Station (BS) conformance testing Part 1: Conducted conformance testing,\nRelease 17\n\n[Tse](https://nvlabs.github.io/sionna/api/channel.wireless.html#id3)\n\nD. Tse and P. Viswanath, Fundamentals of wireless communication,\nCambridge university press, 2005.\n\n[SoS](https://nvlabs.github.io/sionna/api/channel.wireless.html#id9)\n<ol class=\"upperalpha simple\" start=\"3\">\n- Xiao, Y. R. Zheng and N. C. Beaulieu, Novel Sum-of-Sinusoids Simulation Models for Rayleigh and Rician Fading Channels, in IEEE Transactions on Wireless Communications, vol. 5, no. 12, pp. 3667-3679, December 2006, doi: 10.1109/TWC.2006.256990.\n</ol>\n\n[MAL2018](https://nvlabs.github.io/sionna/api/channel.wireless.html#id28)\n\nRanjan K. Mallik,\nThe exponential correlation matrix: Eigen-analysis and\napplications, IEEE Trans. Wireless Commun., vol. 17, no. 7,\npp. 4690-4705, Jul. 2018.\n\n[BHS2017](https://nvlabs.github.io/sionna/api/channel.wireless.html#id29)\n\nEmil Bjrnson, Jakob Hoydis and Luca Sanguinetti (2017),\n[Massive MIMO Networks: Spectral, Energy, and Hardware Efficiency](https://massivemimobook.com),\nFoundations and Trends in Signal Processing:\nVol. 11, No. 3-4, pp 154655."
"# Configuration\n\nSionnas configuration API. It can be used to set global variables which can be used\nby all modules and functions.\n\n`class` `sionna.``Config`[`[source]`](../_modules/sionna/config.html#Config)\n\nThe Sionna configuration class.\n\nThis class is used to define global configuration variables\nthat can be accessed from all modules and functions. It\nis instantiated in `sionna.__init__()` and its properties can be\naccessed as `sionna.config.desired_property`.\n\n`property` `xla_compat`\n\nEnsure that functions execute in an XLA compatible way.\n\nNot all TensorFlow ops support the three execution modes for\nall dtypes: Eager, Graph, and Graph with XLA. For this reason,\nsome functions are implemented differently depending on the\nexecution mode. As it is currently impossible to programmatically\ndetermine if a function is executed in Graph or Graph with XLA mode,\nthe `xla_compat` property can be used to indicate which execution\nmode is desired. Note that most functions will work in all execution\nmodes independently of the value of this property.\n\nThis property can be used like this:\n```python\nimport sionna\nsionna.config.xla_compat=True\n@tf.function(jit_compile=True)\ndef func()\n    # Implementation\nfunc()\n```\n\nType\n\nbool"
"# Convolutional Codes\n\nThis module supports encoding of convolutional codes and provides layers for Viterbi [[Viterbi]](https://nvlabs.github.io/sionna/api/fec.conv.html#viterbi) and BCJR [[BCJR]](https://nvlabs.github.io/sionna/api/fec.conv.html#bcjr) decoding.\n\nWhile the [`ViterbiDecoder`](https://nvlabs.github.io/sionna/api/fec.conv.html#sionna.fec.conv.ViterbiDecoder) decoding algorithm produces maximum likelihood *sequence* estimates, the [`BCJRDecoder`](https://nvlabs.github.io/sionna/api/fec.conv.html#sionna.fec.conv.BCJRDecoder) produces the maximum a posterior (MAP) bit-estimates.\n\nThe following code snippet shows how to set up a rate-1/2, constraint-length-3 [`ConvEncoder`](https://nvlabs.github.io/sionna/api/fec.conv.html#sionna.fec.conv.ConvEncoder) in two alternate ways and a corresponding [`ViterbiDecoder`](https://nvlabs.github.io/sionna/api/fec.conv.html#sionna.fec.conv.ViterbiDecoder) or [`BCJRDecoder`](https://nvlabs.github.io/sionna/api/fec.conv.html#sionna.fec.conv.BCJRDecoder). You can find further examples in the [Channel Coding Tutorial Notebook](../examples/5G_Channel_Coding_Polar_vs_LDPC_Codes.html).\n\nSetting-up:\n```python\nencoder = ConvEncoder(rate=1/2, # rate of the desired code\n                      constraint_length=3) # constraint length of the code\n# or\nencoder = ConvEncoder(gen_poly=['101', '111']) # or polynomial can be used as input directly\n# --- Viterbi decoding ---\ndecoder = ViterbiDecoder(gen_poly=encoder.gen_poly) # polynomial used in encoder\n# or just reference to the encoder\ndecoder = ViterbiDecoder(encoder=encoder) # the code parameters are infered from the encoder\n# --- or BCJR decoding ---\ndecoder = BCJRDecoder(gen_poly=encoder.gen_poly, algorithm=\"map\") # polynomial used in encoder\n# or just reference to the encoder\ndecoder = BCJRDecoder(encoder=encoder, algorithm=\"map\") # the code parameters are infered from the encoder\n```\n\n\nRunning the encoder / decoder:"
"```python\n# --- encoder ---\n# u contains the information bits to be encoded and has shape [...,k].\n# c contains the convolutional encoded codewords and has shape [...,n].\nc = encoder(u)\n# --- decoder ---\n# y contains the de-mapped received codeword from channel and has shape [...,n].\n# u_hat contains the estimated information bits and has shape [...,k].\nu_hat = decoder(y)\n```"
"## Convolutional Encoding\n\n`class` `sionna.fec.conv.``ConvEncoder`(*`gen_poly``=``None`*, *`rate``=``1` `/` `2`*, *`constraint_length``=``3`*, *`rsc``=``False`*, *`terminate``=``False`*, *`output_dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/conv/encoding.html#ConvEncoder)\n\nEncodes an information binary tensor to a convolutional codeword. Currently,\nonly generator polynomials for codes of rate=1/n for n=2,3,4, are allowed.\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **gen_poly** (*tuple*)  Sequence of strings with each string being a 0,1 sequence. If\n<cite>None</cite>, `rate` and `constraint_length` must be provided.\n- **rate** (*float*)  Valid values are 1/3 and 0.5. Only required if `gen_poly` is\n<cite>None</cite>.\n- **constraint_length** (*int*)  Valid values are between 3 and 8 inclusive. Only required if\n`gen_poly` is <cite>None</cite>.\n- **rsc** (*boolean*)  Boolean flag indicating whether the Trellis generated is recursive\nsystematic or not. If <cite>True</cite>, the encoder is recursive-systematic.\nIn this case first polynomial in `gen_poly` is used as the\nfeedback polynomial. Defaults to <cite>False</cite>.\n- **terminate** (*boolean*)  Encoder is terminated to all zero state if <cite>True</cite>.\nIf terminated, the <cite>true</cite> rate of the code is slightly lower than\n`rate`.\n- **output_dtype** (*tf.DType*)  Defaults to <cite>tf.float32</cite>. Defines the output datatype of the layer.\n\n\nInput\n\n**inputs** (*[,k], tf.float32*)  2+D tensor containing the information bits where <cite>k</cite> is the\ninformation length\n\nOutput\n\n*[,k/rate], tf.float32*  2+D tensor containing the encoded codeword for the given input\ninformation tensor where <cite>rate</cite> is\n$\\frac{1}{\\textrm{len}\\left(\\textrm{gen_poly}\\right)}$\n(if `gen_poly` is provided).\n\n\n**Note**\n\nThe generator polynomials from [[Moon]](https://nvlabs.github.io/sionna/api/fec.conv.html#moon) are available for various\nrate and constraint lengths. To select them, use the `rate` and\n`constraint_length` arguments.\n\nIn addition, polynomials for any non-recursive convolutional encoder\ncan be given as input via `gen_poly` argument. Currently, only\npolynomials with rate=1/n are supported. When the `gen_poly` argument\nis given, the `rate` and `constraint_length` arguments are ignored.\n\nVarious notations are used in the literature to represent the generator\npolynomials for convolutional codes. In [[Moon]](https://nvlabs.github.io/sionna/api/fec.conv.html#moon), the octal digits\nformat is primarily used. In the octal format, the generator polynomial\n<cite>10011</cite> corresponds to 46. Another widely used format\nis decimal notation with MSB. In this notation, polynomial <cite>10011</cite>\ncorresponds to 19. For simplicity, the\n[`ConvEncoder`](https://nvlabs.github.io/sionna/api/fec.conv.html#sionna.fec.conv.ConvEncoder) only accepts the bit\nformat i.e. <cite>10011</cite> as `gen_poly` argument.\n\nAlso note that `constraint_length` and `memory` are two different\nterms often used to denote the strength of a convolutional code. In this\nsub-package, we use `constraint_length`. For example, the\npolynomial <cite>10011</cite> has a `constraint_length` of 5, however its\n`memory` is only 4.\n\nWhen `terminate` is <cite>True</cite>, the true rate of the convolutional\ncode is slightly lower than `rate`. It equals\n$\\frac{r*k}{k+\\mu}$ where <cite>r</cite> denotes `rate` and\n$\\mu$ is `constraint_length` - 1. For example when\n`terminate` is <cite>True</cite>, `k=100`,\n$\\mu=4$ and `rate` =0.5, true rate equals\n$\\frac{0.5*100}{104}=0.481$.\n\n`property` `coderate`\n\nRate of the code used in the encoder\n\n\n`property` `gen_poly`\n\nGenerator polynomial used by the encoder\n\n\n`property` `k`\n\nNumber of information bits per codeword\n\n\n`property` `n`\n\nNumber of codeword bits\n\n\n`property` `terminate`\n\nIndicates if the convolutional encoder is terminated\n\n\n`property` `trellis`\n\nTrellis object used during encoding"
"## Viterbi Decoding\n\n`class` `sionna.fec.conv.``ViterbiDecoder`(*`encoder``=``None`*, *`gen_poly``=``None`*, *`rate``=``1` `/` `2`*, *`constraint_length``=``3`*, *`rsc``=``False`*, *`terminate``=``False`*, *`method``=``'soft_llr'`*, *`output_dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/conv/decoding.html#ViterbiDecoder)\n\nImplements the Viterbi decoding algorithm [[Viterbi]](https://nvlabs.github.io/sionna/api/fec.conv.html#viterbi) that returns an\nestimate of the information bits for a noisy convolutional codeword.\nTakes as input either LLR values (<cite>method</cite> = <cite>soft_llr</cite>) or hard bit values\n(<cite>method</cite> = <cite>hard</cite>) and returns a hard decided estimation of the information\nbits.\n\nThe class inherits from the Keras layer class and can be used as layer in\na Keras model.\nParameters\n\n- **encoder** ([`ConvEncoder`](https://nvlabs.github.io/sionna/api/fec.conv.html#sionna.fec.conv.ConvEncoder))  If `encoder` is provided as input, the following input parameters\nare not required and will be ignored: `gen_poly`, `rate`,\n`constraint_length`, `rsc`, `terminate`. They will be inferred\nfrom the `encoder`  object itself. If `encoder` is <cite>None</cite>, the\nabove parameters must be provided explicitly.\n- **gen_poly** (*tuple*)  tuple of strings with each string being a 0, 1 sequence. If <cite>None</cite>,\n`rate` and `constraint_length` must be provided.\n- **rate** (*float*)  Valid values are 1/3 and 0.5. Only required if `gen_poly` is <cite>None</cite>.\n- **constraint_length** (*int*)  Valid values are between 3 and 8 inclusive. Only required if\n`gen_poly` is <cite>None</cite>.\n- **rsc** (*boolean*)  Boolean flag indicating whether the encoder is recursive-systematic for\ngiven generator polynomials.\n<cite>True</cite> indicates encoder is recursive-systematic.\n<cite>False</cite> indicates encoder is feed-forward non-systematic.\n- **terminate** (*boolean*)  Boolean flag indicating whether the codeword is terminated.\n<cite>True</cite> indicates codeword is terminated to all-zero state.\n<cite>False</cite> indicates codeword is not terminated.\n- **method** (*str*)  Valid values are <cite>soft_llr</cite> or <cite>hard</cite>. In computing path\nmetrics,\n<cite>soft_llr</cite> expects channel LLRs as input\n<cite>hard</cite> assumes a <cite>binary symmetric channel</cite> (BSC) with 0/1 values are\ninputs. In case of <cite>hard</cite>, <cite>inputs</cite> will be quantized to 0/1 values.\n- **output_dtype** (*tf.DType*)  Defaults to tf.float32. Defines the output datatype of the layer.\n\n\nInput\n\n**inputs** (*[,n], tf.float32*)  2+D tensor containing the (noisy) channel output symbols where <cite>n</cite>\ndenotes the codeword length\n\nOutput\n\n*[,rate*n], tf.float32*  2+D tensor containing the estimates of the information bit tensor\n\n\n**Note**\n\nA full implementation of the decoder rather than a windowed approach\nis used. For a given codeword of duration <cite>T</cite>, the path metric is\ncomputed from time <cite>0</cite> to <cite>T</cite> and the path with optimal metric at time\n<cite>T</cite> is selected. The optimal path is then traced back from <cite>T</cite> to <cite>0</cite>\nto output the estimate of the information bit vector used to encode.\nFor larger codewords, note that the current method is sub-optimal\nin terms of memory utilization and latency.\n\n`property` `coderate`\n\nRate of the code used in the encoder\n\n\n`property` `gen_poly`\n\nGenerator polynomial used by the encoder\n\n\n`property` `k`\n\nNumber of information bits per codeword\n\n\n`property` `n`\n\nNumber of codeword bits\n\n\n`property` `terminate`\n\nIndicates if the encoder is terminated during codeword generation\n\n\n`property` `trellis`\n\nTrellis object used during encoding"
"## BCJR Decoding\n\n`class` `sionna.fec.conv.``BCJRDecoder`(*`encoder``=``None`*, *`gen_poly``=``None`*, *`rate``=``1` `/` `2`*, *`constraint_length``=``3`*, *`rsc``=``False`*, *`terminate``=``False`*, *`hard_out``=``True`*, *`algorithm``=``'map'`*, *`output_dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/conv/decoding.html#BCJRDecoder)\n\nImplements the BCJR decoding algorithm [[BCJR]](https://nvlabs.github.io/sionna/api/fec.conv.html#bcjr) that returns an\nestimate of the information bits for a noisy convolutional codeword.\nTakes as input either channel LLRs or a tuple\n(channel LLRs, apriori LLRs). Returns an estimate of the information\nbits, either output LLRs ( `hard_out` = <cite>False</cite>) or hard decoded\nbits ( `hard_out` = <cite>True</cite>), respectively.\n\nThe class inherits from the Keras layer class and can be used as layer in\na Keras model.\nParameters\n\n- **encoder** ([`ConvEncoder`](https://nvlabs.github.io/sionna/api/fec.conv.html#sionna.fec.conv.ConvEncoder))  If `encoder` is provided as input, the following input parameters\nare not required and will be ignored: `gen_poly`, `rate`,\n`constraint_length`, `rsc`, `terminate`. They will be inferred\nfrom the `encoder`  object itself. If `encoder` is <cite>None</cite>, the\nabove parameters must be provided explicitly.\n- **gen_poly** (*tuple*)  tuple of strings with each string being a 0, 1 sequence. If <cite>None</cite>,\n`rate` and `constraint_length` must be provided.\n- **rate** (*float*)  Valid values are 1/3 and 1/2. Only required if `gen_poly` is <cite>None</cite>.\n- **constraint_length** (*int*)  Valid values are between 3 and 8 inclusive. Only required if\n`gen_poly` is <cite>None</cite>.\n- **rsc** (*boolean*)  Boolean flag indicating whether the encoder is recursive-systematic for\ngiven generator polynomials. <cite>True</cite> indicates encoder is\nrecursive-systematic. <cite>False</cite> indicates encoder is feed-forward non-systematic.\n- **terminate** (*boolean*)  Boolean flag indicating whether the codeword is terminated.\n<cite>True</cite> indicates codeword is terminated to all-zero state.\n<cite>False</cite> indicates codeword is not terminated.\n- **hard_out** (*boolean*)  Boolean flag indicating whether to output hard or soft decisions on\nthe decoded information vector.\n<cite>True</cite> implies a hard-decoded information vector of 0/1s as output.\n<cite>False</cite> implies output is decoded LLRs of the information.\n- **algorithm** (*str*)  Defaults to <cite>map</cite>. Indicates the implemented BCJR algorithm,\nwhere <cite>map</cite> denotes the exact MAP algorithm, <cite>log</cite> indicates the\nexact MAP implementation, but in log-domain, and\n<cite>maxlog</cite> indicates the approximated MAP implementation in log-domain,\nwhere $\\log(e^{a}+e^{b}) \\sim \\max(a,b)$.\n- **output_dtype** (*tf.DType*)  Defaults to tf.float32. Defines the output datatype of the layer.\n\n\nInput\n\n- **llr_ch or (llr_ch, llr_a)**  Tensor or Tuple:\n- **llr_ch** (*[,n], tf.float32*)  2+D tensor containing the (noisy) channel\nLLRs, where <cite>n</cite> denotes the codeword length\n- **llr_a** (*[,k], tf.float32*)  2+D tensor containing the a priori information of each information bit.\nImplicitly assumed to be 0 if only `llr_ch` is provided.\n\n\nOutput\n\n*tf.float32*  2+D tensor of shape <cite>[,coderate*n]</cite> containing the estimates of the\ninformation bit tensor\n\n\n`property` `coderate`\n\nRate of the code used in the encoder\n\n\n`property` `gen_poly`\n\nGenerator polynomial used by the encoder\n\n\n`property` `k`\n\nNumber of information bits per codeword\n\n\n`property` `n`\n\nNumber of codeword bits\n\n\n`property` `terminate`\n\nIndicates if the encoder is terminated during codeword generation\n\n\n`property` `trellis`\n\nTrellis object used during encoding"
"### Trellis\n\n`sionna.fec.conv.utils.``Trellis`(*`gen_poly`*, *`rsc``=``True`*)[`[source]`](../_modules/sionna/fec/conv/utils.html#Trellis)\n\nTrellis structure for a given generator polynomial. Defines\nstate transitions and output symbols (and bits) for each current\nstate and input.\nParameters\n\n- **gen_poly** (*tuple*)  Sequence of strings with each string being a 0,1 sequence.\nIf <cite>None</cite>, `rate` and `constraint_length` must be provided. If\n<cite>rsc</cite> is True, then first polynomial will act as denominator for\nthe remaining generator polynomials. For e.g., `rsc` = <cite>True</cite> and\n`gen_poly` = (<cite>111</cite>, <cite>101</cite>, <cite>011</cite>) implies generator matrix equals\n$G(D)=[\\frac{1+D^2}{1+D+D^2}, \\frac{D+D^2}{1+D+D^2}]$.\nCurrently Trellis is only implemented for generator matrices of\nsize $\\frac{1}{n}$.\n- **rsc** (*boolean*)  Boolean flag indicating whether the Trellis is recursive systematic\nor not. If <cite>True</cite>, the encoder is recursive systematic in which\ncase first polynomial in `gen_poly` is used as the feedback\npolynomial. Default is <cite>True</cite>."
"### polynomial_selector\n\n`sionna.fec.conv.utils.``polynomial_selector`(*`rate`*, *`constraint_length`*)[`[source]`](../_modules/sionna/fec/conv/utils.html#polynomial_selector)\n\nReturns generator polynomials for given code parameters. The\npolynomials are chosen from [[Moon]](https://nvlabs.github.io/sionna/api/fec.conv.html#moon) which are tabulated by searching\nfor polynomials with best free distances for a given rate and\nconstraint length.\nInput\n\n- **rate** (*float*)  Desired rate of the code.\nCurrently, only r=1/3 and r=1/2 are supported.\n- **constraint_length** (*int*)  Desired constraint length of the encoder\n\n\nOutput\n\n*tuple*  Tuple of strings with each string being a 0,1 sequence where\neach polynomial is represented in binary form.\n\n\nReferences:\nViterbi([1](https://nvlabs.github.io/sionna/api/fec.conv.html#id1),[2](https://nvlabs.github.io/sionna/api/fec.conv.html#id5))\n\nA. Viterbi, Error bounds for convolutional codes and an\nasymptotically optimum decoding algorithm, IEEE Trans. Inf. Theory, 1967.\n\nBCJR([1](https://nvlabs.github.io/sionna/api/fec.conv.html#id2),[2](https://nvlabs.github.io/sionna/api/fec.conv.html#id6))\n\nL. Bahl, J. Cocke, F. Jelinek, und J. Raviv, Optimal Decoding\nof Linear Codes for Minimizing Symbol Error Rate, IEEE Trans. Inf.\nTheory, March 1974.\n\nMoon([1](https://nvlabs.github.io/sionna/api/fec.conv.html#id3),[2](https://nvlabs.github.io/sionna/api/fec.conv.html#id4),[3](https://nvlabs.github.io/sionna/api/fec.conv.html#id7))\n\nTodd. K. Moon, Error Correction Coding: Mathematical\nMethods and Algorithms, John Wiley & Sons, 2020."
"# Cyclic Redundancy Check (CRC)\n\nA cyclic redundancy check adds parity bits to detect transmission errors.\nThe following code snippets show how to add CRC parity bits to a bit sequence\nand how to verify that the check is valid.\n\nFirst, we need to create instances of [`CRCEncoder`](https://nvlabs.github.io/sionna/api/fec.crc.html#sionna.fec.crc.CRCEncoder) and [`CRCDecoder`](https://nvlabs.github.io/sionna/api/fec.crc.html#sionna.fec.crc.CRCDecoder):\n```python\nencoder = CRCEncoder(crc_degree=\"CRC24A\") # the crc_degree denotes the number of added parity bits and is taken from the 3GPP 5G NR standard.\ndecoder = CRCDecoder(crc_encoder=encoder) # the decoder must be associated to a specific encoder\n```\n\n\nWe can now run the CRC encoder and test if the CRC holds:\n```python\n# u contains the information bits to be encoded and has shape [...,k].\n# c contains u and the CRC parity bits. It has shape [...,k+k_crc].\nc = encoder(u)\n# u_hat contains the information bits without parity bits and has shape [...,k].\n# crc_valid contains a boolean per codeword that indicates if the CRC validation was successful.\n# It has shape [...,1].\nu_hat, crc_valid = decoder(c)\n```"
"## CRCEncoder\n\n`class` `sionna.fec.crc.``CRCEncoder`(*`crc_degree`*, *`output_dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/crc.html#CRCEncoder)\n\nAdds cyclic redundancy check to input sequence.\n\nThe CRC polynomials from Sec. 5.1 in [[3GPPTS38212_CRC]](https://nvlabs.github.io/sionna/api/fec.crc.html#gppts38212-crc) are available:\n<cite>{CRC24A, CRC24B, CRC24C, CRC16, CRC11, CRC6}</cite>.\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **crc_degree** (*str*)  Defining the CRC polynomial to be used. Can be any value from\n<cite>{CRC24A, CRC24B, CRC24C, CRC16, CRC11, CRC6}</cite>.\n- **dtype** (*tf.DType*)  Defaults to <cite>tf.float32</cite>. Defines the output dtype.\n\n\nInput\n\n**inputs** (*[,k], tf.float32*)  2+D tensor of arbitrary shape where the last dimension is\n<cite>[,k]</cite>. Must have at least rank two.\n\nOutput\n\n**x_crc** (*[,k+crc_degree], tf.float32*)  2+D tensor containing CRC encoded bits of same shape as\n`inputs` except the last dimension changes to\n<cite>[,k+crc_degree]</cite>.\n\nRaises\n\n- **AssertionError**  If `crc_degree` is not <cite>str</cite>.\n- **ValueError**  If requested CRC polynomial is not available in [[3GPPTS38212_CRC]](https://nvlabs.github.io/sionna/api/fec.crc.html#gppts38212-crc).\n- **InvalidArgumentError**  When rank(`inputs`)<2.\n\n\n**Note**\n\nFor performance enhancements, we implement a generator-matrix based\nimplementation for fixed <cite>k</cite> instead of the more common shift\nregister-based operations. Thus, the encoder need to trigger an\n(internal) rebuild if <cite>k</cite> changes.\n\n`property` `crc_degree`\n\nCRC degree as string.\n\n\n`property` `crc_length`\n\nLength of CRC. Equals number of CRC parity bits.\n\n\n`property` `crc_pol`\n\nCRC polynomial in binary representation.\n\n\n`property` `k`\n\nNumber of information bits per codeword.\n\n\n`property` `n`\n\nNumber of codeword bits."
"## CRCDecoder\n\n`class` `sionna.fec.crc.``CRCDecoder`(*`crc_encoder`*, *`dtype``=``None`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/crc.html#CRCDecoder)\n\nAllows cyclic redundancy check verification and removes parity-bits.\n\nThe CRC polynomials from Sec. 5.1 in [[3GPPTS38212_CRC]](https://nvlabs.github.io/sionna/api/fec.crc.html#gppts38212-crc) are available:\n<cite>{CRC24A, CRC24B, CRC24C, CRC16, CRC11, CRC6}</cite>.\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **crc_encoder** ()  An instance of [`CRCEncoder`](https://nvlabs.github.io/sionna/api/fec.crc.html#sionna.fec.crc.CRCEncoder) to which the\nCRCDecoder is associated.\n- **dtype** (*tf.DType*)  Defaults to <cite>None</cite>. Defines the datatype for internal calculations\nand the output dtype. If no explicit dtype is provided the dtype\nfrom the associated interleaver is used.\n\n\nInput\n\n**inputs** (*[,k+crc_degree], tf.float32*)  2+D Tensor containing the CRC encoded bits (i.e., the last\n<cite>crc_degree</cite> bits are parity bits). Must have at least rank two.\n\nOutput\n\n- **(x, crc_valid)**  Tuple:\n- **x** (*[,k], tf.float32*)  2+D tensor containing the information bit sequence without CRC\nparity bits.\n- **crc_valid** (*[,1], tf.bool*)  2+D tensor containing the result of the CRC per codeword.\n\n\nRaises\n\n- **AssertionError**  If `crc_encoder` is not <cite>CRCEncoder</cite>.\n- **InvalidArgumentError**  When rank(`x`)<2.\n\n\n`property` `crc_degree`\n\nCRC degree as string.\n\n\n`property` `encoder`\n\nCRC Encoder used for internal validation.\n\n\nReferences:\n3GPPTS38212_CRC([1](https://nvlabs.github.io/sionna/api/fec.crc.html#id1),[2](https://nvlabs.github.io/sionna/api/fec.crc.html#id2),[3](https://nvlabs.github.io/sionna/api/fec.crc.html#id3))\n\nETSI 3GPP TS 38.212 5G NR Multiplexing and channel\ncoding, v.16.5.0, 2021-03."
"# Interleaving\n\nThe interleaver module allows to permute tensors with either pseudo-random permutations or by row/column swapping.\n\nTo simplify distributed graph execution (e.g., by running interleaver and deinterleaver in a different sub-graph/device), the interleavers are implemented stateless. Thus, the internal seed cannot be updated on runtime and does not change after the initialization. However, if required, an explicit random seed can be passed as additional input to the interleaver/deinterleaver pair when calling the layer.\n\nThe following code snippet shows how to setup and use an instance of the interleaver:\n```python\n# set-up system\ninterleaver = RandomInterleaver(seed=1234, # an explicit seed can be provided\n                                keep_batch_constant=False, # if True, all samples in the batch are permuted with the same pattern\n                                axis=-1) # axis which shall be permuted\ndeinterleaver = Deinterleaver(interleaver=interleaver) # connect interleaver and deinterleaver\n# --- simplified usage with fixed seed ---\n# c has arbitrary shape (rank>=2)\nc_int = interleaver(c)\n# call deinterleaver to reconstruct the original order\nc_deint = deinterleaver(c_int)\n# --- advanced usage ---\n# provide explicit seed if a new random seed should be used for each call\ns = tf.random.uniform((), minval=0, maxval=12345678, dtype=tf.int32)\nc_int = interleaver([c, s])\nc_deint = deinterleaver([c_int, s])\n```"
"### RowColumnInterleaver\n\n`class` `sionna.fec.interleaving.``RowColumnInterleaver`(*`row_depth`*, *`axis``=``-` `1`*, *`inverse``=``False`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/interleaving.html#RowColumnInterleaver)\n\nInterleaves a sequence of inputs via row/column swapping.\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **row_depth** (*int*)  The row depth, i.e., how many values per row can be stored.\n- **axis** (*int*)  The dimension that should be interleaved. First dimension\n(<cite>axis=0</cite>) is not allowed.\n- **inverse** (*bool*)  A boolean defaults to False. If True, the inverse permutation is\nperformed.\n- **dtype** (*tf.DType*)  Defaults to <cite>tf.float32</cite>. Defines the datatype for internal\ncalculations and the output dtype.\n\n\nInput\n\n**inputs** (*tf.DType*)  2+D tensor of arbitrary shape and arbitrary dtype. Must have at\nleast rank two.\n\nOutput\n\n*tf.DType*  2+D tensor of same shape and dtype as `inputs`.\n\nRaises\n\n- **AssertionError**  If `axis` is not an integer.\n- **AssertionError**  If `row_depth` is not an integer.\n- **AssertionError**  If `axis` > number of input dimensions.\n\n\n**Note**\n\nIf the sequence length is not a multiple of `row_depth`, additional\nfiller bits are used for the last row that will be removed internally.\nHowever, for the last positions the interleaving distance may be\nslightly degraded.\n\nTo permute the batch dimension, expand_dims at <cite>axis=0</cite>, interleave and\nremove new dimension.\n\n`property` `axis`\n\nAxis to be permuted.\n\n\n`call_inverse`(*`inputs`*)[`[source]`](../_modules/sionna/fec/interleaving.html#RowColumnInterleaver.call_inverse)\n\nImplements deinterleaver function corresponding to call().\nInput\n\n**inputs** (*tf.DType*)  2+D tensor of arbitrary shape and arbitrary dtype. Must have at\nleast rank two.\n\nOutput\n\n*tf.DType*  2+D tensor of same shape and dtype as `inputs`.\n\n\n`property` `keep_state`\n\nRow-column interleaver always uses same internal state.\n\n\n`property` `perm_seq`\n\nPermutation sequence.\n\n\n`property` `perm_seq_inv`\n\nInverse permutation sequence.\n\n\n`property` `row_depth`\n\nRow depth of the row-column interleaver."
"### RandomInterleaver\n\n`class` `sionna.fec.interleaving.``RandomInterleaver`(*`seed``=``None`*, *`keep_batch_constant``=``True`*, *`inverse``=``False`*, *`keep_state``=``True`*, *`axis``=``-` `1`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/interleaving.html#RandomInterleaver)\n\nRandom interleaver permuting a sequence of input symbols.\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **seed** (*int*)  Integer defining the random seed used if option `keep_state` is\nTrue.\n- **keep_batch_constant** (*bool*)  Defaults to True. If set to True each sample in the batch uses the\nsame permutation. Otherwise, unique permutations per batch sample\nare generate (slower).\n- **inverse** (*bool*)  A boolean defaults to False. If True, the inverse permutation is\nperformed.\n- **keep_state** (*bool*)  A boolean defaults to True. If True, the permutation is fixed for\nmultiple calls (defined by `seed` attribute).\n- **axis** (*int*)  Defaults to <cite>-1</cite>. The dimension that should be interleaved.\nFirst dimension (<cite>axis=0</cite>) is not allowed.\n- **dtype** (*tf.DType*)  Defaults to <cite>tf.float32</cite>. Defines the datatype for internal\ncalculations and the output dtype.\n\n\nInput\n\n- **(x, seed)**  Either Tuple `(x,` `seed)` or `x` only (no tuple) if the internal\nseed should be used:\n- **x** (*tf.DType*)  2+D tensor of arbitrary shape and dtype.\n- **seed** (*int*)  An integer defining the state of the random number\ngenerator. If explicitly given, the global internal seed is\nreplaced by this seed. Can be used to realize random\ninterleaver/deinterleaver pairs (call with same random seed).\n\n\nOutput\n\n*tf.DType*  2+D tensor of same shape and dtype as the input `x`.\n\nRaises\n\n- **AssertionError**  If `axis` is not <cite>int</cite>.\n- **AssertionError**  If `seed` is not <cite>None</cite> or <cite>int</cite>.\n- **AssertionError**  If `axis` > number of input dimensions.\n- **AssertionError**  If `inverse` is not bool.\n- **AssertionError**  If `keep_state` is not bool.\n- **AssertionError**  If `keep_batch_constant` is not bool.\n- **InvalidArgumentError**  When rank(`x`)<2.\n\n\n**Note**\n\nTo permute the batch dimension, expand_dims at `axis=0`, interleave\nand remove new dimension.\n\nThe interleaver layer is stateless, i.e., the seed is either random\nduring each call or must be explicitly provided during init/call.\nThis simplifies XLA/graph execution.\n\nThis is NOT the 5G interleaver sequence.\n\n`property` `axis`\n\nAxis to be permuted.\n\n\n`call_inverse`(*`inputs`*)[`[source]`](../_modules/sionna/fec/interleaving.html#RandomInterleaver.call_inverse)\n\nImplements deinterleaver function corresponding to call().\nInput\n\n- **(x, seed)**  Either Tuple `(x,` `seed)` or `x` only (no tuple) if the internal\nseed should be used:\n- **x** (*tf.DType*)  2+D tensor of arbitrary shape and dtype.\n- **seed** (*int*)  An integer defining the state of the random number\ngenerator. If explicitly given, the global internal seed is\nreplaced by this seed. Can be used to realize random\ninterleaver/deinterleaver pairs (call with same random seed).\n\n\nOutput\n\n*tf.DType*  2+D tensor of same shape and dtype as the input `x`.\n\nRaises\n\n- **InvalidArgumentError**  When rank(`x`)<2.\n- **ValueError**  If `keep_state` is False and no explicit seed is provided.\n\n\n**Note**\n\nIn case of inverse interleaving (e.g., at the receiver),\n`keep_state` should be True as otherwise a new permutation is\ngenerated and the output is not equal to the original sequence.\nAlternatively, an explicit seed must be provided as function\nargument.\n\n\n`find_s_min`(*`seed`*, *`seq_length`*, *`s_min_stop``=``0`*)[`[source]`](../_modules/sionna/fec/interleaving.html#RandomInterleaver.find_s_min)\n\nFind $S$ parameter such that $\\pi(i)-\\pi(j)>S$ for all\n$i-j<S$. This can be used to find optimized interleaver patterns.\n\n`s_min_stop` is an additional stopping condition, i.e., stop if\ncurrent $S$ is already smaller than `s_min_stop`.\n\nPlease note that this is a Numpy utility function and usually not part\nof the graph.\nInput\n\n- **seed** (*int*)  seed to draw random permutation that shall be analyzed.\n- **seq_length** (*int*)  length of permutation sequence to be analyzed.\n- **s_min_stop** (*int*)  Defaults to 0. Enables early stop if already current s_min< `s_min_stop` .\n\n\nOutput\n\n*float*  The S-parameter for the given `seed`.\n\n\n`property` `keep_state`\n\nGenerate new random seed per call.\n\n\n`property` `seed`\n\nSeed to generate random sequence."
"### Turbo3GPPInterleaver\n\n`class` `sionna.fec.interleaving.``Turbo3GPPInterleaver`(*`inverse``=``False`*, *`axis``=``-` `1`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/interleaving.html#Turbo3GPPInterleaver)\n\nInterleaver as used in the 3GPP Turbo codes [[3GPPTS36212_I]](https://nvlabs.github.io/sionna/api/fec.interleaving.html#gppts36212-i) and, thus,\nthe maximum length is given as 6144 elements (only for the dimension as\nspecific by `axis`).\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **inverse** (*bool*)  A boolean defaults to False. If True, the inverse permutation is\nperformed.\n- **axis** (*int*)  Defaults to <cite>-1</cite>. The dimension that should be interleaved.\nFirst dimension (<cite>axis=0</cite>) is not allowed.\n- **dtype** (*tf.DType*)  Defaults to <cite>tf.float32</cite>. Defines the datatype for internal\ncalculations and the output dtype.\n\n\nInput\n\n**x** (*tf.DType*)  2+D tensor of arbitrary shape and dtype.\n\nOutput\n\n*tf.DType*  2+D tensor of same shape and dtype as the input `x`.\n\nRaises\n\n- **AssertionError**  If `axis` is not <cite>int</cite>.\n- **AssertionError**  If `axis` > number of input dimensions.\n- **AssertionError**  If `inverse` is not bool.\n- **InvalidArgumentError**  When rank(`x`)<2.\n\n\n**Note**\n\nNote that this implementation slightly deviates from the 3GPP\nstandard [[3GPPTS36212_I]](https://nvlabs.github.io/sionna/api/fec.interleaving.html#gppts36212-i) in a sense that zero-padding is introduced\nfor cases when the exact interleaver length is not supported by the\nstandard.\n\n`property` `axis`\n\nAxis to be permuted.\n\n\n`call_inverse`(*`inputs`*)[`[source]`](../_modules/sionna/fec/interleaving.html#Turbo3GPPInterleaver.call_inverse)\n\nImplements deinterleaver function corresponding to call().\nInput\n\n**x** (*tf.DType*)  2+D tensor of arbitrary shape and dtype.\n\nOutput\n\n*tf.DType*  2+D tensor of same shape and dtype as the input `x`.\n\nRaises\n\n**InvalidArgumentError**  When rank(`x`)<2.\n\n\n`find_s_min`(*`frame_size`*, *`s_min_stop``=``0`*)[`[source]`](../_modules/sionna/fec/interleaving.html#Turbo3GPPInterleaver.find_s_min)\n\nFind $S$ parameter such that $\\pi(i)-\\pi(j)>S$ for all\n$i-j<S$. This can be used to find optimized interleaver patterns.\n\n`s_min_stop` is an additional stopping condition, i.e., stop if\ncurrent $S$ is already smaller than `s_min_stop`.\n\nPlease note that this is a Numpy utility function and usually not part\nof the graph.\nInput\n\n- **frame_size** (*int*)  length of interleaver.\n- **s_min_stop** (*int*)  Defaults to 0. Enables early stop if already current\ns_min<`s_min_stop`.\n\n\nOutput\n\n*float*  The S-parameter for the given `frame_size`."
"## Deinterleaver\n\n`class` `sionna.fec.interleaving.``Deinterleaver`(*`interleaver`*, *`dtype``=``None`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/interleaving.html#Deinterleaver)\n\nDeinterleaver that reverts the interleaver for a given input sequence.\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **interleaver** (*Interleaver*)  Associated Interleaver which shall be deinterleaved by this layer.\nCan be either\n[`RandomInterleaver`](https://nvlabs.github.io/sionna/api/fec.interleaving.html#sionna.fec.interleaving.RandomInterleaver) or\n[`RowColumnInterleaver`](https://nvlabs.github.io/sionna/api/fec.interleaving.html#sionna.fec.interleaving.RowColumnInterleaver).\n- **dtype** (*None** or **tf.DType*)  Defaults to <cite>None</cite>. Defines the datatype for internal calculations\nand the output dtype. If no explicit dtype is provided the dtype\nfrom the associated interleaver is used.\n\n\nInput\n\n- **(x, seed)**  Either Tuple `(x,` `seed)` or `x` only (no tuple) if the internal\nseed should be used:\n- **x** (*tf.DType*)  2+D tensor of arbitrary shape.\n- **seed** (*int*)  An integer defining the state of the random number\ngenerator. If explicitly given, the global internal seed is\nreplaced by this seed. Can be used to realize random\ninterleaver/deinterleaver pairs (call with same random seed).\n\n\nOutput\n\n*tf.DType*  2+D tensor of same shape and dtype as the input `x`.\n\nRaises\n\n**AssertionError**  If `interleaver` is not a valid instance of Interleaver.\n\n\n**Note**\n\nThis layer provides a wrapper of the inverse interleaver function.\n\n`property` `interleaver`\n\nAssociated interleaver instance.\n\n\nReferences:\n<blockquote>\n<div>\n3GPPTS36212_I([1](https://nvlabs.github.io/sionna/api/fec.interleaving.html#id1),[2](https://nvlabs.github.io/sionna/api/fec.interleaving.html#id2))\n\nETSI 3GPP TS 36.212 Evolved Universal Terrestrial\nRadio Access (EUTRA); Multiplexing and channel coding, v.15.3.0, 2018-09.\n\n\n</blockquote></blockquote>\n</blockquote></blockquote>"
"# Linear Codes\n\nThis package provides generic support for binary linear block codes.\n\nFor encoding, a universal [`LinearEncoder`](https://nvlabs.github.io/sionna/api/fec.linear.html#sionna.fec.linear.LinearEncoder) is available and can be initialized with either a generator or parity-check matrix. The matrix must be binary and of full rank.\n\nFor decoding, [`OSDecoder`](https://nvlabs.github.io/sionna/api/fec.linear.html#sionna.fec.linear.OSDecoder) implements the\nordered-statistics decoding (OSD) algorithm [[Fossorier]](https://nvlabs.github.io/sionna/api/fec.linear.html#fossorier) which provides close to\nmaximum-likelihood (ML) estimates for a sufficiently large order of the decoder.\nPlease note that OSD is highly complex and not feasible for all code lengths.\n\n*Remark:* As this package provides support for generic encoding and decoding\n(including Polar and LDPC codes), it cannot rely on code specific\noptimizations. To benefit from an optimized decoder and keep the complexity as low as possible, please use the code specific enc-/decoders whenever available.\n\nThe encoder and decoder can be set up as follows:\n```python\npcm, k, n, coderate = load_parity_check_examples(pcm_id=1) # load example code\n# or directly import an external parity-check matrix in alist format\nal = load_alist(path=filename)\npcm, k, n, coderate = alist2mat(al)\n# encoder can be directly initialized with the parity-check matrix\nencoder = LinearEncoder(enc_mat=pcm, is_pcm=True)\n# decoder can be initialized with generator or parity-check matrix\ndecoder = OSDecoder(pcm, t=4, is_pcm=True) # t is the OSD order\n# or instantiated from a specific encoder\ndecoder = OSDecoder(encoder=encoder, t=4) # t is the OSD order\n```\n\n\nWe can now run the encoder and decoder:\n```python\n# u contains the information bits to be encoded and has shape [...,k].\n# c contains codeword bits and has shape [...,n]\nc = encoder(u)\n# after transmission LLRs must be calculated with a demapper\n# let's assume the resulting llr_ch has shape [...,n]\nc_hat = decoder(llr_ch)\n```"
"### LinearEncoder\n\n`class` `sionna.fec.linear.``LinearEncoder`(*`enc_mat`*, *`is_pcm``=``False`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/linear/encoding.html#LinearEncoder)\n\nLinear binary encoder for a given generator or parity-check matrix `enc_mat`.\n\nIf `is_pcm` is True, `enc_mat` is interpreted as parity-check\nmatrix and internally converted to a corresponding generator matrix.\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **enc_mat** (*[**k**, **n**] or **[**n-k**, **n**]**, **ndarray*)  Binary generator matrix of shape <cite>[k, n]</cite>. If `is_pcm` is\nTrue, `enc_mat` is interpreted as parity-check matrix of shape\n<cite>[n-k, n]</cite>.\n- **dtype** (*tf.DType*)  Defaults to <cite>tf.float32</cite>. Defines the datatype for the output dtype.\n\n\nInput\n\n**inputs** (*[,k], tf.float32*)  2+D tensor containing information bits.\n\nOutput\n\n*[,n], tf.float32*  2+D tensor containing codewords with same shape as inputs, except the\nlast dimension changes to <cite>[,n]</cite>.\n\nRaises\n\n**AssertionError**  If the encoding matrix is not a valid binary 2-D matrix.\n\n\n**Note**\n\nIf `is_pcm` is True, this layer uses\n[`pcm2gm`](fec.utils.html#sionna.fec.utils.pcm2gm) to find the generator matrix for\nencoding. Please note that this imposes a few constraints on the\nprovided parity-check matrix such as full rank and it must be binary.\n\nNote that this encoder is generic for all binary linear block codes\nand, thus, cannot implement any code specific optimizations. As a\nresult, the encoding complexity is $O(k^2)$. Please consider code\nspecific encoders such as the\n[`Polar5GEncoder`](fec.polar.html#sionna.fec.polar.encoding.Polar5GEncoder) or\n[`LDPC5GEncoder`](fec.ldpc.html#sionna.fec.ldpc.encoding.LDPC5GEncoder) for an improved\nencoding performance.\n\n`property` `coderate`\n\nCoderate of the code.\n\n\n`property` `gm`\n\nGenerator matrix used for encoding.\n\n\n`property` `k`\n\nNumber of information bits per codeword.\n\n\n`property` `n`\n\nCodeword length."
"### AllZeroEncoder\n\n`class` `sionna.fec.linear.``AllZeroEncoder`(*`k`*, *`n`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/linear/encoding.html#AllZeroEncoder)\n\nDummy encoder that always outputs the all-zero codeword of length `n`.\n\nNote that this encoder is a dummy encoder and does NOT perform real\nencoding!\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **k** (*int*)  Defining the number of information bit per codeword.\n- **n** (*int*)  Defining the desired codeword length.\n- **dtype** (*tf.DType*)  Defaults to <cite>tf.float32</cite>. Defines the datatype for internal\ncalculations and the output dtype.\n\n\nInput\n\n**inputs** (*[,k], tf.float32*)  2+D tensor containing arbitrary values (not used!).\n\nOutput\n\n*[,n], tf.float32*  2+D tensor containing all-zero codewords.\n\nRaises\n\n**AssertionError**  `k` and `n` must be positive integers and `k` must be smaller\n    (or equal) than `n`.\n\n\n**Note**\n\nAs the all-zero codeword is part of any linear code, it is often used\nto simulate BER curves of arbitrary (LDPC) codes without the need of\nhaving access to the actual generator matrix. However, this <cite>all-zero\ncodeword trick</cite> requires symmetric channels (such as BPSK), otherwise\nscrambling is required (cf. [[Pfister]](fec.ldpc.html#pfister) for further details).\n\nThis encoder is a dummy encoder that is needed for some all-zero\ncodeword simulations independent of the input. It does NOT perform\nreal encoding although the information bits are taken as input.\nThis is just to ensure compatibility with other encoding layers.\n\n`property` `coderate`\n\nCoderate of the LDPC code.\n\n\n`property` `k`\n\nNumber of information bits per codeword.\n\n\n`property` `n`\n\nCodeword length."
"### OSDecoder\n\n`class` `sionna.fec.linear.``OSDecoder`(*`enc_mat``=``None`*, *`t``=``0`*, *`is_pcm``=``False`*, *`encoder``=``None`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/linear/decoding.html#OSDecoder)\n\nOrdered statistics decoding (OSD) for binary, linear block codes.\n\nThis layer implements the OSD algorithm as proposed in [[Fossorier]](https://nvlabs.github.io/sionna/api/fec.linear.html#fossorier) and,\nthereby, approximates maximum likelihood decoding for a sufficiently large\norder $t$. The algorithm works for arbitrary linear block codes, but\nhas a high computational complexity for long codes.\n\nThe algorithm consists of the following steps:\n<blockquote>\n<div>\n1. Sort LLRs according to their reliability and apply the same column\npermutation to the generator matrix.\n\n2. Bring the permuted generator matrix into its systematic form\n(so-called *most-reliable basis*).\n\n3. Hard-decide and re-encode the $k$ most reliable bits and\ndiscard the remaining $n-k$ received positions.\n\n4. Generate all possible error patterns up to $t$ errors in the\n$k$ most reliable positions find the most likely codeword within\nthese candidates.\n</blockquote>\n\nThis implementation of the OSD algorithm uses the LLR-based distance metric\nfrom [[Stimming_LLR_OSD]](https://nvlabs.github.io/sionna/api/fec.linear.html#stimming-llr-osd) which simplifies the handling of higher-order\nmodulation schemes.\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **enc_mat** (*[**k**, **n**] or **[**n-k**, **n**]**, **ndarray*)  Binary generator matrix of shape <cite>[k, n]</cite>. If `is_pcm` is\nTrue, `enc_mat` is interpreted as parity-check matrix of shape\n<cite>[n-k, n]</cite>.\n- **t** (*int*)  Order of the OSD algorithm\n- **is_pcm** (*bool*)  Defaults to False. If True, `enc_mat` is interpreted as parity-check\nmatrix.\n- **encoder** (*Layer*)  Keras layer that implements a FEC encoder.\nIf not None, `enc_mat` will be ignored and the code as specified by he\nencoder is used to initialize OSD.\n- **dtype** (*tf.DType*)  Defaults to <cite>tf.float32</cite>. Defines the datatype for the output dtype.\n\n\nInput\n\n**llrs_ch** (*[,n], tf.float32*)  2+D tensor containing the channel logits/llr values.\n\nOutput\n\n*[,n], tf.float32*  2+D Tensor of same shape as `llrs_ch` containing\nbinary hard-decisions of all codeword bits.\n\n\n**Note**\n\nOS decoding is of high complexity and is only feasible for small values of\n$t$ as ${n \\choose t}$ patterns must be evaluated. The\nadvantage of OSD is that it works for arbitrary linear block codes and\nprovides an estimate of the expected ML performance for sufficiently large\n$t$. However, for some code families, more efficient decoding\nalgorithms with close to ML performance exist which can exploit certain\ncode specific properties. Examples of such decoders are the\n[`ViterbiDecoder`](fec.conv.html#sionna.fec.conv.ViterbiDecoder) algorithm for  convolutional codes\nor the [`PolarSCLDecoder`](fec.polar.html#sionna.fec.polar.decoding.PolarSCLDecoder) for Polar codes\n(for a sufficiently large list size).\n\nIt is recommended to run the decoder in XLA mode as it\nsignificantly reduces the memory complexity.\n\n`property` `gm`\n\nGenerator matrix of the code\n\n\n`property` `k`\n\nNumber of information bits per codeword\n\n\n`property` `n`\n\nCodeword length\n\n\n`property` `t`\n\nOrder of the OSD algorithm\n\n\nReferences:\nFossorier([1](https://nvlabs.github.io/sionna/api/fec.linear.html#id1),[2](https://nvlabs.github.io/sionna/api/fec.linear.html#id3))\n\nM. Fossorier, S. Lin, Soft-Decision Decoding of Linear\nBlock Codes Based on Ordered Statistics, IEEE Trans. Inf.\nTheory, vol. 41, no.5, 1995.\n\n[Stimming_LLR_OSD](https://nvlabs.github.io/sionna/api/fec.linear.html#id4)\n\nA.Balatsoukas-Stimming, M. Parizi, A. Burg,\nLLR-Based Successive Cancellation List Decoding\nof Polar Codes. IEEE Trans Signal Processing, 2015."
"# Low-Density Parity-Check (LDPC)\n\nThe low-density parity-check (LDPC) code module supports 5G compliant LDPC codes and allows iterative belief propagation (BP) decoding.\nFurther, the module supports rate-matching for 5G and provides a generic linear encoder.\n\nThe following code snippets show how to setup and run a rate-matched 5G compliant LDPC encoder and a corresponding belief propagation (BP) decoder.\n\nFirst, we need to create instances of [`LDPC5GEncoder`](https://nvlabs.github.io/sionna/api/fec.ldpc.html#sionna.fec.ldpc.encoding.LDPC5GEncoder) and [`LDPC5GDecoder`](https://nvlabs.github.io/sionna/api/fec.ldpc.html#sionna.fec.ldpc.decoding.LDPC5GDecoder):\n```python\nencoder = LDPC5GEncoder(k                 = 100, # number of information bits (input)\n                        n                 = 200) # number of codeword bits (output)\n\ndecoder = LDPC5GDecoder(encoder           = encoder,\n                        num_iter          = 20, # number of BP iterations\n                        return_infobits   = True)\n```\n\n\nNow, the encoder and decoder can be used by:\n```python\n# --- encoder ---\n# u contains the information bits to be encoded and has shape [...,k].\n# c contains the polar encoded codewords and has shape [...,n].\nc = encoder(u)\n# --- decoder ---\n# llr contains the log-likelihood ratios from the demapper and has shape [...,n].\n# u_hat contains the estimated information bits and has shape [...,k].\nu_hat = decoder(llr)\n```"
"### LDPC5GEncoder\n\n`class` `sionna.fec.ldpc.encoding.``LDPC5GEncoder`(*`k`*, *`n`*, *`num_bits_per_symbol``=``None`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/ldpc/encoding.html#LDPC5GEncoder)\n\n5G NR LDPC Encoder following the 3GPP NR Initiative [[3GPPTS38212_LDPC]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#gppts38212-ldpc)\nincluding rate-matching.\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **k** (*int*)  Defining the number of information bit per codeword.\n- **n** (*int*)  Defining the desired codeword length.\n- **num_bits_per_symbol** (*int** or **None*)  Defining the number of bits per QAM symbol. If this parameter is\nexplicitly provided, the codeword will be interleaved after\nrate-matching as specified in Sec. 5.4.2.2 in [[3GPPTS38212_LDPC]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#gppts38212-ldpc).\n- **dtype** (*tf.DType*)  Defaults to <cite>tf.float32</cite>. Defines the output datatype of the layer\n(internal precision remains <cite>tf.uint8</cite>).\n\n\nInput\n\n**inputs** (*[,k], tf.float32*)  2+D tensor containing the information bits to be\nencoded.\n\nOutput\n\n*[,n], tf.float32*  2+D tensor of same shape as inputs besides last dimension has\nchanged to <cite>n</cite> containing the encoded codeword bits.\n\nAttributes\n\n- **k** (*int*)  Defining the number of information bit per codeword.\n- **n** (*int*)  Defining the desired codeword length.\n- **coderate** (*float*)  Defining the coderate r= `k` / `n`.\n- **n_ldpc** (*int*)  An integer defining the total codeword length (before\npunturing) of the lifted parity-check matrix.\n- **k_ldpc** (*int*)  An integer defining the total information bit length\n(before zero removal) of the lifted parity-check matrix. Gap to\n`k` must be filled with so-called filler bits.\n- **num_bits_per_symbol** (*int or None.*)  Defining the number of bits per QAM symbol. If this parameter is\nexplicitly provided, the codeword will be interleaved after\nrate-matching as specified in Sec. 5.4.2.2 in [[3GPPTS38212_LDPC]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#gppts38212-ldpc).\n- **out_int** (*[n], ndarray of int*)  Defining the rate-matching output interleaver sequence.\n- **out_int_inv** (*[n], ndarray of int*)  Defining the inverse rate-matching output interleaver sequence.\n- **_check_input** (*bool*)  A boolean that indicates whether the input vector\nduring call of the layer should be checked for consistency (i.e.,\nbinary).\n- **_bg** (*str*)  Denoting the selected basegraph (either <cite>bg1</cite> or <cite>bg2</cite>).\n- **_z** (*int*)  Denoting the lifting factor.\n- **_i_ls** (*int*)  Defining which version of the basegraph to load.\nCan take values between 0 and 7.\n- **_k_b** (*int*)  Defining the number of <cite>information bit columns</cite> in the\nbasegraph. Determined by the code design procedure in\n[[3GPPTS38212_LDPC]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#gppts38212-ldpc).\n- **_bm** (*ndarray*)  An ndarray defining the basegraph.\n- **_pcm** (*sp.sparse.csr_matrix*)  A sparse matrix of shape <cite>[k_ldpc-n_ldpc, n_ldpc]</cite>\ncontaining the sparse parity-check matrix.\n\n\nRaises\n\n- **AssertionError**  If `k` is not <cite>int</cite>.\n- **AssertionError**  If `n` is not <cite>int</cite>.\n- **ValueError**  If `code_length` is not supported.\n- **ValueError**  If <cite>dtype</cite> is not supported.\n- **ValueError**  If `inputs` contains other values than <cite>0</cite> or <cite>1</cite>.\n- **InvalidArgumentError**  When rank(`inputs`)<2.\n- **InvalidArgumentError**  When shape of last dim is not `k`.\n\n\n**Note**\n\nAs specified in [[3GPPTS38212_LDPC]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#gppts38212-ldpc), the encoder also performs\npuncturing and shortening. Thus, the corresponding decoder needs to\n<cite>invert</cite> these operations, i.e., must be compatible with the 5G\nencoding scheme.\n\n`property` `coderate`\n\nCoderate of the LDPC code after rate-matching.\n\n\n`generate_out_int`(*`n`*, *`num_bits_per_symbol`*)[`[source]`](../_modules/sionna/fec/ldpc/encoding.html#LDPC5GEncoder.generate_out_int)\n\nGenerates LDPC output interleaver sequence as defined in\nSec 5.4.2.2 in [[3GPPTS38212_LDPC]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#gppts38212-ldpc).\nParameters\n\n- **n** (*int*)  Desired output sequence length.\n- **num_bits_per_symbol** (*int*)  Number of symbols per QAM symbol, i.e., the modulation order.\n- **Outputs**\n- **-------**\n- **(****perm_seq**  Tuple:\n- **perm_seq_inv****)**  Tuple:\n- **perm_seq** (*ndarray of length n*)  Containing the permuted indices.\n- **perm_seq_inv** (*ndarray of length n*)  Containing the inverse permuted indices.\n\n\n**Note**\n\nThe interleaver pattern depends on the modulation order and helps to\nreduce dependencies in bit-interleaved coded modulation (BICM) schemes.\n\n\n`property` `k`\n\nNumber of input information bits.\n\n\n`property` `k_ldpc`\n\nNumber of LDPC information bits after rate-matching.\n\n\n`property` `n`\n\nNumber of output codeword bits.\n\n\n`property` `n_ldpc`\n\nNumber of LDPC codeword bits before rate-matching.\n\n\n`property` `num_bits_per_symbol`\n\nModulation order used for the rate-matching output interleaver.\n\n\n`property` `out_int`\n\nOutput interleaver sequence as defined in 5.4.2.2.\n\n\n`property` `out_int_inv`\n\nInverse output interleaver sequence as defined in 5.4.2.2.\n\n\n`property` `pcm`\n\nParity-check matrix for given code parameters.\n\n\n`property` `z`\n\nLifting factor of the basegraph."
"### LDPCBPDecoder\n\n`class` `sionna.fec.ldpc.decoding.``LDPCBPDecoder`(*`pcm`*, *`trainable``=``False`*, *`cn_type``=``'boxplus-phi'`*, *`hard_out``=``True`*, *`track_exit``=``False`*, *`num_iter``=``20`*, *`stateful``=``False`*, *`output_dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/ldpc/decoding.html#LDPCBPDecoder)\n\nIterative belief propagation decoder for low-density parity-check (LDPC)\ncodes and other <cite>codes on graphs</cite>.\n\nThis class defines a generic belief propagation decoder for decoding\nwith arbitrary parity-check matrices. It can be used to iteratively\nestimate/recover the transmitted codeword (or information bits) based on the\nLLR-values of the received noisy codeword observation.\n\nThe decoder implements the flooding SPA algorithm [[Ryan]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#ryan), i.e., all nodes\nare updated in a parallel fashion. Different check node update functions are\navailable\n<ol class=\"arabic\">\n- <cite>boxplus</cite>\n\n$$\ny_{j \\to i} = 2 \\operatorname{tanh}^{-1} \\left( \\prod_{i' \\in \\mathcal{N}_(j) \\setminus i} \\operatorname{tanh} \\left( \\frac{x_{i' \\to j}}{2} \\right) \\right)\n$$\n\n- <cite>boxplus-phi</cite>\n\n$$\ny_{j \\to i} = \\alpha_{j \\to i} \\cdot \\phi \\left( \\sum_{i' \\in \\mathcal{N}_(j) \\setminus i} \\phi \\left( |x_{i' \\to j}|\\right) \\right)\n$$\n\nwith $\\phi(x)=-\\operatorname{log}(\\operatorname{tanh} \\left(\\frac{x}{2}) \\right)$\n\n- <cite>minsum</cite>\n\n$$\n\\qquad y_{j \\to i} = \\alpha_{j \\to i} \\cdot {min}_{i' \\in \\mathcal{N}_(j) \\setminus i} \\left(|x_{i' \\to j}|\\right)\n$$\n\n</ol>\n\nwhere $y_{j \\to i}$ denotes the message from check node (CN) *j* to\nvariable node (VN) *i* and $x_{i \\to j}$ from VN *i* to CN *j*,\nrespectively. Further, $\\mathcal{N}_(j)$ denotes all indices of\nconnected VNs to CN *j* and\n\n$$\n\\alpha_{j \\to i} = \\prod_{i' \\in \\mathcal{N}_(j) \\setminus i} \\operatorname{sign}(x_{i' \\to j})\n$$\n\nis the sign of the outgoing message. For further details we refer to\n[[Ryan]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#ryan).\n\nNote that for full 5G 3GPP NR compatibility, the correct puncturing and\nshortening patterns must be applied (cf. [[Richardson]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#richardson) for details), this\ncan be done by `LDPC5GEncoder` and\n[`LDPC5GDecoder`](https://nvlabs.github.io/sionna/api/fec.ldpc.html#sionna.fec.ldpc.decoding.LDPC5GDecoder), respectively.\n\nIf required, the decoder can be made trainable and is fully differentiable\nby following the concept of <cite>weighted BP</cite> [[Nachmani]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#nachmani) as shown in Fig. 1\nleading to\n\n$$\ny_{j \\to i} = 2 \\operatorname{tanh}^{-1} \\left( \\prod_{i' \\in \\mathcal{N}_(j) \\setminus i} \\operatorname{tanh} \\left( \\frac{\\textcolor{red}{w_{i' \\to j}} \\cdot x_{i' \\to j}}{2} \\right) \\right)\n$$\n\nwhere $w_{i \\to j}$ denotes the trainable weight of message $x_{i \\to j}$.\nPlease note that the training of some check node types may be not supported.\n ig. 5 Fig. 1: Weighted BP as proposed in [[Nachmani]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#nachmani).\n\nFor numerical stability, the decoder applies LLR clipping of\n+/- 20 to the input LLRs.\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **pcm** (*ndarray*)  An ndarray of shape <cite>[n-k, n]</cite> defining the parity-check matrix\nconsisting only of <cite>0</cite> or <cite>1</cite> entries. Can be also of type <cite>scipy.\nsparse.csr_matrix</cite> or <cite>scipy.sparse.csc_matrix</cite>.\n- **trainable** (*bool*)  Defaults to False. If True, every outgoing variable node message is\nscaled with a trainable scalar.\n- **cn_type** (*str*)  A string defaults to boxplus-phi. One of\n{<cite>boxplus</cite>, <cite>boxplus-phi</cite>, <cite>minsum</cite>} where\nboxplus implements the single-parity-check APP decoding rule.\nboxplus-phi implements the numerical more stable version of\nboxplus [[Ryan]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#ryan).\nminsum implements the min-approximation of the CN\nupdate rule [[Ryan]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#ryan).\n- **hard_out** (*bool*)  Defaults to True. If True, the decoder provides hard-decided\ncodeword bits instead of soft-values.\n- **track_exit** (*bool*)  Defaults to False. If True, the decoder tracks EXIT\ncharacteristics. Note that this requires the all-zero\nCW as input.\n- **num_iter** (*int*)  Defining the number of decoder iteration (no early stopping used at\nthe moment!).\n- **stateful** (*bool*)  Defaults to False. If True, the internal VN messages `msg_vn`\nfrom the last decoding iteration are returned, and `msg_vn` or\n<cite>None</cite> needs to be given as a second input when calling the decoder.\nThis is required for iterative demapping and decoding.\n- **output_dtype** (*tf.DType*)  Defaults to tf.float32. Defines the output datatype of the layer\n(internal precision remains tf.float32).\n\n\nInput\n\n- **llrs_ch or (llrs_ch, msg_vn)**  Tensor or Tuple (only required if `stateful` is True):\n- **llrs_ch** (*[,n], tf.float32*)  2+D tensor containing the channel logits/llr values.\n- **msg_vn** (*None or RaggedTensor, tf.float32*)  Ragged tensor of VN messages.\nRequired only if `stateful` is True.\n\n\nOutput\n\n- *[,n], tf.float32*  2+D Tensor of same shape as `inputs` containing\nbit-wise soft-estimates (or hard-decided bit-values) of all\ncodeword bits.\n- *RaggedTensor, tf.float32:*  Tensor of VN messages.\nReturned only if `stateful` is set to True.\n\n\nAttributes\n\n- **pcm** (*ndarray*)  An ndarray of shape <cite>[n-k, n]</cite> defining the parity-check matrix\nconsisting only of <cite>0</cite> or <cite>1</cite> entries. Can be also of type <cite>scipy.\nsparse.csr_matrix</cite> or <cite>scipy.sparse.csc_matrix</cite>.\n- **num_cns** (*int*)  Defining the number of check nodes.\n- **num_vns** (*int*)  Defining the number of variable nodes.\n- **num_edges** (*int*)  Defining the total number of edges.\n- **trainable** (*bool*)  If True, the decoder uses trainable weights.\n- **_atanh_clip_value** (*float*)  Defining the internal clipping value before the atanh is applied\n(relates to the CN update).\n- **_cn_type** (*str*)  Defining the CN update function type.\n- **_cn_update**  A function defining the CN update.\n- **_hard_out** (*bool*)  If True, the decoder outputs hard-decided bits.\n- **_cn_con** (*ndarray*)  An ndarray of shape <cite>[num_edges]</cite> defining all edges from check\nnode perspective.\n- **_vn_con** (*ndarray*)  An ndarray of shape <cite>[num_edges]</cite> defining all edges from variable\nnode perspective.\n- **_vn_mask_tf** (*tf.float32*)  A ragged Tensor of shape <cite>[num_vns, None]</cite> defining the incoming\nmessage indices per VN. The second dimension is ragged and depends\non the node degree.\n- **_cn_mask_tf** (*tf.float32*)  A ragged Tensor of shape <cite>[num_cns, None]</cite> defining the incoming\nmessage indices per CN. The second dimension is ragged and depends\non the node degree.\n- **_ind_cn** (*ndarray*)  An ndarray of shape <cite>[num_edges]</cite> defining the permutation index to\nrearrange messages from variable into check node perspective.\n- **_ind_cn_inv** (*ndarray*)  An ndarray of shape <cite>[num_edges]</cite> defining the permutation index to\nrearrange messages from check into variable node perspective.\n- **_vn_row_splits** (*ndarray*)  An ndarray of shape <cite>[num_vns+1]</cite> defining the row split positions\nof a 1D vector consisting of all edges messages. Used to build a\nragged Tensor of incoming VN messages.\n- **_cn_row_splits** (*ndarray*)  An ndarray of shape <cite>[num_cns+1]</cite> defining the row split positions\nof a 1D vector consisting of all edges messages. Used to build a\nragged Tensor of incoming CN messages.\n- **_edge_weights** (*tf.float32*)  A Tensor of shape <cite>[num_edges]</cite> defining a (trainable) weight per\noutgoing VN message.\n\n\nRaises\n\n- **ValueError**  If the shape of `pcm` is invalid or contains other values than\n    <cite>0</cite> or <cite>1</cite> or dtype is not <cite>tf.float32</cite>.\n- **ValueError**  If `num_iter` is not an integer greater (or equal) <cite>0</cite>.\n- **ValueError**  If `output_dtype` is not\n    {tf.float16, tf.float32, tf.float64}.\n- **ValueError**  If `inputs` is not of shape <cite>[batch_size, n]</cite>.\n- **InvalidArgumentError**  When rank(`inputs`)<2."
"### Note\n\nAs decoding input logits\n$\\operatorname{log} \\frac{p(x=1)}{p(x=0)}$ are\nassumed for compatibility with the learning framework, but internally\nlog-likelihood ratios (LLRs) with definition $\\operatorname{log} \\frac{p(x=0)}{p(x=1)}$ are used.\n\nThe decoder is not (particularly) optimized for quasi-cyclic (QC) LDPC\ncodes and, thus, supports arbitrary parity-check matrices.\n\nThe decoder is implemented by using ragged Tensors [[TF_ragged]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#tf-ragged) to\naccount for arbitrary node degrees. To avoid a performance degradation\ncaused by a severe indexing overhead, the batch-dimension is shifted to\nthe last dimension during decoding.\n\nIf the decoder is made trainable [[Nachmani]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#nachmani), for performance\nimprovements only variable to check node messages are scaled as the VN\noperation is linear and, thus, would not increase the expressive power\nof the weights.\n\n`property` `edge_weights`\n\nTrainable weights of the BP decoder.\n\n\n`property` `has_weights`\n\nIndicates if decoder has trainable weights.\n\n\n`property` `ie_c`\n\nExtrinsic mutual information at check node.\n\n\n`property` `ie_v`\n\nExtrinsic mutual information at variable node.\n\n\n`property` `llr_max`\n\nMax LLR value used for internal calculations and rate-matching.\n\n\n`property` `num_cns`\n\nNumber of check nodes.\n\n\n`property` `num_edges`\n\nNumber of edges in decoding graph.\n\n\n`property` `num_iter`\n\nNumber of decoding iterations.\n\n\n`property` `num_vns`\n\nNumber of variable nodes.\n\n\n`property` `output_dtype`\n\nOutput dtype of decoder.\n\n\n`property` `pcm`\n\nParity-check matrix of LDPC code.\n\n\n`show_weights`(*`size``=``7`*)[`[source]`](../_modules/sionna/fec/ldpc/decoding.html#LDPCBPDecoder.show_weights)\n\nShow histogram of trainable weights.\nInput\n\n**size** (*float*)  Figure size of the matplotlib figure."
"### LDPC5GDecoder\n\n`class` `sionna.fec.ldpc.decoding.``LDPC5GDecoder`(*`encoder`*, *`trainable``=``False`*, *`cn_type``=``'boxplus-phi'`*, *`hard_out``=``True`*, *`track_exit``=``False`*, *`return_infobits``=``True`*, *`prune_pcm``=``True`*, *`num_iter``=``20`*, *`stateful``=``False`*, *`output_dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/ldpc/decoding.html#LDPC5GDecoder)\n\n(Iterative) belief propagation decoder for 5G NR LDPC codes.\n\nInherits from [`LDPCBPDecoder`](https://nvlabs.github.io/sionna/api/fec.ldpc.html#sionna.fec.ldpc.decoding.LDPCBPDecoder) and provides\na wrapper for 5G compatibility, i.e., automatically handles puncturing and\nshortening according to [[3GPPTS38212_LDPC]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#gppts38212-ldpc).\n\nNote that for full 5G 3GPP NR compatibility, the correct puncturing and\nshortening patterns must be applied and, thus, the encoder object is\nrequired as input.\n\nIf required the decoder can be made trainable and is differentiable\n(the training of some check node types may be not supported) following the\nconcept of weighted BP [[Nachmani]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#nachmani).\n\nFor numerical stability, the decoder applies LLR clipping of\n+/- 20 to the input LLRs.\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **encoder** ()  An instance of [`LDPC5GEncoder`](https://nvlabs.github.io/sionna/api/fec.ldpc.html#sionna.fec.ldpc.encoding.LDPC5GEncoder)\ncontaining the correct code parameters.\n- **trainable** (*bool*)  Defaults to False. If True, every outgoing variable node message is\nscaled with a trainable scalar.\n- **cn_type** (*str*)  A string defaults to boxplus-phi. One of\n{<cite>boxplus</cite>, <cite>boxplus-phi</cite>, <cite>minsum</cite>} where\nboxplus implements the single-parity-check APP decoding rule.\nboxplus-phi implements the numerical more stable version of\nboxplus [[Ryan]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#ryan).\nminsum implements the min-approximation of the CN\nupdate rule [[Ryan]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#ryan).\n- **hard_out** (*bool*)  Defaults to True. If True, the decoder provides hard-decided\ncodeword bits instead of soft-values.\n- **track_exit** (*bool*)  Defaults to False. If True, the decoder tracks EXIT characteristics.\nNote that this requires the all-zero CW as input.\n- **return_infobits** (*bool*)  Defaults to True. If True, only the <cite>k</cite> info bits (soft or\nhard-decided) are returned. Otherwise all <cite>n</cite> positions are\nreturned.\n- **prune_pcm** (*bool*)  Defaults to True. If True, all punctured degree-1 VNs and\nconnected check nodes are removed from the decoding graph (see\n[[Cammerer]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#cammerer) for details). Besides numerical differences, this should\nyield the same decoding result but improved the decoding throughput\nand reduces the memory footprint.\n- **num_iter** (*int*)  Defining the number of decoder iteration (no early stopping used at\nthe moment!).\n- **stateful** (*bool*)  Defaults to False. If True, the internal VN messages `msg_vn`\nfrom the last decoding iteration are returned, and `msg_vn` or\n<cite>None</cite> needs to be given as a second input when calling the decoder.\nThis is required for iterative demapping and decoding.\n- **output_dtype** (*tf.DType*)  Defaults to tf.float32. Defines the output datatype of the layer\n(internal precision remains tf.float32).\n\n\nInput\n\n- **llrs_ch or (llrs_ch, msg_vn)**  Tensor or Tuple (only required if `stateful` is True):\n- **llrs_ch** (*[,n], tf.float32*)  2+D tensor containing the channel logits/llr values.\n- **msg_vn** (*None or RaggedTensor, tf.float32*)  Ragged tensor of VN messages.\nRequired only if `stateful` is True.\n\n\nOutput\n\n- *[,n] or [,k], tf.float32*  2+D Tensor of same shape as `inputs` containing\nbit-wise soft-estimates (or hard-decided bit-values) of all\ncodeword bits. If `return_infobits` is True, only the <cite>k</cite>\ninformation bits are returned.\n- *RaggedTensor, tf.float32:*  Tensor of VN messages.\nReturned only if `stateful` is set to True.\n\n\nRaises\n\n- **ValueError**  If the shape of `pcm` is invalid or contains other\n    values than <cite>0</cite> or <cite>1</cite>.\n- **AssertionError**  If `trainable` is not <cite>bool</cite>.\n- **AssertionError**  If `track_exit` is not <cite>bool</cite>.\n- **AssertionError**  If `hard_out` is not <cite>bool</cite>.\n- **AssertionError**  If `return_infobits` is not <cite>bool</cite>.\n- **AssertionError**  If `encoder` is not an instance of\n    [`LDPC5GEncoder`](https://nvlabs.github.io/sionna/api/fec.ldpc.html#sionna.fec.ldpc.encoding.LDPC5GEncoder).\n- **ValueError**  If `output_dtype` is not {tf.float16, tf.float32, tf.\n    float64}.\n- **ValueError**  If `inputs` is not of shape <cite>[batch_size, n]</cite>.\n- **ValueError**  If `num_iter` is not an integer greater (or equal) <cite>0</cite>.\n- **InvalidArgumentError**  When rank(`inputs`)<2.\n\n\n**Note**\n\nAs decoding input logits\n$\\operatorname{log} \\frac{p(x=1)}{p(x=0)}$ are assumed for\ncompatibility with the learning framework, but\ninternally llrs with definition\n$\\operatorname{log} \\frac{p(x=0)}{p(x=1)}$ are used.\n\nThe decoder is not (particularly) optimized for Quasi-cyclic (QC) LDPC\ncodes and, thus, supports arbitrary parity-check matrices.\n\nThe decoder is implemented by using ragged Tensors [[TF_ragged]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#tf-ragged) to\naccount for arbitrary node degrees. To avoid a performance degradation\ncaused by a severe indexing overhead, the batch-dimension is shifted to\nthe last dimension during decoding.\n\nIf the decoder is made trainable [[Nachmani]](https://nvlabs.github.io/sionna/api/fec.ldpc.html#nachmani), for performance\nimprovements only variable to check node messages are scaled as the VN\noperation is linear and, thus, would not increase the expressive power\nof the weights.\n\n`property` `encoder`\n\nLDPC Encoder used for rate-matching/recovery.\n\n\nReferences:\nPfister\n\nJ. Hou, P. H. Siegel, L. B. Milstein, and H. D. Pfister,\nCapacity-approaching bandwidth-efficient coded modulation schemes\nbased on low-density parity-check codes, IEEE Trans. Inf. Theory,\nSep. 2003.\n\n3GPPTS38212_LDPC([1](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id1),[2](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id2),[3](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id3),[4](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id4),[5](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id5),[6](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id6),[7](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id16))\n\nETSI 3GPP TS 38.212 5G NR Multiplexing and channel\ncoding, v.16.5.0, 2021-03.\n\nRyan([1](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id7),[2](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id8),[3](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id12),[4](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id13),[5](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id18),[6](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id19))\n\nW. Ryan, An Introduction to LDPC codes, CRC Handbook for\nCoding and Signal Processing for Recording Systems, 2004.\n\nTF_ragged([1](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id14),[2](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id21))\n\n[https://www.tensorflow.org/guide/ragged_tensor](https://www.tensorflow.org/guide/ragged_tensor)\n\n[Richardson](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id9)\n\nT. Richardson and S. Kudekar. Design of low-density\nparity-check codes for 5G new radio, IEEE Communications\nMagazine 56.3, 2018.\n\nNachmani([1](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id10),[2](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id11),[3](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id15),[4](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id17),[5](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id22))\n\nE. Nachmani, Y. Beery, and D. Burshtein. Learning to\ndecode linear codes using deep learning, IEEE Annual Allerton\nConference on Communication, Control, and Computing (Allerton),\n2016.\n\n[Cammerer](https://nvlabs.github.io/sionna/api/fec.ldpc.html#id20)\n\nS. Cammerer, M. Ebada, A. Elkelesh, and S. ten Brink.\nSparse graphs for belief propagation decoding of polar codes.\nIEEE International Symposium on Information Theory (ISIT), 2018."
"# Polar Codes\n\nThe Polar code module supports 5G-compliant Polar codes and includes successive cancellation (SC), successive cancellation list (SCL), and belief propagation (BP) decoding.\n\nThe module supports rate-matching and CRC-aided decoding.\nFurther, Reed-Muller (RM) code design is available and can be used in combination with the Polar encoding/decoding algorithms.\n\nThe following code snippets show how to setup and run a rate-matched 5G compliant Polar encoder and a corresponding successive cancellation list (SCL) decoder.\n\nFirst, we need to create instances of [`Polar5GEncoder`](https://nvlabs.github.io/sionna/api/fec.polar.html#sionna.fec.polar.encoding.Polar5GEncoder) and [`Polar5GDecoder`](https://nvlabs.github.io/sionna/api/fec.polar.html#sionna.fec.polar.decoding.Polar5GDecoder):\n```python\nencoder = Polar5GEncoder(k          = 100, # number of information bits (input)\n                         n          = 200) # number of codeword bits (output)\n\ndecoder = Polar5GDecoder(encoder    = encoder, # connect the Polar decoder to the encoder\n                         dec_type   = \"SCL\", # can be also \"SC\" or \"BP\"\n                         list_size  = 8)\n```\n\n\nNow, the encoder and decoder can be used by:\n```python\n# --- encoder ---\n# u contains the information bits to be encoded and has shape [...,k].\n# c contains the polar encoded codewords and has shape [...,n].\nc = encoder(u)\n# --- decoder ---\n# llr contains the log-likelihood ratios from the demapper and has shape [...,n].\n# u_hat contains the estimated information bits and has shape [...,k].\nu_hat = decoder(llr)\n```"
"### Polar5GEncoder\n\n`class` `sionna.fec.polar.encoding.``Polar5GEncoder`(*`k`*, *`n`*, *`verbose``=``False`*, *`channel_type``=``'uplink'`*, *`dtype``=``tf.float32`*)[`[source]`](../_modules/sionna/fec/polar/encoding.html#Polar5GEncoder)\n\n5G compliant Polar encoder including rate-matching following [[3GPPTS38212]](https://nvlabs.github.io/sionna/api/fec.polar.html#gppts38212)\nfor the uplink scenario (<cite>UCI</cite>) and downlink scenario (<cite>DCI</cite>).\n\nThis layer performs polar encoding for `k` information bits and\nrate-matching such that the codeword lengths is `n`. This includes the CRC\nconcatenation and the interleaving as defined in [[3GPPTS38212]](https://nvlabs.github.io/sionna/api/fec.polar.html#gppts38212).\n\nNote: <cite>block segmentation</cite> is currently not supported (<cite>I_seq=False</cite>).\n\nWe follow the basic structure from Fig. 6 in [[Bioglio_Design]](https://nvlabs.github.io/sionna/api/fec.polar.html#bioglio-design).\n ig. 6 Fig. 1: Implemented 5G Polar encoding chain following Fig. 6 in\n[[Bioglio_Design]](https://nvlabs.github.io/sionna/api/fec.polar.html#bioglio-design) for the uplink (<cite>I_BIL</cite> = <cite>True</cite>) and the downlink\n(<cite>I_IL</cite> = <cite>True</cite>) scenario without <cite>block segmentation</cite>.\n\nFor further details, we refer to [[3GPPTS38212]](https://nvlabs.github.io/sionna/api/fec.polar.html#gppts38212), [[Bioglio_Design]](https://nvlabs.github.io/sionna/api/fec.polar.html#bioglio-design) and\n[[Hui_ChannelCoding]](https://nvlabs.github.io/sionna/api/fec.polar.html#hui-channelcoding).\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model. Further, the class inherits from PolarEncoder.\nParameters\n\n- **k** (*int*)  Defining the number of information bit per codeword.\n- **n** (*int*)  Defining the codeword length.\n- **channel_type** (*str*)  Defaults to uplink. Can be uplink or downlink.\n- **verbose** (*bool*)  Defaults to False. If True, rate-matching parameters will be\nprinted.\n- **dtype** (*tf.DType*)  Defaults to tf.float32. Defines the output datatype of the layer\n(internal precision remains tf.uint8).\n\n\nInput\n\n**inputs** (*[,k], tf.float32*)  2+D tensor containing the information bits to be encoded.\n\nOutput\n\n*[,n], tf.float32*  2+D tensor containing the codeword bits.\n\nRaises\n\n- **AssertionError**  `k` and `n` must be positive integers and `k` must be smaller\n    (or equal) than `n`.\n- **AssertionError**  If `n` and `k` are invalid code parameters (see [[3GPPTS38212]](https://nvlabs.github.io/sionna/api/fec.polar.html#gppts38212)).\n- **AssertionError**  If `verbose` is not <cite>bool</cite>.\n- **ValueError**  If `dtype` is not supported.\n\n\n**Note**\n\nThe encoder supports the <cite>uplink</cite> Polar coding (<cite>UCI</cite>) scheme from\n[[3GPPTS38212]](https://nvlabs.github.io/sionna/api/fec.polar.html#gppts38212) and the <cite>downlink</cite> Polar coding (<cite>DCI</cite>) [[3GPPTS38212]](https://nvlabs.github.io/sionna/api/fec.polar.html#gppts38212),\nrespectively.\n\nFor <cite>12 <= k <= 19</cite> the 3 additional parity bits as defined in\n[[3GPPTS38212]](https://nvlabs.github.io/sionna/api/fec.polar.html#gppts38212) are not implemented as it would also require a\nmodified decoding procedure to materialize the potential gains.\n\n<cite>Code segmentation</cite> is currently not supported and, thus, `n` is\nlimited to a maximum length of 1088 codeword bits.\n\nFor the downlink scenario, the input length is limited to <cite>k <= 140</cite>\ninformation bits due to the limited input bit interleaver size\n[[3GPPTS38212]](https://nvlabs.github.io/sionna/api/fec.polar.html#gppts38212).\n\nFor simplicity, the implementation does not exactly re-implement the\n<cite>DCI</cite> scheme from [[3GPPTS38212]](https://nvlabs.github.io/sionna/api/fec.polar.html#gppts38212). This implementation neglects the\n<cite>all-one</cite> initialization of the CRC shift register and the scrambling of the CRC parity bits with the <cite>RNTI</cite>.\n\n`channel_interleaver`(*`c`*)[`[source]`](../_modules/sionna/fec/polar/encoding.html#Polar5GEncoder.channel_interleaver)\n\nTriangular interleaver following Sec. 5.4.1.3 in [[3GPPTS38212]](https://nvlabs.github.io/sionna/api/fec.polar.html#gppts38212).\nInput\n\n**c** (*ndarray*)  1D array to be interleaved.\n\nOutput\n\n*ndarray*  Interleaved version of `c` with same shape and dtype as `c`.\n\n\n`property` `enc_crc`\n\nCRC encoder layer used for CRC concatenation.\n\n\n`input_interleaver`(*`c`*)[`[source]`](../_modules/sionna/fec/polar/encoding.html#Polar5GEncoder.input_interleaver)\n\nInput interleaver following Sec. 5.4.1.1 in [[3GPPTS38212]](https://nvlabs.github.io/sionna/api/fec.polar.html#gppts38212).\nInput\n\n**c** (*ndarray*)  1D array to be interleaved.\n\nOutput\n\n*ndarray*  Interleaved version of `c` with same shape and dtype as `c`.\n\n\n`property` `k`\n\nNumber of information bits including rate-matching.\n\n\n`property` `k_polar`\n\nNumber of information bits of the underlying Polar code.\n\n\n`property` `k_target`\n\nNumber of information bits including rate-matching.\n\n\n`property` `n`\n\nCodeword length including rate-matching.\n\n\n`property` `n_polar`\n\nCodeword length of the underlying Polar code.\n\n\n`property` `n_target`\n\nCodeword length including rate-matching.\n\n\n`subblock_interleaving`(*`u`*)[`[source]`](../_modules/sionna/fec/polar/encoding.html#Polar5GEncoder.subblock_interleaving)\n\nInput bit interleaving as defined in Sec 5.4.1.1 [[3GPPTS38212]](https://nvlabs.github.io/sionna/api/fec.polar.html#gppts38212).\nInput\n\n**u** (*ndarray*)  1D array to be interleaved. Length of `u` must be a multiple\nof 32.\n\nOutput\n\n*ndarray*  Interleaved version of `u` with same shape and dtype as `u`.\n\nRaises\n\n**AssertionError**  If length of `u` is not a multiple of 32."
"### PolarEncoder\n\n`class` `sionna.fec.polar.encoding.``PolarEncoder`(*`frozen_pos`*, *`n`*, *`dtype``=``tf.float32`*)[`[source]`](../_modules/sionna/fec/polar/encoding.html#PolarEncoder)\n\nPolar encoder for given code parameters.\n\nThis layer performs polar encoding for the given `k` information bits and\nthe <cite>frozen set</cite> (i.e., indices of frozen positions) specified by\n`frozen_pos`.\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **frozen_pos** (*ndarray*)  Array of <cite>int</cite> defining the <cite>n-k</cite> frozen indices, i.e., information\nbits are mapped onto the <cite>k</cite> complementary positions.\n- **n** (*int*)  Defining the codeword length.\n- **dtype** (*tf.DType*)  Defaults to <cite>tf.float32</cite>. Defines the output datatype of the layer\n(internal precision is <cite>tf.uint8</cite>).\n\n\nInput\n\n**inputs** (*[,k], tf.float32*)  2+D tensor containing the information bits to be encoded.\n\nOutput\n\n*[,n], tf.float32*  2+D tensor containing the codeword bits.\n\nRaises\n\n- **AssertionError**  `k` and `n` must be positive integers and `k` must be smaller\n    (or equal) than `n`.\n- **AssertionError**  If `n` is not a power of 2.\n- **AssertionError**  If the number of elements in `frozen_pos` is great than `n`.\n- **AssertionError**  If `frozen_pos` does not consists of <cite>int</cite>.\n- **ValueError**  If `dtype` is not supported.\n- **ValueError**  If `inputs` contains other values than <cite>0</cite> or <cite>1</cite>.\n- **TypeError**  If `inputs` is not <cite>tf.float32</cite>.\n- **InvalidArgumentError**  When rank(`inputs`)<2.\n- **InvalidArgumentError**  When shape of last dim is not `k`.\n\n\n**Note**\n\nAs commonly done, we assume frozen bits are set to <cite>0</cite>. Please note\nthat - although its practical relevance is only little - setting frozen\nbits to <cite>1</cite> may result in <cite>affine</cite> codes instead of linear code as the\n<cite>all-zero</cite> codeword is not necessarily part of the code any more.\n\n`property` `frozen_pos`\n\nFrozen positions for Polar decoding.\n\n\n`property` `info_pos`\n\nInformation bit positions for Polar encoding.\n\n\n`property` `k`\n\nNumber of information bits.\n\n\n`property` `n`\n\nCodeword length."
"### Polar5GDecoder\n\n`class` `sionna.fec.polar.decoding.``Polar5GDecoder`(*`enc_polar`*, *`dec_type``=``'SC'`*, *`list_size``=``8`*, *`num_iter``=``20`*, *`return_crc_status``=``False`*, *`output_dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/polar/decoding.html#Polar5GDecoder)\n\nWrapper for 5G compliant decoding including rate-recovery and CRC removal.\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **enc_polar** ()  Instance of the [`Polar5GEncoder`](https://nvlabs.github.io/sionna/api/fec.polar.html#sionna.fec.polar.encoding.Polar5GEncoder)\nused for encoding including rate-matching.\n- **dec_type** (*str*)  Defaults to <cite>SC</cite>. Defining the decoder to be used.\nMust be one of the following <cite>{SC, SCL, hybSCL, BP}</cite>.\n- **list_size** (*int*)  Defaults to 8. Defining the list size <cite>iff</cite> list-decoding is used.\nOnly required for `dec_types` <cite>{SCL, hybSCL}</cite>.\n- **num_iter** (*int*)  Defaults to 20. Defining the number of BP iterations. Only required\nfor `dec_type` <cite>BP</cite>.\n- **return_crc_status** (*bool*)  Defaults to False. If True, the decoder additionally returns the\nCRC status indicating if a codeword was (most likely) correctly\nrecovered.\n- **output_dtype** (*tf.DType*)  Defaults to tf.float32. Defines the output datatype of the layer\n(internal precision remains tf.float32).\n\n\nInput\n\n**inputs** (*[,n], tf.float32*)  2+D tensor containing the channel logits/llr values.\n\nOutput\n\n- **b_hat** (*[,k], tf.float32*)  2+D tensor containing hard-decided estimations of all <cite>k</cite>\ninformation bits.\n- **crc_status** (*[], tf.bool*)  CRC status indicating if a codeword was (most likely) correctly\nrecovered. This is only returned if `return_crc_status` is True.\nNote that false positives are possible.\n\n\nRaises\n\n- **AssertionError**  If `enc_polar` is not <cite>Polar5GEncoder</cite>.\n- **ValueError**  If `dec_type` is not <cite>{SC, SCL, SCL8, SCL32, hybSCL,\n    BP}</cite>.\n- **AssertionError**  If `dec_type` is not <cite>str</cite>.\n- **ValueError**  If `inputs` is not of shape <cite>[, n]</cite> or <cite>dtype</cite> is not\n    the same as `output_dtype`.\n- **InvalidArgumentError**  When rank(`inputs`)<2.\n\n\n**Note**\n\nThis layer supports the uplink and downlink Polar rate-matching scheme\nwithout <cite>codeword segmentation</cite>.\n\nAlthough the decoding <cite>list size</cite> is not provided by 3GPP\n[[3GPPTS38212]](https://nvlabs.github.io/sionna/api/fec.polar.html#gppts38212), the consortium has agreed on a <cite>list size</cite> of 8 for the\n5G decoding reference curves [[Bioglio_Design]](https://nvlabs.github.io/sionna/api/fec.polar.html#bioglio-design).\n\nAll list-decoders apply <cite>CRC-aided</cite> decoding, however, the non-list\ndecoders (<cite>SC</cite> and <cite>BP</cite>) cannot materialize the CRC leading to an\neffective rate-loss.\n\n`property` `dec_type`\n\nDecoder type used for decoding as str.\n\n\n`property` `frozen_pos`\n\nFrozen positions for Polar decoding.\n\n\n`property` `info_pos`\n\nInformation bit positions for Polar encoding.\n\n\n`property` `k_polar`\n\nNumber of information bits of mother Polar code.\n\n\n`property` `k_target`\n\nNumber of information bits including rate-matching.\n\n\n`property` `llr_max`\n\nMaximum LLR value for internal calculations.\n\n\n`property` `n_polar`\n\nCodeword length of mother Polar code.\n\n\n`property` `n_target`\n\nCodeword length including rate-matching.\n\n\n`property` `output_dtype`\n\nOutput dtype of decoder.\n\n\n`property` `polar_dec`\n\nDecoder instance used for decoding."
"### PolarSCDecoder\n\n`class` `sionna.fec.polar.decoding.``PolarSCDecoder`(*`frozen_pos`*, *`n`*, *`output_dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/polar/decoding.html#PolarSCDecoder)\n\nSuccessive cancellation (SC) decoder [[Arikan_Polar]](https://nvlabs.github.io/sionna/api/fec.polar.html#arikan-polar) for Polar codes and\nPolar-like codes.\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **frozen_pos** (*ndarray*)  Array of <cite>int</cite> defining the `n-k` indices of the frozen positions.\n- **n**  Defining the codeword length.\n\n\nInput\n\n**inputs** (*[,n], tf.float32*)  2+D tensor containing the channel LLR values (as logits).\n\nOutput\n\n*[,k], tf.float32*  2+D tensor  containing hard-decided estimations of all `k`\ninformation bits.\n\nRaises\n\n- **AssertionError**  If `n` is not <cite>int</cite>.\n- **AssertionError**  If `n` is not a power of 2.\n- **AssertionError**  If the number of elements in `frozen_pos` is greater than `n`.\n- **AssertionError**  If `frozen_pos` does not consists of <cite>int</cite>.\n- **ValueError**  If `output_dtype` is not {tf.float16, tf.float32, tf.float64}.\n\n\n**Note**\n\nThis layer implements the SC decoder as described in\n[[Arikan_Polar]](https://nvlabs.github.io/sionna/api/fec.polar.html#arikan-polar). However, the implementation follows the <cite>recursive\ntree</cite> [[Gross_Fast_SCL]](https://nvlabs.github.io/sionna/api/fec.polar.html#gross-fast-scl) terminology and combines nodes for increased\nthroughputs without changing the outcome of the algorithm.\n\nAs commonly done, we assume frozen bits are set to <cite>0</cite>. Please note\nthat - although its practical relevance is only little - setting frozen\nbits to <cite>1</cite> may result in <cite>affine</cite> codes instead of linear code as the\n<cite>all-zero</cite> codeword is not necessarily part of the code any more.\n\n`property` `frozen_pos`\n\nFrozen positions for Polar decoding.\n\n\n`property` `info_pos`\n\nInformation bit positions for Polar encoding.\n\n\n`property` `k`\n\nNumber of information bits.\n\n\n`property` `llr_max`\n\nMaximum LLR value for internal calculations.\n\n\n`property` `n`\n\nCodeword length.\n\n\n`property` `output_dtype`\n\nOutput dtype of decoder."
"### PolarSCLDecoder\n\n`class` `sionna.fec.polar.decoding.``PolarSCLDecoder`(*`frozen_pos`*, *`n`*, *`list_size``=``8`*, *`crc_degree``=``None`*, *`use_hybrid_sc``=``False`*, *`use_fast_scl``=``True`*, *`cpu_only``=``False`*, *`use_scatter``=``False`*, *`ind_iil_inv``=``None`*, *`return_crc_status``=``False`*, *`output_dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/polar/decoding.html#PolarSCLDecoder)\n\nSuccessive cancellation list (SCL) decoder [[Tal_SCL]](https://nvlabs.github.io/sionna/api/fec.polar.html#tal-scl) for Polar codes\nand Polar-like codes.\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **frozen_pos** (*ndarray*)  Array of <cite>int</cite> defining the `n-k` indices of the frozen positions.\n- **n** (*int*)  Defining the codeword length.\n- **list_size** (*int*)  Defaults to 8. Defines the list size of the decoder.\n- **crc_degree** (*str*)  Defining the CRC polynomial to be used. Can be any value from\n<cite>{CRC24A, CRC24B, CRC24C, CRC16, CRC11, CRC6}</cite>.\n- **use_hybrid_sc** (*bool*)  Defaults to False. If True, SC decoding is applied and only the\ncodewords with invalid CRC are decoded with SCL. This option\nrequires an outer CRC specified via `crc_degree`.\nRemark: hybrid_sc does not support XLA optimization, i.e.,\n<cite>@tf.function(jit_compile=True)</cite>.\n- **use_fast_scl** (*bool*)  Defaults to True. If True, Tree pruning is used to\nreduce the decoding complexity. The output is equivalent to the\nnon-pruned version (besides numerical differences).\n- **cpu_only** (*bool*)  Defaults to False. If True, <cite>tf.py_function</cite> embedding\nis used and the decoder runs on the CPU. This option is usually\nslower, but also more memory efficient and, in particular,\nrecommended for larger blocklengths. Remark: cpu_only does not\nsupport XLA optimization <cite>@tf.function(jit_compile=True)</cite>.\n- **use_scatter** (*bool*)  Defaults to False. If True, <cite>tf.tensor_scatter_update</cite> is used for\ntensor updates. This option is usually slower, but more memory\nefficient.\n- **ind_iil_inv** (*None** or **[**k+k_crc**]**, **int** or **tf.int*)  Defaults to None. If not <cite>None</cite>, the sequence is used as inverse\ninput bit interleaver before evaluating the CRC.\nRemark: this only effects the CRC evaluation but the output\nsequence is not permuted.\n- **return_crc_status** (*bool*)  Defaults to False. If True, the decoder additionally returns the\nCRC status indicating if a codeword was (most likely) correctly\nrecovered. This is only available if `crc_degree` is not None.\n- **output_dtype** (*tf.DType*)  Defaults to tf.float32. Defines the output datatype of the layer\n(internal precision remains tf.float32).\n\n\nInput\n\n**inputs** (*[,n], tf.float32*)  2+D tensor containing the channel LLR values (as logits).\n\nOutput\n\n- **b_hat** (*[,k], tf.float32*)  2+D tensor containing hard-decided estimations of all <cite>k</cite>\ninformation bits.\n- **crc_status** (*[], tf.bool*)  CRC status indicating if a codeword was (most likely) correctly\nrecovered. This is only returned if `return_crc_status` is True.\nNote that false positives are possible.\n\n\nRaises\n\n- **AssertionError**  If `n` is not <cite>int</cite>.\n- **AssertionError**  If `n` is not a power of 2.\n- **AssertionError**  If the number of elements in `frozen_pos` is greater than `n`.\n- **AssertionError**  If `frozen_pos` does not consists of <cite>int</cite>.\n- **AssertionError**  If `list_size` is not <cite>int</cite>.\n- **AssertionError**  If `cpu_only` is not <cite>bool</cite>.\n- **AssertionError**  If `use_scatter` is not <cite>bool</cite>.\n- **AssertionError**  If `use_fast_scl` is not <cite>bool</cite>.\n- **AssertionError**  If `use_hybrid_sc` is not <cite>bool</cite>.\n- **AssertionError**  If `list_size` is not a power of 2.\n- **ValueError**  If `output_dtype` is not {tf.float16, tf.float32, tf.\n    float64}.\n- **ValueError**  If `inputs` is not of shape <cite>[, n]</cite> or <cite>dtype</cite> is not\n    correct.\n- **InvalidArgumentError**  When rank(`inputs`)<2.\n\n\n**Note**\n\nThis layer implements the successive cancellation list (SCL) decoder\nas described in [[Tal_SCL]](https://nvlabs.github.io/sionna/api/fec.polar.html#tal-scl) but uses LLR-based message updates\n[[Stimming_LLR]](https://nvlabs.github.io/sionna/api/fec.polar.html#stimming-llr). The implementation follows the notation from\n[[Gross_Fast_SCL]](https://nvlabs.github.io/sionna/api/fec.polar.html#gross-fast-scl), [[Hashemi_SSCL]](https://nvlabs.github.io/sionna/api/fec.polar.html#hashemi-sscl). If option <cite>use_fast_scl</cite> is active\ntree pruning is used and tree nodes are combined if possible (see\n[[Hashemi_SSCL]](https://nvlabs.github.io/sionna/api/fec.polar.html#hashemi-sscl) for details).\n\nImplementing SCL decoding as TensorFlow graph is a difficult task that\nrequires several design tradeoffs to match the TF constraints while\nmaintaining a reasonable throughput. Thus, the decoder minimizes\nthe <cite>control flow</cite> as much as possible, leading to a strong memory\noccupation (e.g., due to full path duplication after each decision).\nFor longer code lengths, the complexity of the decoding graph becomes\nlarge and we recommend to use the <cite>CPU_only</cite> option that uses an\nembedded Numpy decoder. Further, this function recursively unrolls the\nSCL decoding tree, thus, for larger values of `n` building the\ndecoding graph can become time consuming. Please consider the\n`cpu_only` option if building the graph takes to long.\n\nA hybrid SC/SCL decoder as proposed in [[Cammerer_Hybrid_SCL]](https://nvlabs.github.io/sionna/api/fec.polar.html#cammerer-hybrid-scl) (using SC\ninstead of BP) can be activated with option `use_hybrid_sc` iff an\nouter CRC is available. Please note that the results are not exactly\nSCL performance caused by the false positive rate of the CRC.\n\nAs commonly done, we assume frozen bits are set to <cite>0</cite>. Please note\nthat - although its practical relevance is only little - setting frozen\nbits to <cite>1</cite> may result in <cite>affine</cite> codes instead of linear code as the\n<cite>all-zero</cite> codeword is not necessarily part of the code any more.\n\n`property` `frozen_pos`\n\nFrozen positions for Polar decoding.\n\n\n`property` `info_pos`\n\nInformation bit positions for Polar encoding.\n\n\n`property` `k`\n\nNumber of information bits.\n\n\n`property` `k_crc`\n\nNumber of CRC bits.\n\n\n`property` `list_size`\n\nList size for SCL decoding.\n\n\n`property` `llr_max`\n\nMaximum LLR value for internal calculations.\n\n\n`property` `n`\n\nCodeword length.\n\n\n`property` `output_dtype`\n\nOutput dtype of decoder."
"### PolarBPDecoder\n\n`class` `sionna.fec.polar.decoding.``PolarBPDecoder`(*`frozen_pos`*, *`n`*, *`num_iter``=``20`*, *`hard_out``=``True`*, *`output_dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/polar/decoding.html#PolarBPDecoder)\n\nBelief propagation (BP) decoder for Polar codes [[Arikan_Polar]](https://nvlabs.github.io/sionna/api/fec.polar.html#arikan-polar) and\nPolar-like codes based on [[Arikan_BP]](https://nvlabs.github.io/sionna/api/fec.polar.html#arikan-bp) and [[Forney_Graphs]](https://nvlabs.github.io/sionna/api/fec.polar.html#forney-graphs).\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\n\nRemark: The PolarBPDecoder does currently not support XLA.\nParameters\n\n- **frozen_pos** (*ndarray*)  Array of <cite>int</cite> defining the `n-k` indices of the frozen positions.\n- **n** (*int*)  Defining the codeword length.\n- **num_iter** (*int*)  Defining the number of decoder iterations (no early stopping used\nat the moment).\n- **hard_out** (*bool*)  Defaults to True. If True, the decoder provides hard-decided\ninformation bits instead of soft-values.\n- **output_dtype** (*tf.DType*)  Defaults to tf.float32. Defines the output datatype of the layer\n(internal precision remains tf.float32).\n\n\nInput\n\n**inputs** (*[,n], tf.float32*)  2+D tensor containing the channel logits/llr values.\n\nOutput\n\n*[,k], tf.float32*  2+D tensor containing bit-wise soft-estimates\n(or hard-decided bit-values) of all `k` information bits.\n\nRaises\n\n- **AssertionError**  If `n` is not <cite>int</cite>.\n- **AssertionError**  If `n` is not a power of 2.\n- **AssertionError**  If the number of elements in `frozen_pos` is greater than `n`.\n- **AssertionError**  If `frozen_pos` does not consists of <cite>int</cite>.\n- **AssertionError**  If `hard_out` is not <cite>bool</cite>.\n- **ValueError**  If `output_dtype` is not {tf.float16, tf.float32, tf.float64}.\n- **AssertionError**  If `num_iter` is not <cite>int</cite>.\n- **AssertionError**  If `num_iter` is not a positive value.\n\n\n**Note**\n\nThis decoder is fully differentiable and, thus, well-suited for\ngradient descent-based learning tasks such as <cite>learned code design</cite>\n[[Ebada_Design]](https://nvlabs.github.io/sionna/api/fec.polar.html#ebada-design).\n\nAs commonly done, we assume frozen bits are set to <cite>0</cite>. Please note\nthat - although its practical relevance is only little - setting frozen\nbits to <cite>1</cite> may result in <cite>affine</cite> codes instead of linear code as the\n<cite>all-zero</cite> codeword is not necessarily part of the code any more.\n\n`property` `frozen_pos`\n\nFrozen positions for Polar decoding.\n\n\n`property` `hard_out`\n\nIndicates if decoder hard-decides outputs.\n\n\n`property` `info_pos`\n\nInformation bit positions for Polar encoding.\n\n\n`property` `k`\n\nNumber of information bits.\n\n\n`property` `llr_max`\n\nMaximum LLR value for internal calculations.\n\n\n`property` `n`\n\nCodeword length.\n\n\n`property` `num_iter`\n\nNumber of decoding iterations.\n\n\n`property` `output_dtype`\n\nOutput dtype of decoder."
"### generate_5g_ranking\n\n`sionna.fec.polar.utils.``generate_5g_ranking`(*`k`*, *`n`*, *`sort``=``True`*)[`[source]`](../_modules/sionna/fec/polar/utils.html#generate_5g_ranking)\n\nReturns information and frozen bit positions of the 5G Polar code\nas defined in Tab. 5.3.1.2-1 in [[3GPPTS38212]](https://nvlabs.github.io/sionna/api/fec.polar.html#gppts38212) for given values of `k`\nand `n`.\nInput\n\n- **k** (*int*)  The number of information bit per codeword.\n- **n** (*int*)  The desired codeword length. Must be a power of two.\n- **sort** (*bool*)  Defaults to True. Indicates if the returned indices are\nsorted.\n\n\nOutput\n\n- **[frozen_pos, info_pos]**  List:\n- **frozen_pos** (*ndarray*)  An array of ints of shape <cite>[n-k]</cite> containing the frozen\nposition indices.\n- **info_pos** (*ndarray*)  An array of ints of shape <cite>[k]</cite> containing the information\nposition indices.\n\n\nRaises\n\n- **AssertionError**  If `k` or `n` are not positve ints.\n- **AssertionError**  If `sort` is not bool.\n- **AssertionError**  If `k` or `n` are larger than 1024\n- **AssertionError**  If `n` is less than 32.\n- **AssertionError**  If the resulting coderate is invalid (<cite>>1.0</cite>).\n- **AssertionError**  If `n` is not a power of 2."
"### generate_polar_transform_mat\n\n`sionna.fec.polar.utils.``generate_polar_transform_mat`(*`n_lift`*)[`[source]`](../_modules/sionna/fec/polar/utils.html#generate_polar_transform_mat)\n\nGenerate the polar transformation matrix (Kronecker product).\nInput\n\n**n_lift** (*int*)  Defining the Kronecker power, i.e., how often is the kernel lifted.\n\nOutput\n\n*ndarray*  Array of <cite>0s</cite> and <cite>1s</cite> of shape <cite>[2^n_lift , 2^n_lift]</cite> containing\nthe Polar transformation matrix."
"### generate_rm_code\n\n`sionna.fec.polar.utils.``generate_rm_code`(*`r`*, *`m`*)[`[source]`](../_modules/sionna/fec/polar/utils.html#generate_rm_code)\n\nGenerate frozen positions of the (r, m) Reed Muller (RM) code.\nInput\n\n- **r** (*int*)  The order of the RM code.\n- **m** (*int*)  <cite>log2</cite> of the desired codeword length.\n\n\nOutput\n\n- **[frozen_pos, info_pos, n, k, d_min]**  List:\n- **frozen_pos** (*ndarray*)  An array of ints of shape <cite>[n-k]</cite> containing the frozen\nposition indices.\n- **info_pos** (*ndarray*)  An array of ints of shape <cite>[k]</cite> containing the information\nposition indices.\n- **n** (*int*)  Resulting codeword length\n- **k** (*int*)  Number of information bits\n- **d_min** (*int*)  Minimum distance of the code.\n\n\nRaises\n\n- **AssertionError**  If `r` is larger than `m`.\n- **AssertionError**  If `r` or `m` are not positive ints."
"### generate_dense_polar\n\n`sionna.fec.polar.utils.``generate_dense_polar`(*`frozen_pos`*, *`n`*, *`verbose``=``True`*)[`[source]`](../_modules/sionna/fec/polar/utils.html#generate_dense_polar)\n\nGenerate *naive* (dense) Polar parity-check and generator matrix.\n\nThis function follows Lemma 1 in [[Goala_LP]](https://nvlabs.github.io/sionna/api/fec.polar.html#goala-lp) and returns a parity-check\nmatrix for Polar codes.\n\n**Note**\n\nThe resulting matrix can be used for decoding with the\n`LDPCBPDecoder` class. However, the resulting\nparity-check matrix is (usually) not sparse and, thus, not suitable for\nbelief propagation decoding as the graph has many short cycles.\nPlease consider `PolarBPDecoder` for iterative\ndecoding over the encoding graph.\n\nInput\n\n- **frozen_pos** (*ndarray*)  Array of <cite>int</cite> defining the `n-k` indices of the frozen positions.\n- **n** (*int*)  The codeword length.\n- **verbose** (*bool*)  Defaults to True. If True, the code properties are printed.\n\n\nOutput\n\n- **pcm** (ndarray of <cite>zeros</cite> and <cite>ones</cite> of shape [n-k, n])  The parity-check matrix.\n- **gm** (ndarray of <cite>zeros</cite> and <cite>ones</cite> of shape [k, n])  The generator matrix.\n\n\nReferences:\n3GPPTS38212([1](https://nvlabs.github.io/sionna/api/fec.polar.html#id1),[2](https://nvlabs.github.io/sionna/api/fec.polar.html#id2),[3](https://nvlabs.github.io/sionna/api/fec.polar.html#id5),[4](https://nvlabs.github.io/sionna/api/fec.polar.html#id8),[5](https://nvlabs.github.io/sionna/api/fec.polar.html#id9),[6](https://nvlabs.github.io/sionna/api/fec.polar.html#id10),[7](https://nvlabs.github.io/sionna/api/fec.polar.html#id11),[8](https://nvlabs.github.io/sionna/api/fec.polar.html#id12),[9](https://nvlabs.github.io/sionna/api/fec.polar.html#id13),[10](https://nvlabs.github.io/sionna/api/fec.polar.html#id14),[11](https://nvlabs.github.io/sionna/api/fec.polar.html#id15),[12](https://nvlabs.github.io/sionna/api/fec.polar.html#id16),[13](https://nvlabs.github.io/sionna/api/fec.polar.html#id17),[14](https://nvlabs.github.io/sionna/api/fec.polar.html#id33))\n\nETSI 3GPP TS 38.212 5G NR Multiplexing and channel\ncoding, v.16.5.0, 2021-03.\n\nBioglio_Design([1](https://nvlabs.github.io/sionna/api/fec.polar.html#id3),[2](https://nvlabs.github.io/sionna/api/fec.polar.html#id4),[3](https://nvlabs.github.io/sionna/api/fec.polar.html#id6),[4](https://nvlabs.github.io/sionna/api/fec.polar.html#id18))\n\nV. Bioglio, C. Condo, I. Land, Design of\nPolar Codes in 5G New Radio, IEEE Communications Surveys &\nTutorials, 2020. Online availabe [https://arxiv.org/pdf/1804.04389.pdf](https://arxiv.org/pdf/1804.04389.pdf)\n\n[Hui_ChannelCoding](https://nvlabs.github.io/sionna/api/fec.polar.html#id7)\n\nD. Hui, S. Sandberg, Y. Blankenship, M.\nAndersson, L. Grosjean Channel coding in 5G new radio: A\nTutorial Overview and Performance Comparison with 4G LTE, IEEE\nVehicular Technology Magazine, 2018.\n\nArikan_Polar([1](https://nvlabs.github.io/sionna/api/fec.polar.html#id19),[2](https://nvlabs.github.io/sionna/api/fec.polar.html#id20),[3](https://nvlabs.github.io/sionna/api/fec.polar.html#id29))\n\nE. Arikan, Channel polarization: A method for\nconstructing capacity-achieving codes for symmetric\nbinary-input memoryless channels, IEEE Trans. on Information\nTheory, 2009.\n\nGross_Fast_SCL([1](https://nvlabs.github.io/sionna/api/fec.polar.html#id21),[2](https://nvlabs.github.io/sionna/api/fec.polar.html#id25))\n\nSeyyed Ali Hashemi, Carlo Condo, and Warren J.\nGross, Fast and Flexible Successive-cancellation List Decoders\nfor Polar Codes. IEEE Trans. on Signal Processing, 2017.\n\nTal_SCL([1](https://nvlabs.github.io/sionna/api/fec.polar.html#id22),[2](https://nvlabs.github.io/sionna/api/fec.polar.html#id23))\n\nIdo Tal and Alexander Vardy, List Decoding of Polar\nCodes. IEEE Trans Inf Theory, 2015.\n\n[Stimming_LLR](https://nvlabs.github.io/sionna/api/fec.polar.html#id24)\n\nAlexios Balatsoukas-Stimming, Mani Bastani Parizi,\nAndreas Burg, LLR-Based Successive Cancellation List Decoding\nof Polar Codes. IEEE Trans Signal Processing, 2015.\n\nHashemi_SSCL([1](https://nvlabs.github.io/sionna/api/fec.polar.html#id26),[2](https://nvlabs.github.io/sionna/api/fec.polar.html#id27))\n\nSeyyed Ali Hashemi, Carlo Condo, and Warren J.\nGross, Simplified Successive-Cancellation List Decoding\nof Polar Codes. IEEE ISIT, 2016.\n\n[Cammerer_Hybrid_SCL](https://nvlabs.github.io/sionna/api/fec.polar.html#id28)\n\nSebastian Cammerer, Benedikt Leible, Matthias\nStahl, Jakob Hoydis, and Stephan ten Brink, Combining Belief\nPropagation and Successive Cancellation List Decoding of Polar\nCodes on a GPU Platform, IEEE ICASSP, 2017.\n\n[Arikan_BP](https://nvlabs.github.io/sionna/api/fec.polar.html#id30)\n\nE. Arikan, A Performance Comparison of Polar Codes and\nReed-Muller Codes, IEEE Commun. Lett., vol. 12, no. 6, pp.\n447-449, Jun. 2008.\n\n[Forney_Graphs](https://nvlabs.github.io/sionna/api/fec.polar.html#id31)\n\nG. D. Forney, Codes on graphs: normal realizations,\nIEEE Trans. Inform. Theory, vol. 47, no. 2, pp. 520-548, Feb. 2001.\n\n[Ebada_Design](https://nvlabs.github.io/sionna/api/fec.polar.html#id32)\n\nM. Ebada, S. Cammerer, A. Elkelesh and S. ten Brink,\nDeep Learning-based Polar Code Design, Annual Allerton\nConference on Communication, Control, and Computing, 2019.\n\n[Goala_LP](https://nvlabs.github.io/sionna/api/fec.polar.html#id34)\n\nN. Goela, S. Korada, M. Gastpar, On LP decoding of Polar\nCodes, IEEE ITW 2010."
"# Scrambling\n\nThe [`Scrambler`](https://nvlabs.github.io/sionna/api/fec.scrambling.html#sionna.fec.scrambling.Scrambler) module allows to (pseudo)\nrandomly flip bits in a binary sequence or the signs of a real-valued sequence,\nrespectively. The [`Descrambler`](https://nvlabs.github.io/sionna/api/fec.scrambling.html#sionna.fec.scrambling.Descrambler) implement the corresponding descrambling operation.\n\nTo simplify distributed graph execution (e.g., by running scrambler and\ndescrambler in a different sub-graph/device), the scramblers are implemented\nstateless. Thus, the internal seed cannot be update on runtime and does not\nchange after the initialization.\nHowever, if required an explicit random seed can be passed as additional input\nthe scrambler/descrambler pair when calling the layer.\n\nFurther, the [`TB5GScrambler`](https://nvlabs.github.io/sionna/api/fec.scrambling.html#sionna.fec.scrambling.TB5GScrambler) enables 5G NR compliant\nscrambling as specified in [[3GPPTS38211_scr]](https://nvlabs.github.io/sionna/api/fec.scrambling.html#gppts38211-scr).\n\nThe following code snippet shows how to setup and use an instance of the\nscrambler:\n```python\n# set-up system\nscrambler = Scrambler(seed=1234, # an explicit seed can be provided\n                     binary=True) # indicate if bits shall be flipped\ndescrambler = Descrambler(scrambler=scrambler) # connect scrambler and descrambler\n# --- simplified usage with fixed seed ---\n# c has arbitrary shape and contains 0s and 1s (otherwise set binary=False)\nc_scr = scrambler(c)\n# descramble to reconstruct the original order\nc_descr = descrambler(c_scr)\n# --- advanced usage ---\n# provide explicite seed if a new random seed should be used for each call\ns = tf.random.uniform((), minval=0, maxval=12345678, dtype=tf.int32)\nc_scr = scrambler([c, s])\nc_descr = descrambler([c_scr, s])\n```"
"## Scrambler\n\n`class` `sionna.fec.scrambling.``Scrambler`(*`seed=None`*, *`keep_batch_constant=False`*, *`sequence=None`*, *`binary=True` `keep_state=True`*, *`dtype=tf.float32`*, *`**kwargs`*)[`[source]`](../_modules/sionna/fec/scrambling.html#Scrambler)\n\nRandomly flips the state/sign of a sequence of bits or LLRs, respectively.\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **seed** (*int*)  Defaults to None. Defines the initial state of the\npseudo random generator to generate the scrambling sequence.\nIf None, a random integer will be generated. Only used\nwhen called with `keep_state` is True.\n- **keep_batch_constant** (*bool*)  Defaults to False. If True, all samples in the batch are scrambled\nwith the same scrambling sequence. Otherwise, per sample a random\nsequence is generated.\n- **sequence** (*Array of 0s and 1s** or **None*)  If provided, the seed will be ignored and the explicit scrambling\nsequence is used. Shape must be broadcastable to `x`.\n- **binary** (*bool*)  Defaults to True. Indicates whether bit-sequence should be flipped\n(i.e., binary operations are performed) or the signs should be\nflipped (i.e., soft-value/LLR domain-based).\n- **keep_state** (*bool*)  Defaults to True. Indicates whether the scrambling sequence should\nbe kept constant.\n- **dtype** (*tf.DType*)  Defaults to <cite>tf.float32</cite>. Defines the datatype for internal\ncalculations and the output dtype.\n\n\nInput\n\n- **(x, seed, binary)**  Either Tuple `(x,` `seed,` `binary)` or  `(x,` `seed)` or `x` only\n(no tuple) if the internal  seed should be used:\n- **x** (*tf.float*)  1+D tensor of arbitrary shape.\n- **seed** (*int*)  An integer defining the state of the random number\ngenerator. If explicitly given, the global internal seed is\nreplaced by this seed. Can be used to realize random\nscrambler/descrambler pairs (call with same random seed).\n- **binary** (*bool*)  Overrules the init parameter <cite>binary</cite> iff explicitly given.\nIndicates whether bit-sequence should be flipped\n(i.e., binary operations are performed) or the signs should be\nflipped (i.e., soft-value/LLR domain-based).\n\n\nOutput\n\n*tf.float*  1+D tensor of same shape as `x`.\n\n\n**Note**\n\nFor inverse scrambling, the same scrambler can be re-used (as the values\nare flipped again, i.e., result in the original state). However,\n`keep_state` must be set to True as a new sequence would be generated\notherwise.\n\nThe scrambler layer is stateless, i.e., the seed is either random\nduring each call or must be explicitly provided during init/call.\nThis simplifies XLA/graph execution.\nIf the seed is provided in the init() function, this fixed seed is used\nfor all calls. However, an explicit seed can be provided during\nthe call function to realize <cite>true</cite> random states.\n\nScrambling is typically used to ensure equal likely <cite>0</cite>  and <cite>1</cite> for\nsources with unequal bit probabilities. As we have a perfect source in\nthe simulations, this is not required. However, for all-zero codeword\nsimulations and higher-order modulation, so-called channel-adaptation\n[[Pfister03]](https://nvlabs.github.io/sionna/api/fec.scrambling.html#pfister03) is required.\n\nRaises\n\n- **AssertionError**  If `seed` is not int.\n- **AssertionError**  If `keep_batch_constant` is not bool.\n- **AssertionError**  If `binary` is not bool.\n- **AssertionError**  If `keep_state` is not bool.\n- **AssertionError**  If `seed` is provided to list of inputs but not an\n    int.\n- **TypeError**  If <cite>dtype</cite> of `x` is not as expected.\n\n\n`property` `keep_state`\n\nIndicates if new random sequences are used per call.\n\n\n`property` `seed`\n\nSeed used to generate random sequence.\n\n\n`property` `sequence`\n\nExplicit scrambling sequence if provided."
"## TB5GScrambler\n\n`class` `sionna.fec.scrambling.``TB5GScrambler`(*`n_rnti``=``1`*, *`n_id``=``1`*, *`binary``=``True`*, *`channel_type``=``'PUSCH'`*, *`codeword_index``=``0`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/scrambling.html#TB5GScrambler)\n\nImplements the pseudo-random bit scrambling as defined in\n[[3GPPTS38211_scr]](https://nvlabs.github.io/sionna/api/fec.scrambling.html#gppts38211-scr) Sec. 6.3.1.1 for the PUSCH channel and in Sec. 7.3.1.1\nfor the PDSCH channel.\n\nOnly for the PDSCH channel, the scrambler can be configured for two\ncodeword transmission mode. Hereby, `codeword_index` corresponds to the\nindex of the codeword to be scrambled.\n\nIf `n_rnti` are a list of ints, the scrambler assumes that the second\nlast axis contains <cite>len(</cite> `n_rnti` <cite>)</cite> elements. This allows independent\nscrambling for multiple independent streams.\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **n_rnti** (*int** or **list of ints*)  RNTI identifier provided by higher layer. Defaults to 1 and must be\nin range <cite>[0, 65335]</cite>. If a list is provided, every list element\ndefines a scrambling sequence for multiple independent streams.\n- **n_id** (*int** or **list of ints*)  Scrambling ID related to cell id and provided by higher layer.\nDefaults to 1 and must be in range <cite>[0, 1023]</cite>. If a list is\nprovided, every list element defines a scrambling sequence for\nmultiple independent streams.\n- **binary** (*bool*)  Defaults to True. Indicates whether bit-sequence should be flipped\n(i.e., binary operations are performed) or the signs should be\nflipped (i.e., soft-value/LLR domain-based).\n- **channel_type** (*str*)  Can be either PUSCH or PDSCH.\n- **codeword_index** (*int*)  Scrambler can be configured for two codeword transmission.\n`codeword_index` can be either 0 or 1.\n- **dtype** (*tf.DType*)  Defaults to <cite>tf.float32</cite>. Defines the datatype for internal\ncalculations and the output dtype.\n\n\nInput\n\n- **(x, binary)**  Either Tuple `(x,` `binary)` or  `x` only\n- **x** (*tf.float*)  1+D tensor of arbitrary shape. If `n_rnti` and `n_id` are a\nlist, it is assumed that `x` has shape\n<cite>[,num_streams, n]</cite> where <cite>num_streams=len(</cite> `n_rnti` <cite>)</cite>.\n- **binary** (*bool*)  Overrules the init parameter <cite>binary</cite> iff explicitly given.\nIndicates whether bit-sequence should be flipped\n(i.e., binary operations are performed) or the signs should be\nflipped (i.e., soft-value/LLR domain-based).\n\n\nOutput\n\n*tf.float*  1+D tensor of same shape as `x`.\n\n\n**Note**\n\nThe parameters radio network temporary identifier (RNTI) `n_rnti` and\nthe datascrambling ID `n_id` are usually provided be the higher layer protocols.\n\nFor inverse scrambling, the same scrambler can be re-used (as the values\nare flipped again, i.e., result in the original state).\n\n`property` `keep_state`\n\nRequired for descrambler, is always <cite>True</cite> for the TB5GScrambler."
"## Descrambler\n\n`class` `sionna.fec.scrambling.``Descrambler`(*`scrambler`*, *`binary``=``True`*, *`dtype``=``None`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/scrambling.html#Descrambler)\n\nDescrambler for a given scrambler.\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **scrambler** (*, *)  Associated [`Scrambler`](https://nvlabs.github.io/sionna/api/fec.scrambling.html#sionna.fec.scrambling.Scrambler) or\n[`TB5GScrambler`](https://nvlabs.github.io/sionna/api/fec.scrambling.html#sionna.fec.scrambling.TB5GScrambler) instance which\nshould be descrambled.\n- **binary** (*bool*)  Defaults to True. Indicates whether bit-sequence should be flipped\n(i.e., binary operations are performed) or the signs should be\nflipped (i.e., soft-value/LLR domain-based).\n- **dtype** (*None** or **tf.DType*)  Defaults to <cite>None</cite>. Defines the datatype for internal calculations\nand the output dtype. If no explicit dtype is provided the dtype\nfrom the associated interleaver is used.\n\n\nInput\n\n- **(x, seed)**  Either Tuple `(x,` `seed)` or `x` only (no tuple) if the internal\nseed should be used:\n- **x** (*tf.float*)  1+D tensor of arbitrary shape.\n- **seed** (*int*)  An integer defining the state of the random number\ngenerator. If explicitly given, the global internal seed is\nreplaced by this seed. Can be used to realize random\nscrambler/descrambler pairs (call with same random seed).\n\n\nOutput\n\n*tf.float*  1+D tensor of same shape as `x`.\n\nRaises\n\n- **AssertionError**  If `scrambler` is not an instance of <cite>Scrambler</cite>.\n- **AssertionError**  If `seed` is provided to list of inputs but not an\n    int.\n- **TypeError**  If <cite>dtype</cite> of `x` is not as expected.\n\n\n`property` `scrambler`\n\nAssociated scrambler instance.\n\n\nReferences:\n[Pfister03](https://nvlabs.github.io/sionna/api/fec.scrambling.html#id2)\n\nJ. Hou, P.Siegel, L. Milstein, and H. Pfister, Capacity\napproaching bandwidth-efficient coded modulation schemes\nbased on low-density parity-check codes, IEEE Trans. Inf. Theory,\nSep. 2003.\n\n3GPPTS38211_scr([1](https://nvlabs.github.io/sionna/api/fec.scrambling.html#id1),[2](https://nvlabs.github.io/sionna/api/fec.scrambling.html#id3))\n\nETSI 3GPP TS 38.211 Physical channels and modulation,\nv.16.2.0, 2020-07."
"# Turbo Codes\n\nThis module supports encoding and decoding of Turbo codes [[Berrou]](https://nvlabs.github.io/sionna/api/fec.turbo.html#berrou), e.g., as\nused in the LTE wireless standard. The convolutional component encoders and\ndecoders are composed of the [`ConvEncoder`](fec.conv.html#sionna.fec.conv.ConvEncoder) and\n[`BCJRDecoder`](fec.conv.html#sionna.fec.conv.BCJRDecoder) layers, respectively.\n\nPlease note that various notations are used in literature to represent the\ngenerator polynomials for the underlying convolutional codes. For simplicity,\n[`TurboEncoder`](https://nvlabs.github.io/sionna/api/fec.turbo.html#sionna.fec.turbo.TurboEncoder) only accepts the binary\nformat, i.e., <cite>10011</cite>, for the generator polynomial which corresponds to the\npolynomial $1 + D^3 + D^4$.\n\nThe following code snippet shows how to set-up a rate-1/3, constraint-length-4 [`TurboEncoder`](https://nvlabs.github.io/sionna/api/fec.turbo.html#sionna.fec.turbo.TurboEncoder) and the corresponding [`TurboDecoder`](https://nvlabs.github.io/sionna/api/fec.turbo.html#sionna.fec.turbo.TurboDecoder).\nYou can find further examples in the [Channel Coding Tutorial Notebook](../examples/5G_Channel_Coding_Polar_vs_LDPC_Codes.html).\n\nSetting-up:\n```python\nencoder = TurboEncoder(constraint_length=4, # Desired constraint length of the polynomials\n                       rate=1/3,  # Desired rate of Turbo code\n                       terminate=True) # Terminate the constituent convolutional encoders to all-zero state\n# or\nencoder = TurboEncoder(gen_poly=gen_poly, # Generator polynomials to use in the underlying convolutional encoders\n                       rate=1/3, # Rate of the desired Turbo code\n                       terminate=False) # Do not terminate the constituent convolutional encoders\n# the decoder can be initialized with a reference to the encoder\ndecoder = TurboDecoder(encoder,\n                       num_iter=6, # Number of iterations between component BCJR decoders\n                       algorithm=\"map\", # can be also \"maxlog\"\n                       hard_out=True) # hard_decide output\n```"
"Running the encoder / decoder:\n```python\n# --- encoder ---\n# u contains the information bits to be encoded and has shape [...,k].\n# c contains the turbo encoded codewords and has shape [...,n], where n=k/rate when terminate is False.\nc = encoder(u)\n# --- decoder ---\n# llr contains the log-likelihood ratio values from the de-mapper and has shape [...,n].\n# u_hat contains the estimated information bits and has shape [...,k].\nu_hat = decoder(llr)\n```"
"## Turbo Encoding\n\n`class` `sionna.fec.turbo.``TurboEncoder`(*`gen_poly``=``None`*, *`constraint_length``=``3`*, *`rate``=``1` `/` `3`*, *`terminate``=``False`*, *`interleaver_type``=``'3GPP'`*, *`output_dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/turbo/encoding.html#TurboEncoder)\n\nPerforms encoding of information bits to a Turbo code codeword [[Berrou]](https://nvlabs.github.io/sionna/api/fec.turbo.html#berrou).\nImplements the standard Turbo code framework [[Berrou]](https://nvlabs.github.io/sionna/api/fec.turbo.html#berrou): Two identical\nrate-1/2 convolutional encoders [`ConvEncoder`](fec.conv.html#sionna.fec.conv.ConvEncoder)\nare combined to produce a rate-1/3 Turbo code. Further,\npuncturing to attain a rate-1/2 Turbo code is supported.\n\nThe class inherits from the Keras layer class and can be used as layer in a\nKeras model.\nParameters\n\n- **gen_poly** (*tuple*)  Tuple of strings with each string being a 0,1 sequence. If\n<cite>None</cite>, `constraint_length` must be provided.\n- **constraint_length** (*int*)  Valid values are between 3 and 6 inclusive. Only required if\n`gen_poly` is <cite>None</cite>.\n- **rate** (*float*)  Valid values are 1/3 and 1/2. Note that `rate` here denotes\nthe <cite>design</cite> rate of the Turbo code. If `terminate` is <cite>True</cite>, a\nsmall rate-loss occurs.\n- **terminate** (*boolean*)  Underlying convolutional encoders are terminated to all zero state\nif <cite>True</cite>. If terminated, the true rate of the code is slightly lower\nthan `rate`.\n- **interleaver_type** (*str*)  Valid values are <cite>3GPP</cite> or <cite>random</cite>. Determines the choice of\nthe interleaver to interleave the message bits before input to the\nsecond convolutional encoder. If <cite>3GPP</cite>, the Turbo code interleaver\nfrom the 3GPP LTE standard [[3GPPTS36212_Turbo]](https://nvlabs.github.io/sionna/api/fec.turbo.html#gppts36212-turbo) is used. If <cite>random</cite>,\na random interleaver is used.\n- **output_dtype** (*tf.DType*)  Defaults to <cite>tf.float32</cite>. Defines the output datatype of the layer.\n\n\nInput\n\n**inputs** (*[,k], tf.float32*)  2+D tensor of information bits where <cite>k</cite> is the information length\n\nOutput\n\n<cite>[,k/rate]</cite>, tf.float32  2+D tensor where <cite>rate</cite> is provided as input\nparameter. The output is the encoded codeword for the input\ninformation tensor. When `terminate` is <cite>True</cite>, the effective rate\nof the Turbo code is slightly less than `rate`.\n\n\n**Note**\n\nVarious notations are used in literature to represent the generator\npolynomials for convolutional codes. For simplicity\n[`TurboEncoder`](https://nvlabs.github.io/sionna/api/fec.turbo.html#sionna.fec.turbo.TurboEncoder) only\naccepts the binary format, i.e., <cite>10011</cite>, for the `gen_poly` argument\nwhich corresponds to the polynomial $1 + D^3 + D^4$.\n\nNote that Turbo codes require the underlying convolutional encoders\nto be recursive systematic encoders. Only then the channel output\nfrom the systematic part of the first encoder can be used to decode\nthe second encoder.\n\nAlso note that `constraint_length` and `memory` are two different\nterms often used to denote the strength of the convolutional code. In\nthis sub-package we use `constraint_length`. For example, the polynomial\n<cite>10011</cite> has a `constraint_length` of 5, however its `memory` is\nonly 4.\n\nWhen `terminate` is <cite>True</cite>, the true rate of the Turbo code is\nslightly lower than `rate`. It can be computed as\n$\\frac{k}{\\frac{k}{r}+\\frac{4\\mu}{3r}}$ where <cite>r</cite> denotes\n`rate` and $\\mu$ is the `constraint_length` - 1. For example, in\n3GPP, `constraint_length` = 4, `terminate` = <cite>True</cite>, for\n`rate` = 1/3, true rate is equal to  $\\frac{k}{3k+12}$ .\n\n`property` `coderate`\n\nRate of the code used in the encoder\n\n\n`property` `constraint_length`\n\nConstraint length of the encoder\n\n\n`property` `gen_poly`\n\nGenerator polynomial used by the encoder\n\n\n`property` `k`\n\nNumber of information bits per codeword\n\n\n`property` `n`\n\nNumber of codeword bits\n\n\n`property` `punct_pattern`\n\nPuncturing pattern for the Turbo codeword\n\n\n`property` `terminate`\n\nIndicates if the convolutional encoders are terminated\n\n\n`property` `trellis`\n\nTrellis object used during encoding"
"## Turbo Decoding\n\n`class` `sionna.fec.turbo.``TurboDecoder`(*`encoder``=``None`*, *`gen_poly``=``None`*, *`rate``=``1` `/` `3`*, *`constraint_length``=``None`*, *`interleaver``=``'3GPP'`*, *`terminate``=``False`*, *`num_iter``=``6`*, *`hard_out``=``True`*, *`algorithm``=``'map'`*, *`output_dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/turbo/decoding.html#TurboDecoder)\n\nTurbo code decoder based on BCJR component decoders [[Berrou]](https://nvlabs.github.io/sionna/api/fec.turbo.html#berrou).\nTakes as input LLRs and returns LLRs or hard decided bits, i.e., an\nestimate of the information tensor.\n\nThis decoder is based on the [`BCJRDecoder`](fec.conv.html#sionna.fec.conv.BCJRDecoder)\nand, thus, internally instantiates two\n[`BCJRDecoder`](fec.conv.html#sionna.fec.conv.BCJRDecoder) layers.\n\nThe class inherits from the Keras layer class and can be used as layer in\na Keras model.\nParameters\n\n- **encoder** ([`TurboEncoder`](https://nvlabs.github.io/sionna/api/fec.turbo.html#sionna.fec.turbo.TurboEncoder))  If `encoder` is provided as input, the following input parameters\nare not required and will be ignored: <cite>gen_poly</cite>, <cite>rate</cite>,\n<cite>constraint_length</cite>, <cite>terminate</cite>, <cite>interleaver</cite>. They will be inferred\nfrom the `encoder` object itself.\nIf `encoder` is <cite>None</cite>, the above parameters must be provided\nexplicitly.\n- **gen_poly** (*tuple*)  Tuple of strings with each string being a 0, 1 sequence. If <cite>None</cite>,\n`rate` and `constraint_length` must be provided.\n- **rate** (*float*)  Rate of the Turbo code. Valid values are 1/3 and 1/2. Note that\n`gen_poly`, if provided, is used to encode the underlying\nconvolutional code, which traditionally has rate 1/2.\n- **constraint_length** (*int*)  Valid values are between 3 and 6 inclusive. Only required if\n`encoder` and `gen_poly` are <cite>None</cite>.\n- **interleaver** (*str*)  <cite>3GPP</cite> or <cite>Random</cite>. If <cite>3GPP</cite>, the internal interleaver for Turbo\ncodes as specified in [[3GPPTS36212_Turbo]](https://nvlabs.github.io/sionna/api/fec.turbo.html#gppts36212-turbo) will be used. Only required\nif `encoder` is <cite>None</cite>.\n- **terminate** (*bool*)  If <cite>True</cite>, the two underlying convolutional encoders are assumed\nto have terminated to all zero state.\n- **num_iter** (*int*)  Number of iterations for the Turbo decoding to run. Each iteration of\nTurbo decoding entails one BCJR decoder for each of the underlying\nconvolutional code components.\n- **hard_out** (*boolean*)  Defaults to <cite>True</cite> and indicates whether to output hard or soft\ndecisions on the decoded information vector. <cite>True</cite> implies a hard-\ndecoded information vector of 0/1s is output. <cite>False</cite> implies\ndecoded LLRs of the information is output.\n- **algorithm** (*str*)  Defaults to <cite>map</cite>. Indicates the implemented BCJR algorithm,\nwhere <cite>map</cite> denotes the exact MAP algorithm, <cite>log</cite> indicates the\nexact MAP implementation, but in log-domain, and\n<cite>maxlog</cite> indicates the approximated MAP implementation in log-domain,\nwhere $\\log(e^{a}+e^{b}) \\sim \\max(a,b)$.\n- **output_dtype** (*tf.DType*)  Defaults to <cite>tf.float32</cite>. Defines the output datatype of the layer.\n\n\nInput\n\n**inputs** (*tf.float32*)  2+D tensor of shape <cite>[,n]</cite> containing the (noisy) channel\noutput symbols where <cite>n</cite> is the codeword length\n\nOutput\n\n*tf.float32*  2+D tensor of shape <cite>[,coderate*n]</cite> containing the estimates of the\ninformation bit tensor\n\n\n**Note**\n\nFor decoding, input <cite>logits</cite> defined as\n$\\operatorname{log} \\frac{p(x=1)}{p(x=0)}$ are assumed for\ncompatibility with the rest of Sionna. Internally,\nlog-likelihood ratios (LLRs) with definition\n$\\operatorname{log} \\frac{p(x=0)}{p(x=1)}$ are used.\n\n`property` `coderate`\n\nRate of the code used in the encoder\n\n\n`property` `constraint_length`\n\nConstraint length of the encoder\n\n\n`depuncture`(*`y`*)[`[source]`](../_modules/sionna/fec/turbo/decoding.html#TurboDecoder.depuncture)\n\nGiven a tensor <cite>y</cite> of shape <cite>[batch, n]</cite>, depuncture() scatters <cite>y</cite>\nelements into shape <cite>[batch, 3*rate*n]</cite> where the\nextra elements are filled with 0.\n\nFor e.g., if input is <cite>y</cite>, rate is 1/2 and\n<cite>punct_pattern</cite> is [1, 1, 0, 1, 0, 1], then the\noutput is [y[0], y[1], 0., y[2], 0., y[3], y[4], y[5], 0.,  ,].\n\n\n`property` `gen_poly`\n\nGenerator polynomial used by the encoder\n\n\n`property` `k`\n\nNumber of information bits per codeword\n\n\n`property` `n`\n\nNumber of codeword bits\n\n\n`property` `trellis`\n\nTrellis object used during encoding"
"### TurboTermination\n\n`class` `sionna.fec.turbo.``TurboTermination`(*`constraint_length`*, *`conv_n``=``2`*, *`num_conv_encs``=``2`*, *`num_bit_streams``=``3`*)[`[source]`](../_modules/sionna/fec/turbo/utils.html#TurboTermination)\n\nTermination object, handles the transformation of termination bits from\nthe convolutional encoders to a Turbo codeword. Similarly, it handles the\ntransformation of channel symbols corresponding to the termination of a\nTurbo codeword to the underlying convolutional codewords.\nParameters\n\n- **constraint_length** (*int*)  Constraint length of the convolutional encoder used in the Turbo code.\nNote that the memory of the encoder is `constraint_length` - 1.\n- **conv_n** (*int*)  Number of output bits for one state transition in the underlying\nconvolutional encoder\n- **num_conv_encs** (*int*)  Number of parallel convolutional encoders used in the Turbo code\n- **num_bit_streams** (*int*)  Number of output bit streams from Turbo code\n\n\n`get_num_term_syms`()[`[source]`](../_modules/sionna/fec/turbo/utils.html#TurboTermination.get_num_term_syms)\n\nComputes the number of termination symbols for the Turbo\ncode based on the underlying convolutional code parameters,\nprimarily the memory $\\mu$.\nNote that it is assumed that one Turbo symbol implies\n`num_bitstreams` bits.\nInput\n\n**None**\n\nOutput\n\n**turbo_term_syms** (*int*)  Total number of termination symbols for the Turbo Code. One\nsymbol equals `num_bitstreams` bits.\n\n\n`term_bits_turbo2conv`(*`term_bits`*)[`[source]`](../_modules/sionna/fec/turbo/utils.html#TurboTermination.term_bits_turbo2conv)\n\nThis method splits the termination symbols from a Turbo codeword\nto the termination symbols corresponding to the two convolutional\nencoders, respectively.\n\nLets assume $\\mu=4$ and the underlying convolutional encoders\nare systematic and rate-1/2, for demonstration purposes.\n\nLet `term_bits` tensor, corresponding to the termination symbols of\nthe Turbo codeword be as following:\n\n$y = [x_1(K), z_1(K), x_1(K+1), z_1(K+1), x_1(K+2), z_1(K+2)$,\n$x_1(K+3), z_1(K+3), x_2(K), z_2(K), x_2(K+1), z_2(K+1),$\n$x_2(K+2), z_2(K+2), x_2(K+3), z_2(K+3), 0, 0]$\n\nThe two termination tensors corresponding to the convolutional encoders\nare:\n$y[0,..., 2\\mu]$, $y[2\\mu,..., 4\\mu]$. The output from this method is a tuple of two tensors, each of\nsize $2\\mu$ and shape $[\\mu,2]$.\n\n$[[x_1(K), z_1(K)]$,\n\n$[x_1(K+1), z_1(K+1)]$,\n\n$[x_1(K+2, z_1(K+2)]$,\n\n$[x_1(K+3), z_1(K+3)]]$\n\nand\n\n$[[x_2(K), z_2(K)],$\n\n$[x_2(K+1), z_2(K+1)]$,\n\n$[x_2(K+2), z_2(K+2)]$,\n\n$[x_2(K+3), z_2(K+3)]]$\nInput\n\n**term_bits** (*tf.float32*)  Channel output of the Turbo codeword, corresponding to the\ntermination part\n\nOutput\n\n*tf.float32*  Two tensors of channel outputs, corresponding to encoders 1 and 2,\nrespectively\n\n\n`termbits_conv2turbo`(*`term_bits1`*, *`term_bits2`*)[`[source]`](../_modules/sionna/fec/turbo/utils.html#TurboTermination.termbits_conv2turbo)\n\nThis method merges `term_bits1` and `term_bits2`, termination\nbit streams from the two convolutional encoders, to a bit stream\ncorresponding to the Turbo codeword.\n\nLet `term_bits1` and `term_bits2` be:\n\n$[x_1(K), z_1(K), x_1(K+1), z_1(K+1),..., x_1(K+\\mu-1),z_1(K+\\mu-1)]$\n\n$[x_2(K), z_2(K), x_2(K+1), z_2(K+1),..., x_2(K+\\mu-1), z_2(K+\\mu-1)]$\n\nwhere $x_i, z_i$ are the systematic and parity bit streams\nrespectively for a rate-1/2 convolutional encoder i, for i = 1, 2.\n\nIn the example output below, we assume $\\mu=4$ to demonstrate zero\npadding at the end. Zero padding is done such that the total length is\ndivisible by `num_bitstreams` (defaults to  3) which is the number of\nTurbo bit streams.\n\nAssume `num_bitstreams` = 3. Then number of termination symbols for\nthe TurboEncoder is $\\lceil \\frac{2*conv\\_n*\\mu}{3} \\rceil$:\n\n$[x_1(K), z_1(K), x_1(K+1)]$\n\n$[z_1(K+1), x_1(K+2, z_1(K+2)]$\n\n$[x_1(K+3), z_1(K+3), x_2(K)]$\n\n$[z_2(K), x_2(K+1), z_2(K+1)]$\n\n$[x_2(K+2), z_2(K+2), x_2(K+3)]$\n\n$[z_2(K+3), 0, 0]$\n\nTherefore, the output from this method is a single dimension vector\nwhere all Turbo symbols are concatenated together.\n\n$[x_1(K), z_1(K), x_1(K+1), z_1(K+1), x_1(K+2, z_1(K+2), x_1(K+3),$\n\n$z_1(K+3), x_2(K),z_2(K), x_2(K+1), z_2(K+1), x_2(K+2), z_2(K+2),$\n\n$x_2(K+3), z_2(K+3), 0, 0]$\nInput\n\n- **term_bits1** (*tf.int32*)  2+D Tensor containing termination bits from convolutional encoder 1\n- **term_bits2** (*tf.int32*)  2+D Tensor containing termination bits from convolutional encoder 2\n\n\nOutput\n\n*tf.int32*  1+D tensor of termination bits. The output is obtained by\nconcatenating the inputs and then adding right zero-padding if\nneeded."
"### polynomial_selector\n\n`sionna.fec.turbo.utils.``polynomial_selector`(*`constraint_length`*)[`[source]`](../_modules/sionna/fec/turbo/utils.html#polynomial_selector)\n\nReturns the generator polynomials for rate-1/2 convolutional codes\nfor a given `constraint_length`.\nInput\n\n**constraint_length** (*int*)  An integer defining the desired constraint length of the encoder.\nThe memory of the encoder is `constraint_length` - 1.\n\nOutput\n\n**gen_poly** (*tuple*)  Tuple of strings with each string being a 0,1 sequence where\neach polynomial is represented in binary form.\n\n\n**Note**\n\nPlease note that the polynomials are optimized for rsc codes and are\nnot necessarily the same as used in the polynomial selector\n[`polynomial_selector`](fec.conv.html#sionna.fec.conv.utils.polynomial_selector) of the\nconvolutional codes."
"### puncture_pattern\n\n`sionna.fec.turbo.utils.``puncture_pattern`(*`turbo_coderate`*, *`conv_coderate`*)[`[source]`](../_modules/sionna/fec/turbo/utils.html#puncture_pattern)\n\nThis method returns puncturing pattern such that the\nTurbo code has rate `turbo_coderate` given the underlying\nconvolutional encoder is of rate `conv_coderate`.\nInput\n\n- **turbo_coderate** (*float*)  Desired coderate of the Turbo code\n- **conv_coderate** (*float*)  Coderate of the underlying convolutional encoder\n\n\nOutput\n\n*tf.bool*  2D tensor indicating the positions to be punctured.\n\n\nReferences:\nBerrou([1](https://nvlabs.github.io/sionna/api/fec.turbo.html#id1),[2](https://nvlabs.github.io/sionna/api/fec.turbo.html#id2),[3](https://nvlabs.github.io/sionna/api/fec.turbo.html#id3),[4](https://nvlabs.github.io/sionna/api/fec.turbo.html#id5))\n<ol class=\"upperalpha simple\" start=\"3\">\n- Berrou, A. Glavieux, P. Thitimajshima, Near Shannon limit error-correcting coding and decoding: Turbo-codes, IEEE ICC, 1993.\n</ol>\n\n3GPPTS36212_Turbo([1](https://nvlabs.github.io/sionna/api/fec.turbo.html#id4),[2](https://nvlabs.github.io/sionna/api/fec.turbo.html#id6))\n\nETSI 3GPP TS 36.212 Evolved Universal Terrestrial\nRadio Access (EUTRA); Multiplexing and channel coding, v.15.3.0, 2018-09."
"## (Binary) Linear Codes\n\nSeveral functions are provided to convert parity-check matrices into generator matrices and vice versa. Please note that currently only binary codes are supported.\n```python\n# load example parity-check matrix\npcm, k, n, coderate = load_parity_check_examples(pcm_id=3)\n```\n\n\nNote that many research projects provide their parity-check matrices in the  <cite>alist</cite> format [[MacKay]](https://nvlabs.github.io/sionna/api/fec.utils.html#mackay) (e.g., see [[UniKL]](https://nvlabs.github.io/sionna/api/fec.utils.html#unikl)). The follwing code snippet provides an example of how to import an external LDPC parity-check matrix from an <cite>alist</cite> file and how to set-up an encoder/decoder.\n```python\n# load external example parity-check matrix in alist format\nal = load_alist(path=filename)\npcm, k, n, coderate = alist2mat(al)\n# the linear encoder can be directly initialized with a parity-check matrix\nencoder = LinearEncoder(pcm, is_pcm=True)\n# initalize BP decoder for the given parity-check matrix\ndecoder = LDPCBPDecoder(pcm, num_iter=20)\n# and run simulation with random information bits\nno = 1.\nbatch_size = 10\nnum_bits_per_symbol = 2\nsource = BinarySource()\nmapper = Mapper(\"qam\", num_bits_per_symbol)\nchannel = AWGN()\ndemapper = Demapper(\"app\", \"qam\", num_bits_per_symbol)\nu = source([batch_size, k])\nc = encoder(u)\nx = mapper(c)\ny = channel([x, no])\nllr = demapper([y, no])\nc_hat = decoder(llr)\n```"
"### load_parity_check_examples\n\n`sionna.fec.utils.``load_parity_check_examples`(*`pcm_id`*, *`verbose``=``False`*)[`[source]`](../_modules/sionna/fec/utils.html#load_parity_check_examples)\n\nUtility function to load example codes stored in sub-folder LDPC/codes.\n\nThe following codes are available\n\n- 0 : <cite>(7,4)</cite>-Hamming code of length <cite>k=4</cite> information bits and codeword    length <cite>n=7</cite>.\n- 1 : <cite>(63,45)</cite>-BCH code of length <cite>k=45</cite> information bits and codeword    length <cite>n=63</cite>.\n- 2 : (127,106)-BCH code of length <cite>k=106</cite> information bits and codeword    length <cite>n=127</cite>.\n- 3 : Random LDPC code with regular variable node degree 3 and check node degree 6 of length <cite>k=50</cite> information bits and codeword length         <cite>n=100</cite>.\n- 4 : 802.11n LDPC code of length of length <cite>k=324</cite> information bits and    codeword length <cite>n=648</cite>.\n\nInput\n\n- **pcm_id** (*int*)  An integer defining which matrix id to load.\n- **verbose** (*bool*)  Defaults to False. If True, the code parameters are\nprinted.\n\n\nOutput\n\n- **pcm** (ndarray of <cite>zeros</cite> and <cite>ones</cite>)  An ndarray containing the parity check matrix.\n- **k** (*int*)  An integer defining the number of information bits.\n- **n** (*int*)  An integer defining the number of codeword bits.\n- **coderate** (*float*)  A float defining the coderate (assuming full rank of\nparity-check matrix)."
"### alist2mat\n\n`sionna.fec.utils.``alist2mat`(*`alist`*, *`verbose``=``True`*)[`[source]`](../_modules/sionna/fec/utils.html#alist2mat)\n\nConvert <cite>alist</cite> [[MacKay]](https://nvlabs.github.io/sionna/api/fec.utils.html#mackay) code definition to <cite>full</cite> parity-check matrix.\n\nMany code examples can be found in [[UniKL]](https://nvlabs.github.io/sionna/api/fec.utils.html#unikl).\n\nAbout <cite>alist</cite> (see [[MacKay]](https://nvlabs.github.io/sionna/api/fec.utils.html#mackay) for details):\n<blockquote>\n<div>\n- <cite>1.</cite> Row defines parity-check matrix dimension <cite>m x n</cite>\n- <cite>2.</cite> Row defines int with <cite>max_CN_degree</cite>, <cite>max_VN_degree</cite>\n- <cite>3.</cite> Row defines VN degree of all <cite>n</cite> column\n- <cite>4.</cite> Row defines CN degree of all <cite>m</cite> rows\n- Next <cite>n</cite> rows contain non-zero entries of each column (can be zero padded at the end)\n- Next <cite>m</cite> rows contain non-zero entries of each row.\n\n</blockquote>\nInput\n\n- **alist** (*list*)  Nested list in <cite>alist</cite>-format [[MacKay]](https://nvlabs.github.io/sionna/api/fec.utils.html#mackay).\n- **verbose** (*bool*)  Defaults to True. If True, the code parameters are printed.\n\n\nOutput\n\n- **(pcm, k, n, coderate)**  Tuple:\n- **pcm** (*ndarray*)  NumPy array of shape <cite>[n-k, n]</cite> containing the parity-check matrix.\n- **k** (*int*)  Number of information bits.\n- **n** (*int*)  Number of codewords bits.\n- **coderate** (*float*)  Coderate of the code.\n\n\n**Note**\n\nUse [`load_alist`](https://nvlabs.github.io/sionna/api/fec.utils.html#sionna.fec.utils.load_alist) to import alist from a\ntextfile.\n\nFor example, the following code snippet will import an alist from a file called `filename`:"
"### load_alist\n\n`sionna.fec.utils.``load_alist`(*`path`*)[`[source]`](../_modules/sionna/fec/utils.html#load_alist)\n\nRead <cite>alist</cite>-file [[MacKay]](https://nvlabs.github.io/sionna/api/fec.utils.html#mackay) and return nested list describing the\nparity-check matrix of a code.\n\nMany code examples can be found in [[UniKL]](https://nvlabs.github.io/sionna/api/fec.utils.html#unikl).\nInput\n\n**path** (*str*)  Path to file to be loaded.\n\nOutput\n\n**alist** (*list*)  A nested list containing the imported alist data."
"### generate_reg_ldpc\n\n`sionna.fec.utils.``generate_reg_ldpc`(*`v`*, *`c`*, *`n`*, *`allow_flex_len``=``True`*, *`verbose``=``True`*)[`[source]`](../_modules/sionna/fec/utils.html#generate_reg_ldpc)\n\nGenerate random regular (v,c) LDPC codes.\n\nThis functions generates a random LDPC parity-check matrix of length `n`\nwhere each variable node (VN) has degree `v` and each check node (CN) has\ndegree `c`. Please note that the LDPC code is not optimized to avoid\nshort cycles and the resulting codes may show a non-negligible error-floor.\nFor encoding, the `LinearEncoder` layer can be\nused, however, the construction does not guarantee that the pcm has full\nrank.\nInput\n\n- **v** (*int*)  Desired variable node (VN) degree.\n- **c** (*int*)  Desired check node (CN) degree.\n- **n** (*int*)  Desired codeword length.\n- **allow_flex_len** (*bool*)  Defaults to True. If True, the resulting codeword length can be\n(slightly) increased.\n- **verbose** (*bool*)  Defaults to True. If True, code parameters are printed.\n\n\nOutput\n\n- **(pcm, k, n, coderate)**  Tuple:\n- **pcm** (*ndarray*)  NumPy array of shape <cite>[n-k, n]</cite> containing the parity-check matrix.\n- **k** (*int*)  Number of information bits per codeword.\n- **n** (*int*)  Number of codewords bits.\n- **coderate** (*float*)  Coderate of the code.\n\n\n**Note**\n\nThis algorithm works only for regular node degrees. For state-of-the-art\nbit-error-rate performance, usually one needs to optimize irregular degree\nprofiles (see [[tenBrink]](https://nvlabs.github.io/sionna/api/fec.utils.html#tenbrink))."
"### make_systematic\n\n`sionna.fec.utils.``make_systematic`(*`mat`*, *`is_pcm``=``False`*)[`[source]`](../_modules/sionna/fec/utils.html#make_systematic)\n\nBring binary matrix in its systematic form.\nInput\n\n- **mat** (*ndarray*)  Binary matrix to be transformed to systematic form of shape <cite>[k, n]</cite>.\n- **is_pcm** (*bool*)  Defaults to False. If true, `mat` is interpreted as parity-check\nmatrix and, thus, the last k columns will be the identity part.\n\n\nOutput\n\n- **mat_sys** (*ndarray*)  Binary matrix in systematic form, i.e., the first <cite>k</cite> columns equal the\nidentity matrix (or last <cite>k</cite> if `is_pcm` is True).\n- **column_swaps** (*list of int tuples*)  A list of integer tuples that describes the swapped columns (in the\norder of execution).\n\n\n**Note**\n\nThis algorithm (potentially) swaps columns of the input matrix. Thus, the\nresulting systematic matrix (potentially) relates to a permuted version of\nthe code, this is defined by the returned list `column_swap`.\nNote that, the inverse permutation must be applied in the inverse list\norder (in case specific columns are swapped multiple times).\n\nIf a parity-check matrix is passed as input (i.e., `is_pcm` is True), the\nidentity part will be re-arranged to the last columns."
"### gm2pcm\n\n`sionna.fec.utils.``gm2pcm`(*`gm`*, *`verify_results``=``True`*)[`[source]`](../_modules/sionna/fec/utils.html#gm2pcm)\n\nGenerate the parity-check matrix for a given generator matrix.\n\nThis function brings `gm` $\\mathbf{G}$ in its systematic form and\nuses the following relation to find the parity-check matrix\n$\\mathbf{H}$ in GF(2)\n\n$$\n\\mathbf{G} = [\\mathbf{I} |  \\mathbf{M}]\n\\Leftrightarrow \\mathbf{H} = [\\mathbf{M} ^t | \\mathbf{I}]. \\tag{1}\n$$\n\nThis follows from the fact that for an all-zero syndrome, it must hold that\n\n$$\n\\mathbf{H} \\mathbf{c}^t = \\mathbf{H} * (\\mathbf{u} * \\mathbf{G})^t =\n\\mathbf{H} * \\mathbf{G} ^t * \\mathbf{u}^t =: \\mathbf{0}\n$$\n\nwhere $\\mathbf{c}$ denotes an arbitrary codeword and\n$\\mathbf{u}$ the corresponding information bits.\n\nThis leads to\n\n$$\n\\mathbf{G} * \\mathbf{H} ^t =: \\mathbf{0}. \\tag{2}\n$$\n\nIt can be seen that (1) fulfills (2), as it holds in GF(2) that\n\n$$\n[\\mathbf{I} |  \\mathbf{M}] * [\\mathbf{M} ^t | \\mathbf{I}]^t\n = \\mathbf{M} + \\mathbf{M} = \\mathbf{0}.\n$$\n\nInput\n\n- **gm** (*ndarray*)  Binary generator matrix of shape <cite>[k, n]</cite>.\n- **verify_results** (*bool*)  Defaults to True. If True, it is verified that the generated\nparity-check matrix is orthogonal to the generator matrix in GF(2).\n\n\nOutput\n\n*ndarray*  Binary parity-check matrix of shape <cite>[n-k, n]</cite>.\n\n\n**Note**\n\nThis algorithm only works if `gm` has full rank. Otherwise an error is\nraised."
"### pcm2gm\n\n`sionna.fec.utils.``pcm2gm`(*`pcm`*, *`verify_results``=``True`*)[`[source]`](../_modules/sionna/fec/utils.html#pcm2gm)\n\nGenerate the generator matrix for a given parity-check matrix.\n\nThis function brings `pcm` $\\mathbf{H}$ in its systematic form and\nuses the following relation to find the generator matrix\n$\\mathbf{G}$ in GF(2)\n\n$$\n\\mathbf{G} = [\\mathbf{I} |  \\mathbf{M}]\n\\Leftrightarrow \\mathbf{H} = [\\mathbf{M} ^t | \\mathbf{I}]. \\tag{1}\n$$\n\nThis follows from the fact that for an all-zero syndrome, it must hold that\n\n$$\n\\mathbf{H} \\mathbf{c}^t = \\mathbf{H} * (\\mathbf{u} * \\mathbf{G})^t =\n\\mathbf{H} * \\mathbf{G} ^t * \\mathbf{u}^t =: \\mathbf{0}\n$$\n\nwhere $\\mathbf{c}$ denotes an arbitrary codeword and\n$\\mathbf{u}$ the corresponding information bits.\n\nThis leads to\n\n$$\n\\mathbf{G} * \\mathbf{H} ^t =: \\mathbf{0}. \\tag{2}\n$$\n\nIt can be seen that (1) fulfills (2) as in GF(2) it holds that\n\n$$\n[\\mathbf{I} |  \\mathbf{M}] * [\\mathbf{M} ^t | \\mathbf{I}]^t\n = \\mathbf{M} + \\mathbf{M} = \\mathbf{0}.\n$$\n\nInput\n\n- **pcm** (*ndarray*)  Binary parity-check matrix of shape <cite>[n-k, n]</cite>.\n- **verify_results** (*bool*)  Defaults to True. If True, it is verified that the generated\ngenerator matrix is orthogonal to the parity-check matrix in GF(2).\n\n\nOutput\n\n*ndarray*  Binary generator matrix of shape <cite>[k, n]</cite>.\n\n\n**Note**\n\nThis algorithm only works if `pcm` has full rank. Otherwise an error is\nraised."
"### verify_gm_pcm\n\n`sionna.fec.utils.``verify_gm_pcm`(*`gm`*, *`pcm`*)[`[source]`](../_modules/sionna/fec/utils.html#verify_gm_pcm)\n\nVerify that generator matrix $\\mathbf{G}$ `gm` and parity-check\nmatrix $\\mathbf{H}$ `pcm` are orthogonal in GF(2).\n\nFor an all-zero syndrome, it must hold that\n\n$$\n\\mathbf{H} \\mathbf{c}^t = \\mathbf{H} * (\\mathbf{u} * \\mathbf{G})^t =\n\\mathbf{H} * \\mathbf{G} ^t * \\mathbf{u}^t =: \\mathbf{0}\n$$\n\nwhere $\\mathbf{c}$ denotes an arbitrary codeword and\n$\\mathbf{u}$ the corresponding information bits.\n\nAs $\\mathbf{u}$ can be arbitrary it follows that\n\n$$\n\\mathbf{H} * \\mathbf{G} ^t =: \\mathbf{0}.\n$$\n\nInput\n\n- **gm** (*ndarray*)  Binary generator matrix of shape <cite>[k, n]</cite>.\n- **pcm** (*ndarray*)  Binary parity-check matrix of shape <cite>[n-k, n]</cite>.\n\n\nOutput\n\n*bool*  True if `gm` and `pcm` define a valid pair of parity-check and\ngenerator matrices in GF(2)."
"## EXIT Analysis\n\nThe LDPC BP decoder allows to track the internal information flow (<cite>extrinsic information</cite>) during decoding. This can be plotted in so-called EXIT Charts [[tenBrinkEXIT]](https://nvlabs.github.io/sionna/api/fec.utils.html#tenbrinkexit) to visualize the decoding convergence.\n\nThis short code snippet shows how to generate and plot EXIT charts:\n```python\n# parameters\nebno_db = 2.5 # simulation SNR\nbatch_size = 10000\nnum_bits_per_symbol = 2 # QPSK\npcm_id = 4 # decide which parity check matrix should be used (0-2: BCH; 3: (3,6)-instruction_answer 4: instruction_answer 802.11n\npcm, k, n , coderate = load_parity_check_examples(pcm_id, verbose=True)\nnoise_var = ebnodb2no(ebno_db=ebno_db,\n                      num_bits_per_symbol=num_bits_per_symbol,\n                      coderate=coderate)\n# init components\ndecoder = LDPCBPDecoder(pcm,\n                        hard_out=False,\n                        cn_type=\"boxplus\",\n                        trainable=False,\n                        track_exit=True, # if activated, the decoder stores the outgoing extrinsic mutual information per iteration\n                        num_iter=20)\n# generates fake llrs as if the all-zero codeword was transmitted over an AWNG channel with BPSK modulation\nllr_source = GaussianPriorSource()\n\n# generate fake LLRs (Gaussian approximation)\nllr = llr_source([[batch_size, n], noise_var])\n# simulate free running decoder (for EXIT trajectory)\ndecoder(llr)\n# calculate analytical EXIT characteristics\n# Hint: these curves assume asymptotic code length, i.e., may become inaccurate in the short length regime\nIa, Iev, Iec = get_exit_analytic(pcm, ebno_db)\n# and plot the analytical exit curves\nplt = plot_exit_chart(Ia, Iev, Iec)\n# and add simulated trajectory (requires \"track_exit=True\")\nplot_trajectory(plt, decoder.ie_v, decoder.ie_c, ebno_db)\n```\n\n\nRemark: for rate-matched 5G LDPC codes, the EXIT approximation becomes\ninaccurate due to the rate-matching and the very specific structure of the\ncode."
"### plot_exit_chart\n\n`sionna.fec.utils.``plot_exit_chart`(*`mi_a``=``None`*, *`mi_ev``=``None`*, *`mi_ec``=``None`*, *`title``=``'EXIT-Chart'`*)[`[source]`](../_modules/sionna/fec/utils.html#plot_exit_chart)\n\nUtility function to plot EXIT-Charts [[tenBrinkEXIT]](https://nvlabs.github.io/sionna/api/fec.utils.html#tenbrinkexit).\n\nIf all inputs are <cite>None</cite> an empty EXIT chart is generated. Otherwise,\nthe mutual information curves are plotted.\nInput\n\n- **mi_a** (*float*)  An ndarray of floats containing the a priori mutual\ninformation.\n- **mi_v** (*float*)  An ndarray of floats containing the variable node mutual\ninformation.\n- **mi_c** (*float*)  An ndarray of floats containing the check node mutual\ninformation.\n- **title** (*str*)  A string defining the title of the EXIT chart.\n\n\nOutput\n\n**plt** (*matplotlib.figure*)  A matplotlib figure handle\n\nRaises\n\n**AssertionError**  If `title` is not <cite>str</cite>."
"### get_exit_analytic\n\n`sionna.fec.utils.``get_exit_analytic`(*`pcm`*, *`ebno_db`*)[`[source]`](../_modules/sionna/fec/utils.html#get_exit_analytic)\n\nCalculate the analytic EXIT-curves for a given parity-check matrix.\n\nThis function extracts the degree profile from `pcm` and calculates the\nvariable (VN) and check node (CN) decoder EXIT curves. Please note that\nthis is an asymptotic tool which needs a certain codeword length for\naccurate predictions.\n\nTransmission over an AWGN channel with BPSK modulation and SNR `ebno_db`\nis assumed. The detailed equations can be found in [[tenBrink]](https://nvlabs.github.io/sionna/api/fec.utils.html#tenbrink) and\n[[tenBrinkEXIT]](https://nvlabs.github.io/sionna/api/fec.utils.html#tenbrinkexit).\nInput\n\n- **pcm** (*ndarray*)  The parity-check matrix.\n- **ebno_db** (*float*)  The channel SNR in dB.\n\n\nOutput\n\n- **mi_a** (*ndarray of floats*)  NumPy array containing the <cite>a priori</cite> mutual information.\n- **mi_ev** (*ndarray of floats*)  NumPy array containing the extrinsic mutual information of the\nvariable node decoder for the corresponding `mi_a`.\n- **mi_ec** (*ndarray of floats*)  NumPy array containing the extrinsic mutual information of the check\nnode decoder for the corresponding `mi_a`.\n\n\n**Note**\n\nThis function assumes random parity-check matrices without any imposed\nstructure. Thus, explicit code construction algorithms may lead\nto inaccurate EXIT predictions. Further, this function is based\non asymptotic properties of the code, i.e., only works well for large\nparity-check matrices. For details see [[tenBrink]](https://nvlabs.github.io/sionna/api/fec.utils.html#tenbrink)."
"### plot_trajectory\n\n`sionna.fec.utils.``plot_trajectory`(*`plot`*, *`mi_v`*, *`mi_c`*, *`ebno``=``None`*)[`[source]`](../_modules/sionna/fec/utils.html#plot_trajectory)\n\nUtility function to plot the trajectory of an EXIT-chart.\nInput\n\n- **plot** (*matplotlib.figure*)  A handle to a matplotlib figure.\n- **mi_v** (*float*)  An ndarray of floats containing the variable node mutual\ninformation.\n- **mi_c** (*float*)  An ndarray of floats containing the check node mutual\ninformation.\n- **ebno** (*float*)  A float denoting the EbNo in dB for the legend entry."
"### GaussianPriorSource\n\n`class` `sionna.fec.utils.``GaussianPriorSource`(*`specified_by_mi``=``False`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/fec/utils.html#GaussianPriorSource)\n\nGenerates <cite>fake</cite> LLRs as if the all-zero codeword was transmitted\nover an Bi-AWGN channel with noise variance `no` or mutual information\n(if `specified_by_mi` is True). If selected, the mutual information\ndenotes the mutual information associated with a binary random variable\nobserved at the output of a corresponding AWGN channel (cf. Gaussian\napproximation).\n\nThe generated LLRs are drawn from a Gaussian distribution with\n\n$$\n\\sigma_{\\text{llr}}^2 = \\frac{4}{\\sigma_\\text{ch}^2}\n$$\n\nand\n\n$$\n\\mu_{\\text{llr}} = \\frac{\\sigma_\\text{llr}^2}{2}\n$$\n\nwhere $\\sigma_\\text{ch}^2$ is the channel noise variance as defined by\n`no`.\n\nIf `specified_by_mi` is True, this class uses the of the so-called\n<cite>J-function</cite> (relates mutual information to Gaussian distributed LLRs) as\nproposed in [[Brannstrom]](https://nvlabs.github.io/sionna/api/fec.utils.html#brannstrom).\nParameters\n\n- **specified_by_mi** (*bool*)  Defaults to False. If True, the second input parameter `no` is\ninterpreted as mutual information instead of noise variance.\n- **dtype** (*tf.DType*)  Defaults to <cite>tf.float32</cite>. Defines the datatype for internal\ncalculations and the output. Must be one of the following\n<cite>(tf.float16, tf.bfloat16, tf.float32, tf.float64)</cite>.\n\n\nInput\n\n- **(output_shape, no)**  Tuple:\n- **output_shape** (*tf.int*)  Integer tensor or Python array defining the shape of the desired\noutput tensor.\n- **no** (*tf.float32*)  Scalar defining the noise variance or mutual information (if\n`specified_by_mi` is True) of the corresponding (fake) AWGN\nchannel.\n\n\nOutput\n\n`dtype`, defaults to <cite>tf.float32</cite>  1+D Tensor with shape as defined by `output_shape`.\n\nRaises\n\n- **InvalidArgumentError**  If mutual information is not in (0,1).\n- **AssertionError**  If `inputs` is not a list with 2 elements."
"### bin2int\n\n`sionna.fec.utils.``bin2int`(*`arr`*)[`[source]`](../_modules/sionna/fec/utils.html#bin2int)\n\nConvert binary array to integer.\n\nFor example `arr` = <cite>[1, 0, 1]</cite> is converted to <cite>5</cite>.\nInput\n\n**arr** (*int or float*)  An iterable that yields 0s and 1s.\n\nOutput\n\n*int*  Integer representation of `arr`."
"### int2bin\n\n`sionna.fec.utils.``int2bin`(*`num`*, *`len_`*)[`[source]`](../_modules/sionna/fec/utils.html#int2bin)\n\nConvert `num` of int type to list of length `len_` with 0s and 1s.\n`num` and `len_` have to non-negative.\n\nFor e.g., `num` = <cite>5</cite>; <cite>int2bin(num</cite>, `len_` =4) = <cite>[0, 1, 0, 1]</cite>.\n\nFor e.g., `num` = <cite>12</cite>; <cite>int2bin(num</cite>, `len_` =3) = <cite>[1, 0, 0]</cite>.\nInput\n\n- **num** (*int*)  An integer to be converted into binary representation.\n- **len_** (*int*)  An integer defining the length of the desired output.\n\n\nOutput\n\n*list of int*  Binary representation of `num` of length `len_`."
"### bin2int_tf\n\n`sionna.fec.utils.``bin2int_tf`(*`arr`*)[`[source]`](../_modules/sionna/fec/utils.html#bin2int_tf)\n\nConverts binary tensor to int tensor. Binary representation in `arr`\nis across the last dimension from most significant to least significant.\n\nFor example `arr` = <cite>[0, 1, 1]</cite> is converted to <cite>3</cite>.\nInput\n\n**arr** (*int or float*)  Tensor of  0s and 1s.\n\nOutput\n\n*int*  Tensor containing the integer representation of `arr`."
"### int2bin_tf\n\n`sionna.fec.utils.``int2bin_tf`(*`ints`*, *`len_`*)[`[source]`](../_modules/sionna/fec/utils.html#int2bin_tf)\n\nConverts (int) tensor to (int) tensor with 0s and 1s. <cite>len_</cite> should be\nto non-negative. Additional dimension of size <cite>len_</cite> is inserted at end.\nInput\n\n- **ints** (*int*)  Tensor of arbitrary shape <cite>[,k]</cite> containing integer to be\nconverted into binary representation.\n- **len_** (*int*)  An integer defining the length of the desired output.\n\n\nOutput\n\n*int*  Tensor of same shape as `ints` except dimension of length\n`len_` is added at the end <cite>[,k, len_]</cite>. Contains the binary\nrepresentation of `ints` of length `len_`."
"### int_mod_2\n\n`sionna.fec.utils.``int_mod_2`(*`x`*)[`[source]`](../_modules/sionna/fec/utils.html#int_mod_2)\n\nEfficient implementation of modulo 2 operation for integer inputs.\n\nThis function assumes integer inputs or implicitly casts to int.\n\nRemark: the function <cite>tf.math.mod(x, 2)</cite> is placed on the CPU and, thus,\ncauses unnecessary memory copies.\nParameters\n\n**x** (*tf.Tensor*)  Tensor to which the modulo 2 operation is applied."
"### llr2mi\n\n`sionna.fec.utils.``llr2mi`(*`llr`*, *`s``=``None`*, *`reduce_dims``=``True`*)[`[source]`](../_modules/sionna/fec/utils.html#llr2mi)\n\nImplements an approximation of the mutual information based on LLRs.\n\nThe function approximates the mutual information for given `llr` as\nderived in [[Hagenauer]](https://nvlabs.github.io/sionna/api/fec.utils.html#hagenauer) assuming an <cite>all-zero codeword</cite> transmission\n\n$$\nI \\approx 1 - \\sum \\operatorname{log_2} \\left( 1 + \\operatorname{e}^{-\\text{llr}} \\right).\n$$\n\nThis approximation assumes that the following <cite>symmetry condition</cite> is fulfilled\n\n$$\np(\\text{llr}|x=0) = p(\\text{llr}|x=1) \\cdot \\operatorname{exp}(\\text{llr}).\n$$\n\nFor <cite>non-all-zero</cite> codeword transmissions, this methods requires knowledge\nabout the signs of the original bit sequence `s` and flips the signs\ncorrespondingly (as if the all-zero codeword was transmitted).\n\nPlease note that we define LLRs as $\\frac{p(x=1)}{p(x=0)}$, i.e.,\nthe sign of the LLRs differ to the solution in [[Hagenauer]](https://nvlabs.github.io/sionna/api/fec.utils.html#hagenauer).\nInput\n\n- **llr** (*tf.float32*)  Tensor of arbitrary shape containing LLR-values.\n- **s** (*None or tf.float32*)  Tensor of same shape as llr containing the signs of the\ntransmitted sequence (assuming BPSK), i.e., +/-1 values.\n- **reduce_dims** (*bool*)  Defaults to True. If True, all dimensions are\nreduced and the return is a scalar. Otherwise, <cite>reduce_mean</cite> is\nonly taken over the last dimension.\n\n\nOutput\n\n**mi** (*tf.float32*)  A scalar tensor (if `reduce_dims` is True) or a tensor of same\nshape as `llr` apart from the last dimensions that is removed.\nIt contains the approximated value of the mutual information.\n\nRaises\n\n**TypeError**  If dtype of `llr` is not a real-valued float."
"### j_fun\n\n`sionna.fec.utils.``j_fun`(*`mu`*)[`[source]`](../_modules/sionna/fec/utils.html#j_fun)\n\nCalculates the <cite>J-function</cite> in NumPy.\n\nThe so-called <cite>J-function</cite> relates mutual information to the mean of\nGaussian distributed LLRs (cf. Gaussian approximation). We use the\napproximation as proposed in [[Brannstrom]](https://nvlabs.github.io/sionna/api/fec.utils.html#brannstrom) which can be written as\n\n$$\nJ(\\mu) \\approx \\left( 1- 2^{H_\\text{1}(2\\mu)^{H_\\text{2}}}\\right)^{H_\\text{2}}\n$$\n\nwith $\\mu$ denoting the mean value of the LLR distribution and\n$H_\\text{1}=0.3073$, $H_\\text{2}=0.8935$ and\n$H_\\text{3}=1.1064$.\nInput\n\n**mu** (*float*)  float or <cite>ndarray</cite> of float.\n\nOutput\n\n*float*  <cite>ndarray</cite> of same shape as the input."
"### j_fun_inv\n\n`sionna.fec.utils.``j_fun_inv`(*`mi`*)[`[source]`](../_modules/sionna/fec/utils.html#j_fun_inv)\n\nCalculates the inverse <cite>J-function</cite> in NumPy.\n\nThe so-called <cite>J-function</cite> relates mutual information to the mean of\nGaussian distributed LLRs (cf. Gaussian approximation). We use the\napproximation as proposed in [[Brannstrom]](https://nvlabs.github.io/sionna/api/fec.utils.html#brannstrom) which can be written as\n\n$$\nJ(\\mu) \\approx \\left( 1- 2^{H_\\text{1}(2\\mu)^{H_\\text{2}}}\\right)^{H_\\text{2}}\n$$\n\nwith $\\mu$ denoting the mean value of the LLR distribution and\n$H_\\text{1}=0.3073$, $H_\\text{2}=0.8935$ and\n$H_\\text{3}=1.1064$.\nInput\n\n**mi** (*float*)  float or <cite>ndarray</cite> of float.\n\nOutput\n\n*float*  <cite>ndarray</cite> of same shape as the input.\n\nRaises\n\n**AssertionError**  If `mi` < 0.001 or `mi` > 0.999."
"### j_fun_tf\n\n`sionna.fec.utils.``j_fun_tf`(*`mu`*, *`verify_inputs``=``True`*)[`[source]`](../_modules/sionna/fec/utils.html#j_fun_tf)\n\nCalculates the <cite>J-function</cite> in Tensorflow.\n\nThe so-called <cite>J-function</cite> relates mutual information to the mean of\nGaussian distributed LLRs (cf. Gaussian approximation). We use the\napproximation as proposed in [[Brannstrom]](https://nvlabs.github.io/sionna/api/fec.utils.html#brannstrom) which can be written as\n\n$$\nJ(\\mu) \\approx \\left( 1- 2^{H_\\text{1}(2\\mu)^{H_\\text{2}}}\\right)^{H_\\text{2}}\n$$\n\nwith $\\mu$ denoting the mean value of the LLR distribution and\n$H_\\text{1}=0.3073$, $H_\\text{2}=0.8935$ and\n$H_\\text{3}=1.1064$.\nInput\n\n- **mu** (*tf.float32*)  Tensor of arbitrary shape.\n- **verify_inputs** (*bool*)  A boolean defaults to True. If True, `mu` is clipped internally\nto be numerical stable.\n\n\nOutput\n\n*tf.float32*  Tensor of same shape and dtype as `mu`.\n\nRaises\n\n**InvalidArgumentError**  If `mu` is negative."
"### j_fun_inv_tf\n\n`sionna.fec.utils.``j_fun_inv_tf`(*`mi`*, *`verify_inputs``=``True`*)[`[source]`](../_modules/sionna/fec/utils.html#j_fun_inv_tf)\n\nCalculates the inverse <cite>J-function</cite> in Tensorflow.\n\nThe so-called <cite>J-function</cite> relates mutual information to the mean of\nGaussian distributed LLRs (cf. Gaussian approximation). We use the\napproximation as proposed in [[Brannstrom]](https://nvlabs.github.io/sionna/api/fec.utils.html#brannstrom) which can be written as\n\n$$\nJ(\\mu) \\approx \\left( 1- 2^{H_\\text{1}(2\\mu)^{H_\\text{2}}}\\right)^{H_\\text{2}}\n$$\n\nwith $\\mu$ denoting the mean value of the LLR distribution and\n$H_\\text{1}=0.3073$, $H_\\text{2}=0.8935$ and\n$H_\\text{3}=1.1064$.\nInput\n\n- **mi** (*tf.float32*)  Tensor of arbitrary shape.\n- **verify_inputs** (*bool*)  A boolean defaults to True. If True, `mi` is clipped internally\nto be numerical stable.\n\n\nOutput\n\n*tf.float32*  Tensor of same shape and dtype as the `mi`.\n\nRaises\n\n**InvalidArgumentError**  If `mi` is not in <cite>(0,1)</cite>.\n\n\nReferences:\ntenBrinkEXIT([1](https://nvlabs.github.io/sionna/api/fec.utils.html#id10),[2](https://nvlabs.github.io/sionna/api/fec.utils.html#id11),[3](https://nvlabs.github.io/sionna/api/fec.utils.html#id13))\n\nS. ten Brink, Convergence Behavior of Iteratively\nDecoded Parallel Concatenated Codes, IEEE Transactions on\nCommunications, vol. 49, no. 10, pp. 1727-1737, 2001.\n\nBrannstrom([1](https://nvlabs.github.io/sionna/api/fec.utils.html#id15),[2](https://nvlabs.github.io/sionna/api/fec.utils.html#id18),[3](https://nvlabs.github.io/sionna/api/fec.utils.html#id19),[4](https://nvlabs.github.io/sionna/api/fec.utils.html#id20),[5](https://nvlabs.github.io/sionna/api/fec.utils.html#id21))\n\nF. Brannstrom, L. K. Rasmussen, and A. J. Grant,\nConvergence analysis and optimal scheduling for multiple\nconcatenated codes, IEEE Trans. Inform. Theory, vol. 51, no. 9,\npp. 33543364, 2005.\n\nHagenauer([1](https://nvlabs.github.io/sionna/api/fec.utils.html#id16),[2](https://nvlabs.github.io/sionna/api/fec.utils.html#id17))\n\nJ. Hagenauer, The Turbo Principle in Mobile\nCommunications, in Proc. IEEE Int. Symp. Inf. Theory and its Appl.\n(ISITA), 2002.\n\ntenBrink([1](https://nvlabs.github.io/sionna/api/fec.utils.html#id9),[2](https://nvlabs.github.io/sionna/api/fec.utils.html#id12),[3](https://nvlabs.github.io/sionna/api/fec.utils.html#id14))\n\nS. ten Brink, G. Kramer, and A. Ashikhmin, Design of\nlow-density parity-check codes for modulation and detection, IEEE\nTrans. Commun., vol. 52, no. 4, pp. 670678, Apr. 2004.\n\nMacKay([1](https://nvlabs.github.io/sionna/api/fec.utils.html#id1),[2](https://nvlabs.github.io/sionna/api/fec.utils.html#id3),[3](https://nvlabs.github.io/sionna/api/fec.utils.html#id5),[4](https://nvlabs.github.io/sionna/api/fec.utils.html#id6),[5](https://nvlabs.github.io/sionna/api/fec.utils.html#id7))\n\n[http://www.inference.org.uk/mackay/codes/alist.html](http://www.inference.org.uk/mackay/codes/alist.html)\n\nUniKL([1](https://nvlabs.github.io/sionna/api/fec.utils.html#id2),[2](https://nvlabs.github.io/sionna/api/fec.utils.html#id4),[3](https://nvlabs.github.io/sionna/api/fec.utils.html#id8))\n\n[https://www.uni-kl.de/en/channel-codes/](https://www.uni-kl.de/en/channel-codes/)"
"# Mapping\n\nThis module contains classes and functions related to mapping\nof bits to constellation symbols and demapping of soft-symbols\nto log-likelihood ratios (LLRs). The key components are the\n[`Constellation`](https://nvlabs.github.io/sionna/api/mapping.html#sionna.mapping.Constellation), [`Mapper`](https://nvlabs.github.io/sionna/api/mapping.html#sionna.mapping.Mapper),\nand [`Demapper`](https://nvlabs.github.io/sionna/api/mapping.html#sionna.mapping.Demapper). A [`Constellation`](https://nvlabs.github.io/sionna/api/mapping.html#sionna.mapping.Constellation)\ncan be made trainable to enable learning of geometric shaping."
"### Constellation\n\n`class` `sionna.mapping.``Constellation`(*`constellation_type`*, *`num_bits_per_symbol`*, *`initial_value``=``None`*, *`normalize``=``True`*, *`center``=``False`*, *`trainable``=``False`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/mapping.html#Constellation)\n\nConstellation that can be used by a (de)mapper.\n\nThis class defines a constellation, i.e., a complex-valued vector of\nconstellation points. A constellation can be trainable. The binary\nrepresentation of the index of an element of this vector corresponds\nto the bit label of the constellation point. This implicit bit\nlabeling is used by the `Mapper` and `Demapper` classes.\nParameters\n\n- **constellation_type** (*One of** [**\"qam\"**, **\"pam\"**, **\"custom\"**]**, **str*)  For custom, the constellation points are randomly initialized\nif no `initial_value` is provided.\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation symbol, e.g., 4 for QAM16.\n- **initial_value** ($[2^\\text{num_bits_per_symbol}]$, NumPy array or Tensor)  Initial values of the constellation points. If `normalize` or\n`center` are <cite>True</cite>, the initial constellation might be changed.\n- **normalize** (*bool*)  If <cite>True</cite>, the constellation is normalized to have unit power.\nDefaults to <cite>True</cite>.\n- **center** (*bool*)  If <cite>True</cite>, the constellation is ensured to have zero mean.\nDefaults to <cite>False</cite>.\n- **trainable** (*bool*)  If <cite>True</cite>, the constellation points are trainable variables.\nDefaults to <cite>False</cite>.\n- **dtype** (*[**tf.complex64**, **tf.complex128**]**, **tf.DType*)  The dtype of the constellation.\n\n\nOutput\n\n$[2^\\text{num_bits_per_symbol}]$, `dtype`  The constellation.\n\n\n**Note**\n\nOne can create a trainable PAM/QAM constellation. This is\nequivalent to creating a custom trainable constellation which is\ninitialized with PAM/QAM constellation points.\n\n`property` `center`\n\nIndicates if the constellation is centered.\n\n\n`create_or_check_constellation`(*`num_bits_per_symbol``=``None`*, *`constellation``=``None`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/mapping.html#Constellation.create_or_check_constellation)\n\nStatic method for conviently creating a constellation object or checking that an existing one\nis consistent with requested settings.\n\nIf `constellation` is <cite>None</cite>, then this method creates a [`Constellation`](https://nvlabs.github.io/sionna/api/mapping.html#sionna.mapping.Constellation)\nobject of type `constellation_type` and with `num_bits_per_symbol` bits per symbol.\nOtherwise, this method checks that <cite>constellation</cite> is consistent with `constellation_type` and\n`num_bits_per_symbol`. If it is, `constellation` is returned. Otherwise, an assertion is raised.\nInput\n\n- **constellation_type** (*One of [qam, pam, custom], str*)  For custom, an instance of [`Constellation`](https://nvlabs.github.io/sionna/api/mapping.html#sionna.mapping.Constellation)\nmust be provided.\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation symbol, e.g., 4 for QAM16.\nOnly required for `constellation_type` in [qam, pam].\n- **constellation** (*Constellation*)  An instance of [`Constellation`](https://nvlabs.github.io/sionna/api/mapping.html#sionna.mapping.Constellation) or\n<cite>None</cite>. In the latter case, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n\n\nOutput\n\n[`Constellation`](https://nvlabs.github.io/sionna/api/mapping.html#sionna.mapping.Constellation)  A constellation object.\n\n\n`property` `normalize`\n\nIndicates if the constellation is normalized or not.\n\n\n`property` `num_bits_per_symbol`\n\nThe number of bits per constellation symbol.\n\n\n`property` `points`\n\nThe (possibly) centered and normalized constellation points.\n\n\n`show`(*`labels``=``True`*, *`figsize``=``(7,` `7)`*)[`[source]`](../_modules/sionna/mapping.html#Constellation.show)\n\nGenerate a scatter-plot of the constellation.\nInput\n\n- **labels** (*bool*)  If <cite>True</cite>, the bit labels will be drawn next to each constellation\npoint. Defaults to <cite>True</cite>.\n- **figsize** (*Two-element Tuple, float*)  Width and height in inches. Defaults to <cite>(7,7)</cite>.\n\n\nOutput\n\n*matplotlib.figure.Figure*  A handle to a matplot figure object."
"### qam\n\n`sionna.mapping.``qam`(*`num_bits_per_symbol`*, *`normalize``=``True`*)[`[source]`](../_modules/sionna/mapping.html#qam)\n\nGenerates a QAM constellation.\n\nThis function generates a complex-valued vector, where each element is\na constellation point of an M-ary QAM constellation. The bit\nlabel of the `n` th point is given by the length-`num_bits_per_symbol`\nbinary represenation of `n`.\nInput\n\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation point.\nMust be a multiple of two, e.g., 2, 4, 6, 8, etc.\n- **normalize** (*bool*)  If <cite>True</cite>, the constellation is normalized to have unit power.\nDefaults to <cite>True</cite>.\n\n\nOutput\n\n$[2^{\\text{num_bits_per_symbol}}]$, np.complex64  The QAM constellation.\n\n\n**Note**\n\nThe bit label of the nth constellation point is given by the binary\nrepresentation of its position within the array and can be obtained\nthrough `np.binary_repr(n,` `num_bits_per_symbol)`.\n\nThe normalization factor of a QAM constellation is given in\nclosed-form as:\n\n$$\n\\sqrt{\\frac{1}{2^{n-2}}\\sum_{i=1}^{2^{n-1}}(2i-1)^2}\n$$\n\nwhere $n= \\text{num_bits_per_symbol}/2$ is the number of bits\nper dimension.\n\nThis algorithm is a recursive implementation of the expressions found in\nSection 5.1 of [[3GPPTS38211]](https://nvlabs.github.io/sionna/api/mapping.html#gppts38211). It is used in the 5G standard."
"### pam\n\n`sionna.mapping.``pam`(*`num_bits_per_symbol`*, *`normalize``=``True`*)[`[source]`](../_modules/sionna/mapping.html#pam)\n\nGenerates a PAM constellation.\n\nThis function generates a real-valued vector, where each element is\na constellation point of an M-ary PAM constellation. The bit\nlabel of the `n` th point is given by the length-`num_bits_per_symbol`\nbinary represenation of `n`.\nInput\n\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation point.\nMust be positive.\n- **normalize** (*bool*)  If <cite>True</cite>, the constellation is normalized to have unit power.\nDefaults to <cite>True</cite>.\n\n\nOutput\n\n$[2^{\\text{num_bits_per_symbol}}]$, np.float32  The PAM constellation.\n\n\n**Note**\n\nThe bit label of the nth constellation point is given by the binary\nrepresentation of its position within the array and can be obtained\nthrough `np.binary_repr(n,` `num_bits_per_symbol)`.\n\nThe normalization factor of a PAM constellation is given in\nclosed-form as:\n\n$$\n\\sqrt{\\frac{1}{2^{n-1}}\\sum_{i=1}^{2^{n-1}}(2i-1)^2}\n$$\n\nwhere $n= \\text{num_bits_per_symbol}$ is the number of bits\nper symbol.\n\nThis algorithm is a recursive implementation of the expressions found in\nSection 5.1 of [[3GPPTS38211]](https://nvlabs.github.io/sionna/api/mapping.html#gppts38211). It is used in the 5G standard."
"### pam_gray\n\n`sionna.mapping.``pam_gray`(*`b`*)[`[source]`](../_modules/sionna/mapping.html#pam_gray)\n\nMaps a vector of bits to a PAM constellation points with Gray labeling.\n\nThis recursive function maps a binary vector to Gray-labelled PAM\nconstellation points. It can be used to generated QAM constellations.\nThe constellation is not normalized.\nInput\n\n**b** (*[n], NumPy array*)  Tensor with with binary entries.\n\nOutput\n\n*signed int*  The PAM constellation point taking values in\n$\\{\\pm 1,\\pm 3,\\dots,\\pm (2^n-1)\\}$.\n\n\n**Note**\n\nThis algorithm is a recursive implementation of the expressions found in\nSection 5.1 of [[3GPPTS38211]](https://nvlabs.github.io/sionna/api/mapping.html#gppts38211). It is used in the 5G standard."
"## Mapper\n\n`class` `sionna.mapping.``Mapper`(*`constellation_type``=``None`*, *`num_bits_per_symbol``=``None`*, *`constellation``=``None`*, *`return_indices``=``False`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/mapping.html#Mapper)\n\nMaps binary tensors to points of a constellation.\n\nThis class defines a layer that maps a tensor of binary values\nto a tensor of points from a provided constellation.\nParameters\n\n- **constellation_type** (*One of** [**\"qam\"**, **\"pam\"**, **\"custom\"**]**, **str*)  For custom, an instance of [`Constellation`](https://nvlabs.github.io/sionna/api/mapping.html#sionna.mapping.Constellation)\nmust be provided.\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation symbol, e.g., 4 for QAM16.\nOnly required for `constellation_type` in [qam, pam].\n- **constellation** ()  An instance of [`Constellation`](https://nvlabs.github.io/sionna/api/mapping.html#sionna.mapping.Constellation) or\n<cite>None</cite>. In the latter case, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n- **return_indices** (*bool*)  If enabled, symbol indices are additionally returned.\nDefaults to <cite>False</cite>.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**]**, **tf.DType*)  The output dtype. Defaults to tf.complex64.\n\n\nInput\n\n*[, n], tf.float or tf.int*  Tensor with with binary entries.\n\nOutput\n\n- *[,n/Constellation.num_bits_per_symbol], tf.complex*  The mapped constellation symbols.\n- *[,n/Constellation.num_bits_per_symbol], tf.int32*  The symbol indices corresponding to the constellation symbols.\nOnly returned if `return_indices` is set to True.\n\n\n**Note**\n\nThe last input dimension must be an integer multiple of the\nnumber of bits per constellation symbol.\n\n`property` `constellation`\n\nThe Constellation used by the Mapper."
"### Demapper\n\n`class` `sionna.mapping.``Demapper`(*`demapping_method`*, *`constellation_type``=``None`*, *`num_bits_per_symbol``=``None`*, *`constellation``=``None`*, *`hard_out``=``False`*, *`with_prior``=``False`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/mapping.html#Demapper)\n\nComputes log-likelihood ratios (LLRs) or hard-decisions on bits\nfor a tensor of received symbols.\nIf the flag `with_prior` is set, prior knowledge on the bits is assumed to be available.\n\nThis class defines a layer implementing different demapping\nfunctions. All demapping functions are fully differentiable when soft-decisions\nare computed.\nParameters\n\n- **demapping_method** (*One of** [**\"app\"**, **\"maxlog\"**]**, **str*)  The demapping method used.\n- **constellation_type** (*One of** [**\"qam\"**, **\"pam\"**, **\"custom\"**]**, **str*)  For custom, an instance of [`Constellation`](https://nvlabs.github.io/sionna/api/mapping.html#sionna.mapping.Constellation)\nmust be provided.\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation symbol, e.g., 4 for QAM16.\nOnly required for `constellation_type` in [qam, pam].\n- **constellation** ()  An instance of [`Constellation`](https://nvlabs.github.io/sionna/api/mapping.html#sionna.mapping.Constellation) or <cite>None</cite>.\nIn the latter case, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n- **hard_out** (*bool*)  If <cite>True</cite>, the demapper provides hard-decided bits instead of soft-values.\nDefaults to <cite>False</cite>.\n- **with_prior** (*bool*)  If <cite>True</cite>, it is assumed that prior knowledge on the bits is available.\nThis prior information is given as LLRs as an additional input to the layer.\nDefaults to <cite>False</cite>.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**] **tf.DType** (**dtype**)*)  The dtype of <cite>y</cite>. Defaults to tf.complex64.\nThe output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n\nInput\n\n- **(y,no) or (y, prior, no)**  Tuple:\n- **y** (*[,n], tf.complex*)  The received symbols.\n- **prior** (*[num_bits_per_symbol] or [,num_bits_per_symbol], tf.float*)  Prior for every bit as LLRs.\nIt can be provided either as a tensor of shape <cite>[num_bits_per_symbol]</cite> for the\nentire input batch, or as a tensor that is broadcastable\nto <cite>[, n, num_bits_per_symbol]</cite>.\nOnly required if the `with_prior` flag is set.\n- **no** (*Scalar or [,n], tf.float*)  The noise variance estimate. It can be provided either as scalar\nfor the entire input batch or as a tensor that is broadcastable to\n`y`.\n\n\nOutput\n\n*[,n*num_bits_per_symbol], tf.float*  LLRs or hard-decisions for every bit.\n\n\n**Note**\n\nWith the app demapping method, the LLR for the $i\\text{th}$ bit\nis computed according to\n\n$$\nLLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=1\\lvert y,\\mathbf{p}\\right)}{\\Pr\\left(b_i=0\\lvert y,\\mathbf{p}\\right)}\\right) =\\ln\\left(\\frac{\n        \\sum_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n        \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n        }{\n        \\sum_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n        \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n        }\\right)\n$$\n\nwhere $\\mathcal{C}_{i,1}$ and $\\mathcal{C}_{i,0}$ are the\nsets of constellation points for which the $i\\text{th}$ bit is\nequal to 1 and 0, respectively. $\\mathbf{p} = \\left[p_0,\\dots,p_{K-1}\\right]$\nis the vector of LLRs that serves as prior knowledge on the $K$ bits that are mapped to\na constellation point and is set to $\\mathbf{0}$ if no prior knowledge is assumed to be available,\nand $\\Pr(c\\lvert\\mathbf{p})$ is the prior probability on the constellation symbol $c$:\n\n$$\n\\Pr\\left(c\\lvert\\mathbf{p}\\right) = \\prod_{k=0}^{K-1} \\text{sigmoid}\\left(p_k \\ell(c)_k\\right)\n$$\n\nwhere $\\ell(c)_k$ is the $k^{th}$ bit label of $c$, where 0 is\nreplaced by -1.\nThe definition of the LLR has been\nchosen such that it is equivalent with that of logits. This is\ndifferent from many textbooks in communications, where the LLR is\ndefined as $LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=0\\lvert y\\right)}{\\Pr\\left(b_i=1\\lvert y\\right)}\\right)$.\n\nWith the maxlog demapping method, LLRs for the $i\\text{th}$ bit\nare approximated like\n\n$$\n\\begin{split}\\begin{align}\n    LLR(i) &\\approx\\ln\\left(\\frac{\n        \\max_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n            \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n        }{\n        \\max_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n            \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n        }\\right)\\\\\n        &= \\max_{c\\in\\mathcal{C}_{i,0}}\n            \\left(\\ln\\left(\\Pr\\left(c\\lvert\\mathbf{p}\\right)\\right)-\\frac{|y-c|^2}{N_o}\\right) -\n         \\max_{c\\in\\mathcal{C}_{i,1}}\\left( \\ln\\left(\\Pr\\left(c\\lvert\\mathbf{p}\\right)\\right) - \\frac{|y-c|^2}{N_o}\\right)\n        .\n\\end{align}\\end{split}\n$$"
"### DemapperWithPrior\n\n`class` `sionna.mapping.``DemapperWithPrior`(*`demapping_method`*, *`constellation_type``=``None`*, *`num_bits_per_symbol``=``None`*, *`constellation``=``None`*, *`hard_out``=``False`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/mapping.html#DemapperWithPrior)\n\nComputes log-likelihood ratios (LLRs) or hard-decisions on bits\nfor a tensor of received symbols, assuming that prior knowledge on the bits is available.\n\nThis class defines a layer implementing different demapping\nfunctions. All demapping functions are fully differentiable when soft-decisions\nare computed.\n\nThis class is deprecated as the functionality has been integrated\ninto [`Demapper`](https://nvlabs.github.io/sionna/api/mapping.html#sionna.mapping.Demapper).\nParameters\n\n- **demapping_method** (*One of** [**\"app\"**, **\"maxlog\"**]**, **str*)  The demapping method used.\n- **constellation_type** (*One of** [**\"qam\"**, **\"pam\"**, **\"custom\"**]**, **str*)  For custom, an instance of [`Constellation`](https://nvlabs.github.io/sionna/api/mapping.html#sionna.mapping.Constellation)\nmust be provided.\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation symbol, e.g., 4 for QAM16.\nOnly required for `constellation_type` in [qam, pam].\n- **constellation** ()  An instance of [`Constellation`](https://nvlabs.github.io/sionna/api/mapping.html#sionna.mapping.Constellation) or <cite>None</cite>.\nIn the latter case, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n- **hard_out** (*bool*)  If <cite>True</cite>, the demapper provides hard-decided bits instead of soft-values.\nDefaults to <cite>False</cite>.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**] **tf.DType** (**dtype**)*)  The dtype of <cite>y</cite>. Defaults to tf.complex64.\nThe output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n\nInput\n\n- **(y, prior, no)**  Tuple:\n- **y** (*[,n], tf.complex*)  The received symbols.\n- **prior** (*[num_bits_per_symbol] or [,num_bits_per_symbol], tf.float*)  Prior for every bit as LLRs.\nIt can be provided either as a tensor of shape <cite>[num_bits_per_symbol]</cite> for the\nentire input batch, or as a tensor that is broadcastable\nto <cite>[, n, num_bits_per_symbol]</cite>.\n- **no** (*Scalar or [,n], tf.float*)  The noise variance estimate. It can be provided either as scalar\nfor the entire input batch or as a tensor that is broadcastable to\n`y`.\n\n\nOutput\n\n*[,n*num_bits_per_symbol], tf.float*  LLRs or hard-decisions for every bit.\n\n\n**Note**\n\nWith the app demapping method, the LLR for the $i\\text{th}$ bit\nis computed according to\n\n$$\nLLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=1\\lvert y,\\mathbf{p}\\right)}{\\Pr\\left(b_i=0\\lvert y,\\mathbf{p}\\right)}\\right) =\\ln\\left(\\frac{\n        \\sum_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n        \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n        }{\n        \\sum_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n        \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n        }\\right)\n$$\n\nwhere $\\mathcal{C}_{i,1}$ and $\\mathcal{C}_{i,0}$ are the\nsets of constellation points for which the $i\\text{th}$ bit is\nequal to 1 and 0, respectively. $\\mathbf{p} = \\left[p_0,\\dots,p_{K-1}\\right]$\nis the vector of LLRs that serves as prior knowledge on the $K$ bits that are mapped to\na constellation point,\nand $\\Pr(c\\lvert\\mathbf{p})$ is the prior probability on the constellation symbol $c$:\n\n$$\n\\Pr\\left(c\\lvert\\mathbf{p}\\right) = \\prod_{k=0}^{K-1} \\text{sigmoid}\\left(p_k \\ell(c)_k\\right)\n$$\n\nwhere $\\ell(c)_k$ is the $k^{th}$ bit label of $c$, where 0 is\nreplaced by -1.\nThe definition of the LLR has been\nchosen such that it is equivalent with that of logits. This is\ndifferent from many textbooks in communications, where the LLR is\ndefined as $LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=0\\lvert y\\right)}{\\Pr\\left(b_i=1\\lvert y\\right)}\\right)$.\n\nWith the maxlog demapping method, LLRs for the $i\\text{th}$ bit\nare approximated like\n\n$$\n\\begin{split}\\begin{align}\n    LLR(i) &\\approx\\ln\\left(\\frac{\n        \\max_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n            \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n        }{\n        \\max_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n            \\exp\\left(-\\frac{1}{N_o}\\left|y-c\\right|^2\\right)\n        }\\right)\\\\\n        &= \\max_{c\\in\\mathcal{C}_{i,0}}\n            \\left(\\ln\\left(\\Pr\\left(c\\lvert\\mathbf{p}\\right)\\right)-\\frac{|y-c|^2}{N_o}\\right) -\n         \\max_{c\\in\\mathcal{C}_{i,1}}\\left( \\ln\\left(\\Pr\\left(c\\lvert\\mathbf{p}\\right)\\right) - \\frac{|y-c|^2}{N_o}\\right)\n        .\n\\end{align}\\end{split}\n$$"
"### SymbolDemapper\n\n`class` `sionna.mapping.``SymbolDemapper`(*`constellation_type``=``None`*, *`num_bits_per_symbol``=``None`*, *`constellation``=``None`*, *`hard_out``=``False`*, *`with_prior``=``False`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/mapping.html#SymbolDemapper)\n\nComputes normalized log-probabilities (logits) or hard-decisions on symbols\nfor a tensor of received symbols.\nIf the `with_prior` flag is set, prior knowldge on the transmitted constellation points is assumed to be available.\nThe demapping function is fully differentiable when soft-values are\ncomputed.\nParameters\n\n- **constellation_type** (*One of** [**\"qam\"**, **\"pam\"**, **\"custom\"**]**, **str*)  For custom, an instance of [`Constellation`](https://nvlabs.github.io/sionna/api/mapping.html#sionna.mapping.Constellation)\nmust be provided.\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation symbol, e.g., 4 for QAM16.\nOnly required for `constellation_type` in [qam, pam].\n- **constellation** ()  An instance of [`Constellation`](https://nvlabs.github.io/sionna/api/mapping.html#sionna.mapping.Constellation) or <cite>None</cite>.\nIn the latter case, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n- **hard_out** (*bool*)  If <cite>True</cite>, the demapper provides hard-decided symbols instead of soft-values.\nDefaults to <cite>False</cite>.\n- **with_prior** (*bool*)  If <cite>True</cite>, it is assumed that prior knowledge on the constellation points is available.\nThis prior information is given as log-probabilities (logits) as an additional input to the layer.\nDefaults to <cite>False</cite>.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**] **tf.DType** (**dtype**)*)  The dtype of <cite>y</cite>. Defaults to tf.complex64.\nThe output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n\nInput\n\n- **(y, no) or (y, prior, no)**  Tuple:\n- **y** (*[,n], tf.complex*)  The received symbols.\n- **prior** (*[num_points] or [,num_points], tf.float*)  Prior for every symbol as log-probabilities (logits).\nIt can be provided either as a tensor of shape <cite>[num_points]</cite> for the\nentire input batch, or as a tensor that is broadcastable\nto <cite>[, n, num_points]</cite>.\nOnly required if the `with_prior` flag is set.\n- **no** (*Scalar or [,n], tf.float*)  The noise variance estimate. It can be provided either as scalar\nfor the entire input batch or as a tensor that is broadcastable to\n`y`.\n\n\nOutput\n\n*[,n, num_points] or [,n], tf.float*  A tensor of shape <cite>[,n, num_points]</cite> of logits for every constellation\npoint if <cite>hard_out</cite> is set to <cite>False</cite>.\nOtherwise, a tensor of shape <cite>[,n]</cite> of hard-decisions on the symbols.\n\n\n**Note**\n\nThe normalized log-probability for the constellation point $c$ is computed according to\n\n$$\n\\ln\\left(\\Pr\\left(c \\lvert y,\\mathbf{p}\\right)\\right) = \\ln\\left( \\frac{\\exp\\left(-\\frac{|y-c|^2}{N_0} + p_c \\right)}{\\sum_{c'\\in\\mathcal{C}} \\exp\\left(-\\frac{|y-c'|^2}{N_0} + p_{c'} \\right)} \\right)\n$$\n\nwhere $\\mathcal{C}$ is the set of constellation points used for modulation,\nand $\\mathbf{p} = \\left\\{p_c \\lvert c \\in \\mathcal{C}\\right\\}$ the prior information on constellation points given as log-probabilities\nand which is set to $\\mathbf{0}$ if no prior information on the constellation points is assumed to be available."
"### SymbolDemapperWithPrior\n\n`class` `sionna.mapping.``SymbolDemapperWithPrior`(*`constellation_type``=``None`*, *`num_bits_per_symbol``=``None`*, *`constellation``=``None`*, *`hard_out``=``False`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/mapping.html#SymbolDemapperWithPrior)\n\nComputes normalized log-probabilities (logits) or hard-decisions on symbols\nfor a tensor of received symbols, assuming that prior knowledge on the constellation points is available.\nThe demapping function is fully differentiable when soft-values are\ncomputed.\n\nThis class is deprecated as the functionality has been integrated\ninto [`SymbolDemapper`](https://nvlabs.github.io/sionna/api/mapping.html#sionna.mapping.SymbolDemapper).\nParameters\n\n- **constellation_type** (*One of** [**\"qam\"**, **\"pam\"**, **\"custom\"**]**, **str*)  For custom, an instance of [`Constellation`](https://nvlabs.github.io/sionna/api/mapping.html#sionna.mapping.Constellation)\nmust be provided.\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation symbol, e.g., 4 for QAM16.\nOnly required for `constellation_type` in [qam, pam].\n- **constellation** ()  An instance of [`Constellation`](https://nvlabs.github.io/sionna/api/mapping.html#sionna.mapping.Constellation) or <cite>None</cite>.\nIn the latter case, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n- **hard_out** (*bool*)  If <cite>True</cite>, the demapper provides hard-decided symbols instead of soft-values.\nDefaults to <cite>False</cite>.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**] **tf.DType** (**dtype**)*)  The dtype of <cite>y</cite>. Defaults to tf.complex64.\nThe output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n\nInput\n\n- **(y, prior, no)**  Tuple:\n- **y** (*[,n], tf.complex*)  The received symbols.\n- **prior** (*[num_points] or [,num_points], tf.float*)  Prior for every symbol as log-probabilities (logits).\nIt can be provided either as a tensor of shape <cite>[num_points]</cite> for the\nentire input batch, or as a tensor that is broadcastable\nto <cite>[, n, num_points]</cite>.\n- **no** (*Scalar or [,n], tf.float*)  The noise variance estimate. It can be provided either as scalar\nfor the entire input batch or as a tensor that is broadcastable to\n`y`.\n\n\nOutput\n\n*[,n, num_points] or [,n], tf.float*  A tensor of shape <cite>[,n, num_points]</cite> of logits for every constellation\npoint if <cite>hard_out</cite> is set to <cite>False</cite>.\nOtherwise, a tensor of shape <cite>[,n]</cite> of hard-decisions on the symbols.\n\n\n**Note**\n\nThe normalized log-probability for the constellation point $c$ is computed according to\n\n$$\n\\ln\\left(\\Pr\\left(c \\lvert y,\\mathbf{p}\\right)\\right) = \\ln\\left( \\frac{\\exp\\left(-\\frac{|y-c|^2}{N_0} + p_c \\right)}{\\sum_{c'\\in\\mathcal{C}} \\exp\\left(-\\frac{|y-c'|^2}{N_0} + p_{c'} \\right)} \\right)\n$$\n\nwhere $\\mathcal{C}$ is the set of constellation points used for modulation,\nand $\\mathbf{p} = \\left\\{p_c \\lvert c \\in \\mathcal{C}\\right\\}$ the prior information on constellation points given as log-probabilities."
"### SymbolLogits2LLRs\n\n`class` `sionna.mapping.``SymbolLogits2LLRs`(*`method`*, *`num_bits_per_symbol`*, *`hard_out``=``False`*, *`with_prior``=``False`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/mapping.html#SymbolLogits2LLRs)\n\nComputes log-likelihood ratios (LLRs) or hard-decisions on bits\nfrom a tensor of logits (i.e., unnormalized log-probabilities) on constellation points.\nIf the flag `with_prior` is set, prior knowledge on the bits is assumed to be available.\nParameters\n\n- **method** (*One of** [**\"app\"**, **\"maxlog\"**]**, **str*)  The method used for computing the LLRs.\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation symbol, e.g., 4 for QAM16.\n- **hard_out** (*bool*)  If <cite>True</cite>, the layer provides hard-decided bits instead of soft-values.\nDefaults to <cite>False</cite>.\n- **with_prior** (*bool*)  If <cite>True</cite>, it is assumed that prior knowledge on the bits is available.\nThis prior information is given as LLRs as an additional input to the layer.\nDefaults to <cite>False</cite>.\n- **dtype** (*One of** [**tf.float32**, **tf.float64**] **tf.DType** (**dtype**)*)  The dtype for the input and output.\nDefaults to <cite>tf.float32</cite>.\n\n\nInput\n\n- **logits or (logits, prior)**  Tuple:\n- **logits** (*[,n, num_points], tf.float*)  Logits on constellation points.\n- **prior** (*[num_bits_per_symbol] or [n, num_bits_per_symbol], tf.float*)  Prior for every bit as LLRs.\nIt can be provided either as a tensor of shape <cite>[num_bits_per_symbol]</cite>\nfor the entire input batch, or as a tensor that is broadcastable\nto <cite>[, n, num_bits_per_symbol]</cite>.\nOnly required if the `with_prior` flag is set.\n\n\nOutput\n\n*[,n, num_bits_per_symbol], tf.float*  LLRs or hard-decisions for every bit.\n\n\n**Note**\n\nWith the app method, the LLR for the $i\\text{th}$ bit\nis computed according to\n\n$$\nLLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=1\\lvert \\mathbf{z},\\mathbf{p}\\right)}{\\Pr\\left(b_i=0\\lvert \\mathbf{z},\\mathbf{p}\\right)}\\right) =\\ln\\left(\\frac{\n        \\sum_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n        e^{z_c}\n        }{\n        \\sum_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n        e^{z_c}\n        }\\right)\n$$\n\nwhere $\\mathcal{C}_{i,1}$ and $\\mathcal{C}_{i,0}$ are the\nsets of $2^K$ constellation points for which the $i\\text{th}$ bit is\nequal to 1 and 0, respectively. $\\mathbf{z} = \\left[z_{c_0},\\dots,z_{c_{2^K-1}}\\right]$ is the vector of logits on the constellation points, $\\mathbf{p} = \\left[p_0,\\dots,p_{K-1}\\right]$\nis the vector of LLRs that serves as prior knowledge on the $K$ bits that are mapped to\na constellation point and is set to $\\mathbf{0}$ if no prior knowledge is assumed to be available,\nand $\\Pr(c\\lvert\\mathbf{p})$ is the prior probability on the constellation symbol $c$:\n\n$$\n\\Pr\\left(c\\lvert\\mathbf{p}\\right) = \\prod_{k=0}^{K-1} \\Pr\\left(b_k = \\ell(c)_k \\lvert\\mathbf{p} \\right)\n= \\prod_{k=0}^{K-1} \\text{sigmoid}\\left(p_k \\ell(c)_k\\right)\n$$\n\nwhere $\\ell(c)_k$ is the $k^{th}$ bit label of $c$, where 0 is\nreplaced by -1.\nThe definition of the LLR has been\nchosen such that it is equivalent with that of logits. This is\ndifferent from many textbooks in communications, where the LLR is\ndefined as $LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=0\\lvert y\\right)}{\\Pr\\left(b_i=1\\lvert y\\right)}\\right)$.\n\nWith the maxlog method, LLRs for the $i\\text{th}$ bit\nare approximated like\n\n$$\n\\begin{align}\n    LLR(i) &\\approx\\ln\\left(\\frac{\n        \\max_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n            e^{z_c}\n        }{\n        \\max_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n            e^{z_c}\n        }\\right)\n        .\n\\end{align}\n$$"
"### LLRs2SymbolLogits\n\n`class` `sionna.mapping.``LLRs2SymbolLogits`(*`num_bits_per_symbol`*, *`hard_out``=``False`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/mapping.html#LLRs2SymbolLogits)\n\nComputes logits (i.e., unnormalized log-probabilities) or hard decisions\non constellation points from a tensor of log-likelihood ratios (LLRs) on bits.\nParameters\n\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation symbol, e.g., 4 for QAM16.\n- **hard_out** (*bool*)  If <cite>True</cite>, the layer provides hard-decided constellation points instead of soft-values.\nDefaults to <cite>False</cite>.\n- **dtype** (*One of** [**tf.float32**, **tf.float64**] **tf.DType** (**dtype**)*)  The dtype for the input and output.\nDefaults to <cite>tf.float32</cite>.\n\n\nInput\n\n**llrs** (*[, n, num_bits_per_symbol], tf.float*)  LLRs for every bit.\n\nOutput\n\n*[,n, num_points], tf.float or [, n], tf.int32*  Logits or hard-decisions on constellation points.\n\n\n**Note**\n\nThe logit for the constellation $c$ point\nis computed according to\n\n$$\n\\begin{split}\\begin{align}\n    \\log{\\left(\\Pr\\left(c\\lvert LLRs \\right)\\right)}\n        &= \\log{\\left(\\prod_{k=0}^{K-1} \\Pr\\left(b_k = \\ell(c)_k \\lvert LLRs \\right)\\right)}\\\\\n        &= \\log{\\left(\\prod_{k=0}^{K-1} \\text{sigmoid}\\left(LLR(k) \\ell(c)_k\\right)\\right)}\\\\\n        &= \\sum_{k=0}^{K-1} \\log{\\left(\\text{sigmoid}\\left(LLR(k) \\ell(c)_k\\right)\\right)}\n\\end{align}\\end{split}\n$$\n\nwhere $\\ell(c)_k$ is the $k^{th}$ bit label of $c$, where 0 is\nreplaced by -1.\nThe definition of the LLR has been\nchosen such that it is equivalent with that of logits. This is\ndifferent from many textbooks in communications, where the LLR is\ndefined as $LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=0\\lvert y\\right)}{\\Pr\\left(b_i=1\\lvert y\\right)}\\right)$."
"### SymbolLogits2LLRsWithPrior\n\n`class` `sionna.mapping.``SymbolLogits2LLRsWithPrior`(*`method`*, *`num_bits_per_symbol`*, *`hard_out``=``False`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/mapping.html#SymbolLogits2LLRsWithPrior)\n\nComputes log-likelihood ratios (LLRs) or hard-decisions on bits\nfrom a tensor of logits (i.e., unnormalized log-probabilities) on constellation points,\nassuming that prior knowledge on the bits is available.\n\nThis class is deprecated as the functionality has been integrated\ninto [`SymbolLogits2LLRs`](https://nvlabs.github.io/sionna/api/mapping.html#sionna.mapping.SymbolLogits2LLRs).\nParameters\n\n- **method** (*One of** [**\"app\"**, **\"maxlog\"**]**, **str*)  The method used for computing the LLRs.\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation symbol, e.g., 4 for QAM16.\n- **hard_out** (*bool*)  If <cite>True</cite>, the layer provides hard-decided bits instead of soft-values.\nDefaults to <cite>False</cite>.\n- **dtype** (*One of** [**tf.float32**, **tf.float64**] **tf.DType** (**dtype**)*)  The dtype for the input and output.\nDefaults to <cite>tf.float32</cite>.\n\n\nInput\n\n- **(logits, prior)**  Tuple:\n- **logits** (*[,n, num_points], tf.float*)  Logits on constellation points.\n- **prior** (*[num_bits_per_symbol] or [n, num_bits_per_symbol], tf.float*)  Prior for every bit as LLRs.\nIt can be provided either as a tensor of shape <cite>[num_bits_per_symbol]</cite> for the\nentire input batch, or as a tensor that is broadcastable\nto <cite>[, n, num_bits_per_symbol]</cite>.\n\n\nOutput\n\n*[,n, num_bits_per_symbol], tf.float*  LLRs or hard-decisions for every bit.\n\n\n**Note**\n\nWith the app method, the LLR for the $i\\text{th}$ bit\nis computed according to\n\n$$\nLLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=1\\lvert \\mathbf{z},\\mathbf{p}\\right)}{\\Pr\\left(b_i=0\\lvert \\mathbf{z},\\mathbf{p}\\right)}\\right) =\\ln\\left(\\frac{\n        \\sum_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n        e^{z_c}\n        }{\n        \\sum_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n        e^{z_c}\n        }\\right)\n$$\n\nwhere $\\mathcal{C}_{i,1}$ and $\\mathcal{C}_{i,0}$ are the\nsets of $2^K$ constellation points for which the $i\\text{th}$ bit is\nequal to 1 and 0, respectively. $\\mathbf{z} = \\left[z_{c_0},\\dots,z_{c_{2^K-1}}\\right]$ is the vector of logits on the constellation points, $\\mathbf{p} = \\left[p_0,\\dots,p_{K-1}\\right]$\nis the vector of LLRs that serves as prior knowledge on the $K$ bits that are mapped to\na constellation point,\nand $\\Pr(c\\lvert\\mathbf{p})$ is the prior probability on the constellation symbol $c$:\n\n$$\n\\Pr\\left(c\\lvert\\mathbf{p}\\right) = \\prod_{k=0}^{K-1} \\Pr\\left(b_k = \\ell(c)_k \\lvert\\mathbf{p} \\right)\n= \\prod_{k=0}^{K-1} \\text{sigmoid}\\left(p_k \\ell(c)_k\\right)\n$$\n\nwhere $\\ell(c)_k$ is the $k^{th}$ bit label of $c$, where 0 is\nreplaced by -1.\nThe definition of the LLR has been\nchosen such that it is equivalent with that of logits. This is\ndifferent from many textbooks in communications, where the LLR is\ndefined as $LLR(i) = \\ln\\left(\\frac{\\Pr\\left(b_i=0\\lvert y\\right)}{\\Pr\\left(b_i=1\\lvert y\\right)}\\right)$.\n\nWith the maxlog method, LLRs for the $i\\text{th}$ bit\nare approximated like\n\n$$\n\\begin{align}\n    LLR(i) &\\approx\\ln\\left(\\frac{\n        \\max_{c\\in\\mathcal{C}_{i,1}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n            e^{z_c}\n        }{\n        \\max_{c\\in\\mathcal{C}_{i,0}} \\Pr\\left(c\\lvert\\mathbf{p}\\right)\n            e^{z_c}\n        }\\right)\n        .\n\\end{align}\n$$"
"### SymbolLogits2Moments\n\n`class` `sionna.mapping.``SymbolLogits2Moments`(*`constellation_type``=``None`*, *`num_bits_per_symbol``=``None`*, *`constellation``=``None`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/mapping.html#SymbolLogits2Moments)\n\nComputes the mean and variance of a constellation from logits (unnormalized log-probabilities) on the\nconstellation points.\n\nMore precisely, given a constellation $\\mathcal{C} = \\left[ c_0,\\dots,c_{N-1} \\right]$ of size $N$, this layer computes the mean and variance\naccording to\n\n$$\n\\begin{split}\\begin{align}\n    \\mu &= \\sum_{n = 0}^{N-1} c_n \\Pr \\left(c_n \\lvert \\mathbf{\\ell} \\right)\\\\\n    \\nu &= \\sum_{n = 0}^{N-1} \\left( c_n - \\mu \\right)^2 \\Pr \\left(c_n \\lvert \\mathbf{\\ell} \\right)\n\\end{align}\\end{split}\n$$\n\nwhere $\\mathbf{\\ell} = \\left[ \\ell_0, \\dots, \\ell_{N-1} \\right]$ are the logits, and\n\n$$\n\\Pr \\left(c_n \\lvert \\mathbf{\\ell} \\right) = \\frac{\\exp \\left( \\ell_n \\right)}{\\sum_{i=0}^{N-1} \\exp \\left( \\ell_i \\right) }.\n$$\n\nParameters\n\n- **constellation_type** (*One of** [**\"qam\"**, **\"pam\"**, **\"custom\"**]**, **str*)  For custom, an instance of [`Constellation`](https://nvlabs.github.io/sionna/api/mapping.html#sionna.mapping.Constellation)\nmust be provided.\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation symbol, e.g., 4 for QAM16.\nOnly required for `constellation_type` in [qam, pam].\n- **constellation** ()  An instance of [`Constellation`](https://nvlabs.github.io/sionna/api/mapping.html#sionna.mapping.Constellation) or <cite>None</cite>.\nIn the latter case, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n- **dtype** (*One of** [**tf.float32**, **tf.float64**] **tf.DType** (**dtype**)*)  The dtype for the input and output.\nDefaults to <cite>tf.float32</cite>.\n\n\nInput\n\n**logits** (*[,n, num_points], tf.float*)  Logits on constellation points.\n\nOutput\n\n- **mean** (*[,n], tf.float*)  Mean of the constellation.\n- **var** (*[,n], tf.float*)  Variance of the constellation"
"### SymbolInds2Bits\n\n`class` `sionna.mapping.``SymbolInds2Bits`(*`num_bits_per_symbol`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/mapping.html#SymbolInds2Bits)\n\nTransforms symbol indices to their binary representations.\nParameters\n\n- **num_bits_per_symbol** (*int*)  Number of bits per constellation symbol\n- **dtype** (*tf.DType*)  Output dtype. Defaults to <cite>tf.float32</cite>.\n\n\nInput\n\n*Tensor, tf.int*  Symbol indices\n\nOutput\n\n*input.shape + [num_bits_per_symbol], dtype*  Binary representation of symbol indices"
"### PAM2QAM\n\n`class` `sionna.mapping.``PAM2QAM`(*`num_bits_per_symbol`*, *`hard_in_out``=``True`*)[`[source]`](../_modules/sionna/mapping.html#PAM2QAM)\n\nTransforms PAM symbol indices/logits to QAM symbol indices/logits.\n\nFor two PAM constellation symbol indices or logits, corresponding to\nthe real and imaginary components of a QAM constellation,\ncompute the QAM symbol index or logits.\nParameters\n\n- **num_bits_per_symbol** (*int*)  Number of bits per QAM constellation symbol, e.g., 4 for QAM16\n- **hard_in_out** (*bool*)  Determines if inputs and outputs are indices or logits over\nconstellation symbols.\nDefaults to <cite>True</cite>.\n\n\nInput\n\n- **pam1** (*Tensor, tf.int, or [,2**(num_bits_per_symbol/2)], tf.float*)  Indices or logits for the first PAM constellation\n- **pam2** (*Tensor, tf.int, or [,2**(num_bits_per_symbol/2)], tf.float*)  Indices or logits for the second PAM constellation\n\n\nOutput\n\n**qam** (*Tensor, tf.int, or [,2**num_bits_per_symbol], tf.float*)  Indices or logits for the corresponding QAM constellation"
"### QAM2PAM\n\n`class` `sionna.mapping.``QAM2PAM`(*`num_bits_per_symbol`*)[`[source]`](../_modules/sionna/mapping.html#QAM2PAM)\n\nTransforms QAM symbol indices to PAM symbol indices.\n\nFor indices in a QAM constellation, computes the corresponding indices\nfor the two PAM constellations corresponding the real and imaginary\ncomponents of the QAM constellation.\nParameters\n\n**num_bits_per_symbol** (*int*)  The number of bits per QAM constellation symbol, e.g., 4 for QAM16.\n\nInput\n\n**ind_qam** (*Tensor, tf.int*)  Indices in the QAM constellation\n\nOutput\n\n- **ind_pam1** (*Tensor, tf.int*)  Indices for the first component of the corresponding PAM modulation\n- **ind_pam2** (*Tensor, tf.int*)  Indices for the first component of the corresponding PAM modulation\n\n\nReferences:\n3GPPTS38211([1](https://nvlabs.github.io/sionna/api/mapping.html#id1),[2](https://nvlabs.github.io/sionna/api/mapping.html#id2),[3](https://nvlabs.github.io/sionna/api/mapping.html#id3))\n\nETSI TS 38.211 5G NR Physical channels and modulation, V16.2.0, Jul. 2020\n[https://www.3gpp.org/ftp/Specs/archive/38_series/38.211/38211-h00.zip](https://www.3gpp.org/ftp/Specs/archive/38_series/38.211/38211-h00.zip)"
"## Stream Management\n\nStream management determines which transmitter is sending which stream to\nwhich receiver. Transmitters and receivers can be user terminals or base\nstations, depending on whether uplink or downlink transmissions are considered.\nThe [`StreamManagement`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.StreamManagement) class has various properties that\nare needed to recover desired or interfering channel coefficients for precoding\nand equalization. In order to understand how the various properties of\n[`StreamManagement`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.StreamManagement) can be used, we recommend to have a look\nat the source code of the [`LMMSEEqualizer`](ofdm.html#sionna.ofdm.LMMSEEqualizer) or\n[`ZFPrecoder`](ofdm.html#sionna.ofdm.ZFPrecoder).\n\nThe following code snippet shows how to configure\n[`StreamManagement`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.StreamManagement) for a simple uplink scenario, where\nfour transmitters send each one stream to a receiver. Note that\n[`StreamManagement`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.StreamManagement) is independent of the actual number of\nantennas at the transmitters and receivers.\n```python\nnum_tx = 4\nnum_rx = 1\nnum_streams_per_tx = 1\n# Indicate which transmitter is associated with which receiver\n# rx_tx_association[i,j] = 1 means that transmitter j sends one\n# or mutiple streams to receiver i.\nrx_tx_association = np.zeros([num_rx, num_tx])\nrx_tx_association[0,0] = 1\nrx_tx_association[0,1] = 1\nrx_tx_association[0,2] = 1\nrx_tx_association[0,3] = 1\nsm = StreamManagement(rx_tx_association, num_streams_per_tx)\n```\n`class` `sionna.mimo.``StreamManagement`(*`rx_tx_association`*, *`num_streams_per_tx`*)[`[source]`](../_modules/sionna/mimo/stream_management.html#StreamManagement)\n\nClass for management of streams in multi-cell MIMO networks.\nParameters\n\n- **rx_tx_association** (*[**num_rx**, **num_tx**]**, **np.int*)  A binary NumPy array where `rx_tx_association[i,j]=1` means\nthat receiver <cite>i</cite> gets one or multiple streams from\ntransmitter <cite>j</cite>.\n- **num_streams_per_tx** (*int*)  Indicates the number of streams that are transmitted by each\ntransmitter.\n\n\n**Note**\n\nSeveral symmetry constraints on `rx_tx_association` are imposed\nto ensure efficient processing. All row sums and all column sums\nmust be equal, i.e., all receivers have the same number of associated\ntransmitters and all transmitters have the same number of associated\nreceivers. It is also assumed that all transmitters send the same\nnumber of streams `num_streams_per_tx`.\n\n`property` `detection_desired_ind`\n\nIndices needed to gather desired channels for receive processing.\n\nA NumPy array of shape <cite>[num_rx*num_streams_per_rx]</cite> that\ncan be used to gather desired channels from the flattened\nchannel tensor of shape\n<cite>[,num_rx, num_tx, num_streams_per_tx,]</cite>.\nThe result of the gather operation can be reshaped to\n<cite>[,num_rx, num_streams_per_rx,]</cite>.\n\n\n`property` `detection_undesired_ind`\n\nIndices needed to gather undesired channels for receive processing.\n\nA NumPy array of shape <cite>[num_rx*num_streams_per_rx]</cite> that\ncan be used to gather undesired channels from the flattened\nchannel tensor of shape <cite>[,num_rx, num_tx, num_streams_per_tx,]</cite>.\nThe result of the gather operation can be reshaped to\n<cite>[,num_rx, num_interfering_streams_per_rx,]</cite>.\n\n\n`property` `num_interfering_streams_per_rx`\n\nNumber of interfering streams received at each eceiver.\n\n\n`property` `num_rx`\n\nNumber of receivers.\n\n\n`property` `num_rx_per_tx`\n\nNumber of receivers communicating with a transmitter.\n\n\n`property` `num_streams_per_rx`\n\nNumber of streams transmitted to each receiver.\n\n\n`property` `num_streams_per_tx`\n\nNumber of streams per transmitter.\n\n\n`property` `num_tx`\n\nNumber of transmitters.\n\n\n`property` `num_tx_per_rx`\n\nNumber of transmitters communicating with a receiver.\n\n\n`property` `precoding_ind`\n\nIndices needed to gather channels for precoding.\n\nA NumPy array of shape <cite>[num_tx, num_rx_per_tx]</cite>,\nwhere `precoding_ind[i,:]` contains the indices of the\nreceivers to which transmitter <cite>i</cite> is sending streams.\n\n\n`property` `rx_stream_ids`\n\nMapping of streams to receivers.\n\nA Numpy array of shape <cite>[num_rx, num_streams_per_rx]</cite>.\nThis array is obtained from `tx_stream_ids` together with\nthe `rx_tx_association`. `rx_stream_ids[i,:]` contains\nthe indices of streams that are supposed to be decoded by receiver <cite>i</cite>.\n\n\n`property` `rx_tx_association`\n\nAssociation between receivers and transmitters.\n\nA binary NumPy array of shape <cite>[num_rx, num_tx]</cite>,\nwhere `rx_tx_association[i,j]=1` means that receiver <cite>i</cite>\ngets one ore multiple streams from transmitter <cite>j</cite>.\n\n\n`property` `stream_association`\n\nAssociation between receivers, transmitters, and streams.\n\nA binary NumPy array of shape\n<cite>[num_rx, num_tx, num_streams_per_tx]</cite>, where\n`stream_association[i,j,k]=1` means that receiver <cite>i</cite> gets\nthe <cite>k</cite> th stream from transmitter <cite>j</cite>.\n\n\n`property` `stream_ind`\n\nIndices needed to gather received streams in the correct order.\n\nA NumPy array of shape <cite>[num_rx*num_streams_per_rx]</cite> that can be\nused to gather streams from the flattened tensor of received streams\nof shape <cite>[,num_rx, num_streams_per_rx,]</cite>. The result of the\ngather operation is then reshaped to\n<cite>[,num_tx, num_streams_per_tx,]</cite>.\n\n\n`property` `tx_stream_ids`\n\nMapping of streams to transmitters.\n\nA NumPy array of shape <cite>[num_tx, num_streams_per_tx]</cite>.\nStreams are numbered from 0,1, and assiged to transmitters in\nincreasing order, i.e., transmitter 0 gets the first\n<cite>num_streams_per_tx</cite> and so on."
"### zero_forcing_precoder\n\n`sionna.mimo.``zero_forcing_precoder`(*`x`*, *`h`*, *`return_precoding_matrix``=``False`*)[`[source]`](../_modules/sionna/mimo/precoding.html#zero_forcing_precoder)\n\nZero-Forcing (ZF) Precoder\n\nThis function implements ZF precoding for a MIMO link, assuming the\nfollowing model:\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{G}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^K$ is the received signal vector,\n$\\mathbf{H}\\in\\mathbb{C}^{K\\times M}$ is the known channel matrix,\n$\\mathbf{G}\\in\\mathbb{C}^{M\\times K}$ is the precoding matrix,\n$\\mathbf{x}\\in\\mathbb{C}^K$ is the symbol vector to be precoded,\nand $\\mathbf{n}\\in\\mathbb{C}^K$ is a noise vector. It is assumed that\n$K\\le M$.\n\nThe precoding matrix $\\mathbf{G}$ is defined as (Eq. 4.37) [[BHS2017]](channel.wireless.html#bhs2017) :\n\n$$\n\\mathbf{G} = \\mathbf{V}\\mathbf{D}\n$$\n\nwhere\n\n$$\n\\begin{split}\\mathbf{V} &= \\mathbf{H}^{\\mathsf{H}}\\left(\\mathbf{H} \\mathbf{H}^{\\mathsf{H}}\\right)^{-1}\\\\\n\\mathbf{D} &= \\mathop{\\text{diag}}\\left( \\lVert \\mathbf{v}_{k} \\rVert_2^{-1}, k=0,\\dots,K-1 \\right).\\end{split}\n$$\n\nThis ensures that each stream is precoded with a unit-norm vector,\ni.e., $\\mathop{\\text{tr}}\\left(\\mathbf{G}\\mathbf{G}^{\\mathsf{H}}\\right)=K$.\nThe function returns the precoded vector $\\mathbf{G}\\mathbf{x}$.\nInput\n\n- **x** (*[,K], tf.complex*)  1+D tensor containing the symbol vectors to be precoded.\n- **h** (*[,K,M], tf.complex*)  2+D tensor containing the channel matrices\n- **return_precoding_matrices** (*bool*)  Indicates if the precoding matrices should be returned or not.\nDefaults to False.\n\n\nOutput\n\n- **x_precoded** (*[,M], tf.complex*)  Tensor of the same shape and dtype as `x` apart from the last\ndimensions that has changed from <cite>K</cite> to <cite>M</cite>. It contains the\nprecoded symbol vectors.\n- **g** (*[,M,K], tf.complex*)  2+D tensor containing the precoding matrices. It is only returned\nif `return_precoding_matrices=True`.\n\n\n**Note**\n\nIf you want to use this function in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### lmmse_equalizer\n\n`sionna.mimo.``lmmse_equalizer`(*`y`*, *`h`*, *`s`*, *`whiten_interference``=``True`*)[`[source]`](../_modules/sionna/mimo/equalization.html#lmmse_equalizer)\n\nMIMO LMMSE Equalizer\n\nThis function implements LMMSE equalization for a MIMO link, assuming the\nfollowing model:\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^M$ is the received signal vector,\n$\\mathbf{x}\\in\\mathbb{C}^K$ is the vector of transmitted symbols,\n$\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$ is the known channel matrix,\nand $\\mathbf{n}\\in\\mathbb{C}^M$ is a noise vector.\nIt is assumed that $\\mathbb{E}\\left[\\mathbf{x}\\right]=\\mathbb{E}\\left[\\mathbf{n}\\right]=\\mathbf{0}$,\n$\\mathbb{E}\\left[\\mathbf{x}\\mathbf{x}^{\\mathsf{H}}\\right]=\\mathbf{I}_K$ and\n$\\mathbb{E}\\left[\\mathbf{n}\\mathbf{n}^{\\mathsf{H}}\\right]=\\mathbf{S}$.\n\nThe estimated symbol vector $\\hat{\\mathbf{x}}\\in\\mathbb{C}^K$ is given as\n(Lemma B.19) [[BHS2017]](channel.wireless.html#bhs2017) :\n\n$$\n\\hat{\\mathbf{x}} = \\mathop{\\text{diag}}\\left(\\mathbf{G}\\mathbf{H}\\right)^{-1}\\mathbf{G}\\mathbf{y}\n$$\n\nwhere\n\n$$\n\\mathbf{G} = \\mathbf{H}^{\\mathsf{H}} \\left(\\mathbf{H}\\mathbf{H}^{\\mathsf{H}} + \\mathbf{S}\\right)^{-1}.\n$$\n\nThis leads to the post-equalized per-symbol model:\n\n$$\n\\hat{x}_k = x_k + e_k,\\quad k=0,\\dots,K-1\n$$\n\nwhere the variances $\\sigma^2_k$ of the effective residual noise\nterms $e_k$ are given by the diagonal elements of\n\n$$\n\\mathop{\\text{diag}}\\left(\\mathbb{E}\\left[\\mathbf{e}\\mathbf{e}^{\\mathsf{H}}\\right]\\right)\n= \\mathop{\\text{diag}}\\left(\\mathbf{G}\\mathbf{H} \\right)^{-1} - \\mathbf{I}.\n$$\n\nNote that the scaling by $\\mathop{\\text{diag}}\\left(\\mathbf{G}\\mathbf{H}\\right)^{-1}$\nis important for the [`Demapper`](mapping.html#sionna.mapping.Demapper) although it does\nnot change the signal-to-noise ratio.\n\nThe function returns $\\hat{\\mathbf{x}}$ and\n$\\boldsymbol{\\sigma}^2=\\left[\\sigma^2_0,\\dots, \\sigma^2_{K-1}\\right]^{\\mathsf{T}}$.\nInput\n\n- **y** (*[,M], tf.complex*)  1+D tensor containing the received signals.\n- **h** (*[,M,K], tf.complex*)  2+D tensor containing the channel matrices.\n- **s** (*[,M,M], tf.complex*)  2+D tensor containing the noise covariance matrices.\n- **whiten_interference** (*bool*)  If <cite>True</cite> (default), the interference is first whitened before equalization.\nIn this case, an alternative expression for the receive filter is used that\ncan be numerically more stable. Defaults to <cite>True</cite>.\n\n\nOutput\n\n- **x_hat** (*[,K], tf.complex*)  1+D tensor representing the estimated symbol vectors.\n- **no_eff** (*tf.float*)  Tensor of the same shape as `x_hat` containing the effective noise\nvariance estimates.\n\n\n**Note**\n\nIf you want to use this function in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### mf_equalizer\n\n`sionna.mimo.``mf_equalizer`(*`y`*, *`h`*, *`s`*)[`[source]`](../_modules/sionna/mimo/equalization.html#mf_equalizer)\n\nMIMO MF Equalizer\n\nThis function implements matched filter (MF) equalization for a\nMIMO link, assuming the following model:\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^M$ is the received signal vector,\n$\\mathbf{x}\\in\\mathbb{C}^K$ is the vector of transmitted symbols,\n$\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$ is the known channel matrix,\nand $\\mathbf{n}\\in\\mathbb{C}^M$ is a noise vector.\nIt is assumed that $\\mathbb{E}\\left[\\mathbf{x}\\right]=\\mathbb{E}\\left[\\mathbf{n}\\right]=\\mathbf{0}$,\n$\\mathbb{E}\\left[\\mathbf{x}\\mathbf{x}^{\\mathsf{H}}\\right]=\\mathbf{I}_K$ and\n$\\mathbb{E}\\left[\\mathbf{n}\\mathbf{n}^{\\mathsf{H}}\\right]=\\mathbf{S}$.\n\nThe estimated symbol vector $\\hat{\\mathbf{x}}\\in\\mathbb{C}^K$ is given as\n(Eq. 4.11) [[BHS2017]](channel.wireless.html#bhs2017) :\n\n$$\n\\hat{\\mathbf{x}} = \\mathbf{G}\\mathbf{y}\n$$\n\nwhere\n\n$$\n\\mathbf{G} = \\mathop{\\text{diag}}\\left(\\mathbf{H}^{\\mathsf{H}}\\mathbf{H}\\right)^{-1}\\mathbf{H}^{\\mathsf{H}}.\n$$\n\nThis leads to the post-equalized per-symbol model:\n\n$$\n\\hat{x}_k = x_k + e_k,\\quad k=0,\\dots,K-1\n$$\n\nwhere the variances $\\sigma^2_k$ of the effective residual noise\nterms $e_k$ are given by the diagonal elements of the matrix\n\n$$\n\\mathbb{E}\\left[\\mathbf{e}\\mathbf{e}^{\\mathsf{H}}\\right]\n= \\left(\\mathbf{I}-\\mathbf{G}\\mathbf{H} \\right)\\left(\\mathbf{I}-\\mathbf{G}\\mathbf{H} \\right)^{\\mathsf{H}} + \\mathbf{G}\\mathbf{S}\\mathbf{G}^{\\mathsf{H}}.\n$$\n\nNote that the scaling by $\\mathop{\\text{diag}}\\left(\\mathbf{H}^{\\mathsf{H}}\\mathbf{H}\\right)^{-1}$\nin the definition of $\\mathbf{G}$\nis important for the [`Demapper`](mapping.html#sionna.mapping.Demapper) although it does\nnot change the signal-to-noise ratio.\n\nThe function returns $\\hat{\\mathbf{x}}$ and\n$\\boldsymbol{\\sigma}^2=\\left[\\sigma^2_0,\\dots, \\sigma^2_{K-1}\\right]^{\\mathsf{T}}$.\nInput\n\n- **y** (*[,M], tf.complex*)  1+D tensor containing the received signals.\n- **h** (*[,M,K], tf.complex*)  2+D tensor containing the channel matrices.\n- **s** (*[,M,M], tf.complex*)  2+D tensor containing the noise covariance matrices.\n\n\nOutput\n\n- **x_hat** (*[,K], tf.complex*)  1+D tensor representing the estimated symbol vectors.\n- **no_eff** (*tf.float*)  Tensor of the same shape as `x_hat` containing the effective noise\nvariance estimates."
"### zf_equalizer\n\n`sionna.mimo.``zf_equalizer`(*`y`*, *`h`*, *`s`*)[`[source]`](../_modules/sionna/mimo/equalization.html#zf_equalizer)\n\nMIMO ZF Equalizer\n\nThis function implements zero-forcing (ZF) equalization for a MIMO link, assuming the\nfollowing model:\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^M$ is the received signal vector,\n$\\mathbf{x}\\in\\mathbb{C}^K$ is the vector of transmitted symbols,\n$\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$ is the known channel matrix,\nand $\\mathbf{n}\\in\\mathbb{C}^M$ is a noise vector.\nIt is assumed that $\\mathbb{E}\\left[\\mathbf{x}\\right]=\\mathbb{E}\\left[\\mathbf{n}\\right]=\\mathbf{0}$,\n$\\mathbb{E}\\left[\\mathbf{x}\\mathbf{x}^{\\mathsf{H}}\\right]=\\mathbf{I}_K$ and\n$\\mathbb{E}\\left[\\mathbf{n}\\mathbf{n}^{\\mathsf{H}}\\right]=\\mathbf{S}$.\n\nThe estimated symbol vector $\\hat{\\mathbf{x}}\\in\\mathbb{C}^K$ is given as\n(Eq. 4.10) [[BHS2017]](channel.wireless.html#bhs2017) :\n\n$$\n\\hat{\\mathbf{x}} = \\mathbf{G}\\mathbf{y}\n$$\n\nwhere\n\n$$\n\\mathbf{G} = \\left(\\mathbf{H}^{\\mathsf{H}}\\mathbf{H}\\right)^{-1}\\mathbf{H}^{\\mathsf{H}}.\n$$\n\nThis leads to the post-equalized per-symbol model:\n\n$$\n\\hat{x}_k = x_k + e_k,\\quad k=0,\\dots,K-1\n$$\n\nwhere the variances $\\sigma^2_k$ of the effective residual noise\nterms $e_k$ are given by the diagonal elements of the matrix\n\n$$\n\\mathbb{E}\\left[\\mathbf{e}\\mathbf{e}^{\\mathsf{H}}\\right]\n= \\mathbf{G}\\mathbf{S}\\mathbf{G}^{\\mathsf{H}}.\n$$\n\nThe function returns $\\hat{\\mathbf{x}}$ and\n$\\boldsymbol{\\sigma}^2=\\left[\\sigma^2_0,\\dots, \\sigma^2_{K-1}\\right]^{\\mathsf{T}}$.\nInput\n\n- **y** (*[,M], tf.complex*)  1+D tensor containing the received signals.\n- **h** (*[,M,K], tf.complex*)  2+D tensor containing the channel matrices.\n- **s** (*[,M,M], tf.complex*)  2+D tensor containing the noise covariance matrices.\n\n\nOutput\n\n- **x_hat** (*[,K], tf.complex*)  1+D tensor representing the estimated symbol vectors.\n- **no_eff** (*tf.float*)  Tensor of the same shape as `x_hat` containing the effective noise\nvariance estimates.\n\n\n**Note**\n\nIf you want to use this function in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### EPDetector\n\n`class` `sionna.mimo.``EPDetector`(*`output`*, *`num_bits_per_symbol`*, *`hard_out``=``False`*, *`l``=``10`*, *`beta``=``0.9`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/mimo/detection.html#EPDetector)\n\nMIMO Expectation Propagation (EP) detector\n\nThis layer implements Expectation Propagation (EP) MIMO detection as described\nin [[EP2014]](https://nvlabs.github.io/sionna/api/mimo.html#ep2014). It can generate hard- or soft-decisions for symbols or bits.\n\nThis layer assumes the following channel model:\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^M$ is the received signal vector,\n$\\mathbf{x}\\in\\mathcal{C}^S$ is the vector of transmitted symbols which\nare uniformly and independently drawn from the constellation $\\mathcal{C}$,\n$\\mathbf{H}\\in\\mathbb{C}^{M\\times S}$ is the known channel matrix,\nand $\\mathbf{n}\\in\\mathbb{C}^M$ is a complex Gaussian noise vector.\nIt is assumed that $\\mathbb{E}\\left[\\mathbf{n}\\right]=\\mathbf{0}$ and\n$\\mathbb{E}\\left[\\mathbf{n}\\mathbf{n}^{\\mathsf{H}}\\right]=\\mathbf{S}$,\nwhere $\\mathbf{S}$ has full rank.\n\nThe channel model is first whitened using [`whiten_channel()`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.whiten_channel)\nand then converted to its real-valued equivalent,\nsee [`complex2real_channel()`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.complex2real_channel), prior to MIMO detection.\n\nThe computation of LLRs is done by converting the symbol logits\nthat naturally arise in the algorithm to LLRs using\n[`PAM2QAM()`](mapping.html#sionna.mapping.PAM2QAM). Custom conversions of symbol logits to LLRs\ncan be implemented by using the soft-symbol output.\nParameters\n\n- **output** (*One of** [**\"bit\"**, **\"symbol\"**]**, **str*)  The type of output, either bits or symbols. Whether soft- or\nhard-decisions are returned can be configured with the\n`hard_out` flag.\n- **num_bits_per_symbol** (*int*)  The number of bits per QAM constellation symbol, e.g., 4 for QAM16.\n- **hard_out** (*bool*)  If <cite>True</cite>, the detector computes hard-decided bit values or\nconstellation point indices instead of soft-values.\nDefaults to <cite>False</cite>.\n- **l** (*int*)  Number of iterations. Defaults to 10.\n- **beta** (*float*)  Parameter $\\beta\\in[0,1]$ for update smoothing.\nDefaults to 0.9.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**] **tf.DType** (**dtype**)*)  Precision used for internal computations. Defaults to `tf.complex64`.\nEspecially for large MIMO setups, the precision can make a significant\nperformance difference.\n\n\nInput\n\n- **(y, h, s)**  Tuple:\n- **y** (*[,M], tf.complex*)  1+D tensor containing the received signals\n- **h** (*[,M,num_streams], tf.complex*)  2+D tensor containing the channel matrices\n- **s** (*[,M,M], tf.complex*)  2+D tensor containing the noise covariance matrices\n\n\nOutput\n\n- **One of**\n- *[,num_streams,num_bits_per_symbol], tf.float*  LLRs or hard-decisions for every bit of every stream, if `output` equals <cite>bit</cite>\n- *[,num_streams,2**num_bits_per_symbol], tf.float or [,num_streams], tf.int*  Logits or hard-decisions for constellation symbols for every stream, if `output` equals <cite>symbol</cite>\n\n\n**Note**\n\nFor numerical stability, we do not recommend to use this function in Graph\nmode with XLA, i.e., within a function that is decorated with\n`@tf.function(jit_compile=True)`.\nHowever, it is possible to do so by setting\n`sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### KBestDetector\n\n`class` `sionna.mimo.``KBestDetector`(*`output`*, *`num_streams`*, *`k`*, *`constellation_type``=``None`*, *`num_bits_per_symbol``=``None`*, *`constellation``=``None`*, *`hard_out``=``False`*, *`use_real_rep``=``False`*, *`list2llr``=``None`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/mimo/detection.html#KBestDetector)\n\nMIMO K-Best detector\n\nThis layer implements K-Best MIMO detection as described\nin (Eq. 4-5) [[FT2015]](https://nvlabs.github.io/sionna/api/mimo.html#ft2015). It can either generate hard decisions (for symbols\nor bits) or compute LLRs.\n\nThe algorithm operates in either the complex or real-valued domain.\nAlthough both options produce identical results, the former has the advantage\nthat it can be applied to arbitrary non-QAM constellations. It also reduces\nthe number of streams (or depth) by a factor of two.\n\nThe way soft-outputs (i.e., LLRs) are computed is determined by the\n`list2llr` function. The default solution\n[`List2LLRSimple`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.List2LLRSimple) assigns a predetermined\nvalue to all LLRs without counter-hypothesis.\n\nThis layer assumes the following channel model:\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^M$ is the received signal vector,\n$\\mathbf{x}\\in\\mathcal{C}^S$ is the vector of transmitted symbols which\nare uniformly and independently drawn from the constellation $\\mathcal{C}$,\n$\\mathbf{H}\\in\\mathbb{C}^{M\\times S}$ is the known channel matrix,\nand $\\mathbf{n}\\in\\mathbb{C}^M$ is a complex Gaussian noise vector.\nIt is assumed that $\\mathbb{E}\\left[\\mathbf{n}\\right]=\\mathbf{0}$ and\n$\\mathbb{E}\\left[\\mathbf{n}\\mathbf{n}^{\\mathsf{H}}\\right]=\\mathbf{S}$,\nwhere $\\mathbf{S}$ has full rank.\n\nIn a first optional step, the channel model is converted to its real-valued equivalent,\nsee [`complex2real_channel()`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.complex2real_channel). We assume in the sequel the complex-valued\nrepresentation. Then, the channel is whitened using [`whiten_channel()`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.whiten_channel):\n\n$$\n\\begin{split}\\tilde{\\mathbf{y}} &= \\mathbf{S}^{-\\frac{1}{2}}\\mathbf{y}\\\\\n&=  \\mathbf{S}^{-\\frac{1}{2}}\\mathbf{H}\\mathbf{x} + \\mathbf{S}^{-\\frac{1}{2}}\\mathbf{n}\\\\\n&= \\tilde{\\mathbf{H}}\\mathbf{x} + \\tilde{\\mathbf{n}}.\\end{split}\n$$\n\nNext, the columns of $\\tilde{\\mathbf{H}}$ are sorted according\nto their norm in descending order. Then, the QR decomposition of the\nresulting channel matrix is computed:\n\n$$\n\\tilde{\\mathbf{H}} = \\mathbf{Q}\\mathbf{R}\n$$\n\nwhere $\\mathbf{Q}\\in\\mathbb{C}^{M\\times S}$ is unitary and\n$\\mathbf{R}\\in\\mathbb{C}^{S\\times S}$ is upper-triangular.\nThe channel outputs are then pre-multiplied by $\\mathbf{Q}^{\\mathsf{H}}$.\nThis leads to the final channel model on which the K-Best detection algorithm operates:\n\n$$\n\\bar{\\mathbf{y}} = \\mathbf{R}\\bar{\\mathbf{x}} + \\bar{\\mathbf{n}}\n$$\n\nwhere $\\bar{\\mathbf{y}}\\in\\mathbb{C}^S$,\n$\\bar{\\mathbf{x}}\\in\\mathbb{C}^S$, and $\\bar{\\mathbf{n}}\\in\\mathbb{C}^S$\nwith $\\mathbb{E}\\left[\\bar{\\mathbf{n}}\\right]=\\mathbf{0}$ and\n$\\mathbb{E}\\left[\\bar{\\mathbf{n}}\\bar{\\mathbf{n}}^{\\mathsf{H}}\\right]=\\mathbf{I}$.\n\n**LLR Computation**\n\nThe K-Best algorithm produces $K$ candidate solutions $\\bar{\\mathbf{x}}_k\\in\\mathcal{C}^S$\nand their associated distance metrics $d_k=\\lVert \\bar{\\mathbf{y}} - \\mathbf{R}\\bar{\\mathbf{x}}_k \\rVert^2$\nfor $k=1,\\dots,K$. If the real-valued channel representation is used, the distance\nmetrics are scaled by 0.5 to account for the reduced noise power in each complex dimension.\nA hard-decision is simply the candidate with the shortest distance.\nVarious ways to compute LLRs from this list (and possibly\nadditional side-information) are possible. The (sub-optimal) default solution\nis [`List2LLRSimple`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.List2LLRSimple). Custom solutions can be provided.\nParameters\n\n- **output** (*One of** [**\"bit\"**, **\"symbol\"**]**, **str*)  The type of output, either bits or symbols. Whether soft- or\nhard-decisions are returned can be configured with the\n`hard_out` flag.\n- **num_streams** (*tf.int*)  Number of transmitted streams\n- **k** (*tf.int*)  The number of paths to keep. Cannot be larger than the\nnumber of constellation points to the power of the number of\nstreams.\n- **constellation_type** (*One of** [**\"qam\"**, **\"pam\"**, **\"custom\"**]**, **str*)  For custom, an instance of [`Constellation`](mapping.html#sionna.mapping.Constellation)\nmust be provided.\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation symbol, e.g., 4 for QAM16.\nOnly required for `constellation_type` in [qam, pam].\n- **constellation** ()  An instance of [`Constellation`](mapping.html#sionna.mapping.Constellation) or <cite>None</cite>.\nIn the latter case, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n- **hard_out** (*bool*)  If <cite>True</cite>, the detector computes hard-decided bit values or\nconstellation point indices instead of soft-values.\nDefaults to <cite>False</cite>. The detector cannot compute soft-symbols.\n- **use_real_rep** (*bool*)  If <cite>True</cite>, the detector use the real-valued equivalent representation\nof the channel. Note that this only works with a QAM constellation.\nDefaults to <cite>False</cite>.\n- **list2llr** (<cite>None</cite> or instance of [`List2LLR`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.List2LLR))  The function to be used to compute LLRs from a list of candidate solutions.\nIf <cite>None</cite>, the default solution [`List2LLRSimple`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.List2LLRSimple)\nis used.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**] **tf.DType** (**dtype**)*)  The dtype of `y`. Defaults to tf.complex64.\nThe output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n\nInput\n\n- **(y, h, s)**  Tuple:\n- **y** (*[,M], tf.complex*)  1+D tensor containing the received signals\n- **h** (*[,M,num_streams], tf.complex*)  2+D tensor containing the channel matrices\n- **s** (*[,M,M], tf.complex*)  2+D tensor containing the noise covariance matrices\n\n\nOutput\n\n- **One of**\n- *[,num_streams,num_bits_per_symbol], tf.float*  LLRs or hard-decisions for every bit of every stream, if `output` equals <cite>bit</cite>\n- *[,num_streams,2**num_points], tf.float or [,num_streams], tf.int*  Logits or hard-decisions for constellation symbols for every stream, if `output` equals <cite>symbol</cite>\nHard-decisions correspond to the symbol indices.\n\n\n**Note**\n\nIf you want to use this layer in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### LinearDetector\n\n`class` `sionna.mimo.``LinearDetector`(*`equalizer`*, *`output`*, *`demapping_method`*, *`constellation_type``=``None`*, *`num_bits_per_symbol``=``None`*, *`constellation``=``None`*, *`hard_out``=``False`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/mimo/detection.html#LinearDetector)\n\nConvenience class that combines an equalizer,\nsuch as [`lmmse_equalizer()`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.lmmse_equalizer), and a [`Demapper`](mapping.html#sionna.mapping.Demapper).\nParameters\n\n- **equalizer** (*str**, **one of** [**\"lmmse\"**, **\"zf\"**, **\"mf\"**]**, or **an equalizer function*)  The equalizer to be used. Either one of the existing equalizers\n[`lmmse_equalizer()`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.lmmse_equalizer), [`zf_equalizer()`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.zf_equalizer), or\n[`mf_equalizer()`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.mf_equalizer) can be used, or a custom equalizer\ncallable provided that has the same input/output specification.\n- **output** (*One of** [**\"bit\"**, **\"symbol\"**]**, **str*)  The type of output, either LLRs on bits or logits on constellation symbols.\n- **demapping_method** (*One of** [**\"app\"**, **\"maxlog\"**]**, **str*)  The demapping method used.\n- **constellation_type** (*One of** [**\"qam\"**, **\"pam\"**, **\"custom\"**]**, **str*)  For custom, an instance of [`Constellation`](mapping.html#sionna.mapping.Constellation)\nmust be provided.\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation symbol, e.g., 4 for QAM16.\nOnly required for `constellation_type` in [qam, pam].\n- **constellation** ()  An instance of [`Constellation`](mapping.html#sionna.mapping.Constellation) or <cite>None</cite>.\nIn the latter case, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n- **hard_out** (*bool*)  If <cite>True</cite>, the detector computes hard-decided bit values or\nconstellation point indices instead of soft-values.\nDefaults to <cite>False</cite>.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**] **tf.DType** (**dtype**)*)  The dtype of `y`. Defaults to tf.complex64.\nThe output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n\nInput\n\n- **(y, h, s)**  Tuple:\n- **y** (*[,M], tf.complex*)  1+D tensor containing the received signals\n- **h** (*[,M,num_streams], tf.complex*)  2+D tensor containing the channel matrices\n- **s** (*[,M,M], tf.complex*)  2+D tensor containing the noise covariance matrices\n\n\nOutput\n\n- **One of**\n- *[, num_streams, num_bits_per_symbol], tf.float*  LLRs or hard-decisions for every bit of every stream, if `output` equals <cite>bit</cite>\n- *[, num_streams, num_points], tf.float or [, num_streams], tf.int*  Logits or hard-decisions for constellation symbols for every stream, if `output` equals <cite>symbol</cite>\nHard-decisions correspond to the symbol indices.\n\n\n**Note**\n\nIf you want to use this layer in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou might need to set `sionna.Config.xla_compat=true`. This depends on the\nchosen equalizer function. See [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### MaximumLikelihoodDetector\n\n`class` `sionna.mimo.``MaximumLikelihoodDetector`(*`output`*, *`demapping_method`*, *`num_streams`*, *`constellation_type``=``None`*, *`num_bits_per_symbol``=``None`*, *`constellation``=``None`*, *`hard_out``=``False`*, *`with_prior``=``False`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/mimo/detection.html#MaximumLikelihoodDetector)\n\nMIMO maximum-likelihood (ML) detector.\nIf the `with_prior` flag is set, prior knowledge on the bits or constellation points is assumed to be available.\n\nThis layer implements MIMO maximum-likelihood (ML) detection assuming the\nfollowing channel model:\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^M$ is the received signal vector,\n$\\mathbf{x}\\in\\mathcal{C}^K$ is the vector of transmitted symbols which\nare uniformly and independently drawn from the constellation $\\mathcal{C}$,\n$\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$ is the known channel matrix,\nand $\\mathbf{n}\\in\\mathbb{C}^M$ is a complex Gaussian noise vector.\nIt is assumed that $\\mathbb{E}\\left[\\mathbf{n}\\right]=\\mathbf{0}$ and\n$\\mathbb{E}\\left[\\mathbf{n}\\mathbf{n}^{\\mathsf{H}}\\right]=\\mathbf{S}$,\nwhere $\\mathbf{S}$ has full rank.\nIf the `with_prior` flag is set, it is assumed that prior information of the transmitted signal $\\mathbf{x}$ is available,\nprovided either as LLRs on the bits mapped onto $\\mathbf{x}$ or as logits on the individual\nconstellation points forming $\\mathbf{x}$.\n\nPrior to demapping, the received signal is whitened:\n\n$$\n\\begin{split}\\tilde{\\mathbf{y}} &= \\mathbf{S}^{-\\frac{1}{2}}\\mathbf{y}\\\\\n&=  \\mathbf{S}^{-\\frac{1}{2}}\\mathbf{H}\\mathbf{x} + \\mathbf{S}^{-\\frac{1}{2}}\\mathbf{n}\\\\\n&= \\tilde{\\mathbf{H}}\\mathbf{x} + \\tilde{\\mathbf{n}}\\end{split}\n$$\n\nThe layer can compute ML detection of symbols or bits with either\nsoft- or hard-decisions. Note that decisions are computed symbol-/bit-wise\nand not jointly for the entire vector $\\textbf{x}$ (or the underlying vector\nof bits).\n\n**ML detection of bits:**\n\nSoft-decisions on bits are called log-likelihood ratios (LLR).\nWith the app demapping method, the LLR for the $i\\text{th}$ bit\nof the $k\\text{th}$ user is then computed according to\n\n$$\n\\begin{split}\\begin{align}\n    LLR(k,i)&= \\ln\\left(\\frac{\\Pr\\left(b_{k,i}=1\\lvert \\mathbf{y},\\mathbf{H}\\right)}{\\Pr\\left(b_{k,i}=0\\lvert \\mathbf{y},\\mathbf{H}\\right)}\\right)\\\\\n            &=\\ln\\left(\\frac{\n            \\sum_{\\mathbf{x}\\in\\mathcal{C}_{k,i,1}} \\exp\\left(\n                -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2\n                \\right) \\Pr\\left( \\mathbf{x} \\right)\n            }{\n            \\sum_{\\mathbf{x}\\in\\mathcal{C}_{k,i,0}} \\exp\\left(\n                -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2\n                \\right) \\Pr\\left( \\mathbf{x} \\right)\n            }\\right)\n\\end{align}\\end{split}\n$$\n\nwhere $\\mathcal{C}_{k,i,1}$ and $\\mathcal{C}_{k,i,0}$ are the\nsets of vectors of constellation points for which the $i\\text{th}$ bit\nof the $k\\text{th}$ user is equal to 1 and 0, respectively.\n$\\Pr\\left( \\mathbf{x} \\right)$ is the prior distribution of the vector of\nconstellation points $\\mathbf{x}$. Assuming that the constellation points and\nbit levels are independent, it is computed from the prior of the bits according to\n\n$$\n\\Pr\\left( \\mathbf{x} \\right) = \\prod_{k=1}^K \\prod_{i=1}^{I} \\sigma \\left( LLR_p(k,i) \\right)\n$$\n\nwhere $LLR_p(k,i)$ is the prior knowledge of the $i\\text{th}$ bit of the\n$k\\text{th}$ user given as an LLR and which is set to $0$ if no prior knowledge is assumed to be available,\nand $\\sigma\\left(\\cdot\\right)$ is the sigmoid function.\nThe definition of the LLR has been chosen such that it is equivalent with that of logit. This is\ndifferent from many textbooks in communications, where the LLR is\ndefined as $LLR(k,i) = \\ln\\left(\\frac{\\Pr\\left(b_{k,i}=0\\lvert \\mathbf{y},\\mathbf{H}\\right)}{\\Pr\\left(b_{k,i}=1\\lvert \\mathbf{y},\\mathbf{H}\\right)}\\right)$.\n\nWith the maxlog demapping method, the LLR for the $i\\text{th}$ bit\nof the $k\\text{th}$ user is approximated like\n\n$$\n\\begin{split}\\begin{align}\n    LLR(k,i) \\approx&\\ln\\left(\\frac{\n        \\max_{\\mathbf{x}\\in\\mathcal{C}_{k,i,1}} \\left( \\exp\\left(\n            -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2\n            \\right) \\Pr\\left( \\mathbf{x} \\right) \\right)\n        }{\n        \\max_{\\mathbf{x}\\in\\mathcal{C}_{k,i,0}} \\left( \\exp\\left(\n            -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2\n            \\right) \\Pr\\left( \\mathbf{x} \\right) \\right)\n        }\\right)\\\\\n        = &\\min_{\\mathbf{x}\\in\\mathcal{C}_{k,i,0}} \\left( \\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2 - \\ln \\left(\\Pr\\left( \\mathbf{x} \\right) \\right) \\right) -\n            \\min_{\\mathbf{x}\\in\\mathcal{C}_{k,i,1}} \\left( \\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2 - \\ln \\left( \\Pr\\left( \\mathbf{x} \\right) \\right) \\right).\n    \\end{align}\\end{split}\n$$\n\n**ML detection of symbols:**\n\nSoft-decisions on symbols are called logits (i.e., unnormalized log-probability).\n\nWith the app demapping method, the logit for the\nconstellation point $c \\in \\mathcal{C}$ of the $k\\text{th}$ user  is computed according to\n\n$$\n\\begin{align}\n    \\text{logit}(k,c) &= \\ln\\left(\\sum_{\\mathbf{x} : x_k = c} \\exp\\left(\n                -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2\n                \\right)\\Pr\\left( \\mathbf{x} \\right)\\right).\n\\end{align}\n$$\n\nWith the maxlog demapping method, the logit for the constellation point $c \\in \\mathcal{C}$\nof the $k\\text{th}$ user  is approximated like\n\n$$\n\\text{logit}(k,c) \\approx \\max_{\\mathbf{x} : x_k = c} \\left(\n        -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2 + \\ln \\left( \\Pr\\left( \\mathbf{x} \\right) \\right)\n        \\right).\n$$\n\nWhen hard decisions are requested, this layer returns for the $k$ th stream\n\n$$\n\\hat{c}_k = \\underset{c \\in \\mathcal{C}}{\\text{argmax}} \\left( \\sum_{\\mathbf{x} : x_k = c} \\exp\\left(\n                -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2\n                \\right)\\Pr\\left( \\mathbf{x} \\right) \\right)\n$$\n\nwhere $\\mathcal{C}$ is the set of constellation points.\nParameters\n\n- **output** (*One of** [**\"bit\"**, **\"symbol\"**]**, **str*)  The type of output, either LLRs on bits or logits on constellation symbols.\n- **demapping_method** (*One of** [**\"app\"**, **\"maxlog\"**]**, **str*)  The demapping method used.\n- **num_streams** (*tf.int*)  Number of transmitted streams\n- **constellation_type** (*One of** [**\"qam\"**, **\"pam\"**, **\"custom\"**]**, **str*)  For custom, an instance of [`Constellation`](mapping.html#sionna.mapping.Constellation)\nmust be provided.\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation symbol, e.g., 4 for QAM16.\nOnly required for `constellation_type` in [qam, pam].\n- **constellation** ()  An instance of [`Constellation`](mapping.html#sionna.mapping.Constellation) or <cite>None</cite>.\nIn the latter case, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n- **hard_out** (*bool*)  If <cite>True</cite>, the detector computes hard-decided bit values or\nconstellation point indices instead of soft-values.\nDefaults to <cite>False</cite>.\n- **with_prior** (*bool*)  If <cite>True</cite>, it is assumed that prior knowledge on the bits or constellation points is available.\nThis prior information is given as LLRs (for bits) or log-probabilities (for constellation points) as an\nadditional input to the layer.\nDefaults to <cite>False</cite>.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**] **tf.DType** (**dtype**)*)  The dtype of `y`. Defaults to tf.complex64.\nThe output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n\nInput\n\n- **(y, h, s) or (y, h, prior, s)**  Tuple:\n- **y** (*[,M], tf.complex*)  1+D tensor containing the received signals.\n- **h** (*[,M,num_streams], tf.complex*)  2+D tensor containing the channel matrices.\n- **prior** (*[,num_streams,num_bits_per_symbol] or [,num_streams,num_points], tf.float*)  Prior of the transmitted signals.\nIf `output` equals bit, then LLRs of the transmitted bits are expected.\nIf `output` equals symbol, then logits of the transmitted constellation points are expected.\nOnly required if the `with_prior` flag is set.\n- **s** (*[,M,M], tf.complex*)  2+D tensor containing the noise covariance matrices.\n\n\nOutput\n\n- **One of**\n- *[, num_streams, num_bits_per_symbol], tf.float*  LLRs or hard-decisions for every bit of every stream, if `output` equals <cite>bit</cite>.\n- *[, num_streams, num_points], tf.float or [, num_streams], tf.int*  Logits or hard-decisions for constellation symbols for every stream, if `output` equals <cite>symbol</cite>.\nHard-decisions correspond to the symbol indices.\n\n\n**Note**\n\nIf you want to use this layer in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### MaximumLikelihoodDetectorWithPrior\n\n`class` `sionna.mimo.``MaximumLikelihoodDetectorWithPrior`(*`output`*, *`demapping_method`*, *`num_streams`*, *`constellation_type``=``None`*, *`num_bits_per_symbol``=``None`*, *`constellation``=``None`*, *`hard_out``=``False`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/mimo/detection.html#MaximumLikelihoodDetectorWithPrior)\n\nMIMO maximum-likelihood (ML) detector, assuming prior\nknowledge on the bits or constellation points is available.\n\nThis class is deprecated as the functionality has been integrated\ninto [`MaximumLikelihoodDetector`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.MaximumLikelihoodDetector).\n\nThis layer implements MIMO maximum-likelihood (ML) detection assuming the\nfollowing channel model:\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^M$ is the received signal vector,\n$\\mathbf{x}\\in\\mathcal{C}^K$ is the vector of transmitted symbols which\nare uniformly and independently drawn from the constellation $\\mathcal{C}$,\n$\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$ is the known channel matrix,\nand $\\mathbf{n}\\in\\mathbb{C}^M$ is a complex Gaussian noise vector.\nIt is assumed that $\\mathbb{E}\\left[\\mathbf{n}\\right]=\\mathbf{0}$ and\n$\\mathbb{E}\\left[\\mathbf{n}\\mathbf{n}^{\\mathsf{H}}\\right]=\\mathbf{S}$,\nwhere $\\mathbf{S}$ has full rank.\nIt is assumed that prior information of the transmitted signal $\\mathbf{x}$ is available,\nprovided either as LLRs on the bits modulated onto $\\mathbf{x}$ or as logits on the individual\nconstellation points forming $\\mathbf{x}$.\n\nPrior to demapping, the received signal is whitened:\n\n$$\n\\begin{split}\\tilde{\\mathbf{y}} &= \\mathbf{S}^{-\\frac{1}{2}}\\mathbf{y}\\\\\n&=  \\mathbf{S}^{-\\frac{1}{2}}\\mathbf{H}\\mathbf{x} + \\mathbf{S}^{-\\frac{1}{2}}\\mathbf{n}\\\\\n&= \\tilde{\\mathbf{H}}\\mathbf{x} + \\tilde{\\mathbf{n}}\\end{split}\n$$\n\nThe layer can compute ML detection of symbols or bits with either\nsoft- or hard-decisions. Note that decisions are computed symbol-/bit-wise\nand not jointly for the entire vector $\\textbf{x}$ (or the underlying vector\nof bits).\n\n**ML detection of bits:**\n\nSoft-decisions on bits are called log-likelihood ratios (LLR).\nWith the app demapping method, the LLR for the $i\\text{th}$ bit\nof the $k\\text{th}$ user is then computed according to\n\n$$\n\\begin{split}\\begin{align}\n    LLR(k,i)&= \\ln\\left(\\frac{\\Pr\\left(b_{k,i}=1\\lvert \\mathbf{y},\\mathbf{H}\\right)}{\\Pr\\left(b_{k,i}=0\\lvert \\mathbf{y},\\mathbf{H}\\right)}\\right)\\\\\n            &=\\ln\\left(\\frac{\n            \\sum_{\\mathbf{x}\\in\\mathcal{C}_{k,i,1}} \\exp\\left(\n                -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2\n                \\right) \\Pr\\left( \\mathbf{x} \\right)\n            }{\n            \\sum_{\\mathbf{x}\\in\\mathcal{C}_{k,i,0}} \\exp\\left(\n                -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2\n                \\right) \\Pr\\left( \\mathbf{x} \\right)\n            }\\right)\n\\end{align}\\end{split}\n$$\n\nwhere $\\mathcal{C}_{k,i,1}$ and $\\mathcal{C}_{k,i,0}$ are the\nsets of vectors of constellation points for which the $i\\text{th}$ bit\nof the $k\\text{th}$ user is equal to 1 and 0, respectively.\n$\\Pr\\left( \\mathbf{x} \\right)$ is the prior distribution of the vector of\nconstellation points $\\mathbf{x}$. Assuming that the constellation points and\nbit levels are independent, it is computed from the prior of the bits according to\n\n$$\n\\Pr\\left( \\mathbf{x} \\right) = \\prod_{k=1}^K \\prod_{i=1}^{I} \\sigma \\left( LLR_p(k,i) \\right)\n$$\n\nwhere $LLR_p(k,i)$ is the prior knowledge of the $i\\text{th}$ bit of the\n$k\\text{th}$ user given as an LLR, and $\\sigma\\left(\\cdot\\right)$ is the sigmoid function.\nThe definition of the LLR has been chosen such that it is equivalent with that of logit. This is\ndifferent from many textbooks in communications, where the LLR is\ndefined as $LLR(k,i) = \\ln\\left(\\frac{\\Pr\\left(b_{k,i}=0\\lvert \\mathbf{y},\\mathbf{H}\\right)}{\\Pr\\left(b_{k,i}=1\\lvert \\mathbf{y},\\mathbf{H}\\right)}\\right)$.\n\nWith the maxlog demapping method, the LLR for the $i\\text{th}$ bit\nof the $k\\text{th}$ user is approximated like\n\n$$\n\\begin{split}\\begin{align}\n    LLR(k,i) \\approx&\\ln\\left(\\frac{\n        \\max_{\\mathbf{x}\\in\\mathcal{C}_{k,i,1}} \\left( \\exp\\left(\n            -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2\n            \\right) \\Pr\\left( \\mathbf{x} \\right) \\right)\n        }{\n        \\max_{\\mathbf{x}\\in\\mathcal{C}_{k,i,0}} \\left( \\exp\\left(\n            -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2\n            \\right) \\Pr\\left( \\mathbf{x} \\right) \\right)\n        }\\right)\\\\\n        = &\\min_{\\mathbf{x}\\in\\mathcal{C}_{k,i,0}} \\left( \\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2 - \\ln \\left(\\Pr\\left( \\mathbf{x} \\right) \\right) \\right) -\n            \\min_{\\mathbf{x}\\in\\mathcal{C}_{k,i,1}} \\left( \\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2 - \\ln \\left( \\Pr\\left( \\mathbf{x} \\right) \\right) \\right).\n    \\end{align}\\end{split}\n$$\n\n**ML detection of symbols:**\n\nSoft-decisions on symbols are called logits (i.e., unnormalized log-probability).\n\nWith the app demapping method, the logit for the\nconstellation point $c \\in \\mathcal{C}$ of the $k\\text{th}$ user  is computed according to\n\n$$\n\\begin{align}\n    \\text{logit}(k,c) &= \\ln\\left(\\sum_{\\mathbf{x} : x_k = c} \\exp\\left(\n                -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2\n                \\right)\\Pr\\left( \\mathbf{x} \\right)\\right).\n\\end{align}\n$$\n\nWith the maxlog demapping method, the logit for the constellation point $c \\in \\mathcal{C}$\nof the $k\\text{th}$ user  is approximated like\n\n$$\n\\text{logit}(k,c) \\approx \\max_{\\mathbf{x} : x_k = c} \\left(\n        -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2 + \\ln \\left( \\Pr\\left( \\mathbf{x} \\right) \\right)\n        \\right).\n$$\n\nWhen hard decisions are requested, this layer returns for the $k$ th stream\n\n$$\n\\hat{c}_k = \\underset{c \\in \\mathcal{C}}{\\text{argmax}} \\left( \\sum_{\\mathbf{x} : x_k = c} \\exp\\left(\n                -\\left\\lVert\\tilde{\\mathbf{y}}-\\tilde{\\mathbf{H}}\\mathbf{x}\\right\\rVert^2\n                \\right)\\Pr\\left( \\mathbf{x} \\right) \\right)\n$$\n\nwhere $\\mathcal{C}$ is the set of constellation points.\nParameters\n\n- **output** (*One of** [**\"bit\"**, **\"symbol\"**]**, **str*)  The type of output, either LLRs on bits or logits on constellation symbols.\n- **demapping_method** (*One of** [**\"app\"**, **\"maxlog\"**]**, **str*)  The demapping method used.\n- **num_streams** (*tf.int*)  Number of transmitted streams\n- **constellation_type** (*One of** [**\"qam\"**, **\"pam\"**, **\"custom\"**]**, **str*)  For custom, an instance of [`Constellation`](mapping.html#sionna.mapping.Constellation)\nmust be provided.\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation symbol, e.g., 4 for QAM16.\nOnly required for `constellation_type` in [qam, pam].\n- **constellation** ()  An instance of [`Constellation`](mapping.html#sionna.mapping.Constellation) or <cite>None</cite>.\nIn the latter case, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n- **hard_out** (*bool*)  If <cite>True</cite>, the detector computes hard-decided bit values or\nconstellation point indices instead of soft-values.\nDefaults to <cite>False</cite>.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**] **tf.DType** (**dtype**)*)  The dtype of `y`. Defaults to tf.complex64.\nThe output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n\nInput\n\n- **(y, h, prior, s)**  Tuple:\n- **y** (*[,M], tf.complex*)  1+D tensor containing the received signals.\n- **h** (*[,M,num_streams], tf.complex*)  2+D tensor containing the channel matrices.\n- **prior** (*[,num_streams,num_bits_per_symbol] or [,num_streams,num_points], tf.float*)  Prior of the transmitted signals.\nIf `output` equals bit, then LLRs of the transmitted bits are expected.\nIf `output` equals symbol, then logits of the transmitted constellation points are expected.\n- **s** (*[,M,M], tf.complex*)  2+D tensor containing the noise covariance matrices.\n\n\nOutput\n\n- **One of**\n- *[, num_streams, num_bits_per_symbol], tf.float*  LLRs or hard-decisions for every bit of every stream, if `output` equals <cite>bit</cite>.\n- *[, num_streams, num_points], tf.float or [, num_streams], tf.int*  Logits or hard-decisions for constellation symbols for every stream, if `output` equals <cite>symbol</cite>.\nHard-decisions correspond to the symbol indices.\n\n\n**Note**\n\nIf you want to use this layer in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### MMSE-PIC\n\n`class` `sionna.mimo.``MMSEPICDetector`(*`output`*, *`demapping_method``=``'maxlog'`*, *`num_iter``=``1`*, *`constellation_type``=``None`*, *`num_bits_per_symbol``=``None`*, *`constellation``=``None`*, *`hard_out``=``False`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/mimo/detection.html#MMSEPICDetector)\n\nMinimum mean square error (MMSE) with parallel interference cancellation (PIC) detector\n\nThis layer implements the MMSE PIC detector, as proposed in [[CST2011]](https://nvlabs.github.io/sionna/api/mimo.html#cst2011).\nFor `num_iter`>1, this implementation performs MMSE PIC self-iterations.\nMMSE PIC self-iterations can be understood as a concatenation of MMSE PIC\ndetectors from [[CST2011]](https://nvlabs.github.io/sionna/api/mimo.html#cst2011), which forward intrinsic LLRs to the next\nself-iteration.\n\nCompared to [[CST2011]](https://nvlabs.github.io/sionna/api/mimo.html#cst2011), this implementation also accepts priors on the\nconstellation symbols as an alternative to priors on the bits.\n\nThis layer assumes the following channel model:\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^M$ is the received signal vector,\n$\\mathbf{x}\\in\\mathcal{C}^S$ is the vector of transmitted symbols which\nare uniformly and independently drawn from the constellation $\\mathcal{C}$,\n$\\mathbf{H}\\in\\mathbb{C}^{M\\times S}$ is the known channel matrix,\nand $\\mathbf{n}\\in\\mathbb{C}^M$ is a complex Gaussian noise vector.\nIt is assumed that $\\mathbb{E}\\left[\\mathbf{n}\\right]=\\mathbf{0}$ and\n$\\mathbb{E}\\left[\\mathbf{n}\\mathbf{n}^{\\mathsf{H}}\\right]=\\mathbf{S}$,\nwhere $\\mathbf{S}$ has full rank.\n\nThe algorithm starts by computing the soft symbols\n$\\bar{x}_s=\\mathbb{E}\\left[ x_s \\right]$ and\nvariances $v_s=\\mathbb{E}\\left[ |e_s|^2\\right]$ from the priors,\nwhere $e_s = x_s - \\bar{x}_s$, for all $s=1,\\dots,S$.\n\nNext, for each stream, the interference caused by all other streams is cancelled\nfrom the observation $\\mathbf{y}$, leading to\n\n$$\n\\hat{\\mathbf{y}}_s = \\mathbf{y} - \\sum_{j\\neq s} \\mathbf{h}_j x_j = \\mathbf{h}_s x_s + \\tilde{\\mathbf{n}}_s,\\quad s=1,\\dots,S\n$$\n\nwhere $\\tilde{\\mathbf{n}}_s=\\sum_{j\\neq s} \\mathbf{h}_j e_j + \\mathbf{n}$.\n\nThen, a linear MMSE filter $\\mathbf{w}_s$ is computed to reduce the resdiual noise\nfor each observation $\\hat{\\mathbf{y}}_s$, which is given as\n\n$$\n\\mathbf{w}_s = \\mathbf{h}_s^{\\mathsf{H}}\\left( \\mathbf{H} \\mathbf{D}_s\\mathbf{H}^{\\mathsf{H}} +\\mathbf{S} \\right)^{-1}\n$$\n\nwhere $\\mathbf{D}_s \\in \\mathbb{C}^{S\\times S}$ is diagonal with entries\n\n$$\n\\begin{split}\\left[\\mathbf{D}_s\\right]_{i,i} = \\begin{cases}\n                                    v_i & i\\neq s \\\\\n                                    1 & i=s.\n                                  \\end{cases}\\end{split}\n$$\n\nThe filtered observations\n\n$$\n\\tilde{z}_s = \\mathbf{w}_s^{\\mathsf{H}} \\hat{\\mathbf{y}}_s = \\tilde{\\mu}_s x_s + \\mathbf{w}_s^{\\mathsf{H}}\\tilde{\\mathbf{n}}_s\n$$\n\nwhere $\\tilde{\\mu}_s=\\mathbf{w}_s^{\\mathsf{H}} \\mathbf{h}_s$, are then demapped to either symbol logits or LLRs, assuming that the remaining noise is Gaussian with variance\n\n$$\n\\nu_s^2 = \\mathop{\\text{Var}}\\left[\\tilde{z}_s\\right] = \\mathbf{w}_s^{\\mathsf{H}} \\left(\\sum_{j\\neq s} \\mathbf{h}_j \\mathbf{h}_j^{\\mathsf{H}} v_j +\\mathbf{S} \\right)\\mathbf{w}_s.\n$$\n\nThe resulting soft-symbols can then be used for the next self-iteration of the algorithm.\n\nNote that this algorithm can be substantially simplified as described in [[CST2011]](https://nvlabs.github.io/sionna/api/mimo.html#cst2011) to avoid\nthe computation of different matrix inverses for each stream. This is the version which is\nimplemented.\nParameters\n\n- **output** (*One of** [**\"bit\"**, **\"symbol\"**]**, **str*)  The type of output, either LLRs on bits or logits on constellation\nsymbols.\n- **demapping_method** (*One of** [**\"app\"**, **\"maxlog\"**]**, **str*)  The demapping method used.\nDefaults to maxlog.\n- **num_iter** (*int*)  Number of MMSE PIC iterations.\nDefaults to 1.\n- **constellation_type** (*One of** [**\"qam\"**, **\"pam\"**, **\"custom\"**]**, **str*)  For custom, an instance of [`Constellation`](mapping.html#sionna.mapping.Constellation)\nmust be provided.\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation symbol, e.g., 4 for QAM16.\nOnly required for `constellation_type` in [qam, pam].\n- **constellation** ()  An instance of [`Constellation`](mapping.html#sionna.mapping.Constellation) or <cite>None</cite>.\nIn the latter case, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n- **hard_out** (*bool*)  If <cite>True</cite>, the detector computes hard-decided bit values or\nconstellation point indices instead of soft-values.\nDefaults to <cite>False</cite>.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**] **tf.DType** (**dtype**)*)  The dtype of `y`. Defaults to tf.complex64.\nThe output dtype is the corresponding real dtype\n(tf.float32 or tf.float64).\n\n\nInput\n\n- **(y, h, prior, s)**  Tuple:\n- **y** (*[,M], tf.complex*)  1+D tensor containing the received signals\n- **h** (*[,M,S], tf.complex*)  2+D tensor containing the channel matrices\n- **prior** (*[,S,num_bits_per_symbol] or [,S,num_points], tf.float*)  Prior of the transmitted signals.\nIf `output` equals bit, then LLRs of the transmitted bits are expected.\nIf `output` equals symbol, then logits of the transmitted constellation points are expected.\n- **s** (*[,M,M], tf.complex*)  2+D tensor containing the noise covariance matrices\n\n\nOutput\n\n- **One of**\n- *[,S,num_bits_per_symbol], tf.float*  LLRs or hard-decisions for every bit of every stream, if `output` equals <cite>bit</cite>\n- *[,S,2**num_bits_per_symbol], tf.float or [,S], tf.int*  Logits or hard-decisions for constellation symbols for every stream, if `output` equals <cite>symbol</cite>\n\n\n**Note**\n\nFor numerical stability, we do not recommend to use this function in Graph\nmode with XLA, i.e., within a function that is decorated with\n`@tf.function(jit_compile=True)`.\nHowever, it is possible to do so by setting\n`sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### List2LLR\n\n`class` `sionna.mimo.``List2LLR`[`[source]`](../_modules/sionna/mimo/utils.html#List2LLR)\n\nAbstract class defining a callable to compute LLRs from a list of\ncandidate vectors (or paths) provided by a MIMO detector.\n\nThe following channel model is assumed\n\n$$\n\\bar{\\mathbf{y}} = \\mathbf{R}\\bar{\\mathbf{x}} + \\bar{\\mathbf{n}}\n$$\n\nwhere $\\bar{\\mathbf{y}}\\in\\mathbb{C}^S$ are the channel outputs,\n$\\mathbf{R}\\in\\mathbb{C}^{S\\times S}$ is an upper-triangular matrix,\n$\\bar{\\mathbf{x}}\\in\\mathbb{C}^S$ is the transmitted vector whose entries\nare uniformly and independently drawn from the constellation $\\mathcal{C}$,\nand $\\bar{\\mathbf{n}}\\in\\mathbb{C}^S$ is white noise\nwith $\\mathbb{E}\\left[\\bar{\\mathbf{n}}\\right]=\\mathbf{0}$ and\n$\\mathbb{E}\\left[\\bar{\\mathbf{n}}\\bar{\\mathbf{n}}^{\\mathsf{H}}\\right]=\\mathbf{I}$.\n\nIt is assumed that a MIMO detector such as [`KBestDetector`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.KBestDetector)\nproduces $K$ candidate solutions $\\bar{\\mathbf{x}}_k\\in\\mathcal{C}^S$\nand their associated distance metrics $d_k=\\lVert \\bar{\\mathbf{y}} - \\mathbf{R}\\bar{\\mathbf{x}}_k \\rVert^2$\nfor $k=1,\\dots,K$. This layer can also be used with the real-valued representation of the channel.\nInput\n\n- **(y, r, dists, path_inds, path_syms)**  Tuple:\n- **y** (*[,M], tf.complex or tf.float*)  Channel outputs of the whitened channel\n- **r** ([,num_streams, num_streams], same dtype as `y`)  Upper triangular channel matrix of the whitened channel\n- **dists** (*[,num_paths], tf.float*)  Distance metric for each path (or candidate)\n- **path_inds** (*[,num_paths,num_streams], tf.int32*)  Symbol indices for every stream of every path (or candidate)\n- **path_syms** ([,num_path,num_streams], same dtype as `y`)  Constellation symbol for every stream of every path (or candidate)\n\n\nOutput\n\n**llr** (*[num_streams,num_bits_per_symbol], tf.float*)  LLRs for all bits of every stream\n\n\n**Note**\n\nAn implementation of this class does not need to make use of all of\nthe provided inputs which enable various different implementations."
"### List2LLRSimple\n\n`class` `sionna.mimo.``List2LLRSimple`(*`num_bits_per_symbol`*, *`llr_clip_val``=``20.0`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/mimo/utils.html#List2LLRSimple)\n\nComputes LLRs from a list of candidate vectors (or paths) provided by a MIMO detector.\n\nThe following channel model is assumed:\n\n$$\n\\bar{\\mathbf{y}} = \\mathbf{R}\\bar{\\mathbf{x}} + \\bar{\\mathbf{n}}\n$$\n\nwhere $\\bar{\\mathbf{y}}\\in\\mathbb{C}^S$ are the channel outputs,\n$\\mathbf{R}\\in\\mathbb{C}^{S\\times S}$ is an upper-triangular matrix,\n$\\bar{\\mathbf{x}}\\in\\mathbb{C}^S$ is the transmitted vector whose entries\nare uniformly and independently drawn from the constellation $\\mathcal{C}$,\nand $\\bar{\\mathbf{n}}\\in\\mathbb{C}^S$ is white noise\nwith $\\mathbb{E}\\left[\\bar{\\mathbf{n}}\\right]=\\mathbf{0}$ and\n$\\mathbb{E}\\left[\\bar{\\mathbf{n}}\\bar{\\mathbf{n}}^{\\mathsf{H}}\\right]=\\mathbf{I}$.\n\nIt is assumed that a MIMO detector such as [`KBestDetector`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.KBestDetector)\nproduces $K$ candidate solutions $\\bar{\\mathbf{x}}_k\\in\\mathcal{C}^S$\nand their associated distance metrics $d_k=\\lVert \\bar{\\mathbf{y}} - \\mathbf{R}\\bar{\\mathbf{x}}_k \\rVert^2$\nfor $k=1,\\dots,K$. This layer can also be used with the real-valued representation of the channel.\n\nThe LLR for the $i\\text{th}$ bit of the $k\\text{th}$ stream is computed as\n\n$$\n\\begin{split}\\begin{align}\n    LLR(k,i) &= \\log\\left(\\frac{\\Pr(b_{k,i}=1|\\bar{\\mathbf{y}},\\mathbf{R})}{\\Pr(b_{k,i}=0|\\bar{\\mathbf{y}},\\mathbf{R})}\\right)\\\\\n        &\\approx \\min_{j \\in  \\mathcal{C}_{k,i,0}}d_j - \\min_{j \\in  \\mathcal{C}_{k,i,1}}d_j\n\\end{align}\\end{split}\n$$\n\nwhere $\\mathcal{C}_{k,i,1}$ and $\\mathcal{C}_{k,i,0}$ are the set of indices\nin the list of candidates for which the $i\\text{th}$ bit of the $k\\text{th}$\nstream is equal to 1 and 0, respectively. The LLRs are clipped to $\\pm LLR_\\text{clip}$\nwhich can be configured through the parameter `llr_clip_val`.\n\nIf $\\mathcal{C}_{k,i,0}$ is empty, $LLR(k,i)=LLR_\\text{clip}$;\nif $\\mathcal{C}_{k,i,1}$ is empty, $LLR(k,i)=-LLR_\\text{clip}$.\nParameters\n\n- **num_bits_per_symbol** (*int*)  Number of bits per constellation symbol\n- **llr_clip_val** (*float*)  The absolute values of LLRs are clipped to this value.\nDefaults to 20.0. Can also be a trainable variable.\n\n\nInput\n\n- **(y, r, dists, path_inds, path_syms)**  Tuple:\n- **y** (*[,M], tf.complex or tf.float*)  Channel outputs of the whitened channel\n- **r** ([,num_streams, num_streams], same dtype as `y`)  Upper triangular channel matrix of the whitened channel\n- **dists** (*[,num_paths], tf.float*)  Distance metric for each path (or candidate)\n- **path_inds** (*[,num_paths,num_streams], tf.int32*)  Symbol indices for every stream of every path (or candidate)\n- **path_syms** ([,num_path,num_streams], same dtype as `y`)  Constellation symbol for every stream of every path (or candidate)\n\n\nOutput\n\n**llr** (*[num_streams,num_bits_per_symbol], tf.float*)  LLRs for all bits of every stream"
"### complex2real_vector\n\n`sionna.mimo.``complex2real_vector`(*`z`*)[`[source]`](../_modules/sionna/mimo/utils.html#complex2real_vector)\n\nTransforms a complex-valued vector into its real-valued equivalent.\n\nTransforms the last dimension of a complex-valued tensor into\nits real-valued equivalent by stacking the real and imaginary\nparts on top of each other.\n\nFor a vector $\\mathbf{z}\\in \\mathbb{C}^M$ with real and imaginary\nparts $\\mathbf{x}\\in \\mathbb{R}^M$ and\n$\\mathbf{y}\\in \\mathbb{R}^M$, respectively, this function returns\nthe vector $\\left[\\mathbf{x}^{\\mathsf{T}}, \\mathbf{y}^{\\mathsf{T}} \\right ]^{\\mathsf{T}}\\in\\mathbb{R}^{2M}$.\nInput\n\n*[,M], tf.complex*\n\nOutput\n\n*[,2M], tf.complex.real_dtype*"
"### real2complex_vector\n\n`sionna.mimo.``real2complex_vector`(*`z`*)[`[source]`](../_modules/sionna/mimo/utils.html#real2complex_vector)\n\nTransforms a real-valued vector into its complex-valued equivalent.\n\nTransforms the last dimension of a real-valued tensor into\nits complex-valued equivalent by interpreting the first half\nas the real and the second half as the imaginary part.\n\nFor a vector $\\mathbf{z}=\\left[\\mathbf{x}^{\\mathsf{T}}, \\mathbf{y}^{\\mathsf{T}} \\right ]^{\\mathsf{T}}\\in \\mathbb{R}^{2M}$\nwith $\\mathbf{x}\\in \\mathbb{R}^M$ and $\\mathbf{y}\\in \\mathbb{R}^M$,\nthis function returns\nthe vector $\\mathbf{x}+j\\mathbf{y}\\in\\mathbb{C}^M$.\nInput\n\n*[,2M], tf.float*\n\nOutput\n\n*[,M], tf.complex*"
"### complex2real_matrix\n\n`sionna.mimo.``complex2real_matrix`(*`z`*)[`[source]`](../_modules/sionna/mimo/utils.html#complex2real_matrix)\n\nTransforms a complex-valued matrix into its real-valued equivalent.\n\nTransforms the last two dimensions of a complex-valued tensor into\ntheir real-valued matrix equivalent representation.\n\nFor a matrix $\\mathbf{Z}\\in \\mathbb{C}^{M\\times K}$ with real and imaginary\nparts $\\mathbf{X}\\in \\mathbb{R}^{M\\times K}$ and\n$\\mathbf{Y}\\in \\mathbb{R}^{M\\times K}$, respectively, this function returns\nthe matrix $\\tilde{\\mathbf{Z}}\\in \\mathbb{R}^{2M\\times 2K}$, given as\n\n$$\n\\begin{split}\\tilde{\\mathbf{Z}} = \\begin{pmatrix}\n                        \\mathbf{X} & -\\mathbf{Y}\\\\\n                        \\mathbf{Y} & \\mathbf{X}\n                     \\end{pmatrix}.\\end{split}\n$$\n\nInput\n\n*[,M,K], tf.complex*\n\nOutput\n\n*[,2M, 2K], tf.complex.real_dtype*"
"### real2complex_matrix\n\n`sionna.mimo.``real2complex_matrix`(*`z`*)[`[source]`](../_modules/sionna/mimo/utils.html#real2complex_matrix)\n\nTransforms a real-valued matrix into its complex-valued equivalent.\n\nTransforms the last two dimensions of a real-valued tensor into\ntheir complex-valued matrix equivalent representation.\n\nFor a matrix $\\tilde{\\mathbf{Z}}\\in \\mathbb{R}^{2M\\times 2K}$,\nsatisfying\n\n$$\n\\begin{split}\\tilde{\\mathbf{Z}} = \\begin{pmatrix}\n                        \\mathbf{X} & -\\mathbf{Y}\\\\\n                        \\mathbf{Y} & \\mathbf{X}\n                     \\end{pmatrix}\\end{split}\n$$\n\nwith $\\mathbf{X}\\in \\mathbb{R}^{M\\times K}$ and\n$\\mathbf{Y}\\in \\mathbb{R}^{M\\times K}$, this function returns\nthe matrix $\\mathbf{Z}=\\mathbf{X}+j\\mathbf{Y}\\in\\mathbb{C}^{M\\times K}$.\nInput\n\n*[,2M,2K], tf.float*\n\nOutput\n\n*[,M, 2], tf.complex*"
"### complex2real_covariance\n\n`sionna.mimo.``complex2real_covariance`(*`r`*)[`[source]`](../_modules/sionna/mimo/utils.html#complex2real_covariance)\n\nTransforms a complex-valued covariance matrix to its real-valued equivalent.\n\nAssume a proper complex random variable $\\mathbf{z}\\in\\mathbb{C}^M$ [[ProperRV]](https://nvlabs.github.io/sionna/api/mimo.html#properrv)\nwith covariance matrix $\\mathbf{R}= \\in\\mathbb{C}^{M\\times M}$\nand real and imaginary parts $\\mathbf{x}\\in \\mathbb{R}^M$ and\n$\\mathbf{y}\\in \\mathbb{R}^M$, respectively.\nThis function transforms the given $\\mathbf{R}$ into the covariance matrix of the real-valued equivalent\nvector $\\tilde{\\mathbf{z}}=\\left[\\mathbf{x}^{\\mathsf{T}}, \\mathbf{y}^{\\mathsf{T}} \\right ]^{\\mathsf{T}}\\in\\mathbb{R}^{2M}$, which\nis computed as [[CovProperRV]](https://nvlabs.github.io/sionna/api/mimo.html#covproperrv)\n\n$$\n\\begin{split}\\mathbb{E}\\left[\\tilde{\\mathbf{z}}\\tilde{\\mathbf{z}}^{\\mathsf{H}} \\right] =\n\\begin{pmatrix}\n    \\frac12\\Re\\{\\mathbf{R}\\} & -\\frac12\\Im\\{\\mathbf{R}\\}\\\\\n    \\frac12\\Im\\{\\mathbf{R}\\} & \\frac12\\Re\\{\\mathbf{R}\\}\n\\end{pmatrix}.\\end{split}\n$$\n\nInput\n\n*[,M,M], tf.complex*\n\nOutput\n\n*[,2M, 2M], tf.complex.real_dtype*"
"### real2complex_covariance\n\n`sionna.mimo.``real2complex_covariance`(*`q`*)[`[source]`](../_modules/sionna/mimo/utils.html#real2complex_covariance)\n\nTransforms a real-valued covariance matrix to its complex-valued equivalent.\n\nAssume a proper complex random variable $\\mathbf{z}\\in\\mathbb{C}^M$ [[ProperRV]](https://nvlabs.github.io/sionna/api/mimo.html#properrv)\nwith covariance matrix $\\mathbf{R}= \\in\\mathbb{C}^{M\\times M}$\nand real and imaginary parts $\\mathbf{x}\\in \\mathbb{R}^M$ and\n$\\mathbf{y}\\in \\mathbb{R}^M$, respectively.\nThis function transforms the given covariance matrix of the real-valued equivalent\nvector $\\tilde{\\mathbf{z}}=\\left[\\mathbf{x}^{\\mathsf{T}}, \\mathbf{y}^{\\mathsf{T}} \\right ]^{\\mathsf{T}}\\in\\mathbb{R}^{2M}$, which\nis given as [[CovProperRV]](https://nvlabs.github.io/sionna/api/mimo.html#covproperrv)\n\n$$\n\\begin{split}\\mathbb{E}\\left[\\tilde{\\mathbf{z}}\\tilde{\\mathbf{z}}^{\\mathsf{H}} \\right] =\n\\begin{pmatrix}\n    \\frac12\\Re\\{\\mathbf{R}\\} & -\\frac12\\Im\\{\\mathbf{R}\\}\\\\\n    \\frac12\\Im\\{\\mathbf{R}\\} & \\frac12\\Re\\{\\mathbf{R}\\}\n\\end{pmatrix},\\end{split}\n$$\n\ninto is complex-valued equivalent $\\mathbf{R}$.\nInput\n\n*[,2M,2M], tf.float*\n\nOutput\n\n*[,M, M], tf.complex*"
"### complex2real_channel\n\n`sionna.mimo.``complex2real_channel`(*`y`*, *`h`*, *`s`*)[`[source]`](../_modules/sionna/mimo/utils.html#complex2real_channel)\n\nTransforms a complex-valued MIMO channel into its real-valued equivalent.\n\nAssume the canonical MIMO channel model\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^M$ is the received signal vector,\n$\\mathbf{x}\\in\\mathbb{C}^K$ is the vector of transmitted symbols,\n$\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$ is the known channel matrix,\nand $\\mathbf{n}\\in\\mathbb{C}^M$ is a noise vector with covariance\nmatrix $\\mathbf{S}\\in\\mathbb{C}^{M\\times M}$.\n\nThis function returns the real-valued equivalent representations of\n$\\mathbf{y}$, $\\mathbf{H}$, and $\\mathbf{S}$,\nwhich are used by a wide variety of MIMO detection algorithms (Section VII) [[YH2015]](https://nvlabs.github.io/sionna/api/mimo.html#yh2015).\nThese are obtained by applying [`complex2real_vector()`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.complex2real_vector) to $\\mathbf{y}$,\n[`complex2real_matrix()`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.complex2real_matrix) to $\\mathbf{H}$,\nand [`complex2real_covariance()`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.complex2real_covariance) to $\\mathbf{S}$.\nInput\n\n- **y** (*[,M], tf.complex*)  1+D tensor containing the received signals.\n- **h** (*[,M,K], tf.complex*)  2+D tensor containing the channel matrices.\n- **s** (*[,M,M], tf.complex*)  2+D tensor containing the noise covariance matrices.\n\n\nOutput\n\n- *[,2M], tf.complex.real_dtype*  1+D tensor containing the real-valued equivalent received signals.\n- *[,2M,2K], tf.complex.real_dtype*  2+D tensor containing the real-valued equivalent channel matrices.\n- *[,2M,2M], tf.complex.real_dtype*  2+D tensor containing the real-valued equivalent noise covariance matrices."
"### real2complex_channel\n\n`sionna.mimo.``real2complex_channel`(*`y`*, *`h`*, *`s`*)[`[source]`](../_modules/sionna/mimo/utils.html#real2complex_channel)\n\nTransforms a real-valued MIMO channel into its complex-valued equivalent.\n\nAssume the canonical MIMO channel model\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^M$ is the received signal vector,\n$\\mathbf{x}\\in\\mathbb{C}^K$ is the vector of transmitted symbols,\n$\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$ is the known channel matrix,\nand $\\mathbf{n}\\in\\mathbb{C}^M$ is a noise vector with covariance\nmatrix $\\mathbf{S}\\in\\mathbb{C}^{M\\times M}$.\n\nThis function transforms the real-valued equivalent representations of\n$\\mathbf{y}$, $\\mathbf{H}$, and $\\mathbf{S}$, as, e.g.,\nobtained with the function [`complex2real_channel()`](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.complex2real_channel),\nback to their complex-valued equivalents (Section VII) [[YH2015]](https://nvlabs.github.io/sionna/api/mimo.html#yh2015).\nInput\n\n- **y** (*[,2M], tf.float*)  1+D tensor containing the real-valued received signals.\n- **h** (*[,2M,2K], tf.float*)  2+D tensor containing the real-valued channel matrices.\n- **s** (*[,2M,2M], tf.float*)  2+D tensor containing the real-valued noise covariance matrices.\n\n\nOutput\n\n- *[,M], tf.complex*  1+D tensor containing the complex-valued equivalent received signals.\n- *[,M,K], tf.complex*  2+D tensor containing the complex-valued equivalent channel matrices.\n- *[,M,M], tf.complex*  2+D tensor containing the complex-valued equivalent noise covariance matrices."
"### whiten_channel\n\n`sionna.mimo.``whiten_channel`(*`y`*, *`h`*, *`s`*, *`return_s``=``True`*)[`[source]`](../_modules/sionna/mimo/utils.html#whiten_channel)\n\nWhitens a canonical MIMO channel.\n\nAssume the canonical MIMO channel model\n\n$$\n\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^M(\\mathbb{R}^M)$ is the received signal vector,\n$\\mathbf{x}\\in\\mathbb{C}^K(\\mathbb{R}^K)$ is the vector of transmitted symbols,\n$\\mathbf{H}\\in\\mathbb{C}^{M\\times K}(\\mathbb{R}^{M\\times K})$ is the known channel matrix,\nand $\\mathbf{n}\\in\\mathbb{C}^M(\\mathbb{R}^M)$ is a noise vector with covariance\nmatrix $\\mathbf{S}\\in\\mathbb{C}^{M\\times M}(\\mathbb{R}^{M\\times M})$.\n\nThis function whitens this channel by multiplying $\\mathbf{y}$ and\n$\\mathbf{H}$ from the left by $\\mathbf{S}^{-\\frac{1}{2}}$.\nOptionally, the whitened noise covariance matrix $\\mathbf{I}_M$\ncan be returned.\nInput\n\n- **y** (*[,M], tf.float or tf.complex*)  1+D tensor containing the received signals.\n- **h** (*[,M,K], tf.float or tf.complex*)  2+D tensor containing the  channel matrices.\n- **s** (*[,M,M], tf.float or complex*)  2+D tensor containing the noise covariance matrices.\n- **return_s** (*bool*)  If <cite>True</cite>, the whitened covariance matrix is returned.\nDefaults to <cite>True</cite>.\n\n\nOutput\n\n- *[,M], tf.float or tf.complex*  1+D tensor containing the whitened received signals.\n- *[,M,K], tf.float or tf.complex*  2+D tensor containing the whitened channel matrices.\n- *[,M,M], tf.float or tf.complex*  2+D tensor containing the whitened noise covariance matrices.\nOnly returned if `return_s` is <cite>True</cite>.\n\n\nReferences:\nProperRV([1](https://nvlabs.github.io/sionna/api/mimo.html#id11),[2](https://nvlabs.github.io/sionna/api/mimo.html#id13))\n\n[Proper complex random variables](https://en.wikipedia.org/wiki/Complex_random_variable#Proper_complex_random_variables),\nWikipedia, accessed 11 September, 2022.\n\nCovProperRV([1](https://nvlabs.github.io/sionna/api/mimo.html#id12),[2](https://nvlabs.github.io/sionna/api/mimo.html#id14))\n\n[Covariance matrices of real and imaginary parts](https://en.wikipedia.org/wiki/Complex_random_vector#Covariance_matrices_of_real_and_imaginary_parts),\nWikipedia, accessed 11 September, 2022.\n\nYH2015([1](https://nvlabs.github.io/sionna/api/mimo.html#id15),[2](https://nvlabs.github.io/sionna/api/mimo.html#id16))\n\nS. Yang and L. Hanzo, [Fifty Years of MIMO Detection: The Road to Large-Scale MIMOs](https://ieeexplore.ieee.org/abstract/document/7244171),\nIEEE Communications Surveys & Tutorials, vol. 17, no. 4, pp. 1941-1988, 2015.\n\n[FT2015](https://nvlabs.github.io/sionna/api/mimo.html#id6)\n\nW. Fu and J. S. Thompson, [Performance analysis of K-best detection with adaptive modulation](https://ieeexplore.ieee.org/abstract/document/7454351), IEEE Int. Symp. Wirel. Commun. Sys. (ISWCS), 2015.\n\n[EP2014](https://nvlabs.github.io/sionna/api/mimo.html#id5)\n\nJ. Cspedes, P. M. Olmos, M. Snchez-Fernndez, and F. Perez-Cruz,\n[Expectation Propagation Detection for High-Order High-Dimensional MIMO Systems](https://ieeexplore.ieee.org/abstract/document/6841617),\nIEEE Trans. Commun., vol. 62, no. 8, pp. 2840-2849, Aug. 2014.\n\nCST2011([1](https://nvlabs.github.io/sionna/api/mimo.html#id7),[2](https://nvlabs.github.io/sionna/api/mimo.html#id8),[3](https://nvlabs.github.io/sionna/api/mimo.html#id9),[4](https://nvlabs.github.io/sionna/api/mimo.html#id10))\n\nC. Studer, S. Fateh, and D. Seethaler,\n[ASIC Implementation of Soft-Input Soft-Output MIMO Detection Using MMSE Parallel Interference Cancellation](https://ieeexplore.ieee.org/abstract/document/5779722),\nIEEE Journal of Solid-State Circuits, vol. 46, no. 7, pp. 17541765, July 2011."
"# Orthogonal Frequency-Division Multiplexing (OFDM)\n\nThis module provides layers and functions to support\nsimulation of OFDM-based systems. The key component is the\n[`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid) that defines how data and pilot symbols\nare mapped onto a sequence of OFDM symbols with a given FFT size. The resource\ngrid can also define guard and DC carriers which are nulled. In 4G/5G parlance,\na [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid) would be a slot.\nOnce a [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid) is defined, one can use the\n[`ResourceGridMapper`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGridMapper) to map a tensor of complex-valued\ndata symbols onto the resource grid, prior to OFDM modulation using the\n[`OFDMModulator`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.OFDMModulator) or further processing in the\nfrequency domain.\n\nThe [`PilotPattern`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.PilotPattern) allows for a fine-grained configuration\nof how transmitters send pilots for each of their streams or antennas. As the\nmanagement of pilots in multi-cell MIMO setups can quickly become complicated,\nthe module provides the [`KroneckerPilotPattern`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.KroneckerPilotPattern) class\nthat automatically generates orthogonal pilot transmissions for all transmitters\nand streams.\n\nAdditionally, the module contains layers for channel estimation, precoding,\nequalization, and detection,\nsuch as the [`LSChannelEstimator`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.LSChannelEstimator), the\n[`ZFPrecoder`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ZFPrecoder), and the [`LMMSEEqualizer`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.LMMSEEqualizer) and\n[`LinearDetector`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.LinearDetector).\nThese are good starting points for the development of more advanced algorithms\nand provide robust baselines for benchmarking."
"## Resource Grid\n\nThe following code snippet shows how to setup and visualize an instance of\n[`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid):\n```python\nrg = ResourceGrid(num_ofdm_symbols = 14,\n                  fft_size = 64,\n                  subcarrier_spacing = 30e3,\n                  num_tx = 1,\n                  num_streams_per_tx = 1,\n                  num_guard_carriers = [5, 6],\n                  dc_null = True,\n                  pilot_pattern = \"kronecker\",\n                  pilot_ofdm_symbol_indices = [2, 11])\nrg.show();\n```\n\n\nThis code creates a resource grid consisting of 14 OFDM symbols with 64\nsubcarriers. The first five and last six subcarriers as well as the DC\nsubcarriers are nulled. The second and eleventh OFDM symbol are reserved\nfor pilot transmissions.\n\nSubcarriers are numbered from $0$ to $N-1$, where $N$\nis the FTT size. The index $0$ corresponds to the lowest frequency,\nwhich is $-\\frac{N}{2}\\Delta_f$ (for $N$ even) or\n$-\\frac{N-1}{2}\\Delta_f$ (for $N$ odd), where $\\Delta_f$\nis the subcarrier spacing which is irrelevant for the resource grid.\nThe index $N-1$ corresponds to the highest frequency,\nwhich is $(\\frac{N}{2}-1)\\Delta_f$ (for $N$ even) or\n$\\frac{N-1}{2}\\Delta_f$ (for $N$ odd)."
"### ResourceGrid\n\n`class` `sionna.ofdm.``ResourceGrid`(*`num_ofdm_symbols`*, *`fft_size`*, *`subcarrier_spacing`*, *`num_tx``=``1`*, *`num_streams_per_tx``=``1`*, *`cyclic_prefix_length``=``0`*, *`num_guard_carriers``=``(0,` `0)`*, *`dc_null``=``False`*, *`pilot_pattern``=``None`*, *`pilot_ofdm_symbol_indices``=``None`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/ofdm/resource_grid.html#ResourceGrid)\n\nDefines a <cite>ResourceGrid</cite> spanning multiple OFDM symbols and subcarriers.\nParameters\n\n- **num_ofdm_symbols** (*int*)  Number of OFDM symbols.\n- **fft_size** (*int*)  FFT size (, i.e., the number of subcarriers).\n- **subcarrier_spacing** (*float*)  The subcarrier spacing in Hz.\n- **num_tx** (*int*)  Number of transmitters.\n- **num_streams_per_tx** (*int*)  Number of streams per transmitter.\n- **cyclic_prefix_length** (*int*)  Length of the cyclic prefix.\n- **num_guard_carriers** (*int*)  List of two integers defining the number of guardcarriers at the\nleft and right side of the resource grid.\n- **dc_null** (*bool*)  Indicates if the DC carrier is nulled or not.\n- **pilot_pattern** (*One of** [**None**, **\"kronecker\"**, **\"empty\"**, **]*)  An instance of [`PilotPattern`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.PilotPattern), a string\nshorthand for the [`KroneckerPilotPattern`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.KroneckerPilotPattern)\nor [`EmptyPilotPattern`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.EmptyPilotPattern), or <cite>None</cite>.\nDefaults to <cite>None</cite> which is equivalent to <cite>empty</cite>.\n- **pilot_ofdm_symbol_indices** (*List**, **int*)  List of indices of OFDM symbols reserved for pilot transmissions.\nOnly needed if `pilot_pattern=\"kronecker\"`. Defaults to <cite>None</cite>.\n- **dtype** (*tf.Dtype*)  Defines the datatype for internal calculations and the output\ndtype. Defaults to <cite>tf.complex64</cite>.\n\n\n`property` `bandwidth`\n\n`fft_size*subcarrier_spacing`.\nType\n\nThe occupied bandwidth [Hz]\n\n\n`build_type_grid`()[`[source]`](../_modules/sionna/ofdm/resource_grid.html#ResourceGrid.build_type_grid)\n\nReturns a tensor indicating the type of each resource element.\n\nResource elements can be one of\n\n- 0 : Data symbol\n- 1 : Pilot symbol\n- 2 : Guard carrier symbol\n- 3 : DC carrier symbol\n\nOutput\n\n*[num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size], tf.int32*  Tensor indicating for each transmitter and stream the type of\nthe resource elements of the corresponding resource grid.\nThe type can be one of [0,1,2,3] as explained above.\n\n\n`property` `cyclic_prefix_length`\n\nLength of the cyclic prefix.\n\n\n`property` `dc_ind`\n\nIndex of the DC subcarrier.\n\nIf `fft_size` is odd, the index is (`fft_size`-1)/2.\nIf `fft_size` is even, the index is `fft_size`/2.\n\n\n`property` `dc_null`\n\nIndicates if the DC carriers is nulled or not.\n\n\n`property` `effective_subcarrier_ind`\n\nReturns the indices of the effective subcarriers.\n\n\n`property` `fft_size`\n\nThe FFT size.\n\n\n`property` `num_data_symbols`\n\nNumber of resource elements used for data transmissions.\n\n\n`property` `num_effective_subcarriers`\n\nNumber of subcarriers used for data and pilot transmissions.\n\n\n`property` `num_guard_carriers`\n\nNumber of left and right guard carriers.\n\n\n`property` `num_ofdm_symbols`\n\nThe number of OFDM symbols of the resource grid.\n\n\n`property` `num_pilot_symbols`\n\nNumber of resource elements used for pilot symbols.\n\n\n`property` `num_resource_elements`\n\nNumber of resource elements.\n\n\n`property` `num_streams_per_tx`\n\nNumber of streams  per transmitter.\n\n\n`property` `num_time_samples`\n\nThe number of time-domain samples occupied by the resource grid.\n\n\n`property` `num_tx`\n\nNumber of transmitters.\n\n\n`property` `num_zero_symbols`\n\nNumber of empty resource elements.\n\n\n`property` `ofdm_symbol_duration`\n\nDuration of an OFDM symbol with cyclic prefix [s].\n\n\n`property` `pilot_pattern`\n\nThe used PilotPattern.\n\n\n`show`(*`tx_ind``=``0`*, *`tx_stream_ind``=``0`*)[`[source]`](../_modules/sionna/ofdm/resource_grid.html#ResourceGrid.show)\n\nVisualizes the resource grid for a specific transmitter and stream.\nInput\n\n- **tx_ind** (*int*)  Indicates the transmitter index.\n- **tx_stream_ind** (*int*)  Indicates the index of the stream.\n\n\nOutput\n\n<cite>matplotlib.figure</cite>  A handle to a matplot figure object.\n\n\n`property` `subcarrier_spacing`\n\nThe subcarrier spacing [Hz]."
"### ResourceGridMapper\n\n`class` `sionna.ofdm.``ResourceGridMapper`(*`resource_grid`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/ofdm/resource_grid.html#ResourceGridMapper)\n\nMaps a tensor of modulated data symbols to a ResourceGrid.\n\nThis layer takes as input a tensor of modulated data symbols\nand maps them together with pilot symbols onto an\nOFDM [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid). The output can be\nconverted to a time-domain signal with the\n`Modulator` or further processed in the\nfrequency domain.\nParameters\n\n- **resource_grid** ()  An instance of [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid).\n- **dtype** (*tf.Dtype*)  Datatype for internal calculations and the output dtype.\nDefaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n*[batch_size, num_tx, num_streams_per_tx, num_data_symbols], tf.complex*  The modulated data symbols to be mapped onto the resource grid.\n\nOutput\n\n*[batch_size, num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size], tf.complex*  The full OFDM resource grid in the frequency domain."
"### ResourceGridDemapper\n\n`class` `sionna.ofdm.``ResourceGridDemapper`(*`resource_grid`*, *`stream_management`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/ofdm/resource_grid.html#ResourceGridDemapper)\n\nExtracts data-carrying resource elements from a resource grid.\n\nThis layer takes as input an OFDM [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid) and\nextracts the data-carrying resource elements. In other words, it implements\nthe reverse operation of [`ResourceGridMapper`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGridMapper).\nParameters\n\n- **resource_grid** ()  An instance of [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid).\n- **stream_management** ()  An instance of [`StreamManagement`](mimo.html#sionna.mimo.StreamManagement).\n- **dtype** (*tf.Dtype*)  Datatype for internal calculations and the output dtype.\nDefaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n*[batch_size, num_rx, num_streams_per_rx, num_ofdm_symbols, fft_size, data_dim]*  The full OFDM resource grid in the frequency domain.\nThe last dimension <cite>data_dim</cite> is optional. If <cite>data_dim</cite>\nis used, it refers to the dimensionality of the data that should be\ndemapped to individual streams. An example would be LLRs.\n\nOutput\n\n*[batch_size, num_rx, num_streams_per_rx, num_data_symbols, data_dim]*  The data that were mapped into the resource grid.\nThe last dimension <cite>data_dim</cite> is only returned if it was used for the\ninput."
"### RemoveNulledSubcarriers\n\n`class` `sionna.ofdm.``RemoveNulledSubcarriers`(*`resource_grid`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/ofdm/resource_grid.html#RemoveNulledSubcarriers)\n\nRemoves nulled guard and/or DC subcarriers from a resource grid.\nParameters\n\n**resource_grid** ()  An instance of [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid).\n\nInput\n\n*[batch_size, num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size], tf.complex64*  Full resource grid.\n\nOutput\n\n*[batch_size, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex64*  Resource grid without nulled subcarriers."
"### OFDMModulator\n\n`class` `sionna.ofdm.``OFDMModulator`(*`cyclic_prefix_length`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/ofdm/modulator.html#OFDMModulator)\n\nComputes the time-domain representation of an OFDM resource grid\nwith (optional) cyclic prefix.\nParameters\n\n**cyclic_prefix_length** (*int*)  Integer indicating the length of the\ncyclic prefix that it prepended to each OFDM symbol. It cannot\nbe longer than the FFT size.\n\nInput\n\n*[,num_ofdm_symbols,fft_size], tf.complex*  A resource grid in the frequency domain.\n\nOutput\n\n*[,num_ofdm_symbols*(fft_size+cyclic_prefix_length)], tf.complex*  Time-domain OFDM signal."
"### OFDMDemodulator\n\n`class` `sionna.ofdm.``OFDMDemodulator`(*`fft_size`*, *`l_min`*, *`cyclic_prefix_length`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/ofdm/demodulator.html#OFDMDemodulator)\n\nComputes the frequency-domain representation of an OFDM waveform\nwith cyclic prefix removal.\n\nThe demodulator assumes that the input sequence is generated by the\n[`TimeChannel`](channel.wireless.html#sionna.channel.TimeChannel). For a single pair of antennas,\nthe received signal sequence is given as:\n\n$$\ny_b = \\sum_{\\ell =L_\\text{min}}^{L_\\text{max}} \\bar{h}_\\ell x_{b-\\ell} + w_b, \\quad b \\in[L_\\text{min}, N_B+L_\\text{max}-1]\n$$\n\nwhere $\\bar{h}_\\ell$ are the discrete-time channel taps,\n$x_{b}$ is the the transmitted signal,\nand $w_\\ell$ Gaussian noise.\n\nStarting from the first symbol, the demodulator cuts the input\nsequence into pieces of size `cyclic_prefix_length` `+` `fft_size`,\nand throws away any trailing symbols. For each piece, the cyclic\nprefix is removed and the `fft_size`-point discrete Fourier\ntransform is computed.\n\nSince the input sequence starts at time $L_\\text{min}$,\nthe FFT-window has a timing offset of $L_\\text{min}$ symbols,\nwhich leads to a subcarrier-dependent phase shift of\n$e^{\\frac{j2\\pi k L_\\text{min}}{N}}$, where $k$\nis the subcarrier index, $N$ is the FFT size,\nand $L_\\text{min} \\le 0$ is the largest negative time lag of\nthe discrete-time channel impulse response. This phase shift\nis removed in this layer, by explicitly multiplying\neach subcarrier by  $e^{\\frac{-j2\\pi k L_\\text{min}}{N}}$.\nThis is a very important step to enable channel estimation with\nsparse pilot patterns that needs to interpolate the channel frequency\nresponse accross subcarriers. It also ensures that the\nchannel frequency response <cite>seen</cite> by the time-domain channel\nis close to the [`OFDMChannel`](channel.wireless.html#sionna.channel.OFDMChannel).\nParameters\n\n- **fft_size** (*int*)  FFT size (, i.e., the number of subcarriers).\n- **l_min** (*int*)  The largest negative time lag of the discrete-time channel\nimpulse response. It should be the same value as that used by the\n<cite>cir_to_time_channel</cite> function.\n- **cyclic_prefix_length** (*int*)  Integer indicating the length of the cyclic prefix that\nis prepended to each OFDM symbol.\n\n\nInput\n\n*[,num_ofdm_symbols*(fft_size+cyclic_prefix_length)+n], tf.complex*  Tensor containing the time-domain signal along the last dimension.\n<cite>n</cite> is a nonnegative integer.\n\nOutput\n\n*[,num_ofdm_symbols,fft_size], tf.complex*  Tensor containing the OFDM resource grid along the last\ntwo dimension."
"## Pilot Pattern\n\nA [`PilotPattern`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.PilotPattern) defines how transmitters send pilot\nsequences for each of their antennas or streams over an OFDM resource grid.\nIt consists of two components,\na `mask` and `pilots`. The `mask` indicates which resource elements are\nreserved for pilot transmissions by each transmitter and its respective\nstreams. In some cases, the number of streams is equal to the number of\ntransmit antennas, but this does not need to be the case, e.g., for precoded\ntransmissions. The `pilots` contains the pilot symbols that are transmitted\nat the positions indicated by the `mask`. Separating a pilot pattern into\n`mask` and `pilots` enables the implementation of a wide range of pilot\nconfigurations, including trainable pilot sequences.\n\nThe following code snippet shows how to define a simple custom\n[`PilotPattern`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.PilotPattern) for single transmitter, sending two streams\nNote that `num_effective_subcarriers` is the number of subcarriers that\ncan be used for data or pilot transmissions. Due to guard\ncarriers or a nulled DC carrier, this number can be smaller than the\n`fft_size` of the [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid).\n```python\nnum_tx = 1\nnum_streams_per_tx = 2\nnum_ofdm_symbols = 14\nnum_effective_subcarriers = 12\n# Create a pilot mask\nmask = np.zeros([num_tx,\n                 num_streams_per_tx,\n                 num_ofdm_symbols,\n                 num_effective_subcarriers])\nmask[0, :, [2,11], :] = 1\nnum_pilot_symbols = int(np.sum(mask[0,0]))\n# Define pilot sequences\npilots = np.zeros([num_tx,\n                   num_streams_per_tx,\n                   num_pilot_symbols], np.complex64)\npilots[0, 0, 0:num_pilot_symbols:2] = (1+1j)/np.sqrt(2)\npilots[0, 1, 1:num_pilot_symbols:2] = (1+1j)/np.sqrt(2)\n# Create a PilotPattern instance\npp = PilotPattern(mask, pilots)\n# Visualize non-zero elements of the pilot sequence\npp.show(show_pilot_ind=True);\n```"
"As shown in the figures above, the pilots are mapped onto the mask from\nthe smallest effective subcarrier and OFDM symbol index to the highest\neffective subcarrier and OFDM symbol index. Here, boths stream have 24\npilot symbols, out of which only 12 are nonzero. It is important to keep\nthis order of mapping in mind when designing more complex pilot sequences."
"### PilotPattern\n\n`class` `sionna.ofdm.``PilotPattern`(*`mask`*, *`pilots`*, *`trainable``=``False`*, *`normalize``=``False`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/ofdm/pilot_pattern.html#PilotPattern)\n\nClass defining a pilot pattern for an OFDM ResourceGrid.\n\nThis class defines a pilot pattern object that is used to configure\nan OFDM [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid).\nParameters\n\n- **mask** (*[**num_tx**, **num_streams_per_tx**, **num_ofdm_symbols**, **num_effective_subcarriers**]**, **bool*)  Tensor indicating resource elements that are reserved for pilot transmissions.\n- **pilots** (*[**num_tx**, **num_streams_per_tx**, **num_pilots**]**, **tf.complex*)  The pilot symbols to be mapped onto the `mask`.\n- **trainable** (*bool*)  Indicates if `pilots` is a trainable <cite>Variable</cite>.\nDefaults to <cite>False</cite>.\n- **normalize** (*bool*)  Indicates if the `pilots` should be normalized to an average\nenergy of one across the last dimension. This can be useful to\nensure that trainable `pilots` have a finite energy.\nDefaults to <cite>False</cite>.\n- **dtype** (*tf.Dtype*)  Defines the datatype for internal calculations and the output\ndtype. Defaults to <cite>tf.complex64</cite>.\n\n\n`property` `mask`\n\nMask of the pilot pattern\n\n\n`property` `normalize`\n\nReturns or sets the flag indicating if the pilots\nare normalized or not\n\n\n`property` `num_data_symbols`\n\nNumber of data symbols per transmit stream.\n\n\n`property` `num_effective_subcarriers`\n\nNumber of effectvie subcarriers\n\n\n`property` `num_ofdm_symbols`\n\nNumber of OFDM symbols\n\n\n`property` `num_pilot_symbols`\n\nNumber of pilot symbols per transmit stream.\n\n\n`property` `num_streams_per_tx`\n\nNumber of streams per transmitter\n\n\n`property` `num_tx`\n\nNumber of transmitters\n\n\n`property` `pilots`\n\nReturns or sets the possibly normalized tensor of pilot symbols.\nIf pilots are normalized, the normalization will be applied\nafter new values for pilots have been set. If this is\nnot the desired behavior, turn normalization off.\n\n\n`show`(*`tx_ind``=``None`*, *`stream_ind``=``None`*, *`show_pilot_ind``=``False`*)[`[source]`](../_modules/sionna/ofdm/pilot_pattern.html#PilotPattern.show)\n\nVisualizes the pilot patterns for some transmitters and streams.\nInput\n\n- **tx_ind** (*list, int*)  Indicates the indices of transmitters to be included.\nDefaults to <cite>None</cite>, i.e., all transmitters included.\n- **stream_ind** (*list, int*)  Indicates the indices of streams to be included.\nDefaults to <cite>None</cite>, i.e., all streams included.\n- **show_pilot_ind** (*bool*)  Indicates if the indices of the pilot symbols should be shown.\n\n\nOutput\n\n**list** (*matplotlib.figure.Figure*)  List of matplot figure objects showing each the pilot pattern\nfrom a specific transmitter and stream.\n\n\n`property` `trainable`\n\nReturns if pilots are trainable or not"
"### EmptyPilotPattern\n\n`class` `sionna.ofdm.``EmptyPilotPattern`(*`num_tx`*, *`num_streams_per_tx`*, *`num_ofdm_symbols`*, *`num_effective_subcarriers`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/ofdm/pilot_pattern.html#EmptyPilotPattern)\n\nCreates an empty pilot pattern.\n\nGenerates a instance of [`PilotPattern`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.PilotPattern) with\nan empty `mask` and `pilots`.\nParameters\n\n- **num_tx** (*int*)  Number of transmitters.\n- **num_streams_per_tx** (*int*)  Number of streams per transmitter.\n- **num_ofdm_symbols** (*int*)  Number of OFDM symbols.\n- **num_effective_subcarriers** (*int*)  Number of effective subcarriers\nthat are available for the transmission of data and pilots.\nNote that this number is generally smaller than the `fft_size`\ndue to nulled subcarriers.\n- **dtype** (*tf.Dtype*)  Defines the datatype for internal calculations and the output\ndtype. Defaults to <cite>tf.complex64</cite>."
"### KroneckerPilotPattern\n\n`class` `sionna.ofdm.``KroneckerPilotPattern`(*`resource_grid`*, *`pilot_ofdm_symbol_indices`*, *`normalize``=``True`*, *`seed``=``0`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/ofdm/pilot_pattern.html#KroneckerPilotPattern)\n\nSimple orthogonal pilot pattern with Kronecker structure.\n\nThis function generates an instance of [`PilotPattern`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.PilotPattern)\nthat allocates non-overlapping pilot sequences for all transmitters and\nstreams on specified OFDM symbols. As the same pilot sequences are reused\nacross those OFDM symbols, the resulting pilot pattern has a frequency-time\nKronecker structure. This structure enables a very efficient implementation\nof the LMMSE channel estimator. Each pilot sequence is constructed from\nrandomly drawn QPSK constellation points.\nParameters\n\n- **resource_grid** ()  An instance of a [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid).\n- **pilot_ofdm_symbol_indices** (*list**, **int*)  List of integers defining the OFDM symbol indices that are reserved\nfor pilots.\n- **normalize** (*bool*)  Indicates if the `pilots` should be normalized to an average\nenergy of one across the last dimension.\nDefaults to <cite>True</cite>.\n- **seed** (*int*)  Seed for the generation of the pilot sequence. Different seed values\nlead to different sequences. Defaults to 0.\n- **dtype** (*tf.Dtype*)  Defines the datatype for internal calculations and the output\ndtype. Defaults to <cite>tf.complex64</cite>.\n\n\n**Note**\n\nIt is required that the `resource_grid`s property\n`num_effective_subcarriers` is an\ninteger multiple of `num_tx` `*` `num_streams_per_tx`. This condition is\nrequired to ensure that all transmitters and streams get\nnon-overlapping pilot sequences. For a large number of streams and/or\ntransmitters, the pilot pattern becomes very sparse in the frequency\ndomain.\n xamples\n```python\n>>> rg = ResourceGrid(num_ofdm_symbols=14,\n...                   fft_size=64,\n...                   subcarrier_spacing = 30e3,\n...                   num_tx=4,\n...                   num_streams_per_tx=2,\n...                   pilot_pattern = \"kronecker\",\n...                   pilot_ofdm_symbol_indices = [2, 11])\n>>> rg.pilot_pattern.show();\n```"
"### BaseChannelEstimator\n\n`class` `sionna.ofdm.``BaseChannelEstimator`(*`resource_grid`*, *`interpolation_type``=``'nn'`*, *`interpolator``=``None`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/ofdm/channel_estimation.html#BaseChannelEstimator)\n\nAbstract layer for implementing an OFDM channel estimator.\n\nAny layer that implements an OFDM channel estimator must implement this\nclass and its\n[`estimate_at_pilot_locations()`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.BaseChannelEstimator.estimate_at_pilot_locations)\nabstract method.\n\nThis class extracts the pilots from the received resource grid `y`, calls\nthe [`estimate_at_pilot_locations()`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.BaseChannelEstimator.estimate_at_pilot_locations)\nmethod to estimate the channel for the pilot-carrying resource elements,\nand then interpolates the channel to compute channel estimates for the\ndata-carrying resouce elements using the interpolation method specified by\n`interpolation_type` or the `interpolator` object.\nParameters\n\n- **resource_grid** ()  An instance of [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid).\n- **interpolation_type** (*One of** [**\"nn\"**, **\"lin\"**, **\"lin_time_avg\"**]**, **string*)  The interpolation method to be used.\nIt is ignored if `interpolator` is not <cite>None</cite>.\nAvailable options are [`NearestNeighborInterpolator`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.NearestNeighborInterpolator) (<cite>nn</cite>)\nor [`LinearInterpolator`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.LinearInterpolator) without (<cite>lin</cite>) or with\naveraging across OFDM symbols (<cite>lin_time_avg</cite>).\nDefaults to nn.\n- **interpolator** ()  An instance of [`BaseChannelInterpolator`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.BaseChannelInterpolator),\nsuch as [`LMMSEInterpolator`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.LMMSEInterpolator),\nor <cite>None</cite>. In the latter case, the interpolator specfied\nby `interpolation_type` is used.\nOtherwise, the `interpolator` is used and `interpolation_type`\nis ignored.\nDefaults to <cite>None</cite>.\n- **dtype** (*tf.Dtype*)  Datatype for internal calculations and the output dtype.\nDefaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n- **(y, no)**  Tuple:\n- **y** (*[batch_size, num_rx, num_rx_ant, num_ofdm_symbols,fft_size], tf.complex*)  Observed resource grid\n- **no** (*[batch_size, num_rx, num_rx_ant] or only the first n>=0 dims, tf.float*)  Variance of the AWGN\n\n\nOutput\n\n- **h_hat** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols,fft_size], tf.complex*)  Channel estimates accross the entire resource grid for all\ntransmitters and streams\n- **err_var** (Same shape as `h_hat`, tf.float)  Channel estimation error variance accross the entire resource grid\nfor all transmitters and streams\n\n\n`abstract` `estimate_at_pilot_locations`(*`y_pilots`*, *`no`*)[`[source]`](../_modules/sionna/ofdm/channel_estimation.html#BaseChannelEstimator.estimate_at_pilot_locations)\n\nEstimates the channel for the pilot-carrying resource elements.\n\nThis is an abstract method that must be implemented by a concrete\nOFDM channel estimator that implement this class.\nInput\n\n- **y_pilots** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams, num_pilot_symbols], tf.complex*)  Observed signals for the pilot-carrying resource elements\n- **no** (*[batch_size, num_rx, num_rx_ant] or only the first n>=0 dims, tf.float*)  Variance of the AWGN\n\n\nOutput\n\n- **h_hat** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams, num_pilot_symbols], tf.complex*)  Channel estimates for the pilot-carrying resource elements\n- **err_var** (Same shape as `h_hat`, tf.float)  Channel estimation error variance for the pilot-carrying\nresource elements"
"### BaseChannelInterpolator\n\n`class` `sionna.ofdm.``BaseChannelInterpolator`[`[source]`](../_modules/sionna/ofdm/channel_estimation.html#BaseChannelInterpolator)\n\nAbstract layer for implementing an OFDM channel interpolator.\n\nAny layer that implements an OFDM channel interpolator must implement this\ncallable class.\n\nA channel interpolator is used by an OFDM channel estimator\n([`BaseChannelEstimator`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.BaseChannelEstimator)) to compute channel estimates\nfor the data-carrying resource elements from the channel estimates for the\npilot-carrying resource elements.\nInput\n\n- **h_hat** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_pilot_symbols], tf.complex*)  Channel estimates for the pilot-carrying resource elements\n- **err_var** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_pilot_symbols], tf.complex*)  Channel estimation error variances for the pilot-carrying resource elements\n\n\nOutput\n\n- **h_hat** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size], tf.complex*)  Channel estimates accross the entire resource grid for all\ntransmitters and streams\n- **err_var** (Same shape as `h_hat`, tf.float)  Channel estimation error variance accross the entire resource grid\nfor all transmitters and streams"
"### LSChannelEstimator\n\n`class` `sionna.ofdm.``LSChannelEstimator`(*`resource_grid`*, *`interpolation_type``=``'nn'`*, *`interpolator``=``None`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/ofdm/channel_estimation.html#LSChannelEstimator)\n\nLayer implementing least-squares (LS) channel estimation for OFDM MIMO systems.\n\nAfter LS channel estimation at the pilot positions, the channel estimates\nand error variances are interpolated accross the entire resource grid using\na specified interpolation function.\n\nFor simplicity, the underlying algorithm is described for a vectorized observation,\nwhere we have a nonzero pilot for all elements to be estimated.\nThe actual implementation works on a full OFDM resource grid with sparse\npilot patterns. The following model is assumed:\n\n$$\n\\mathbf{y} = \\mathbf{h}\\odot\\mathbf{p} + \\mathbf{n}\n$$\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^{M}$ is the received signal vector,\n$\\mathbf{p}\\in\\mathbb{C}^M$ is the vector of pilot symbols,\n$\\mathbf{h}\\in\\mathbb{C}^{M}$ is the channel vector to be estimated,\nand $\\mathbf{n}\\in\\mathbb{C}^M$ is a zero-mean noise vector whose\nelements have variance $N_0$. The operator $\\odot$ denotes\nelement-wise multiplication.\n\nThe channel estimate $\\hat{\\mathbf{h}}$ and error variances\n$\\sigma^2_i$, $i=0,\\dots,M-1$, are computed as\n\n$$\n\\begin{split}\\hat{\\mathbf{h}} &= \\mathbf{y} \\odot\n                   \\frac{\\mathbf{p}^\\star}{\\left|\\mathbf{p}\\right|^2}\n                 = \\mathbf{h} + \\tilde{\\mathbf{h}}\\\\\n     \\sigma^2_i &= \\mathbb{E}\\left[\\tilde{h}_i \\tilde{h}_i^\\star \\right]\n                 = \\frac{N_0}{\\left|p_i\\right|^2}.\\end{split}\n$$\n\nThe channel estimates and error variances are then interpolated accross\nthe entire resource grid.\nParameters\n\n- **resource_grid** ()  An instance of [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid).\n- **interpolation_type** (*One of** [**\"nn\"**, **\"lin\"**, **\"lin_time_avg\"**]**, **string*)  The interpolation method to be used.\nIt is ignored if `interpolator` is not <cite>None</cite>.\nAvailable options are [`NearestNeighborInterpolator`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.NearestNeighborInterpolator) (<cite>nn</cite>)\nor [`LinearInterpolator`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.LinearInterpolator) without (<cite>lin</cite>) or with\naveraging across OFDM symbols (<cite>lin_time_avg</cite>).\nDefaults to nn.\n- **interpolator** ()  An instance of [`BaseChannelInterpolator`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.BaseChannelInterpolator),\nsuch as [`LMMSEInterpolator`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.LMMSEInterpolator),\nor <cite>None</cite>. In the latter case, the interpolator specfied\nby `interpolation_type` is used.\nOtherwise, the `interpolator` is used and `interpolation_type`\nis ignored.\nDefaults to <cite>None</cite>.\n- **dtype** (*tf.Dtype*)  Datatype for internal calculations and the output dtype.\nDefaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n- **(y, no)**  Tuple:\n- **y** (*[batch_size, num_rx, num_rx_ant, num_ofdm_symbols,fft_size], tf.complex*)  Observed resource grid\n- **no** (*[batch_size, num_rx, num_rx_ant] or only the first n>=0 dims, tf.float*)  Variance of the AWGN\n\n\nOutput\n\n- **h_ls** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols,fft_size], tf.complex*)  Channel estimates accross the entire resource grid for all\ntransmitters and streams\n- **err_var** (Same shape as `h_ls`, tf.float)  Channel estimation error variance accross the entire resource grid\nfor all transmitters and streams"
"### LinearInterpolator\n\n`class` `sionna.ofdm.``LinearInterpolator`(*`pilot_pattern`*, *`time_avg``=``False`*)[`[source]`](../_modules/sionna/ofdm/channel_estimation.html#LinearInterpolator)\n\nLinear channel estimate interpolation on a resource grid.\n\nThis class computes for each element of an OFDM resource grid\na channel estimate based on `num_pilots` provided channel estimates and\nerror variances through linear interpolation.\nIt is assumed that the measurements were taken at the nonzero positions\nof a [`PilotPattern`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.PilotPattern).\n\nThe interpolation is done first across sub-carriers and then\nacross OFDM symbols.\nParameters\n\n- **pilot_pattern** ()  An instance of [`PilotPattern`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.PilotPattern)\n- **time_avg** (*bool*)  If enabled, measurements will be averaged across OFDM symbols\n(i.e., time). This is useful for channels that do not vary\nsubstantially over the duration of an OFDM frame. Defaults to <cite>False</cite>.\n\n\nInput\n\n- **h_hat** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_pilot_symbols], tf.complex*)  Channel estimates for the pilot-carrying resource elements\n- **err_var** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_pilot_symbols], tf.complex*)  Channel estimation error variances for the pilot-carrying resource elements\n\n\nOutput\n\n- **h_hat** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size], tf.complex*)  Channel estimates accross the entire resource grid for all\ntransmitters and streams\n- **err_var** (Same shape as `h_hat`, tf.float)  Channel estimation error variances accross the entire resource grid\nfor all transmitters and streams"
"### LMMSEInterpolator\n\n`class` `sionna.ofdm.``LMMSEInterpolator`(*`pilot_pattern`*, *`cov_mat_time`*, *`cov_mat_freq`*, *`cov_mat_space``=``None`*, *`order``=``'t-f'`*)[`[source]`](../_modules/sionna/ofdm/channel_estimation.html#LMMSEInterpolator)\n\nLMMSE interpolation on a resource grid with optional spatial smoothing.\n\nThis class computes for each element of an OFDM resource grid\na channel estimate and error variance\nthrough linear minimum mean square error (LMMSE) interpolation/smoothing.\nIt is assumed that the measurements were taken at the nonzero positions\nof a [`PilotPattern`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.PilotPattern).\n\nDepending on the value of `order`, the interpolation is carried out\naccross time (t), i.e., OFDM symbols, frequency (f), i.e., subcarriers,\nand optionally space (s), i.e., receive antennas, in any desired order.\n\nFor simplicity, we describe the underlying algorithm assuming that interpolation\nacross the sub-carriers is performed first, followed by interpolation across\nOFDM symbols, and finally by spatial smoothing across receive\nantennas.\nThe algorithm is similar if interpolation and/or smoothing are performed in\na different order.\nFor clarity, antenna indices are omitted when describing frequency and time\ninterpolation, as the same process is applied to all the antennas.\n\nThe input `h_hat` is first reshaped to a resource grid\n$\\hat{\\mathbf{H}} \\in \\mathbb{C}^{N \\times M}$, by scattering the channel\nestimates at pilot locations according to the `pilot_pattern`. $N$\ndenotes the number of OFDM symbols and $M$ the number of sub-carriers.\n\nThe first pass consists in interpolating across the sub-carriers:\n\n$$\n\\hat{\\mathbf{h}}_n^{(1)} = \\mathbf{A}_n \\hat{\\mathbf{h}}_n\n$$\n\nwhere $1 \\leq n \\leq N$ is the OFDM symbol index and $\\hat{\\mathbf{h}}_n$ is\nthe $n^{\\text{th}}$ (transposed) row of $\\hat{\\mathbf{H}}$.\n$\\mathbf{A}_n$ is the $M \\times M$ matrix such that:\n\n$$\n\\mathbf{A}_n = \\bar{\\mathbf{A}}_n \\mathbf{\\Pi}_n^\\intercal\n$$\n\nwhere\n\n$$\n\\bar{\\mathbf{A}}_n = \\underset{\\mathbf{Z} \\in \\mathbb{C}^{M \\times K_n}}{\\text{argmin}} \\left\\lVert \\mathbf{Z}\\left( \\mathbf{\\Pi}_n^\\intercal \\mathbf{R^{(f)}} \\mathbf{\\Pi}_n + \\mathbf{\\Sigma}_n \\right) - \\mathbf{R^{(f)}} \\mathbf{\\Pi}_n \\right\\rVert_{\\text{F}}^2\n$$\n\nand $\\mathbf{R^{(f)}}$ is the $M \\times M$ channel frequency covariance matrix,\n$\\mathbf{\\Pi}_n$ the $M \\times K_n$ matrix that spreads $K_n$\nvalues to a vector of size $M$ according to the `pilot_pattern` for the $n^{\\text{th}}$ OFDM symbol,\nand $\\mathbf{\\Sigma}_n \\in \\mathbb{R}^{K_n \\times K_n}$ is the channel estimation error covariance built from\n`err_var` and assumed to be diagonal.\nComputation of $\\bar{\\mathbf{A}}_n$ is done using an algorithm based on complete orthogonal decomposition.\nThis is done to avoid matrix inversion for badly conditioned covariance matrices.\n\nThe channel estimation error variances after the first interpolation pass are computed as\n\n$$\n\\mathbf{\\Sigma}^{(1)}_n = \\text{diag} \\left( \\mathbf{R^{(f)}} - \\mathbf{A}_n \\mathbf{\\Xi}_n \\mathbf{R^{(f)}} \\right)\n$$\n\nwhere $\\mathbf{\\Xi}_n$ is the diagonal matrix of size $M \\times M$ that zeros the\ncolumns corresponding to sub-carriers not carrying any pilots.\nNote that interpolation is not performed for OFDM symbols which do not carry pilots.\n\n**Remark**: The interpolation matrix differs across OFDM symbols as different\nOFDM symbols may carry pilots on different sub-carriers and/or have different\nestimation error variances.\n\nScaling of the estimates is then performed to ensure that their\nvariances match the ones expected by the next interpolation step, and the error variances are updated accordingly:\n\n$$\n\\begin{split}\\begin{align}\n    \\left[\\hat{\\mathbf{h}}_n^{(2)}\\right]_m &= s_{n,m} \\left[\\hat{\\mathbf{h}}_n^{(1)}\\right]_m\\\\\n    \\left[\\mathbf{\\Sigma}^{(2)}_n\\right]_{m,m}  &= s_{n,m}\\left( s_{n,m}-1 \\right) \\left[\\hat{\\mathbf{\\Sigma}}^{(1)}_n\\right]_{m,m} + \\left( 1 - s_{n,m} \\right) \\left[\\mathbf{R^{(f)}}\\right]_{m,m} + s_{n,m} \\left[\\mathbf{\\Sigma}^{(1)}_n\\right]_{m,m}\n\\end{align}\\end{split}\n$$\n\nwhere the scaling factor $s_{n,m}$ is such that:\n\n$$\n\\mathbb{E} \\left\\{ \\left\\lvert s_{n,m} \\left[\\hat{\\mathbf{h}}_n^{(1)}\\right]_m \\right\\rvert^2 \\right\\} = \\left[\\mathbf{R^{(f)}}\\right]_{m,m} +  \\mathbb{E} \\left\\{ \\left\\lvert s_{n,m} \\left[\\hat{\\mathbf{h}}^{(1)}_n\\right]_m - \\left[\\mathbf{h}_n\\right]_m \\right\\rvert^2 \\right\\}\n$$\n\nwhich leads to:\n\n$$\n\\begin{split}\\begin{align}\n    s_{n,m} &= \\frac{2 \\left[\\mathbf{R^{(f)}}\\right]_{m,m}}{\\left[\\mathbf{R^{(f)}}\\right]_{m,m} - \\left[\\mathbf{\\Sigma}^{(1)}_n\\right]_{m,m} + \\left[\\hat{\\mathbf{\\Sigma}}^{(1)}_n\\right]_{m,m}}\\\\\n    \\hat{\\mathbf{\\Sigma}}^{(1)}_n &= \\mathbf{A}_n \\mathbf{R^{(f)}} \\mathbf{A}_n^{\\mathrm{H}}.\n\\end{align}\\end{split}\n$$\n\nThe second pass consists in interpolating across the OFDM symbols:\n\n$$\n\\hat{\\mathbf{h}}_m^{(3)} = \\mathbf{B}_m \\tilde{\\mathbf{h}}^{(2)}_m\n$$\n\nwhere $1 \\leq m \\leq M$ is the sub-carrier index and $\\tilde{\\mathbf{h}}^{(2)}_m$ is\nthe $m^{\\text{th}}$ column of\n\n$$\n\\begin{split}\\hat{\\mathbf{H}}^{(2)} = \\begin{bmatrix}\n                            {\\hat{\\mathbf{h}}_1^{(2)}}^\\intercal\\\\\n                            \\vdots\\\\\n                            {\\hat{\\mathbf{h}}_N^{(2)}}^\\intercal\n                         \\end{bmatrix}\\end{split}\n$$\n\nand $\\mathbf{B}_m$ is the $N \\times N$ interpolation LMMSE matrix:\n\n$$\n\\mathbf{B}_m = \\bar{\\mathbf{B}}_m \\tilde{\\mathbf{\\Pi}}_m^\\intercal\n$$\n\nwhere\n\n$$\n\\bar{\\mathbf{B}}_m = \\underset{\\mathbf{Z} \\in \\mathbb{C}^{N \\times L_m}}{\\text{argmin}} \\left\\lVert \\mathbf{Z} \\left( \\tilde{\\mathbf{\\Pi}}_m^\\intercal \\mathbf{R^{(t)}}\\tilde{\\mathbf{\\Pi}}_m + \\tilde{\\mathbf{\\Sigma}}^{(2)}_m \\right) -  \\mathbf{R^{(t)}}\\tilde{\\mathbf{\\Pi}}_m \\right\\rVert_{\\text{F}}^2\n$$\n\nwhere $\\mathbf{R^{(t)}}$ is the $N \\times N$ channel time covariance matrix,\n$\\tilde{\\mathbf{\\Pi}}_m$ the $N \\times L_m$ matrix that spreads $L_m$\nvalues to a vector of size $N$ according to the `pilot_pattern` for the $m^{\\text{th}}$ sub-carrier,\nand $\\tilde{\\mathbf{\\Sigma}}^{(2)}_m \\in \\mathbb{R}^{L_m \\times L_m}$ is the diagonal matrix of channel estimation error variances\nbuilt by gathering the error variances from ($\\mathbf{\\Sigma}^{(2)}_1,\\dots,\\mathbf{\\Sigma}^{(2)}_N$) corresponding\nto resource elements carried by the $m^{\\text{th}}$ sub-carrier.\nComputation of $\\bar{\\mathbf{B}}_m$ is done using an algorithm based on complete orthogonal decomposition.\nThis is done to avoid matrix inversion for badly conditioned covariance matrices.\n\nThe resulting channel estimate for the resource grid is\n\n$$\n\\hat{\\mathbf{H}}^{(3)} = \\left[ \\hat{\\mathbf{h}}_1^{(3)} \\dots \\hat{\\mathbf{h}}_M^{(3)} \\right]\n$$\n\nThe resulting channel estimation error variances are the diagonal coefficients of the matrices\n\n$$\n\\mathbf{\\Sigma}^{(3)}_m = \\mathbf{R^{(t)}} - \\mathbf{B}_m \\tilde{\\mathbf{\\Xi}}_m \\mathbf{R^{(t)}}, 1 \\leq m \\leq M\n$$\n\nwhere $\\tilde{\\mathbf{\\Xi}}_m$ is the diagonal matrix of size $N \\times N$ that zeros the\ncolumns corresponding to OFDM symbols not carrying any pilots.\n\n**Remark**: The interpolation matrix differs across sub-carriers as different\nsub-carriers may have different estimation error variances computed by the first\npass.\nHowever, all sub-carriers carry at least one channel estimate as a result of\nthe first pass, ensuring that a channel estimate is computed for all the resource\nelements after the second pass.\n\n**Remark:** LMMSE interpolation requires knowledge of the time and frequency\ncovariance matrices of the channel. The notebook [OFDM MIMO Channel Estimation and Detection](../examples/OFDM_MIMO_Detection.html) shows how to estimate\nsuch matrices for arbitrary channel models.\nMoreover, the functions [`tdl_time_cov_mat()`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.tdl_time_cov_mat)\nand [`tdl_freq_cov_mat()`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.tdl_freq_cov_mat) compute the expected time and frequency\ncovariance matrices, respectively, for the [`TDL`](channel.wireless.html#sionna.channel.tr38901.TDL) channel models.\n\nScaling of the estimates is then performed to ensure that their\nvariances match the ones expected by the next smoothing step, and the\nerror variances are updated accordingly:\n\n$$\n\\begin{split}\\begin{align}\n    \\left[\\hat{\\mathbf{h}}_m^{(4)}\\right]_n &= \\gamma_{m,n} \\left[\\hat{\\mathbf{h}}_m^{(3)}\\right]_n\\\\\n    \\left[\\mathbf{\\Sigma}^{(4)}_m\\right]_{n,n}  &= \\gamma_{m,n}\\left( \\gamma_{m,n}-1 \\right) \\left[\\hat{\\mathbf{\\Sigma}}^{(3)}_m\\right]_{n,n} + \\left( 1 - \\gamma_{m,n} \\right) \\left[\\mathbf{R^{(t)}}\\right]_{n,n} + \\gamma_{m,n} \\left[\\mathbf{\\Sigma}^{(3)}_n\\right]_{m,m}\n\\end{align}\\end{split}\n$$\n\nwhere:\n\n$$\n\\begin{split}\\begin{align}\n    \\gamma_{m,n} &= \\frac{2 \\left[\\mathbf{R^{(t)}}\\right]_{n,n}}{\\left[\\mathbf{R^{(t)}}\\right]_{n,n} - \\left[\\mathbf{\\Sigma}^{(3)}_m\\right]_{n,n} + \\left[\\hat{\\mathbf{\\Sigma}}^{(3)}_n\\right]_{m,m}}\\\\\n    \\hat{\\mathbf{\\Sigma}}^{(3)}_m &= \\mathbf{B}_m \\mathbf{R^{(t)}} \\mathbf{B}_m^{\\mathrm{H}}\n\\end{align}\\end{split}\n$$\n\nFinally, a spatial smoothing step is applied to every resource element carrying\na channel estimate.\nFor clarity, we drop the resource element indexing $(n,m)$.\nWe denote by $L$ the number of receive antennas, and by\n$\\mathbf{R^{(s)}}\\in\\mathbb{C}^{L \\times L}$ the spatial covariance matrix.\n\nLMMSE spatial smoothing consists in the following computations:\n\n$$\n\\hat{\\mathbf{h}}^{(5)} = \\mathbf{C} \\hat{\\mathbf{h}}^{(4)}\n$$\n\nwhere\n\n$$\n\\mathbf{C} = \\mathbf{R^{(s)}} \\left( \\mathbf{R^{(s)}} + \\mathbf{\\Sigma}^{(4)} \\right)^{-1}.\n$$\n\nThe estimation error variances are the digonal coefficients of\n\n$$\n\\mathbf{\\Sigma}^{(5)} = \\mathbf{R^{(s)}} - \\mathbf{C}\\mathbf{R^{(s)}}\n$$\n\nThe smoothed channel estimate $\\hat{\\mathbf{h}}^{(5)}$ and corresponding\nerror variances $\\text{diag}\\left( \\mathbf{\\Sigma}^{(5)} \\right)$ are\nreturned for every resource element $(m,n)$.\n\n**Remark:** No scaling is performed after the last interpolation or smoothing\nstep.\n\n**Remark:** All passes assume that the estimation error covariance matrix\n($\\mathbf{\\Sigma}$, $\\tilde{\\mathbf{\\Sigma}}^{(2)}$, or $\\tilde{\\mathbf{\\Sigma}}^{(4)}$) is diagonal, which\nmay not be accurate. When this assumption does not hold, this interpolator is only\nan approximation of LMMSE interpolation.\n\n**Remark:** The order in which frequency interpolation, temporal\ninterpolation, and, optionally, spatial smoothing are applied, is controlled using the\n`order` parameter.\n\n**Note**\n\nThis layer does not support graph mode with XLA.\n\nParameters\n\n- **pilot_pattern** ()  An instance of [`PilotPattern`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.PilotPattern)\n- **cov_mat_time** (*[**num_ofdm_symbols**, **num_ofdm_symbols**]**, **tf.complex*)  Time covariance matrix of the channel\n- **cov_mat_freq** (*[**fft_size**, **fft_size**]**, **tf.complex*)  Frequency covariance matrix of the channel\n- **cov_time_space** (*[**num_rx_ant**, **num_rx_ant**]**, **tf.complex*)  Spatial covariance matrix of the channel.\nDefaults to <cite>None</cite>.\nOnly required if spatial smoothing is requested (see `order`).\n- **order** (*str*)  Order in which to perform interpolation and optional smoothing.\nFor example, `\"t-f-s\"` means that interpolation across the OFDM symbols\nis performed first (`\"t\"`: time), followed by interpolation across the\nsub-carriers (`\"f\"`: frequency), and finally smoothing across the\nreceive antennas (`\"s\"`: space).\nSimilarly, `\"f-t\"` means interpolation across the sub-carriers followed\nby interpolation across the OFDM symbols and no spatial smoothing.\nThe spatial covariance matrix (`cov_time_space`) is only required when\nspatial smoothing is requested.\nTime and frequency interpolation are not optional to ensure that a channel\nestimate is computed for all resource elements.\n\n\nInput\n\n- **h_hat** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_pilot_symbols], tf.complex*)  Channel estimates for the pilot-carrying resource elements\n- **err_var** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_pilot_symbols], tf.complex*)  Channel estimation error variances for the pilot-carrying resource elements\n\n\nOutput\n\n- **h_hat** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size], tf.complex*)  Channel estimates accross the entire resource grid for all\ntransmitters and streams\n- **err_var** (Same shape as `h_hat`, tf.float)  Channel estimation error variances accross the entire resource grid\nfor all transmitters and streams"
"### NearestNeighborInterpolator\n\n`class` `sionna.ofdm.``NearestNeighborInterpolator`(*`pilot_pattern`*)[`[source]`](../_modules/sionna/ofdm/channel_estimation.html#NearestNeighborInterpolator)\n\nNearest-neighbor channel estimate interpolation on a resource grid.\n\nThis class assigns to each element of an OFDM resource grid one of\n`num_pilots` provided channel estimates and error\nvariances according to the nearest neighbor method. It is assumed\nthat the measurements were taken at the nonzero positions of a\n[`PilotPattern`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.PilotPattern).\n\nThe figure below shows how four channel estimates are interpolated\naccross a resource grid. Grey fields indicate measurement positions\nwhile the colored regions show which resource elements are assigned\nto the same measurement value.\nParameters\n\n**pilot_pattern** ()  An instance of [`PilotPattern`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.PilotPattern)\n\nInput\n\n- **h_hat** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_pilot_symbols], tf.complex*)  Channel estimates for the pilot-carrying resource elements\n- **err_var** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_pilot_symbols], tf.complex*)  Channel estimation error variances for the pilot-carrying resource elements\n\n\nOutput\n\n- **h_hat** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size], tf.complex*)  Channel estimates accross the entire resource grid for all\ntransmitters and streams\n- **err_var** (Same shape as `h_hat`, tf.float)  Channel estimation error variances accross the entire resource grid\nfor all transmitters and streams"
"### tdl_time_cov_mat\n\n`sionna.ofdm.``tdl_time_cov_mat`(*`model`*, *`speed`*, *`carrier_frequency`*, *`ofdm_symbol_duration`*, *`num_ofdm_symbols`*, *`los_angle_of_arrival``=``0.7853981633974483`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/ofdm/channel_estimation.html#tdl_time_cov_mat)\n\nComputes the time covariance matrix of a\n[`TDL`](channel.wireless.html#sionna.channel.tr38901.TDL) channel model.\n\nFor non-line-of-sight (NLoS) model, the channel time covariance matrix\n$\\mathbf{R^{(t)}}$ of a TDL channel model is\n\n$$\n\\mathbf{R^{(t)}}_{u,v} = J_0 \\left( \\nu \\Delta_t \\left( u-v \\right) \\right)\n$$\n\nwhere $J_0$ is the zero-order Bessel function of the first kind,\n$\\Delta_t$ the duration of an OFDM symbol, and $\\nu$ the Doppler\nspread defined by\n\n$$\n\\nu = 2 \\pi \\frac{v}{c} f_c\n$$\n\nwhere $v$ is the movement speed, $c$ the speed of light, and\n$f_c$ the carrier frequency.\n\nFor line-of-sight (LoS) channel models, the channel time covariance matrix\nis\n\n$$\n\\mathbf{R^{(t)}}_{u,v} = P_{\\text{NLoS}} J_0 \\left( \\nu \\Delta_t \\left( u-v \\right) \\right) + P_{\\text{LoS}}e^{j \\nu \\Delta_t \\left( u-v \\right) \\cos{\\alpha_{\\text{LoS}}}}\n$$\n\nwhere $\\alpha_{\\text{LoS}}$ is the angle-of-arrival for the LoS path,\n$P_{\\text{NLoS}}$ the total power of NLoS paths, and\n$P_{\\text{LoS}}$ the power of the LoS path. The power delay profile\nis assumed to have unit power, i.e., $P_{\\text{NLoS}} + P_{\\text{LoS}} = 1$.\nInput\n\n- **model** (*str*)  TDL model for which to return the covariance matrix.\nShould be one of A, B, C, D, or E.\n- **speed** (*float*)  Speed [m/s]\n- **carrier_frequency** (*float*)  Carrier frequency [Hz]\n- **ofdm_symbol_duration** (*float*)  Duration of an OFDM symbol [s]\n- **num_ofdm_symbols** (*int*)  Number of OFDM symbols\n- **los_angle_of_arrival** (*float*)  Angle-of-arrival for LoS path [radian]. Only used with LoS models.\nDefaults to $\\pi/4$.\n- **dtype** (*tf.DType*)  Datatype to use for the output.\nShould be one of <cite>tf.complex64</cite> or <cite>tf.complex128</cite>.\nDefaults to <cite>tf.complex64</cite>.\n\n\nOutput\n\n**cov_mat** (*[num_ofdm_symbols, num_ofdm_symbols], tf.complex*)  Channel time covariance matrix"
"### tdl_freq_cov_mat\n\n`sionna.ofdm.``tdl_freq_cov_mat`(*`model`*, *`subcarrier_spacing`*, *`fft_size`*, *`delay_spread`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/ofdm/channel_estimation.html#tdl_freq_cov_mat)\n\nComputes the frequency covariance matrix of a\n[`TDL`](channel.wireless.html#sionna.channel.tr38901.TDL) channel model.\n\nThe channel frequency covariance matrix $\\mathbf{R}^{(f)}$ of a TDL channel model is\n\n$$\n\\mathbf{R}^{(f)}_{u,v} = \\sum_{\\ell=1}^L P_\\ell e^{-j 2 \\pi \\tau_\\ell \\Delta_f (u-v)}, 1 \\leq u,v \\leq M\n$$\n\nwhere $M$ is the FFT size, $L$ is the number of paths for the selected TDL model,\n$P_\\ell$ and $\\tau_\\ell$ are the average power and delay for the\n$\\ell^{\\text{th}}$ path, respectively, and $\\Delta_f$ is the sub-carrier spacing.\nInput\n\n- **model** (*str*)  TDL model for which to return the covariance matrix.\nShould be one of A, B, C, D, or E.\n- **subcarrier_spacing** (*float*)  Sub-carrier spacing [Hz]\n- **fft_size** (*float*)  FFT size\n- **delay_spread** (*float*)  Delay spread [s]\n- **dtype** (*tf.DType*)  Datatype to use for the output.\nShould be one of <cite>tf.complex64</cite> or <cite>tf.complex128</cite>.\nDefaults to <cite>tf.complex64</cite>.\n\n\nOutput\n\n**cov_mat** (*[fft_size, fft_size], tf.complex*)  Channel frequency covariance matrix"
"### ZFPrecoder\n\n`class` `sionna.ofdm.``ZFPrecoder`(*`resource_grid`*, *`stream_management`*, *`return_effective_channel``=``False`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/ofdm/precoding.html#ZFPrecoder)\n\nZero-forcing precoding for multi-antenna transmissions.\n\nThis layer precodes a tensor containing OFDM resource grids using\nthe [`zero_forcing_precoder()`](mimo.html#sionna.mimo.zero_forcing_precoder). For every\ntransmitter, the channels to all intended receivers are gathered\ninto a channel matrix, based on the which the precoding matrix\nis computed and the input tensor is precoded. The layer also outputs\noptionally the effective channel after precoding for each stream.\nParameters\n\n- **resource_grid** ()  An instance of [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid).\n- **stream_management** ()  An instance of [`StreamManagement`](mimo.html#sionna.mimo.StreamManagement).\n- **return_effective_channel** (*bool*)  Indicates if the effective channel after precoding should be returned.\n- **dtype** (*tf.Dtype*)  Datatype for internal calculations and the output dtype.\nDefaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n- **(x, h)**  Tuple:\n- **x** (*[batch_size, num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size], tf.complex*)  Tensor containing the resource grid to be precoded.\n- **h** (*[batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_ofdm, fft_size], tf.complex*)  Tensor containing the channel knowledge based on which the precoding\nis computed.\n\n\nOutput\n\n- **x_precoded** (*[batch_size, num_tx, num_tx_ant, num_ofdm_symbols, fft_size], tf.complex*)  The precoded resource grids.\n- **h_eff** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm, num_effective_subcarriers], tf.complex*)  Only returned if `return_effective_channel=True`.\nThe effectice channels for all streams after precoding. Can be used to\nsimulate perfect channel state information (CSI) at the receivers.\nNulled subcarriers are automatically removed to be compliant with the\nbehavior of a channel estimator.\n\n\n**Note**\n\nIf you want to use this layer in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### OFDMEqualizer\n\n`class` `sionna.ofdm.``OFDMEqualizer`(*`equalizer`*, *`resource_grid`*, *`stream_management`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/ofdm/equalization.html#OFDMEqualizer)\n\nLayer that wraps a MIMO equalizer for use with the OFDM waveform.\n\nThe parameter `equalizer` is a callable (e.g., a function) that\nimplements a MIMO equalization algorithm for arbitrary batch dimensions.\n\nThis class pre-processes the received resource grid `y` and channel\nestimate `h_hat`, and computes for each receiver the\nnoise-plus-interference covariance matrix according to the OFDM and stream\nconfiguration provided by the `resource_grid` and\n`stream_management`, which also accounts for the channel\nestimation error variance `err_var`. These quantities serve as input\nto the equalization algorithm that is implemented by the callable `equalizer`.\nThis layer computes soft-symbol estimates together with effective noise\nvariances for all streams which can, e.g., be used by a\n[`Demapper`](mapping.html#sionna.mapping.Demapper) to obtain LLRs.\n\n**Note**\n\nThe callable `equalizer` must take three inputs:\n\n- **y** ([,num_rx_ant], tf.complex)  1+D tensor containing the received signals.\n- **h** ([,num_rx_ant,num_streams_per_rx], tf.complex)  2+D tensor containing the channel matrices.\n- **s** ([,num_rx_ant,num_rx_ant], tf.complex)  2+D tensor containing the noise-plus-interference covariance matrices.\n\n\nIt must generate two outputs:\n\n- **x_hat** ([,num_streams_per_rx], tf.complex)  1+D tensor representing the estimated symbol vectors.\n- **no_eff** (tf.float)  Tensor of the same shape as `x_hat` containing the effective noise variance estimates.\nParameters\n\n- **equalizer** (*Callable*)  Callable object (e.g., a function) that implements a MIMO equalization\nalgorithm for arbitrary batch dimensions\n- **resource_grid** ()  Instance of [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid)\n- **stream_management** ()  Instance of [`StreamManagement`](mimo.html#sionna.mimo.StreamManagement)\n- **dtype** (*tf.Dtype*)  Datatype for internal calculations and the output dtype.\nDefaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n- **(y, h_hat, err_var, no)**  Tuple:\n- **y** (*[batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex*)  Received OFDM resource grid after cyclic prefix removal and FFT\n- **h_hat** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex*)  Channel estimates for all streams from all transmitters\n- **err_var** ([Broadcastable to shape of `h_hat`], tf.float)  Variance of the channel estimation error\n- **no** (*[batch_size, num_rx, num_rx_ant] (or only the first n dims), tf.float*)  Variance of the AWGN\n\n\nOutput\n\n- **x_hat** (*[batch_size, num_tx, num_streams, num_data_symbols], tf.complex*)  Estimated symbols\n- **no_eff** (*[batch_size, num_tx, num_streams, num_data_symbols], tf.float*)  Effective noise variance for each estimated symbol"
"### LMMSEEqualizer\n\n`class` `sionna.ofdm.``LMMSEEqualizer`(*`resource_grid`*, *`stream_management`*, *`whiten_interference``=``True`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/ofdm/equalization.html#LMMSEEqualizer)\n\nLMMSE equalization for OFDM MIMO transmissions.\n\nThis layer computes linear minimum mean squared error (LMMSE) equalization\nfor OFDM MIMO transmissions. The OFDM and stream configuration are provided\nby a [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid) and\n[`StreamManagement`](mimo.html#sionna.mimo.StreamManagement) instance, respectively. The\ndetection algorithm is the [`lmmse_equalizer()`](mimo.html#sionna.mimo.lmmse_equalizer). The layer\ncomputes soft-symbol estimates together with effective noise variances\nfor all streams which can, e.g., be used by a\n[`Demapper`](mapping.html#sionna.mapping.Demapper) to obtain LLRs.\nParameters\n\n- **resource_grid** ()  Instance of [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid)\n- **stream_management** ()  Instance of [`StreamManagement`](mimo.html#sionna.mimo.StreamManagement)\n- **whiten_interference** (*bool*)  If <cite>True</cite> (default), the interference is first whitened before equalization.\nIn this case, an alternative expression for the receive filter is used which\ncan be numerically more stable.\n- **dtype** (*tf.Dtype*)  Datatype for internal calculations and the output dtype.\nDefaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n- **(y, h_hat, err_var, no)**  Tuple:\n- **y** (*[batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex*)  Received OFDM resource grid after cyclic prefix removal and FFT\n- **h_hat** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex*)  Channel estimates for all streams from all transmitters\n- **err_var** ([Broadcastable to shape of `h_hat`], tf.float)  Variance of the channel estimation error\n- **no** (*[batch_size, num_rx, num_rx_ant] (or only the first n dims), tf.float*)  Variance of the AWGN\n\n\nOutput\n\n- **x_hat** (*[batch_size, num_tx, num_streams, num_data_symbols], tf.complex*)  Estimated symbols\n- **no_eff** (*[batch_size, num_tx, num_streams, num_data_symbols], tf.float*)  Effective noise variance for each estimated symbol\n\n\n**Note**\n\nIf you want to use this layer in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### MFEqualizer\n\n`class` `sionna.ofdm.``MFEqualizer`(*`resource_grid`*, *`stream_management`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/ofdm/equalization.html#MFEqualizer)\n\nMF equalization for OFDM MIMO transmissions.\n\nThis layer computes matched filter (MF) equalization\nfor OFDM MIMO transmissions. The OFDM and stream configuration are provided\nby a [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid) and\n[`StreamManagement`](mimo.html#sionna.mimo.StreamManagement) instance, respectively. The\ndetection algorithm is the [`mf_equalizer()`](mimo.html#sionna.mimo.mf_equalizer). The layer\ncomputes soft-symbol estimates together with effective noise variances\nfor all streams which can, e.g., be used by a\n[`Demapper`](mapping.html#sionna.mapping.Demapper) to obtain LLRs.\nParameters\n\n- **resource_grid** ()  An instance of [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid).\n- **stream_management** ()  An instance of [`StreamManagement`](mimo.html#sionna.mimo.StreamManagement).\n- **dtype** (*tf.Dtype*)  Datatype for internal calculations and the output dtype.\nDefaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n- **(y, h_hat, err_var, no)**  Tuple:\n- **y** (*[batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex*)  Received OFDM resource grid after cyclic prefix removal and FFT\n- **h_hat** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex*)  Channel estimates for all streams from all transmitters\n- **err_var** ([Broadcastable to shape of `h_hat`], tf.float)  Variance of the channel estimation error\n- **no** (*[batch_size, num_rx, num_rx_ant] (or only the first n dims), tf.float*)  Variance of the AWGN\n\n\nOutput\n\n- **x_hat** (*[batch_size, num_tx, num_streams, num_data_symbols], tf.complex*)  Estimated symbols\n- **no_eff** (*[batch_size, num_tx, num_streams, num_data_symbols], tf.float*)  Effective noise variance for each estimated symbol\n\n\n**Note**\n\nIf you want to use this layer in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### ZFEqualizer\n\n`class` `sionna.ofdm.``ZFEqualizer`(*`resource_grid`*, *`stream_management`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/ofdm/equalization.html#ZFEqualizer)\n\nZF equalization for OFDM MIMO transmissions.\n\nThis layer computes zero-forcing (ZF) equalization\nfor OFDM MIMO transmissions. The OFDM and stream configuration are provided\nby a [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid) and\n[`StreamManagement`](mimo.html#sionna.mimo.StreamManagement) instance, respectively. The\ndetection algorithm is the [`zf_equalizer()`](mimo.html#sionna.mimo.zf_equalizer). The layer\ncomputes soft-symbol estimates together with effective noise variances\nfor all streams which can, e.g., be used by a\n[`Demapper`](mapping.html#sionna.mapping.Demapper) to obtain LLRs.\nParameters\n\n- **resource_grid** ()  An instance of [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid).\n- **stream_management** ()  An instance of [`StreamManagement`](mimo.html#sionna.mimo.StreamManagement).\n- **dtype** (*tf.Dtype*)  Datatype for internal calculations and the output dtype.\nDefaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n- **(y, h_hat, err_var, no)**  Tuple:\n- **y** (*[batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex*)  Received OFDM resource grid after cyclic prefix removal and FFT\n- **h_hat** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex*)  Channel estimates for all streams from all transmitters\n- **err_var** ([Broadcastable to shape of `h_hat`], tf.float)  Variance of the channel estimation error\n- **no** (*[batch_size, num_rx, num_rx_ant] (or only the first n dims), tf.float*)  Variance of the AWGN\n\n\nOutput\n\n- **x_hat** (*[batch_size, num_tx, num_streams, num_data_symbols], tf.complex*)  Estimated symbols\n- **no_eff** (*[batch_size, num_tx, num_streams, num_data_symbols], tf.float*)  Effective noise variance for each estimated symbol\n\n\n**Note**\n\nIf you want to use this layer in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### OFDMDetector\n\n`class` `sionna.ofdm.``OFDMDetector`(*`detector`*, *`output`*, *`resource_grid`*, *`stream_management`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/ofdm/detection.html#OFDMDetector)\n\nLayer that wraps a MIMO detector for use with the OFDM waveform.\n\nThe parameter `detector` is a callable (e.g., a function) that\nimplements a MIMO detection algorithm for arbitrary batch dimensions.\n\nThis class pre-processes the received resource grid `y` and channel\nestimate `h_hat`, and computes for each receiver the\nnoise-plus-interference covariance matrix according to the OFDM and stream\nconfiguration provided by the `resource_grid` and\n`stream_management`, which also accounts for the channel\nestimation error variance `err_var`. These quantities serve as input to the detection\nalgorithm that is implemented by `detector`.\nBoth detection of symbols or bits with either soft- or hard-decisions are supported.\n\n**Note**\n\nThe callable `detector` must take as input a tuple $(\\mathbf{y}, \\mathbf{h}, \\mathbf{s})$ such that:\n\n- **y** ([,num_rx_ant], tf.complex)  1+D tensor containing the received signals.\n- **h** ([,num_rx_ant,num_streams_per_rx], tf.complex)  2+D tensor containing the channel matrices.\n- **s** ([,num_rx_ant,num_rx_ant], tf.complex)  2+D tensor containing the noise-plus-interference covariance matrices.\n\n\nIt must generate one of following outputs depending on the value of `output`:\n\n- **b_hat** ([, num_streams_per_rx, num_bits_per_symbol], tf.float)  LLRs or hard-decisions for every bit of every stream, if `output` equals <cite>bit</cite>.\n- **x_hat** ([, num_streams_per_rx, num_points], tf.float) or ([, num_streams_per_rx], tf.int)  Logits or hard-decisions for constellation symbols for every stream, if `output` equals <cite>symbol</cite>. Hard-decisions correspond to the symbol indices.\nParameters\n\n- **detector** (*Callable*)  Callable object (e.g., a function) that implements a MIMO detection\nalgorithm for arbitrary batch dimensions. Either one of the existing detectors, e.g.,\n[`LinearDetector`](mimo.html#sionna.mimo.LinearDetector), [`MaximumLikelihoodDetector`](mimo.html#sionna.mimo.MaximumLikelihoodDetector), or\n[`KBestDetector`](mimo.html#sionna.mimo.KBestDetector) can be used, or a custom detector\ncallable provided that has the same input/output specification.\n- **output** (*One of** [**\"bit\"**, **\"symbol\"**]**, **str*)  Type of output, either bits or symbols\n- **resource_grid** ()  Instance of [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid)\n- **stream_management** ()  Instance of [`StreamManagement`](mimo.html#sionna.mimo.StreamManagement)\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**] **tf.DType** (**dtype**)*)  The dtype of <cite>y</cite>. Defaults to tf.complex64.\nThe output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n\nInput\n\n- **(y, h_hat, err_var, no)**  Tuple:\n- **y** (*[batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex*)  Received OFDM resource grid after cyclic prefix removal and FFT\n- **h_hat** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex*)  Channel estimates for all streams from all transmitters\n- **err_var** ([Broadcastable to shape of `h_hat`], tf.float)  Variance of the channel estimation error\n- **no** (*[batch_size, num_rx, num_rx_ant] (or only the first n dims), tf.float*)  Variance of the AWGN\n\n\nOutput\n\n- **One of**\n- *[batch_size, num_tx, num_streams, num_data_symbols*num_bits_per_symbol], tf.float*  LLRs or hard-decisions for every bit of every stream, if `output` equals <cite>bit</cite>\n- *[batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float or [batch_size, num_tx, num_streams, num_data_symbols], tf.int*  Logits or hard-decisions for constellation symbols for every stream, if `output` equals <cite>symbol</cite>.\nHard-decisions correspond to the symbol indices."
"### OFDMDetectorWithPrior\n\n`class` `sionna.ofdm.``OFDMDetectorWithPrior`(*`detector`*, *`output`*, *`resource_grid`*, *`stream_management`*, *`constellation_type`*, *`num_bits_per_symbol`*, *`constellation`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/ofdm/detection.html#OFDMDetectorWithPrior)\n\nLayer that wraps a MIMO detector that assumes prior knowledge of the bits or\nconstellation points is available, for use with the OFDM waveform.\n\nThe parameter `detector` is a callable (e.g., a function) that\nimplements a MIMO detection algorithm with prior for arbitrary batch\ndimensions.\n\nThis class pre-processes the received resource grid `y`, channel\nestimate `h_hat`, and the prior information `prior`, and computes for each receiver the\nnoise-plus-interference covariance matrix according to the OFDM and stream\nconfiguration provided by the `resource_grid` and\n`stream_management`, which also accounts for the channel\nestimation error variance `err_var`. These quantities serve as input to the detection\nalgorithm that is implemented by `detector`.\nBoth detection of symbols or bits with either soft- or hard-decisions are supported.\n\n**Note**\n\nThe callable `detector` must take as input a tuple $(\\mathbf{y}, \\mathbf{h}, \\mathbf{prior}, \\mathbf{s})$ such that:\n\n- **y** ([,num_rx_ant], tf.complex)  1+D tensor containing the received signals.\n- **h** ([,num_rx_ant,num_streams_per_rx], tf.complex)  2+D tensor containing the channel matrices.\n- **prior** ([,num_streams_per_rx,num_bits_per_symbol] or [,num_streams_per_rx,num_points], tf.float)  Prior for the transmitted signals. If `output` equals bit, then LLRs for the transmitted bits are expected. If `output` equals symbol, then logits for the transmitted constellation points are expected.\n- **s** ([,num_rx_ant,num_rx_ant], tf.complex)  2+D tensor containing the noise-plus-interference covariance matrices.\n\n\nIt must generate one of the following outputs depending on the value of `output`:\n\n- **b_hat** ([, num_streams_per_rx, num_bits_per_symbol], tf.float)  LLRs or hard-decisions for every bit of every stream, if `output` equals <cite>bit</cite>.\n- **x_hat** ([, num_streams_per_rx, num_points], tf.float) or ([, num_streams_per_rx], tf.int)  Logits or hard-decisions for constellation symbols for every stream, if `output` equals <cite>symbol</cite>. Hard-decisions correspond to the symbol indices.\nParameters\n\n- **detector** (*Callable*)  Callable object (e.g., a function) that implements a MIMO detection\nalgorithm with prior for arbitrary batch dimensions. Either the existing detector\n[`MaximumLikelihoodDetectorWithPrior`](mimo.html#sionna.mimo.MaximumLikelihoodDetectorWithPrior) can be used, or a custom detector\ncallable provided that has the same input/output specification.\n- **output** (*One of** [**\"bit\"**, **\"symbol\"**]**, **str*)  Type of output, either bits or symbols\n- **resource_grid** ()  Instance of [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid)\n- **stream_management** ()  Instance of [`StreamManagement`](mimo.html#sionna.mimo.StreamManagement)\n- **constellation_type** (*One of** [**\"qam\"**, **\"pam\"**, **\"custom\"**]**, **str*)  For custom, an instance of [`Constellation`](mapping.html#sionna.mapping.Constellation)\nmust be provided.\n- **num_bits_per_symbol** (*int*)  Number of bits per constellation symbol, e.g., 4 for QAM16.\nOnly required for `constellation_type` in [qam, pam].\n- **constellation** ()  Instance of [`Constellation`](mapping.html#sionna.mapping.Constellation) or <cite>None</cite>.\nIn the latter case, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**] **tf.DType** (**dtype**)*)  The dtype of <cite>y</cite>. Defaults to tf.complex64.\nThe output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n\nInput\n\n- **(y, h_hat, prior, err_var, no)**  Tuple:\n- **y** (*[batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex*)  Received OFDM resource grid after cyclic prefix removal and FFT\n- **h_hat** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex*)  Channel estimates for all streams from all transmitters\n- **prior** (*[batch_size, num_tx, num_streams, num_data_symbols x num_bits_per_symbol] or [batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float*)  Prior of the transmitted signals.\nIf `output` equals bit, LLRs of the transmitted bits are expected.\nIf `output` equals symbol, logits of the transmitted constellation points are expected.\n- **err_var** ([Broadcastable to shape of `h_hat`], tf.float)  Variance of the channel estimation error\n- **no** (*[batch_size, num_rx, num_rx_ant] (or only the first n dims), tf.float*)  Variance of the AWGN\n\n\nOutput\n\n- **One of**\n- *[batch_size, num_tx, num_streams, num_data_symbols*num_bits_per_symbol], tf.float*  LLRs or hard-decisions for every bit of every stream, if `output` equals <cite>bit</cite>.\n- *[batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float or [batch_size, num_tx, num_streams, num_data_symbols], tf.int*  Logits or hard-decisions for constellation symbols for every stream, if `output` equals <cite>symbol</cite>.\nHard-decisions correspond to the symbol indices."
"### EPDetector\n\n`class` `sionna.ofdm.``EPDetector`(*`output`*, *`resource_grid`*, *`stream_management`*, *`num_bits_per_symbol`*, *`hard_out``=``False`*, *`l``=``10`*, *`beta``=``0.9`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/ofdm/detection.html#EPDetector)\n\nThis layer wraps the MIMO EP detector for use with the OFDM waveform.\n\nBoth detection of symbols or bits with either\nsoft- or hard-decisions are supported. The OFDM and stream configuration are provided\nby a [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid) and\n[`StreamManagement`](mimo.html#sionna.mimo.StreamManagement) instance, respectively. The\nactual detector is an instance of [`EPDetector`](mimo.html#sionna.mimo.EPDetector).\nParameters\n\n- **output** (*One of** [**\"bit\"**, **\"symbol\"**]**, **str*)  Type of output, either bits or symbols. Whether soft- or\nhard-decisions are returned can be configured with the\n`hard_out` flag.\n- **resource_grid** ()  Instance of [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid)\n- **stream_management** ()  Instance of [`StreamManagement`](mimo.html#sionna.mimo.StreamManagement)\n- **num_bits_per_symbol** (*int*)  Number of bits per constellation symbol, e.g., 4 for QAM16.\nOnly required for `constellation_type` in [qam, pam].\n- **hard_out** (*bool*)  If <cite>True</cite>, the detector computes hard-decided bit values or\nconstellation point indices instead of soft-values.\nDefaults to <cite>False</cite>.\n- **l** (*int*)  Number of iterations. Defaults to 10.\n- **beta** (*float*)  Parameter $\\beta\\in[0,1]$ for update smoothing.\nDefaults to 0.9.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**] **tf.DType** (**dtype**)*)  Precision used for internal computations. Defaults to `tf.complex64`.\nEspecially for large MIMO setups, the precision can make a significant\nperformance difference.\n\n\nInput\n\n- **(y, h_hat, err_var, no)**  Tuple:\n- **y** (*[batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex*)  Received OFDM resource grid after cyclic prefix removal and FFT\n- **h_hat** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex*)  Channel estimates for all streams from all transmitters\n- **err_var** ([Broadcastable to shape of `h_hat`], tf.float)  Variance of the channel estimation error\n- **no** (*[batch_size, num_rx, num_rx_ant] (or only the first n dims), tf.float*)  Variance of the AWGN\n\n\nOutput\n\n- **One of**\n- *[batch_size, num_tx, num_streams, num_data_symbols*num_bits_per_symbol], tf.float*  LLRs or hard-decisions for every bit of every stream, if `output` equals <cite>bit</cite>.\n- *[batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float or [batch_size, num_tx, num_streams, num_data_symbols], tf.int*  Logits or hard-decisions for constellation symbols for every stream, if `output` equals <cite>symbol</cite>.\nHard-decisions correspond to the symbol indices.\n\n\n**Note**\n\nFor numerical stability, we do not recommend to use this function in Graph\nmode with XLA, i.e., within a function that is decorated with\n`@tf.function(jit_compile=True)`.\nHowever, it is possible to do so by setting\n`sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### KBestDetector\n\n`class` `sionna.ofdm.``KBestDetector`(*`output`*, *`num_streams`*, *`k`*, *`resource_grid`*, *`stream_management`*, *`constellation_type``=``None`*, *`num_bits_per_symbol``=``None`*, *`constellation``=``None`*, *`hard_out``=``False`*, *`use_real_rep``=``False`*, *`list2llr``=``None`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/ofdm/detection.html#KBestDetector)\n\nThis layer wraps the MIMO K-Best detector for use with the OFDM waveform.\n\nBoth detection of symbols or bits with either\nsoft- or hard-decisions are supported. The OFDM and stream configuration are provided\nby a [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid) and\n[`StreamManagement`](mimo.html#sionna.mimo.StreamManagement) instance, respectively. The\nactual detector is an instance of [`KBestDetector`](mimo.html#sionna.mimo.KBestDetector).\nParameters\n\n- **output** (*One of** [**\"bit\"**, **\"symbol\"**]**, **str*)  Type of output, either bits or symbols. Whether soft- or\nhard-decisions are returned can be configured with the\n`hard_out` flag.\n- **num_streams** (*tf.int*)  Number of transmitted streams\n- **k** (*tf.int*)  Number of paths to keep. Cannot be larger than the\nnumber of constellation points to the power of the number of\nstreams.\n- **resource_grid** ()  Instance of [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid)\n- **stream_management** ()  Instance of [`StreamManagement`](mimo.html#sionna.mimo.StreamManagement)\n- **constellation_type** (*One of** [**\"qam\"**, **\"pam\"**, **\"custom\"**]**, **str*)  For custom, an instance of [`Constellation`](mapping.html#sionna.mapping.Constellation)\nmust be provided.\n- **num_bits_per_symbol** (*int*)  Number of bits per constellation symbol, e.g., 4 for QAM16.\nOnly required for `constellation_type` in [qam, pam].\n- **constellation** ()  Instance of [`Constellation`](mapping.html#sionna.mapping.Constellation) or <cite>None</cite>.\nIn the latter case, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n- **hard_out** (*bool*)  If <cite>True</cite>, the detector computes hard-decided bit values or\nconstellation point indices instead of soft-values.\nDefaults to <cite>False</cite>.\n- **use_real_rep** (*bool*)  If <cite>True</cite>, the detector use the real-valued equivalent representation\nof the channel. Note that this only works with a QAM constellation.\nDefaults to <cite>False</cite>.\n- **list2llr** (<cite>None</cite> or instance of [`List2LLR`](mimo.html#sionna.mimo.List2LLR))  The function to be used to compute LLRs from a list of candidate solutions.\nIf <cite>None</cite>, the default solution [`List2LLRSimple`](mimo.html#sionna.mimo.List2LLRSimple)\nis used.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**] **tf.DType** (**dtype**)*)  The dtype of <cite>y</cite>. Defaults to tf.complex64.\nThe output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n\nInput\n\n- **(y, h_hat, err_var, no)**  Tuple:\n- **y** (*[batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex*)  Received OFDM resource grid after cyclic prefix removal and FFT\n- **h_hat** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex*)  Channel estimates for all streams from all transmitters\n- **err_var** ([Broadcastable to shape of `h_hat`], tf.float)  Variance of the channel estimation error\n- **no** (*[batch_size, num_rx, num_rx_ant] (or only the first n dims), tf.float*)  Variance of the AWGN\n\n\nOutput\n\n- **One of**\n- *[batch_size, num_tx, num_streams, num_data_symbols*num_bits_per_symbol], tf.float*  LLRs or hard-decisions for every bit of every stream, if `output` equals <cite>bit</cite>.\n- *[batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float or [batch_size, num_tx, num_streams, num_data_symbols], tf.int*  Logits or hard-decisions for constellation symbols for every stream, if `output` equals <cite>symbol</cite>.\nHard-decisions correspond to the symbol indices.\n\n\n**Note**\n\nIf you want to use this layer in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### LinearDetector\n\n`class` `sionna.ofdm.``LinearDetector`(*`equalizer`*, *`output`*, *`demapping_method`*, *`resource_grid`*, *`stream_management`*, *`constellation_type``=``None`*, *`num_bits_per_symbol``=``None`*, *`constellation``=``None`*, *`hard_out``=``False`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/ofdm/detection.html#LinearDetector)\n\nThis layer wraps a MIMO linear equalizer and a [`Demapper`](mapping.html#sionna.mapping.Demapper)\nfor use with the OFDM waveform.\n\nBoth detection of symbols or bits with either\nsoft- or hard-decisions are supported. The OFDM and stream configuration are provided\nby a [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid) and\n[`StreamManagement`](mimo.html#sionna.mimo.StreamManagement) instance, respectively. The\nactual detector is an instance of [`LinearDetector`](mimo.html#sionna.mimo.LinearDetector).\nParameters\n\n- **equalizer** (*str**, **one of** [**\"lmmse\"**, **\"zf\"**, **\"mf\"**]**, or **an equalizer function*)  Equalizer to be used. Either one of the existing equalizers, e.g.,\n[`lmmse_equalizer()`](mimo.html#sionna.mimo.lmmse_equalizer), [`zf_equalizer()`](mimo.html#sionna.mimo.zf_equalizer), or\n[`mf_equalizer()`](mimo.html#sionna.mimo.mf_equalizer) can be used, or a custom equalizer\nfunction provided that has the same input/output specification.\n- **output** (*One of** [**\"bit\"**, **\"symbol\"**]**, **str*)  Type of output, either bits or symbols. Whether soft- or\nhard-decisions are returned can be configured with the\n`hard_out` flag.\n- **demapping_method** (*One of** [**\"app\"**, **\"maxlog\"**]**, **str*)  Demapping method used\n- **resource_grid** ()  Instance of [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid)\n- **stream_management** ()  Instance of [`StreamManagement`](mimo.html#sionna.mimo.StreamManagement)\n- **constellation_type** (*One of** [**\"qam\"**, **\"pam\"**, **\"custom\"**]**, **str*)  For custom, an instance of [`Constellation`](mapping.html#sionna.mapping.Constellation)\nmust be provided.\n- **num_bits_per_symbol** (*int*)  Number of bits per constellation symbol, e.g., 4 for QAM16.\nOnly required for `constellation_type` in [qam, pam].\n- **constellation** ()  Instance of [`Constellation`](mapping.html#sionna.mapping.Constellation) or <cite>None</cite>.\nIn the latter case, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n- **hard_out** (*bool*)  If <cite>True</cite>, the detector computes hard-decided bit values or\nconstellation point indices instead of soft-values.\nDefaults to <cite>False</cite>.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**] **tf.DType** (**dtype**)*)  The dtype of <cite>y</cite>. Defaults to tf.complex64.\nThe output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n\nInput\n\n- **(y, h_hat, err_var, no)**  Tuple:\n- **y** (*[batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex*)  Received OFDM resource grid after cyclic prefix removal and FFT\n- **h_hat** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex*)  Channel estimates for all streams from all transmitters\n- **err_var** ([Broadcastable to shape of `h_hat`], tf.float)  Variance of the channel estimation error\n- **no** (*[batch_size, num_rx, num_rx_ant] (or only the first n dims), tf.float*)  Variance of the AWGN\n\n\nOutput\n\n- **One of**\n- *[batch_size, num_tx, num_streams, num_data_symbols*num_bits_per_symbol], tf.float*  LLRs or hard-decisions for every bit of every stream, if `output` equals <cite>bit</cite>.\n- *[batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float or [batch_size, num_tx, num_streams, num_data_symbols], tf.int*  Logits or hard-decisions for constellation symbols for every stream, if `output` equals <cite>symbol</cite>.\nHard-decisions correspond to the symbol indices.\n\n\n**Note**\n\nIf you want to use this layer in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### MaximumLikelihoodDetector\n\n`class` `sionna.ofdm.``MaximumLikelihoodDetector`(*`output`*, *`demapping_method`*, *`resource_grid`*, *`stream_management`*, *`constellation_type``=``None`*, *`num_bits_per_symbol``=``None`*, *`constellation``=``None`*, *`hard_out``=``False`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/ofdm/detection.html#MaximumLikelihoodDetector)\n\nMaximum-likelihood (ML) detection for OFDM MIMO transmissions.\n\nThis layer implements maximum-likelihood (ML) detection\nfor OFDM MIMO transmissions. Both ML detection of symbols or bits with either\nsoft- or hard-decisions are supported. The OFDM and stream configuration are provided\nby a [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid) and\n[`StreamManagement`](mimo.html#sionna.mimo.StreamManagement) instance, respectively. The\nactual detector is an instance of [`MaximumLikelihoodDetector`](mimo.html#sionna.mimo.MaximumLikelihoodDetector).\nParameters\n\n- **output** (*One of** [**\"bit\"**, **\"symbol\"**]**, **str*)  Type of output, either bits or symbols. Whether soft- or\nhard-decisions are returned can be configured with the\n`hard_out` flag.\n- **demapping_method** (*One of** [**\"app\"**, **\"maxlog\"**]**, **str*)  Demapping method used\n- **resource_grid** ()  Instance of [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid)\n- **stream_management** ()  Instance of [`StreamManagement`](mimo.html#sionna.mimo.StreamManagement)\n- **constellation_type** (*One of** [**\"qam\"**, **\"pam\"**, **\"custom\"**]**, **str*)  For custom, an instance of [`Constellation`](mapping.html#sionna.mapping.Constellation)\nmust be provided.\n- **num_bits_per_symbol** (*int*)  Number of bits per constellation symbol, e.g., 4 for QAM16.\nOnly required for `constellation_type` in [qam, pam].\n- **constellation** ()  Instance of [`Constellation`](mapping.html#sionna.mapping.Constellation) or <cite>None</cite>.\nIn the latter case, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n- **hard_out** (*bool*)  If <cite>True</cite>, the detector computes hard-decided bit values or\nconstellation point indices instead of soft-values.\nDefaults to <cite>False</cite>.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**] **tf.DType** (**dtype**)*)  The dtype of <cite>y</cite>. Defaults to tf.complex64.\nThe output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n\nInput\n\n- **(y, h_hat, err_var, no)**  Tuple:\n- **y** (*[batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex*)  Received OFDM resource grid after cyclic prefix removal and FFT\n- **h_hat** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex*)  Channel estimates for all streams from all transmitters\n- **err_var** ([Broadcastable to shape of `h_hat`], tf.float)  Variance of the channel estimation error\n- **no** (*[batch_size, num_rx, num_rx_ant] (or only the first n dims), tf.float*)  Variance of the AWGN noise\n\n\nOutput\n\n- **One of**\n- *[batch_size, num_tx, num_streams, num_data_symbols*num_bits_per_symbol], tf.float*  LLRs or hard-decisions for every bit of every stream, if `output` equals <cite>bit</cite>.\n- *[batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float or [batch_size, num_tx, num_streams, num_data_symbols], tf.int*  Logits or hard-decisions for constellation symbols for every stream, if `output` equals <cite>symbol</cite>.\nHard-decisions correspond to the symbol indices.\n\n\n**Note**\n\nIf you want to use this layer in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### MaximumLikelihoodDetectorWithPrior\n\n`class` `sionna.ofdm.``MaximumLikelihoodDetectorWithPrior`(*`output`*, *`demapping_method`*, *`resource_grid`*, *`stream_management`*, *`constellation_type``=``None`*, *`num_bits_per_symbol``=``None`*, *`constellation``=``None`*, *`hard_out``=``False`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/ofdm/detection.html#MaximumLikelihoodDetectorWithPrior)\n\nMaximum-likelihood (ML) detection for OFDM MIMO transmissions, assuming prior\nknowledge of the bits or constellation points is available.\n\nThis layer implements maximum-likelihood (ML) detection\nfor OFDM MIMO transmissions assuming prior knowledge on the transmitted data is available.\nBoth ML detection of symbols or bits with either\nsoft- or hard-decisions are supported. The OFDM and stream configuration are provided\nby a [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid) and\n[`StreamManagement`](mimo.html#sionna.mimo.StreamManagement) instance, respectively. The\nactual detector is an instance of [`MaximumLikelihoodDetectorWithPrior`](mimo.html#sionna.mimo.MaximumLikelihoodDetectorWithPrior).\nParameters\n\n- **output** (*One of** [**\"bit\"**, **\"symbol\"**]**, **str*)  Type of output, either bits or symbols. Whether soft- or\nhard-decisions are returned can be configured with the\n`hard_out` flag.\n- **demapping_method** (*One of** [**\"app\"**, **\"maxlog\"**]**, **str*)  Demapping method used\n- **resource_grid** ()  Instance of [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid)\n- **stream_management** ()  Instance of [`StreamManagement`](mimo.html#sionna.mimo.StreamManagement)\n- **constellation_type** (*One of** [**\"qam\"**, **\"pam\"**, **\"custom\"**]**, **str*)  For custom, an instance of [`Constellation`](mapping.html#sionna.mapping.Constellation)\nmust be provided.\n- **num_bits_per_symbol** (*int*)  Number of bits per constellation symbol, e.g., 4 for QAM16.\nOnly required for `constellation_type` in [qam, pam].\n- **constellation** ()  Instance of [`Constellation`](mapping.html#sionna.mapping.Constellation) or <cite>None</cite>.\nIn the latter case, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n- **hard_out** (*bool*)  If <cite>True</cite>, the detector computes hard-decided bit values or\nconstellation point indices instead of soft-values.\nDefaults to <cite>False</cite>.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**] **tf.DType** (**dtype**)*)  The dtype of <cite>y</cite>. Defaults to tf.complex64.\nThe output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n\nInput\n\n- **(y, h_hat, prior, err_var, no)**  Tuple:\n- **y** (*[batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex*)  Received OFDM resource grid after cyclic prefix removal and FFT\n- **h_hat** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex*)  Channel estimates for all streams from all transmitters\n- **prior** (*[batch_size, num_tx, num_streams, num_data_symbols x num_bits_per_symbol] or [batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float*)  Prior of the transmitted signals.\nIf `output` equals bit, LLRs of the transmitted bits are expected.\nIf `output` equals symbol, logits of the transmitted constellation points are expected.\n- **err_var** ([Broadcastable to shape of `h_hat`], tf.float)  Variance of the channel estimation error\n- **no** (*[batch_size, num_rx, num_rx_ant] (or only the first n dims), tf.float*)  Variance of the AWGN noise\n\n\nOutput\n\n- **One of**\n- *[batch_size, num_tx, num_streams, num_data_symbols*num_bits_per_symbol], tf.float*  LLRs or hard-decisions for every bit of every stream, if `output` equals <cite>bit</cite>.\n- *[batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float or [batch_size, num_tx, num_streams, num_data_symbols], tf.int*  Logits or hard-decisions for constellation symbols for every stream, if `output` equals <cite>symbol</cite>.\nHard-decisions correspond to the symbol indices.\n\n\n**Note**\n\nIf you want to use this layer in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### MMSEPICDetector\n\n`class` `sionna.ofdm.``MMSEPICDetector`(*`output`*, *`resource_grid`*, *`stream_management`*, *`demapping_method``=``'maxlog'`*, *`num_iter``=``1`*, *`constellation_type``=``None`*, *`num_bits_per_symbol``=``None`*, *`constellation``=``None`*, *`hard_out``=``False`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/ofdm/detection.html#MMSEPICDetector)\n\nThis layer wraps the MIMO MMSE PIC detector for use with the OFDM waveform.\n\nBoth detection of symbols or bits with either\nsoft- or hard-decisions are supported. The OFDM and stream configuration are provided\nby a [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid) and\n[`StreamManagement`](mimo.html#sionna.mimo.StreamManagement) instance, respectively. The\nactual detector is an instance of [`MMSEPICDetector`](mimo.html#sionna.mimo.MMSEPICDetector).\nParameters\n\n- **output** (*One of** [**\"bit\"**, **\"symbol\"**]**, **str*)  Type of output, either bits or symbols. Whether soft- or\nhard-decisions are returned can be configured with the\n`hard_out` flag.\n- **resource_grid** ()  Instance of [`ResourceGrid`](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid)\n- **stream_management** ()  Instance of [`StreamManagement`](mimo.html#sionna.mimo.StreamManagement)\n- **demapping_method** (*One of** [**\"app\"**, **\"maxlog\"**]**, **str*)  The demapping method used.\nDefaults to maxlog.\n- **num_iter** (*int*)  Number of MMSE PIC iterations.\nDefaults to 1.\n- **constellation_type** (*One of** [**\"qam\"**, **\"pam\"**, **\"custom\"**]**, **str*)  For custom, an instance of [`Constellation`](mapping.html#sionna.mapping.Constellation)\nmust be provided.\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation symbol, e.g., 4 for QAM16.\nOnly required for `constellation_type` in [qam, pam].\n- **constellation** ()  An instance of [`Constellation`](mapping.html#sionna.mapping.Constellation) or <cite>None</cite>.\nIn the latter case, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n- **hard_out** (*bool*)  If <cite>True</cite>, the detector computes hard-decided bit values or\nconstellation point indices instead of soft-values.\nDefaults to <cite>False</cite>.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**] **tf.DType** (**dtype**)*)  Precision used for internal computations. Defaults to `tf.complex64`.\nEspecially for large MIMO setups, the precision can make a significant\nperformance difference.\n\n\nInput\n\n- **(y, h_hat, prior, err_var, no)**  Tuple:\n- **y** (*[batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex*)  Received OFDM resource grid after cyclic prefix removal and FFT\n- **h_hat** (*[batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex*)  Channel estimates for all streams from all transmitters\n- **prior** (*[batch_size, num_tx, num_streams, num_data_symbols x num_bits_per_symbol] or [batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float*)  Prior of the transmitted signals.\nIf `output` equals bit, LLRs of the transmitted bits are expected.\nIf `output` equals symbol, logits of the transmitted constellation points are expected.\n- **err_var** ([Broadcastable to shape of `h_hat`], tf.float)  Variance of the channel estimation error\n- **no** (*[batch_size, num_rx, num_rx_ant] (or only the first n dims), tf.float*)  Variance of the AWGN\n\n\nOutput\n\n- **One of**\n- *[batch_size, num_tx, num_streams, num_data_symbols*num_bits_per_symbol], tf.float*  LLRs or hard-decisions for every bit of every stream, if `output` equals <cite>bit</cite>.\n- *[batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float or [batch_size, num_tx, num_streams, num_data_symbols], tf.int*  Logits or hard-decisions for constellation symbols for every stream, if `output` equals <cite>symbol</cite>.\nHard-decisions correspond to the symbol indices.\n\n\n**Note**\n\nFor numerical stability, we do not recommend to use this function in Graph\nmode with XLA, i.e., within a function that is decorated with\n`@tf.function(jit_compile=True)`.\nHowever, it is possible to do so by setting\n`sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat).\nSee [`xla_compat`](config.html#sionna.Config.xla_compat).\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"# Ray Tracing\n\nThis module provides a differentiable ray tracer for radio propagation modeling.\nThe best way to get started is by having a look at the [Sionna Ray Tracing Tutorial](../examples/Sionna_Ray_Tracing_Introduction.html).\nThe [Primer on Electromagnetics](../em_primer.html) provides useful background knowledge and various definitions that are used throughout the API documentation.\n\nThe most important component of the ray tracer is the [`Scene`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene).\nIt has methods for the computation of propagation [`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths) ([`compute_paths()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_paths)) and [`CoverageMap`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.CoverageMap) ([`coverage_map()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.coverage_map)).\nSionna has several integrated [Example Scenes](https://nvlabs.github.io/sionna/api/rt.html#example-scenes) that you can use for your own experiments. In this [video](https://youtu.be/7xHLDxUaQ7c), we explain how you can create your own scenes using [OpenStreetMap](https://www.openstreetmap.org) and [Blender](https://www.blender.org).\nYou can preview a scene within a Jupyter notebook ([`preview()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.preview)) or render it to a file from the viewpoint of a camera ([`render()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.render) or [`render_to_file()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.render_to_file)).\n\nPropagation [`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths) can be transformed into time-varying channel impulse responses (CIRs) via [`cir()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths.cir). The CIRs can then be used for link-level simulations in Sionna via the functions [`cir_to_time_channel()`](channel.wireless.html#sionna.channel.cir_to_time_channel) or [`cir_to_ofdm_channel()`](channel.wireless.html#sionna.channel.cir_to_ofdm_channel). Alternatively, you can create a dataset of CIRs that can be used by a channel model with the help of [`CIRDataset`](channel.wireless.html#sionna.channel.CIRDataset).\n\nThe paper [Sionna RT: Differentiable Ray Tracing for Radio Propagation Modeling](https://nvlabs.github.io/sionna/made_with_sionna.html#sionna-rt-differentiable-ray-tracing-for-radio-propagation-modeling) shows how differentiable ray tracing can be used for various optimization tasks. The related [notebooks](https://nvlabs.github.io/sionna/made_with_sionna.html#sionna-rt-differentiable-ray-tracing-for-radio-propagation-modeling) can be a good starting point for your own experiments."
"## Scene\n\nThe scene contains everything that is needed for radio propagation simulation\nand rendering.\n\nA scene is a collection of multiple instances of [`SceneObject`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.SceneObject) which define\nthe geometry and materials of the objects in the scene.\nThe scene also includes transmitters ([`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter)) and receivers ([`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver))\nfor which propagation [`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths) or  channel impulse responses (CIRs) can be computed,\nas well as cameras ([`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera)) for rendering.\n\nA scene is loaded from a file using the [`load_scene()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.load_scene) function.\nSionna contains a few [Example Scenes](https://nvlabs.github.io/sionna/api/rt.html#example-scenes).\nThe following code snippet shows how to load one of them and\nrender it through the lens of the preconfigured scene [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) scene-cam-0:\n```python\nscene = load_scene(sionna.rt.scene.munich)\nscene.render(camera=\"scene-cam-0\")\n```\n\n\nYou can preview a scene in an interactive 3D viewer within a Jupyter notebook using [`preview()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.preview):\n```python\nscene.preview()\n```\n\n\nIn the code snippet above, the [`load_scene()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.load_scene) function returns the [`Scene`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene) instance which can be used\nto access scene objects, transmitters, receivers, cameras, and to set the\nfrequency for radio wave propagation simulation. Note that you can load only a single scene at a time.\n\nIt is important to understand that all transmitters in a scene share the same [`AntennaArray`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.AntennaArray) which can be set\nthrough the scene property [`tx_array`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.tx_array). The same holds for all receivers whose [`AntennaArray`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.AntennaArray)\ncan be set through [`rx_array`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.rx_array). However, each transmitter and receiver can have a different position and orientation.\n\nThe code snippet below shows how to configure the [`tx_array`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.tx_array) and [`rx_array`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.rx_array) and\nto instantiate a transmitter and receiver."
"```python\n# Configure antenna array for all transmitters\nscene.tx_array = PlanarArray(num_rows=8,\n                          num_cols=2,\n                          vertical_spacing=0.7,\n                          horizontal_spacing=0.5,\n                          pattern=\"tr38901\",\n                          polarization=\"VH\")\n# Configure antenna array for all receivers\nscene.rx_array = PlanarArray(num_rows=1,\n                          num_cols=1,\n                          vertical_spacing=0.5,\n                          horizontal_spacing=0.5,\n                          pattern=\"dipole\",\n                          polarization=\"cross\")\n# Create transmitter\ntx = Transmitter(name=\"tx\",\n              position=[8.5,21,27],\n              orientation=[0,0,0])\nscene.add(tx)\n# Create a receiver\nrx = Receiver(name=\"rx\",\n           position=[45,90,1.5],\n           orientation=[0,0,0])\nscene.add(rx)\n# TX points towards RX\ntx.look_at(rx)\nprint(scene.transmitters)\nprint(scene.receivers)\n```\n\n```python\n{'tx': <sionna.rt.transmitter.Transmitter object at 0x7f83d0555d30>}\n{'rx': <sionna.rt.receiver.Receiver object at 0x7f81f00ef0a0>}\n```\n\n\nOnce you have loaded a scene and configured transmitters and receivers, you can use the scene method\n[`compute_paths()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_paths) to compute propagation paths:\n```python\npaths = scene.compute_paths()\n```\n\n\nThe output of this function is an instance of [`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths) and can be used to compute channel\nimpulse responses (CIRs) using the method [`cir()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths.cir).\nYou can visualize the paths within a scene by one of the following commands:\n```python\nscene.preview(paths=paths) # Open preview showing paths\nscene.render(camera=\"preview\", paths=paths) # Render scene with paths from preview camera\nscene.render_to_file(camera=\"preview\",\n                     filename=\"scene.png\",\n                     paths=paths) # Render scene with paths to file\n```\n\n\nNote that the calls to the render functions in the code above use the preview camera which is configured through\n[`preview()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.preview). You can use any other [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) that you create here as well.\n\nThe function [`coverage_map()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.coverage_map) computes a [`CoverageMap`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.CoverageMap) for every transmitter in a scene:"
"```python\ncm = scene.coverage_map(cm_cell_size=[1.,1.], # Configure size of each cell\n                        num_samples=1e7) # Number of rays to trace\n```\n\n\nCoverage maps can be visualized in the same way as propagation paths:\n```python\nscene.preview(coverage_map=cm) # Open preview showing coverage map\nscene.render(camera=\"preview\", coverage_map=cm) # Render scene with coverage map\nscene.render_to_file(camera=\"preview\",\n                     filename=\"scene.png\",\n                     coverage_map=cm) # Render scene with coverage map to file\n```"
"### Scene\n\n`class` `sionna.rt.``Scene`[`[source]`](../_modules/sionna/rt/scene.html#Scene)\n\nThe scene contains everything that is needed for radio propagation simulation\nand rendering.\n\nA scene is a collection of multiple instances of [`SceneObject`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.SceneObject) which define\nthe geometry and materials of the objects in the scene.\nThe scene also includes transmitters ([`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter)) and receivers ([`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver))\nfor which propagation [`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths), channel impulse responses (CIRs) or coverage maps ([`CoverageMap`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.CoverageMap)) can be computed,\nas well as cameras ([`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera)) for rendering.\n\nThe only way to instantiate a scene is by calling `load_scene()`.\nNote that only a single scene can be loaded at a time.\n\nExample scenes can be loaded as follows:\n```python\nscene = load_scene(sionna.rt.scene.munich)\nscene.preview()\n```\n\n\n`add`(*`item`*)[`[source]`](../_modules/sionna/rt/scene.html#Scene.add)\n\nAdds a transmitter, receiver, radio material, or camera to the scene.\n\nIf a different item with the same name as `item` is already part of the scene,\nan error is raised.\nInput\n\n**item** ([`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter) | [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver) | [`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial) | [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera))  Item to add to the scene\n\n\n`property` `cameras`\n\nDictionary\nof cameras in the scene\nType\n\n<cite>dict</cite> (read-only), { name, [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera)}\n\n\n`property` `center`\n\nGet the center of the scene\nType\n\n[3], tf.float\n\n\n`property` `dtype`\n\nDatatype used in tensors\nType\n\n<cite>tf.complex64 | tf.complex128</cite>\n\n\n`property` `frequency`\n\nGet/set the carrier frequency [Hz]\n\nSetting the frequency updates the parameters of frequency-dependent\nradio materials. Defaults to 3.5e9.\nType\n\nfloat\n\n\n`get`(*`name`*)[`[source]`](../_modules/sionna/rt/scene.html#Scene.get)\n\nReturns a scene object, transmitter, receiver, camera, or radio material\nInput\n\n**name** (*str*)  Name of the item to retrieve\n\nOutput\n\n**item** ([`SceneObject`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.SceneObject) | [`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial) | [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter) | [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver) | [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) | <cite>None</cite>)  Retrieved item. Returns <cite>None</cite> if no corresponding item was found in the scene.\n\n\n`property` `objects`\n\nDictionary\nof scene objects\nType\n\n<cite>dict</cite> (read-only), { name, [`SceneObject`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.SceneObject)}\n\n\n`property` `radio_material_callable`\n\nGet/set a callable that computes the radio material properties at the\npoints of intersection between the rays and the scene objects.\n\nIf set, then the [`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial) of the objects are\nnot used and the callable is invoked instead to obtain the\nelectromagnetic properties required to simulate the propagation of radio\nwaves.\n\nIf not set, i.e., <cite>None</cite> (default), then the\n[`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial) of objects are used to simulate the\npropagation of radio waves in the scene.\n\nThis callable is invoked on batches of intersection points.\nIt takes as input the following tensors:\n\n- `object_id` (<cite>[batch_dims]</cite>, <cite>int</cite>) : Integers uniquely identifying the intersected objects\n- `points` (<cite>[batch_dims, 3]</cite>, <cite>float</cite>) : Positions of the intersection points\n\n\nThe callable must output a tuple/list of the following tensors:\n\n- `complex_relative_permittivity` (<cite>[batch_dims]</cite>, <cite>complex</cite>) : Complex relative permittivities $\\eta$ [(9)](../em_primer.html#equation-eta)\n- `scattering_coefficient` (<cite>[batch_dims]</cite>, <cite>float</cite>) : Scattering coefficients $S\\in[0,1]$ [(37)](../em_primer.html#equation-scattering-coefficient)\n- `xpd_coefficient` (<cite>[batch_dims]</cite>, <cite>float</cite>) : Cross-polarization discrimination coefficients $K_x\\in[0,1]$ [(39)](../em_primer.html#equation-xpd). Only relevant for the scattered field.\n\n\n**Note:** The number of batch dimensions is not necessarily equal to one.\n\n\n`property` `radio_materials`\n\nDictionary\nof radio materials\nType\n\n<cite>dict</cite> (read-only), { name, [`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial)}\n\n\n`property` `receivers`\n\nDictionary\nof receivers in the scene\nType\n\n<cite>dict</cite> (read-only), { name, [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver)}\n\n\n`remove`(*`name`*)[`[source]`](../_modules/sionna/rt/scene.html#Scene.remove)\n\nRemoves a transmitter, receiver, camera, or radio material from the\nscene.\n\nIn the case of a radio material, it must not be used by any object of\nthe scene.\nInput\n\n**name** (*str*)  Name of the item to remove\n\n\n`property` `rx_array`\n\nGet/set the antenna array used by\nall receivers in the scene. Defaults to <cite>None</cite>.\nType\n\n[`AntennaArray`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.AntennaArray)\n\n\n`property` `scattering_pattern_callable`\n\nGet/set a callable that computes the scattering pattern at the\npoints of intersection between the rays and the scene objects.\n\nIf set, then the [`scattering_pattern`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial.scattering_pattern) of\nthe radio materials of the objects are not used and the callable is invoked\ninstead to evaluate the scattering pattern required to simulate the\npropagation of diffusely reflected radio waves.\n\nIf not set, i.e., <cite>None</cite> (default), then the\n[`scattering_pattern`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial.scattering_pattern) of the objects\nradio materials are used to simulate the propagation of diffusely\nreflected radio waves in the scene.\n\nThis callable is invoked on batches of intersection points.\nIt takes as input the following tensors:\n\n- `object_id` (<cite>[batch_dims]</cite>, <cite>int</cite>) : Integers uniquely identifying the intersected objects\n- `points` (<cite>[batch_dims, 3]</cite>, <cite>float</cite>) : Positions of the intersection points\n- `k_i` (<cite>[batch_dims, 3]</cite>, <cite>float</cite>) : Unitary vector corresponding to the direction of incidence in the scenes global coordinate system\n- `k_s` (<cite>[batch_dims, 3]</cite>, <cite>float</cite>) : Unitary vector corresponding to the direction of the diffuse reflection in the scenes global coordinate system\n- `n` (<cite>[batch_dims, 3]</cite>, <cite>float</cite>) : Unitary vector corresponding to the normal to the surface at the intersection point\n\n\nThe callable must output the following tensor:\n\n- `f_s` (<cite>[batch_dims]</cite>, <cite>float</cite>) : The scattering pattern evaluated for the previous inputs\n\n\n**Note:** The number of batch dimensions is not necessarily equal to one.\n\n\n`property` `size`\n\nGet the size of the scene, i.e., the size of the\naxis-aligned minimum bounding box for the scene\nType\n\n[3], tf.float\n\n\n`property` `synthetic_array`\n\nGet/set if the antenna arrays are applied synthetically.\nDefaults to <cite>True</cite>.\nType\n\nbool\n\n\n`property` `transmitters`\n\nDictionary\nof transmitters in the scene\nType\n\n<cite>dict</cite> (read-only), { name, [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter)}\n\n\n`property` `tx_array`\n\nGet/set the antenna array used by\nall transmitters in the scene. Defaults to <cite>None</cite>.\nType\n\n[`AntennaArray`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.AntennaArray)\n\n\n`property` `wavelength`\n\nWavelength [m]\nType\n\nfloat (read-only)"
"### compute_paths\n\n`sionna.rt.Scene.``compute_paths`(*`self`*, *`max_depth``=``3`*, *`method``=``'fibonacci'`*, *`num_samples``=``1000000`*, *`los``=``True`*, *`reflection``=``True`*, *`diffraction``=``False`*, *`scattering``=``False`*, *`scat_keep_prob``=``0.001`*, *`edge_diffraction``=``False`*, *`check_scene``=``True`*, *`scat_random_phases``=``True`*, *`testing``=``False`*)\n\nComputes propagation paths\n\nThis function computes propagation paths between the antennas of\nall transmitters and receivers in the current scene.\nFor each propagation path $i$, the corresponding channel coefficient\n$a_i$ and delay $\\tau_i$, as well as the\nangles of departure $(\\theta_{\\text{T},i}, \\varphi_{\\text{T},i})$\nand arrival $(\\theta_{\\text{R},i}, \\varphi_{\\text{R},i})$ are returned.\nFor more detail, see [(26)](../em_primer.html#equation-h-final).\nDifferent propagation phenomena, such as line-of-sight, reflection, diffraction,\nand diffuse scattering can be individually enabled/disabled.\n\nIf the scene is configured to use synthetic arrays\n([`synthetic_array`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.synthetic_array) is <cite>True</cite>), transmitters and receivers\nare modelled as if they had a single antenna located at their\n[`position`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter.position). The channel responses for each\nindividual antenna of the arrays are then computed synthetically by applying\nappropriate phase shifts. This reduces the complexity significantly\nfor large arrays. Time evolution of the channel coefficients can be simulated with\nthe help of the function [`apply_doppler()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths.apply_doppler) of the returned\n[`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths) object.\n\nThe path computation consists of two main steps as shown in the below figure.\n\nFor a configured [`Scene`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene), the function first traces geometric propagation paths\nusing [`trace_paths()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.trace_paths). This step is independent of the\n[`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial) of the scene objects as well as the transmitters and receivers\nantenna [`patterns`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Antenna.patterns) and  [`orientation`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter.orientation),\nbut depends on the selected propagation\nphenomena, such as reflection, scattering, and diffraction. The traced paths\nare then converted to EM fields by the function [`compute_fields()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_fields).\nThe resulting [`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths) object can be used to compute channel\nimpulse responses via [`cir()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths.cir). The advantage of separating path tracing\nand field computation is that one can study the impact of different radio materials\nby executing [`compute_fields()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_fields) multiple times without\nre-tracing the propagation paths. This can for example speed-up the calibration of scene parameters\nby several orders of magnitude.\n xample"
"```python\nimport sionna\nfrom sionna.rt import load_scene, Camera, Transmitter, Receiver, PlanarArray\n# Load example scene\nscene = load_scene(sionna.rt.scene.munich)\n# Configure antenna array for all transmitters\nscene.tx_array = PlanarArray(num_rows=8,\n                          num_cols=2,\n                          vertical_spacing=0.7,\n                          horizontal_spacing=0.5,\n                          pattern=\"tr38901\",\n                          polarization=\"VH\")\n# Configure antenna array for all receivers\nscene.rx_array = PlanarArray(num_rows=1,\n                          num_cols=1,\n                          vertical_spacing=0.5,\n                          horizontal_spacing=0.5,\n                          pattern=\"dipole\",\n                          polarization=\"cross\")\n# Create transmitter\ntx = Transmitter(name=\"tx\",\n              position=[8.5,21,27],\n              orientation=[0,0,0])\nscene.add(tx)\n# Create a receiver\nrx = Receiver(name=\"rx\",\n           position=[45,90,1.5],\n           orientation=[0,0,0])\nscene.add(rx)\n# TX points towards RX\ntx.look_at(rx)\n# Compute paths\npaths = scene.compute_paths()\n# Open preview showing paths\nscene.preview(paths=paths, resolution=[1000,600])\n```\n\n\nInput\n\n- **max_depth** (*int*)  Maximum depth (i.e., number of bounces) allowed for tracing the\npaths. Defaults to 3.\n- **method** (*str (exhaustive|fibonacci)*)  Ray tracing method to be used.\nThe exhaustive method tests all possible combinations of primitives.\nThis method is not compatible with scattering.\nThe fibonacci method uses a shoot-and-bounce approach to find\ncandidate chains of primitives. Initial ray directions are chosen\naccording to a Fibonacci lattice on the unit sphere. This method can be\napplied to very large scenes. However, there is no guarantee that\nall possible paths are found.\nDefaults to fibonacci.\n- **num_samples** (*int*)  Number of rays to trace in order to generate candidates with\nthe fibonacci method.\nThis number is split equally among the different transmitters\n(when using synthetic arrays) or transmit antennas (when not using\nsynthetic arrays).\nThis parameter is ignored when using the exhaustive method.\nTracing more rays can lead to better precision\nat the cost of increased memory requirements.\nDefaults to 1e6.\n- **los** (*bool*)  If set to <cite>True</cite>, then the LoS paths are computed.\nDefaults to <cite>True</cite>.\n- **reflection** (*bool*)  If set to <cite>True</cite>, then the reflected paths are computed.\nDefaults to <cite>True</cite>.\n- **diffraction** (*bool*)  If set to <cite>True</cite>, then the diffracted paths are computed.\nDefaults to <cite>False</cite>.\n- **scattering** (*bool*)  if set to <cite>True</cite>, then the scattered paths are computed.\nOnly works with the Fibonacci method.\nDefaults to <cite>False</cite>.\n- **scat_keep_prob** (*float*)  Probability with which a scattered path is kept.\nThis is helpful to reduce the number of computed scattered\npaths, which might be prohibitively high in some scenes.\nMust be in the range (0,1). Defaults to 0.001.\n- **edge_diffraction** (*bool*)  If set to <cite>False</cite>, only diffraction on wedges, i.e., edges that\nconnect two primitives, is considered.\nDefaults to <cite>False</cite>.\n- **check_scene** (*bool*)  If set to <cite>True</cite>, checks that the scene is well configured before\ncomputing the paths. This can add a significant overhead.\nDefaults to <cite>True</cite>.\n- **scat_random_phases** (*bool*)  If set to <cite>True</cite> and if scattering is enabled, random uniform phase\nshifts are added to the scattered paths.\nDefaults to <cite>True</cite>.\n- **testing** (*bool*)  If set to <cite>True</cite>, then additional data is returned for testing.\nDefaults to <cite>False</cite>.\n\n\nOutput\n\npaths : [`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths)  Simulated paths"
"### trace_paths\n\n`sionna.rt.Scene.``trace_paths`(*`self`*, *`max_depth``=``3`*, *`method``=``'fibonacci'`*, *`num_samples``=``1000000`*, *`los``=``True`*, *`reflection``=``True`*, *`diffraction``=``False`*, *`scattering``=``False`*, *`scat_keep_prob``=``0.001`*, *`edge_diffraction``=``False`*, *`check_scene``=``True`*)\n\nComputes the trajectories of the paths by shooting rays\n\nThe EM fields corresponding to the traced paths are not computed.\nThey can be computed using [`compute_fields()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_fields):\n```python\ntraced_paths = scene.trace_paths()\npaths = scene.compute_fields(*traced_paths)\n```\n\n\nPath tracing is independent of the radio materials, antenna patterns,\nand radio device orientations.\nTherefore, a set of traced paths could be reused for different values\nof these quantities, e.g., to calibrate the ray tracer.\nThis can enable significant resource savings as path tracing is\ntypically significantly more resource-intensive than field computation.\n\nNote that [`compute_paths()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_paths) does both path tracing and\nfield computation.\nInput\n\n- **max_depth** (*int*)  Maximum depth (i.e., number of interaction with objects in the scene)\nallowed for tracing the paths.\nDefaults to 3.\n- **method** (*str (exhaustive|fibonacci)*)  Method to be used to list candidate paths.\nThe exhaustive method tests all possible combination of primitives as\npaths. This method is not compatible with scattering.\nThe fibonacci method uses a shoot-and-bounce approach to find\ncandidate chains of primitives. Initial ray directions are arranged\nin a Fibonacci lattice on the unit sphere. This method can be\napplied to very large scenes. However, there is no guarantee that\nall possible paths are found.\nDefaults to fibonacci.\n- **num_samples** (*int*)  Number of random rays to trace in order to generate candidates.\nA large sample count may exhaust GPU memory.\nDefaults to 1e6. Only needed if `method` is fibonacci.\n- **los** (*bool*)  If set to <cite>True</cite>, then the LoS paths are computed.\nDefaults to <cite>True</cite>.\n- **reflection** (*bool*)  If set to <cite>True</cite>, then the reflected paths are computed.\nDefaults to <cite>True</cite>.\n- **diffraction** (*bool*)  If set to <cite>True</cite>, then the diffracted paths are computed.\nDefaults to <cite>False</cite>.\n- **scattering** (*bool*)  If set to <cite>True</cite>, then the scattered paths are computed.\nOnly works with the Fibonacci method.\nDefaults to <cite>False</cite>.\n- **scat_keep_prob** (*float*)  Probability with which to keep scattered paths.\nThis is helpful to reduce the number of scattered paths computed,\nwhich might be prohibitively high in some setup.\nMust be in the range (0,1).\nDefaults to 0.001.\n- **edge_diffraction** (*bool*)  If set to <cite>False</cite>, only diffraction on wedges, i.e., edges that\nconnect two primitives, is considered.\nDefaults to <cite>False</cite>.\n- **check_scene** (*bool*)  If set to <cite>True</cite>, checks that the scene is well configured before\ncomputing the paths. This can add a significant overhead.\nDefaults to <cite>True</cite>.\n\n\nOutput\n\n- **spec_paths** ([`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths))  Computed specular paths\n- **diff_paths** ([`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths))  Computed diffracted paths\n- **scat_paths** ([`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths))  Computed scattered paths\n- **spec_paths_tmp** (`PathsTmpData`)  Additional data required to compute the EM fields of the specular\npaths\n- **diff_paths_tmp** (`PathsTmpData`)  Additional data required to compute the EM fields of the diffracted\npaths\n- **scat_paths_tmp** (`PathsTmpData`)  Additional data required to compute the EM fields of the scattered\npaths"
"### compute_fields\n\n`sionna.rt.Scene.``compute_fields`(*`self`*, *`spec_paths`*, *`diff_paths`*, *`scat_paths`*, *`spec_paths_tmp`*, *`diff_paths_tmp`*, *`scat_paths_tmp`*, *`check_scene``=``True`*, *`scat_random_phases``=``True`*)\n\nComputes the EM fields corresponding to traced paths\n\nPaths can be traced using [`trace_paths()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.trace_paths).\nThis method can then be used to finalize the paths calculation by\ncomputing the corresponding fields:\n```python\ntraced_paths = scene.trace_paths()\npaths = scene.compute_fields(*traced_paths)\n```\n\n\nPaths tracing is independent from the radio materials, antenna patterns,\nand radio devices orientations.\nTherefore, a set of traced paths could be reused for different values\nof these quantities, e.g., to calibrate the ray tracer.\nThis can enable significant resource savings as paths tracing is\ntypically significantly more resource-intensive than field computation.\n\nNote that [`compute_paths()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_paths) does both tracing and\nfield computation.\nInput\n\n- **spec_paths** ([`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths))  Specular paths\n- **diff_paths** ([`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths))  Diffracted paths\n- **scat_paths** ([`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths))  Scattered paths\n- **spec_paths_tmp** (`PathsTmpData`)  Additional data required to compute the EM fields of the specular\npaths\n- **diff_paths_tmp** (`PathsTmpData`)  Additional data required to compute the EM fields of the diffracted\npaths\n- **scat_paths_tmp** (`PathsTmpData`)  Additional data required to compute the EM fields of the scattered\npaths\n- **check_scene** (*bool*)  If set to <cite>True</cite>, checks that the scene is well configured before\ncomputing the paths. This can add a significant overhead.\nDefaults to <cite>True</cite>.\n- **scat_random_phases** (*bool*)  If set to <cite>True</cite> and if scattering is enabled, random uniform phase\nshifts are added to the scattered paths.\nDefaults to <cite>True</cite>.\n\n\nOutput\n\n**paths** ([`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths))  Computed paths"
"### coverage_map\n\n`sionna.rt.Scene.``coverage_map`(*`self`*, *`rx_orientation``=``(0.0,` `0.0,` `0.0)`*, *`max_depth``=``3`*, *`cm_center``=``None`*, *`cm_orientation``=``None`*, *`cm_size``=``None`*, *`cm_cell_size``=``(10.0,` `10.0)`*, *`combining_vec``=``None`*, *`precoding_vec``=``None`*, *`num_samples``=``2000000`*, *`los``=``True`*, *`reflection``=``True`*, *`diffraction``=``False`*, *`scattering``=``False`*, *`edge_diffraction``=``False`*, *`check_scene``=``True`*)\n\nThis function computes a coverage map for every transmitter in the scene.\n\nFor a given transmitter, a coverage map is a rectangular surface with\narbitrary orientation subdivded\ninto rectangular cells of size $\\lvert C \\rvert = \\texttt{cm_cell_size[0]} \\times  \\texttt{cm_cell_size[1]}$.\nThe parameter `cm_cell_size` therefore controls the granularity of the map.\nThe coverage map associates with every cell $(i,j)$ the quantity\n\n$$\nb_{i,j} = \\frac{1}{\\lvert C \\rvert} \\int_{C_{i,j}} \\lvert h(s) \\rvert^2 ds\n$$\n\nwhere $\\lvert h(s) \\rvert^2$ is the squared amplitude\nof the path coefficients $a_i$ at position $s=(x,y)$,\nthe integral is over the cell $C_{i,j}$, and\n$ds$ is the infinitesimal small surface element\n$ds=dx \\cdot dy$.\nThe dimension indexed by $i$ ($j$) corresponds to the $y\\, (x)$-axis of the\ncoverage map in its local coordinate system.\n\nFor specularly and diffusely reflected paths, [(43)](https://nvlabs.github.io/sionna/api/rt.html#equation-cm-def) can be rewritten as an integral over the directions\nof departure of the rays from the transmitter, by substituting $s$\nwith the corresponding direction $\\omega$:\n\n$$\nb_{i,j} = \\frac{1}{\\lvert C \\rvert} \\int_{\\Omega} \\lvert h\\left(s(\\omega) \\right) \\rvert^2 \\frac{r(\\omega)^2}{\\lvert \\cos{\\alpha(\\omega)} \\rvert} \\mathbb{1}_{\\left\\{ s(\\omega) \\in C_{i,j} \\right\\}} d\\omega\n$$\n\nwhere the integration is over the unit sphere $\\Omega$, $r(\\omega)$ is the length of\nthe path with direction of departure $\\omega$, $s(\\omega)$ is the point\nwhere the path with direction of departure $\\omega$ intersects the coverage map,\n$\\alpha(\\omega)$ is the angle between the coverage map normal and the direction of arrival\nof the path with direction of departure $\\omega$,\nand $\\mathbb{1}_{\\left\\{ s(\\omega) \\in C_{i,j} \\right\\}}$ is the function that takes as value\none if $s(\\omega) \\in C_{i,j}$ and zero otherwise.\nNote that $ds = \\frac{r(\\omega)^2 d\\omega}{\\lvert \\cos{\\alpha(\\omega)} \\rvert}$.\n\nThe previous integral is approximated through Monte Carlo sampling by shooting $N$ rays\nwith directions $\\omega_n$ arranged as a Fibonacci lattice on the unit sphere around the transmitter,\nand bouncing the rays on the intersected objects until the maximum depth (`max_depth`) is reached or\nthe ray bounces out of the scene.\nAt every intersection with an object of the scene, a new ray is shot from the intersection which corresponds to either\nspecular reflection or diffuse scattering, following a Bernoulli distribution with parameter the\nsquared scattering coefficient.\nWhen diffuse scattering is selected, the direction of the scattered ray is uniformly sampled on the half-sphere.\nThe resulting Monte Carlo estimate is:\n\n$$\n\\hat{b}_{i,j}^{\\text{(ref)}} = \\frac{4\\pi}{N\\lvert C \\rvert} \\sum_{n=1}^N \\lvert h\\left(s(\\omega_n)\\right)  \\rvert^2 \\frac{r(\\omega_n)^2}{\\lvert \\cos{\\alpha(\\omega_n)} \\rvert} \\mathbb{1}_{\\left\\{ s(\\omega_n) \\in C_{i,j} \\right\\}}.\n$$\n\nFor the diffracted paths, [(43)](https://nvlabs.github.io/sionna/api/rt.html#equation-cm-def) can be rewritten for any wedge\nwith length $L$ and opening angle $\\Phi$ as an integral over the wedge and its opening angle,\nby substituting $s$ with the position on the wedge $\\ell \\in [1,L]$ and the angle $\\phi \\in [0, \\Phi]$:\n\n$$\nb_{i,j} = \\frac{1}{\\lvert C \\rvert} \\int_{\\ell} \\int_{\\phi} \\lvert h\\left(s(\\ell,\\phi) \\right) \\rvert^2 \\mathbb{1}_{\\left\\{ s(\\ell,\\phi) \\in C_{i,j} \\right\\}} \\left\\lVert \\frac{\\partial r}{\\partial \\ell} \\times \\frac{\\partial r}{\\partial \\phi} \\right\\rVert d\\ell d\\phi\n$$\n\nwhere the integral is over the wedge length $L$ and opening angle $\\Phi$, and\n$r\\left( \\ell, \\phi \\right)$ is the reparametrization with respected to $(\\ell, \\phi)$ of the\nintersection between the diffraction cone at $\\ell$ and the rectangle defining the coverage map (see, e.g., [[SurfaceIntegral]](https://nvlabs.github.io/sionna/api/rt.html#surfaceintegral)).\nThe previous integral is approximated through Monte Carlo sampling by shooting $N'$ rays from equally spaced\nlocations $\\ell_n$ along the wedge with directions $\\phi_n$ sampled uniformly from $(0, \\Phi)$:\n\n$$\n\\hat{b}_{i,j}^{\\text{(diff)}} = \\frac{L\\Phi}{N'\\lvert C \\rvert} \\sum_{n=1}^{N'} \\lvert h\\left(s(\\ell_n,\\phi_n)\\right) \\rvert^2 \\mathbb{1}_{\\left\\{ s(\\ell_n,\\phi_n) \\in C_{i,j} \\right\\}} \\left\\lVert \\left(\\frac{\\partial r}{\\partial \\ell}\\right)_n \\times \\left(\\frac{\\partial r}{\\partial \\phi}\\right)_n \\right\\rVert.\n$$\n\nThe output of this function is therefore a real-valued matrix of size `[num_cells_y,` `num_cells_x]`,\nfor every transmitter, with elements equal to the sum of the contributions of the reflected and scattered paths\n[(44)](https://nvlabs.github.io/sionna/api/rt.html#equation-cm-mc-ref) and diffracted paths [(45)](https://nvlabs.github.io/sionna/api/rt.html#equation-cm-mc-diff) for all the wedges, and where\n\n$$\n\\begin{split}\\texttt{num_cells_x} = \\bigg\\lceil\\frac{\\texttt{cm_size[0]}}{\\texttt{cm_cell_size[0]}} \\bigg\\rceil\\\\\n\\texttt{num_cells_y} = \\bigg\\lceil \\frac{\\texttt{cm_size[1]}}{\\texttt{cm_cell_size[1]}} \\bigg\\rceil.\\end{split}\n$$\n\nThe surface defining the coverage map is a rectangle centered at\n`cm_center`, with orientation `cm_orientation`, and with size\n`cm_size`. An orientation of (0,0,0) corresponds to\na coverage map parallel to the XY plane, with surface normal pointing towards\nthe $+z$ axis. By default, the coverage map\nis parallel to the XY plane, covers all of the scene, and has\nan elevation of $z = 1.5\\text{m}$.\nThe receiver is assumed to use the antenna array\n`scene.rx_array`. If transmitter and/or receiver have multiple antennas, transmit precoding\nand receive combining are applied which are defined by `precoding_vec` and\n`combining_vec`, respectively.\n\nThe $(i,j)$ indices are omitted in the following for clarity.\nFor reflection and scattering, paths are generated by shooting `num_samples` rays from the\ntransmitters with directions arranged in a Fibonacci lattice on the unit\nsphere and by simulating their propagation for up to `max_depth` interactions with\nscene objects.\nIf `max_depth` is set to 0 and if `los` is set to <cite>True</cite>,\nonly the line-of-sight path is considered.\nFor diffraction, paths are generated by shooting `num_samples` rays from equally\nspaced locations along the wedges in line-of-sight with the transmitter, with\ndirections uniformly sampled on the diffraction cone.\n\nFor every ray $n$ intersecting the coverage map cell $(i,j)$, the\nchannel coefficients, $a_n$, and the angles of departure (AoDs)\n$(\\theta_{\\text{T},n}, \\varphi_{\\text{T},n})$\nand arrival (AoAs) $(\\theta_{\\text{R},n}, \\varphi_{\\text{R},n})$\nare computed. See the [Primer on Electromagnetics](../em_primer.html) for more details.\n\nA synthetic array is simulated by adding additional phase shifts that depend on the\nantenna position relative to the position of the transmitter (receiver) as well as the AoDs (AoAs).\nFor the $k^\\text{th}$ transmit antenna and $\\ell^\\text{th}$ receive antenna, let\nus denote by $\\mathbf{d}_{\\text{T},k}$ and $\\mathbf{d}_{\\text{R},\\ell}$ the relative positions (with respect to\nthe positions of the transmitter/receiver) of the pair of antennas\nfor which the channel impulse response shall be computed. These can be accessed through the antenna arrays property\n[`positions`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.AntennaArray.positions). Using a plane-wave assumption, the resulting phase shifts\nfrom these displacements can be computed as\n\n$$\n\\begin{split}p_{\\text{T}, n,k} &= \\frac{2\\pi}{\\lambda}\\hat{\\mathbf{r}}(\\theta_{\\text{T},n}, \\varphi_{\\text{T},n})^\\mathsf{T} \\mathbf{d}_{\\text{T},k}\\\\\np_{\\text{R}, n,\\ell} &= \\frac{2\\pi}{\\lambda}\\hat{\\mathbf{r}}(\\theta_{\\text{R},n}, \\varphi_{\\text{R},n})^\\mathsf{T} \\mathbf{d}_{\\text{R},\\ell}.\\end{split}\n$$\n\nThe final expression for the path coefficient is\n\n$$\nh_{n,k,\\ell} =  a_n e^{j(p_{\\text{T}, i,k} + p_{\\text{R}, i,\\ell})}\n$$\n\nfor every transmit antenna $k$ and receive antenna $\\ell$.\nThese coefficients form the complex-valued channel matrix, $\\mathbf{H}_n$,\nof size $\\texttt{num_rx_ant} \\times \\texttt{num_tx_ant}$.\n\nFinally, the coefficient of the equivalent SISO channel is\n\n$$\nh_n =  \\mathbf{c}^{\\mathsf{H}} \\mathbf{H}_n \\mathbf{p}\n$$\n\nwhere $\\mathbf{c}$ and $\\mathbf{p}$ are the combining and\nprecoding vectors (`combining_vec` and `precoding_vec`),\nrespectively.\n xample"
"```python\nimport sionna\nfrom sionna.rt import load_scene, PlanarArray, Transmitter, Receiver\nscene = load_scene(sionna.rt.scene.munich)\n# Configure antenna array for all transmitters\nscene.tx_array = PlanarArray(num_rows=8,\n                        num_cols=2,\n                        vertical_spacing=0.7,\n                        horizontal_spacing=0.5,\n                        pattern=\"tr38901\",\n                        polarization=\"VH\")\n# Configure antenna array for all receivers\nscene.rx_array = PlanarArray(num_rows=1,\n                        num_cols=1,\n                        vertical_spacing=0.5,\n                        horizontal_spacing=0.5,\n                        pattern=\"dipole\",\n                        polarization=\"cross\")\n# Add a transmitters\ntx = Transmitter(name=\"tx\",\n            position=[8.5,21,30],\n            orientation=[0,0,0])\nscene.add(tx)\ntx.look_at([40,80,1.5])\n# Compute coverage map\ncm = scene.coverage_map(cm_cell_size=[1.,1.],\n                    num_samples=int(10e6))\n# Visualize coverage in preview\nscene.preview(coverage_map=cm,\n            resolution=[1000, 600])\n```\n\n\nInput\n\n- **rx_orientation** (*[3], float*)  Orientation of the receiver $(\\alpha, \\beta, \\gamma)$\nspecified through three angles corresponding to a 3D rotation\nas defined in [(3)](../em_primer.html#equation-rotation). Defaults to $(0,0,0)$.\n- **max_depth** (*int*)  Maximum depth (i.e., number of bounces) allowed for tracing the\npaths. Defaults to 3.\n- **cm_center** ([3], float | <cite>None</cite>)  Center of the coverage map $(x,y,z)$ as three-dimensional\nvector. If set to <cite>None</cite>, the coverage map is centered on the\ncenter of the scene, except for the elevation $z$ that is set\nto 1.5m. Otherwise, `cm_orientation` and `cm_scale` must also\nnot be <cite>None</cite>. Defaults to <cite>None</cite>.\n- **cm_orientation** ([3], float | <cite>None</cite>)  Orientation of the coverage map $(\\alpha, \\beta, \\gamma)$\nspecified through three angles corresponding to a 3D rotation\nas defined in [(3)](../em_primer.html#equation-rotation).\nAn orientation of $(0,0,0)$ or <cite>None</cite> corresponds to a\ncoverage map that is parallel to the XY plane.\nIf not set to <cite>None</cite>, then `cm_center` and `cm_scale` must also\nnot be <cite>None</cite>.\nDefaults to <cite>None</cite>.\n- **cm_size** ([2], float | <cite>None</cite>)  Size of the coverage map [m].\nIf set to <cite>None</cite>, then the size of the coverage map is set such that\nit covers the entire scene.\nOtherwise, `cm_center` and `cm_orientation` must also not be\n<cite>None</cite>. Defaults to <cite>None</cite>.\n- **cm_cell_size** (*[2], float*)  Size of a cell of the coverage map [m].\nDefaults to $(10,10)$.\n- **combining_vec** (*[num_rx_ant], complex | None*)  Combining vector.\nIf set to <cite>None</cite>, then no combining is applied, and\nthe energy received by all antennas is summed.\n- **precoding_vec** (*[num_tx_ant], complex | None*)  Precoding vector.\nIf set to <cite>None</cite>, then defaults to\n$\\frac{1}{\\sqrt{\\text{num_tx_ant}}} [1,\\dots,1]^{\\mathsf{T}}$.\n- **num_samples** (*int*)  Number of random rays to trace.\nFor the reflected paths, this number is split equally over the different transmitters.\nFor the diffracted paths, it is split over the wedges in line-of-sight with the\ntransmitters such that the number of rays allocated\nto a wedge is proportional to its length.\nDefaults to 2e6.\n- **los** (*bool*)  If set to <cite>True</cite>, then the LoS paths are computed.\nDefaults to <cite>True</cite>.\n- **reflection** (*bool*)  If set to <cite>True</cite>, then the reflected paths are computed.\nDefaults to <cite>True</cite>.\n- **diffraction** (*bool*)  If set to <cite>True</cite>, then the diffracted paths are computed.\nDefaults to <cite>False</cite>.\n- **scattering** (*bool*)  If set to <cite>True</cite>, then the scattered paths are computed.\nDefaults to <cite>False</cite>.\n- **edge_diffraction** (*bool*)  If set to <cite>False</cite>, only diffraction on wedges, i.e., edges that\nconnect two primitives, is considered.\nDefaults to <cite>False</cite>.\n- **check_scene** (*bool*)  If set to <cite>True</cite>, checks that the scene is well configured before\ncomputing the coverage map. This can add a significant overhead.\nDefaults to <cite>True</cite>.\n\n\nOutput\n\ncm : [`CoverageMap`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.CoverageMap)  The coverage maps"
"### load_scene\n\n`sionna.rt.``load_scene`(*`filename``=``None`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/scene.html#load_scene)\n\nLoad a scene from file\n\nNote that only one scene can be loaded at a time.\nInput\n\n- **filename** (*str*)  Name of a valid scene file. Sionna uses the simple XML-based format\nfrom [Mitsuba 3](https://mitsuba.readthedocs.io/en/stable/src/key_topics/scene_format.html).\nDefaults to <cite>None</cite> for which an empty scene is created.\n- **dtype** (*tf.complex*)  Dtype used for all internal computations and outputs.\nDefaults to <cite>tf.complex64</cite>.\n\n\nOutput\n\n**scene** ([`Scene`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene))  Reference to the current scene"
"### preview\n\n`sionna.rt.Scene.``preview`(*`paths``=``None`*, *`show_paths``=``True`*, *`show_devices``=``True`*, *`coverage_map``=``None`*, *`cm_tx``=``0`*, *`cm_vmin``=``None`*, *`cm_vmax``=``None`*, *`resolution``=``(655,` `500)`*, *`fov``=``45`*, *`background``=``'#ffffff'`*, *`clip_at``=``None`*, *`clip_plane_orientation``=``(0,` `0,` `-` `1)`*)\n\nIn an interactive notebook environment, opens an interactive 3D\nviewer of the scene.\n\nThe returned value of this method must be the last line of\nthe cell so that it is displayed. For example:\n```python\nfig = scene.preview()\n# ...\nfig\n```\n\n\nOr simply:\n```python\nscene.preview()\n```\n\n\nColor coding:\n\n- Green: Receiver\n- Blue: Transmitter\n\n\nControls:\n\n- Mouse left: Rotate\n- Scroll wheel: Zoom\n- Mouse right: Move\n\nInput\n\n- **paths** ([`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths) | <cite>None</cite>)  Simulated paths generated by\n[`compute_paths()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_paths) or <cite>None</cite>.\nIf <cite>None</cite>, only the scene is rendered.\nDefaults to <cite>None</cite>.\n- **show_paths** (*bool*)  If <cite>paths</cite> is not <cite>None</cite>, shows the paths.\nDefaults to <cite>True</cite>.\n- **show_devices** (*bool*)  If set to <cite>True</cite>, shows the radio devices.\nDefaults to <cite>True</cite>.\n- **show_orientations** (*bool*)  If <cite>show_devices</cite> is <cite>True</cite>, shows the radio devices orientations.\nDefaults to <cite>False</cite>.\n- **coverage_map** ([`CoverageMap`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.CoverageMap) | <cite>None</cite>)  An optional coverage map to overlay in the scene for visualization.\nDefaults to <cite>None</cite>.\n- **cm_tx** (*int | str*)  When <cite>coverage_map</cite> is specified, controls which of the transmitters\nto display the coverage map for. Either the transmitters name\nor index can be given.\nDefaults to <cite>0</cite>.\n- **cm_db_scale** (*bool*)  Use logarithmic scale for coverage map visualization, i.e. the\ncoverage values are mapped with:\n$y = 10 \\cdot \\log_{10}(x)$.\nDefaults to <cite>True</cite>.\n- **cm_vmin, cm_vmax** (*floot | None*)  For coverage map visualization, defines the range of path gains that\nthe colormap covers.\nThese parameters should be provided in dB if `cm_db_scale` is\nset to <cite>True</cite>, or in linear scale otherwise.\nIf set to None, then covers the complete range.\nDefaults to <cite>None</cite>.\n- **resolution** (*[2], int*)  Size of the viewer figure.\nDefaults to <cite>[655, 500]</cite>.\n- **fov** (*float*)  Field of view, in degrees.\nDefaults to 45.\n- **background** (*str*)  Background color in hex format prefixed by #.\nDefaults to #ffffff (white).\n- **clip_at** (*float*)  If not <cite>None</cite>, the scene preview will be clipped (cut) by a plane\nwith normal orientation `clip_plane_orientation` and offset `clip_at`.\nThat means that everything *behind* the plane becomes invisible.\nThis allows visualizing the interior of meshes, such as buildings.\nDefaults to <cite>None</cite>.\n- **clip_plane_orientation** (*tuple[float, float, float]*)  Normal vector of the clipping plane.\nDefaults to (0,0,-1)."
"### render\n\n`sionna.rt.Scene.``render`(*`camera`*, *`paths``=``None`*, *`show_paths``=``True`*, *`show_devices``=``True`*, *`coverage_map``=``None`*, *`cm_tx``=``0`*, *`cm_vmin``=``None`*, *`cm_vmax``=``None`*, *`cm_show_color_bar``=``True`*, *`num_samples``=``512`*, *`resolution``=``(655,` `500)`*, *`fov``=``45`*)\n\nRenders the scene from the viewpoint of a camera or the interactive\nviewer\nInput\n\n- **camera** (str | [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera))  The name or instance of a [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera).\nIf an interactive viewer was opened with\n[`preview()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.preview), set to <cite>preview</cite> to use its\nviewpoint.\n- **paths** ([`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths) | <cite>None</cite>)  Simulated paths generated by\n[`compute_paths()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_paths) or <cite>None</cite>.\nIf <cite>None</cite>, only the scene is rendered.\nDefaults to <cite>None</cite>.\n- **show_paths** (*bool*)  If <cite>paths</cite> is not <cite>None</cite>, shows the paths.\nDefaults to <cite>True</cite>.\n- **show_devices** (*bool*)  If <cite>paths</cite> is not <cite>None</cite>, shows the radio devices.\nDefaults to <cite>True</cite>.\n- **coverage_map** ([`CoverageMap`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.CoverageMap) | <cite>None</cite>)  An optional coverage map to overlay in the scene for visualization.\nDefaults to <cite>None</cite>.\n- **cm_tx** (*int | str*)  When <cite>coverage_map</cite> is specified, controls which of the transmitters\nto display the coverage map for. Either the transmitters name\nor index can be given.\nDefaults to <cite>0</cite>.\n- **cm_db_scale** (*bool*)  Use logarithmic scale for coverage map visualization, i.e. the\ncoverage values are mapped with:\n$y = 10 \\cdot \\log_{10}(x)$.\nDefaults to <cite>True</cite>.\n- **cm_vmin, cm_vmax** (*float | None*)  For coverage map visualization, defines the range of path gains that\nthe colormap covers.\nThese parameters should be provided in dB if `cm_db_scale` is\nset to <cite>True</cite>, or in linear scale otherwise.\nIf set to None, then covers the complete range.\nDefaults to <cite>None</cite>.\n- **cm_show_color_bar** (*bool*)  For coverage map visualization, show the color bar describing the\ncolor mapping used next to the rendering.\nDefaults to <cite>True</cite>.\n- **num_samples** (*int*)  Number of rays thrown per pixel.\nDefaults to 512.\n- **resolution** (*[2], int*)  Size of the rendered figure.\nDefaults to <cite>[655, 500]</cite>.\n- **fov** (*float*)  Field of view, in degrees.\nDefaults to 45.\n\n\nOutput\n\n`Figure`  Rendered image"
"### render_to_file\n\n`sionna.rt.Scene.``render_to_file`(*`camera`*, *`filename`*, *`paths``=``None`*, *`show_paths``=``True`*, *`show_devices``=``True`*, *`coverage_map``=``None`*, *`cm_tx``=``0`*, *`cm_db_scale``=``True`*, *`cm_vmin``=``None`*, *`cm_vmax``=``None`*, *`num_samples``=``512`*, *`resolution``=``(655,` `500)`*, *`fov``=``45`*)\n\nRenders the scene from the viewpoint of a camera or the interactive\nviewer, and saves the resulting image\nInput\n\n- **camera** (str | [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera))  The name or instance of a [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera).\nIf an interactive viewer was opened with\n[`preview()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.preview), set to <cite>preview</cite> to use its\nviewpoint.\n- **filename** (*str*)  Filename for saving the rendered image, e.g., my_scene.png\n- **paths** ([`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths) | <cite>None</cite>)  Simulated paths generated by\n[`compute_paths()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_paths) or <cite>None</cite>.\nIf <cite>None</cite>, only the scene is rendered.\nDefaults to <cite>None</cite>.\n- **show_paths** (*bool*)  If <cite>paths</cite> is not <cite>None</cite>, shows the paths.\nDefaults to <cite>True</cite>.\n- **show_devices** (*bool*)  If <cite>paths</cite> is not <cite>None</cite>, shows the radio devices.\nDefaults to <cite>True</cite>.\n- **coverage_map** ([`CoverageMap`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.CoverageMap) | <cite>None</cite>)  An optional coverage map to overlay in the scene for visualization.\nDefaults to <cite>None</cite>.\n- **cm_tx** (*int | str*)  When <cite>coverage_map</cite> is specified, controls which of the transmitters\nto display the coverage map for. Either the transmitters name\nor index can be given.\nDefaults to <cite>0</cite>.\n- **cm_db_scale** (*bool*)  Use logarithmic scale for coverage map visualization, i.e. the\ncoverage values are mapped with:\n$y = 10 \\cdot \\log_{10}(x)$.\nDefaults to <cite>True</cite>.\n- **cm_vmin, cm_vmax** (*float | None*)  For coverage map visualization, defines the range of path gains that\nthe colormap covers.\nThese parameters should be provided in dB if `cm_db_scale` is\nset to <cite>True</cite>, or in linear scale otherwise.\nIf set to None, then covers the complete range.\nDefaults to <cite>None</cite>.\n- **num_samples** (*int*)  Number of rays thrown per pixel.\nDefaults to 512.\n- **resolution** (*[2], int*)  Size of the rendered figure.\nDefaults to <cite>[655, 500]</cite>.\n- **fov** (*float*)  Field of view, in degrees.\nDefaults to 45."
"## Example Scenes\n\nSionna has several integrated scenes that are listed below.\nThey can be loaded and used as follows:\n```python\nscene = load_scene(sionna.rt.scene.etoile)\nscene.preview()\n```"
"### floor_wall\n\n`sionna.rt.scene.``floor_wall`\n\nExample scene containing a ground plane and a vertical wall\n\n\n([Blender file](https://drive.google.com/file/d/1djXBj3VYLT4_bQpmp4vR6o6agGmv_p1F/view?usp=share_link))"
"### simple_street_canyon\n\n`sionna.rt.scene.``simple_street_canyon`\n\nExample scene containing a few rectangular building blocks and a ground plane\n\n\n([Blender file](https://drive.google.com/file/d/1_1nsLtSC8cy1QfRHAN_JetT3rPP21tNb/view?usp=share_link))"
"### etoile\n\n`sionna.rt.scene.``etoile`\n\nExample scene containing the area around the Arc de Triomphe in Paris\nThe scene was created with data downloaded from [OpenStreetMap](https://www.openstreetmap.org) and\nthe help of [Blender](https://www.blender.org) and the [Blender-OSM](https://github.com/vvoovv/blender-osm)\nand [Mitsuba Blender](https://github.com/mitsuba-renderer/mitsuba-blender) add-ons.\nThe data is licensed under the [Open Data Commons Open Database License (ODbL)](https://openstreetmap.org/copyright).\n\n\n([Blender file](https://drive.google.com/file/d/1bamQ67lLGZHTfNmcVajQDmq2oiSY8FEn/view?usp=share_link))"
"### munich\n\n`sionna.rt.scene.``munich`\n\nExample scene containing the area around the Frauenkirche in Munich\nThe scene was created with data downloaded from [OpenStreetMap](https://www.openstreetmap.org) and\nthe help of [Blender](https://www.blender.org) and the [Blender-OSM](https://github.com/vvoovv/blender-osm)\nand [Mitsuba Blender](https://github.com/mitsuba-renderer/mitsuba-blender) add-ons.\nThe data is licensed under the [Open Data Commons Open Database License (ODbL)](https://openstreetmap.org/copyright).\n\n\n([Blender file](https://drive.google.com/file/d/15WrvMGrPWsoVKYvDG6Ab7btq-ktTCGR1/view?usp=share_link))"
"### simple_wedge\n\n`sionna.rt.scene.``simple_wedge`\n\nExample scene containing a wedge with a $90^{\\circ}$ opening angle\n\n\n([Blender file](https://drive.google.com/file/d/1RnJoYzXKkILMEmf-UVSsyjq-EowU6JRA/view?usp=share_link))"
"### simple_reflector\n\n`sionna.rt.scene.``simple_reflector`\n\nExample scene containing a metallic square\n\n\n([Blender file](https://drive.google.com/file/d/1iYPD11zAAMj0gNUKv_nv6QdLhOJcPpIa/view?usp=share_link))"
"### double_reflector\n\n`sionna.rt.scene.``double_reflector`\n\nExample scene containing two metallic squares\n\n\n([Blender file](https://drive.google.com/file/d/1K2ZUYHPPkrq9iUauJtInRu7x2r16D1zN/view?usp=share_link))"
"### triple_reflector\n\n`sionna.rt.scene.``triple_reflector`\n\nExample scene containing three metallic rectangles\n\n\n([Blender file](https://drive.google.com/file/d/1l95_0U2b3cEVtz3G8mQxuLxy8xiPsVID/view?usp=share_link))"
"### Box\n\n`sionna.rt.scene.``box`\n\nExample scene containing a metallic box\n\n\n([Blender file](https://drive.google.com/file/d/1pywetyKr0HBz3aSYpkmykGnjs_1JMsHY/view?usp=share_link))"
"## Paths\n\nA propagation path $i$ starts at a transmit antenna and ends at a receive antenna. It is described by\nits channel coefficient $a_i$ and delay $\\tau_i$, as well as the\nangles of departure $(\\theta_{\\text{T},i}, \\varphi_{\\text{T},i})$\nand arrival $(\\theta_{\\text{R},i}, \\varphi_{\\text{R},i})$.\nFor more detail, see the [Primer on Electromagnetics](../em_primer.html).\n\nIn Sionna, paths are computed with the help of the function [`compute_paths()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_paths) which returns an instance of\n[`Paths`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths). Paths can be visualized by providing them as arguments to the functions [`render()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.render),\n[`render_to_file()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.render_to_file), or [`preview()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.preview).\n\nChannel impulse responses (CIRs) can be obtained with [`cir()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths.cir) which can\nthen be used for link-level simulations. This is for example done in the [Sionna Ray Tracing Tutorial](../examples/Sionna_Ray_Tracing_Introduction.html)."
"### Paths\n\n`class` `sionna.rt.``Paths`[`[source]`](../_modules/sionna/rt/paths.html#Paths)\n\nStores the simulated propagation paths\n\nPaths are generated for the loaded scene using\n[`compute_paths()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_paths). Please refer to the\ndocumentation of this function for further details.\nThese paths can then be used to compute channel impulse responses:\n```python\npaths = scene.compute_paths()\na, tau = paths.cir()\n```\n\n\nwhere `scene` is the [`Scene`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene) loaded using\n[`load_scene()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.load_scene).\n\n`property` `a`\n\nPassband channel coefficients $a_i$ of each path as defined in [(26)](../em_primer.html#equation-h-final).\nType\n\n[batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths, num_time_steps], tf.complex\n\n\n`apply_doppler`(*`sampling_frequency`*, *`num_time_steps`*, *`tx_velocities``=``(0.0,` `0.0,` `0.0)`*, *`rx_velocities``=``(0.0,` `0.0,` `0.0)`*)[`[source]`](../_modules/sionna/rt/paths.html#Paths.apply_doppler)\n\nApply Doppler shifts corresponding to input transmitters and receivers\nvelocities.\n\nThis function replaces the last dimension of the tensor storing the\npaths coefficients [`a`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths.a), which stores the the temporal evolution of\nthe channel, with a dimension of size `num_time_steps` computed\naccording to the input velocities.\n\nTime evolution of the channel coefficients is simulated by computing the\nDoppler shift due to movements of the transmitter and receiver. If we denote by\n$\\mathbf{v}_{\\text{T}}\\in\\mathbb{R}^3$ and $\\mathbf{v}_{\\text{R}}\\in\\mathbb{R}^3$\nthe velocity vectors of the transmitter and receiver, respectively, the Doppler shifts are computed as\n\n$$\n\\begin{split}f_{\\text{T}, i} &= \\frac{\\hat{\\mathbf{r}}(\\theta_{\\text{T},i}, \\varphi_{\\text{T},i})^\\mathsf{T}\\mathbf{v}_{\\text{T}}}{\\lambda}\\qquad \\text{[Hz]}\\\\\nf_{\\text{R}, i} &= \\frac{\\hat{\\mathbf{r}}(\\theta_{\\text{R},i}, \\varphi_{\\text{R},i})^\\mathsf{T}\\mathbf{v}_{\\text{R}}}{\\lambda}\\qquad \\text{[Hz]}\\end{split}\n$$\n\nfor an arbitrary path $i$, where $(\\theta_{\\text{T},i}, \\varphi_{\\text{T},i})$ are the AoDs,\n$(\\theta_{\\text{R},i}, \\varphi_{\\text{R},i})$ are the AoAs, and $\\lambda$ is the wavelength.\nThis leads to the time-dependent path coefficient\n\n$$\na_i(t) = a_i e^{j2\\pi(f_{\\text{T}, i}+f_{\\text{R}, i})t}.\n$$\n\nNote that this model is only valid as long as the AoDs, AoAs, and path delay do not change.\n\nWhen this function is called multiple times, it overwrites the previous\ntime steps dimension.\nInput\n\n- **sampling_frequency** (*float*)  Frequency [Hz] at which the channel impulse response is sampled\n- **num_time_steps** (*int*)  Number of time steps.\n- **tx_velocities** ([batch_size, num_tx, 3] or broadcastable, tf.float | <cite>None</cite>)  Velocity vectors $(v_\\text{x}, v_\\text{y}, v_\\text{z})$ of all\ntransmitters [m/s].\nDefaults to <cite>[0,0,0]</cite>.\n- **rx_velocities** ([batch_size, num_tx, 3] or broadcastable, tf.float | <cite>None</cite>)  Velocity vectors $(v_\\text{x}, v_\\text{y}, v_\\text{z})$ of all\nreceivers [m/s].\nDefaults to <cite>[0,0,0]</cite>.\n\n\n`cir`(*`los``=``True`*, *`reflection``=``True`*, *`diffraction``=``True`*, *`scattering``=``True`*, *`num_paths``=``None`*)[`[source]`](../_modules/sionna/rt/paths.html#Paths.cir)\n\nReturns the baseband equivalent channel impulse response [(28)](../em_primer.html#equation-h-b)\nwhich can be used for link simulations by other Sionna components.\n\nThe baseband equivalent channel coefficients $a^{\\text{b}}_{i}$\nare computed as :\n\n$$\na^{\\text{b}}_{i} = a_{i} e^{-j2 \\pi f \\tau_{i}}\n$$\n\nwhere $i$ is the index of an arbitrary path, $a_{i}$\nis the passband path coefficient ([`a`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths.a)),\n$\\tau_{i}$ is the path delay ([`tau`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths.tau)),\nand $f$ is the carrier frequency.\n\nNote: For the paths of a given type to be returned (LoS, reflection, etc.), they\nmust have been previously computed by [`compute_paths()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.compute_paths), i.e.,\nthe corresponding flags must have been set to <cite>True</cite>.\nInput\n\n- **los** (*bool*)  If set to <cite>False</cite>, LoS paths are not returned.\nDefaults to <cite>True</cite>.\n- **reflection** (*bool*)  If set to <cite>False</cite>, specular paths are not returned.\nDefaults to <cite>True</cite>.\n- **diffraction** (*bool*)  If set to <cite>False</cite>, diffracted paths are not returned.\nDefaults to <cite>True</cite>.\n- **scattering** (*bool*)  If set to <cite>False</cite>, scattered paths are not returned.\nDefaults to <cite>True</cite>.\n- **num_paths** (int or <cite>None</cite>)  All CIRs are either zero-padded or cropped to the largest\n`num_paths` paths.\nDefaults to <cite>None</cite> which means that no padding or cropping is done.\n\n\nOutput\n\n- **a** (*[batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths, num_time_steps], tf.complex*)  Path coefficients\n- **tau** (*[batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths] or [batch_size, num_rx, num_tx, max_num_paths], tf.float*)  Path delays\n\n\n`export`(*`filename`*)[`[source]`](../_modules/sionna/rt/paths.html#Paths.export)\n\nSaves the paths as an OBJ file for visualisation, e.g., in Blender\nInput\n\n**filename** (*str*)  Path and name of the file\n\n\n`from_dict`(*`data_dict`*)[`[source]`](../_modules/sionna/rt/paths.html#Paths.from_dict)\n\nSet the paths from a dictionnary which values are tensors\n\nThe format of the dictionnary is expected to be the same as the one\nreturned by [`to_dict()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths.to_dict).\nInput\n\n**data_dict** (<cite>dict</cite>)\n\n\n`property` `mask`\n\nSet to <cite>False</cite> for non-existent paths.\nWhen there are multiple transmitters or receivers, path counts may vary between links. This is used to identify non-existent paths.\nFor such paths, the channel coefficient is set to <cite>0</cite> and the delay to <cite>-1</cite>.\nType\n\n[batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths] or [batch_size, num_rx, num_tx, max_num_paths], tf.bool\n\n\n`property` `normalize_delays`\n\nSet to <cite>True</cite> to normalize path delays such that the first path\nbetween any pair of antennas of a transmitter and receiver arrives at\n`tau` `=` `0`. Defaults to <cite>True</cite>.\nType\n\nbool\n\n\n`property` `phi_r`\n\nAzimuth angles of arrival [rad]\nType\n\n[batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths] or [batch_size, num_rx, num_tx, max_num_paths], tf.float\n\n\n`property` `phi_t`\n\nAzimuth angles of departure [rad]\nType\n\n[batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths] or [batch_size, num_rx, num_tx, max_num_paths], tf.float\n\n\n`property` `reverse_direction`\n\nIf set to <cite>True</cite>, swaps receivers and transmitters\nType\n\nbool\n\n\n`property` `tau`\n\nPropagation delay $\\tau_i$ [s] of each path as defined in [(26)](../em_primer.html#equation-h-final).\nType\n\n[batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths] or [batch_size, num_rx, num_tx, max_num_paths], tf.float\n\n\n`property` `theta_r`\n\nZenith angles of arrival [rad]\nType\n\n[batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths] or [batch_size, num_rx, num_tx, max_num_paths], tf.float\n\n\n`property` `theta_t`\n\nZenith  angles of departure [rad]\nType\n\n[batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths] or [batch_size, num_rx, num_tx, max_num_paths], tf.float\n\n\n`to_dict`()[`[source]`](../_modules/sionna/rt/paths.html#Paths.to_dict)\n\nReturns the properties of the paths as a dictionnary which values are\ntensors\nOutput\n\n<cite>dict</cite>\n\n\n`property` `types`\n\nType of the paths:\n\n- 0 : LoS\n- 1 : Reflected\n- 2 : Diffracted\n- 3 : Scattered\n\nType\n\n[batch_size, max_num_paths], tf.int"
"## Coverage Maps\n\nA coverage map describes the received power from a specific transmitter at every point on a plane.\nIn other words, for a given transmitter, it associates every point on a surface  with the power that a receiver with\na specific orientation would observe at this point. A coverage map is not uniquely defined as it depends on\nthe transmit and receive arrays and their respective antenna patterns, the transmitter and receiver orientations, as well as\ntransmit precoding and receive combining vectors. Moreover, a coverage map is not continuous but discrete because the plane\nneeds to be quantized into small rectangular bins.\n\nIn Sionna, coverage maps are computed with the help of the function [`coverage_map()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.coverage_map) which returns an instance of\n[`CoverageMap`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.CoverageMap). They can be visualized by providing them either as arguments to the functions [`render()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.render),\n[`render_to_file()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.render_to_file), and [`preview()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.preview), or by using the class method [`show()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.CoverageMap.show).\n\nA very useful feature is [`sample_positions()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.CoverageMap.sample_positions) which allows sampling\nof random positions within the scene that have sufficient coverage from a specific transmitter.\nThis feature is used in the [Sionna Ray Tracing Tutorial](../examples/Sionna_Ray_Tracing_Introduction.html) to generate a dataset of channel impulse responses\nfor link-level simulations."
"### CoverageMap\n\n`class` `sionna.rt.``CoverageMap`[`[source]`](../_modules/sionna/rt/coverage_map.html#CoverageMap)\n\nStores the simulated coverage maps\n\nA coverage map is generated for the loaded scene for every transmitter using\n[`coverage_map()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.coverage_map). Please refer to the documentation of this function\nfor further details.\n\nAn instance of this class can be indexed like a tensor of rank three with\nshape `[num_tx,` `num_cells_y,` `num_cells_x]`, i.e.:\n```python\ncm = scene.coverage_map()\nprint(cm[0])      # prints the coverage map for transmitter 0\nprint(cm[0,1,2])  # prints the value of the cell (1,2) for transmitter 0\n```\n\n\nwhere `scene` is the [`Scene`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene) loaded using\n[`load_scene()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.load_scene).\n xample\n```python\nimport sionna\nfrom sionna.rt import load_scene, PlanarArray, Transmitter, Receiver\nscene = load_scene(sionna.rt.scene.munich)\n# Configure antenna array for all transmitters\nscene.tx_array = PlanarArray(num_rows=8,\n                          num_cols=2,\n                          vertical_spacing=0.7,\n                          horizontal_spacing=0.5,\n                          pattern=\"tr38901\",\n                          polarization=\"VH\")\n# Configure antenna array for all receivers\nscene.rx_array = PlanarArray(num_rows=1,\n                          num_cols=1,\n                          vertical_spacing=0.5,\n                          horizontal_spacing=0.5,\n                          pattern=\"dipole\",\n                          polarization=\"cross\")\n# Add a transmitters\ntx = Transmitter(name=\"tx\",\n              position=[8.5,21,30],\n              orientation=[0,0,0])\nscene.add(tx)\ntx.look_at([40,80,1.5])\n# Compute coverage map\ncm = scene.coverage_map(max_depth=8)\n# Show coverage map\ncm.show()\n```\n\n\n`as_tensor`()[`[source]`](../_modules/sionna/rt/coverage_map.html#CoverageMap.as_tensor)\n\nReturns the coverage map as a tensor\nOutput\n\n*[num_tx, num_cells_y, num_cells_x], tf.float*  The coverage map as a tensor\n\n\n`property` `cell_centers`\n\nGet the positions of the\ncenters of the cells in the global coordinate system\nType\n\n[num_cells_y, num_cells_x, 3], tf.float\n\n\n`property` `cell_size`\n\nGet the resolution of the coverage map, i.e., width\n(in the local X direction) and height (in the local Y direction) in\nof the cells of the coverage map\nType\n\n[2], tf.float\n\n\n`property` `center`\n\nGet the center of the coverage map\nType\n\n[3], tf.float\n\n\n`property` `num_cells_x`\n\nGet the number of cells along the local X-axis\nType\n\nint\n\n\n`property` `num_cells_y`\n\nGet the number of cells along the local Y-axis\nType\n\nint\n\n\n`property` `num_tx`\n\nGet the number of transmitters\nType\n\nint\n\n\n`property` `orientation`\n\nGet the orientation of the coverage map\nType\n\n[3], tf.float\n\n\n`sample_positions`(*`batch_size`*, *`tx``=``0`*, *`min_gain_db``=``None`*, *`max_gain_db``=``None`*, *`min_dist``=``None`*, *`max_dist``=``None`*, *`center_pos``=``False`*)[`[source]`](../_modules/sionna/rt/coverage_map.html#CoverageMap.sample_positions)\n\nSample random user positions from a coverage map\n\nFor a given coverage map, `batch_size` random positions are sampled\nsuch that the *expected*  path gain of this position is larger\nthan a given threshold `min_gain_db` or smaller than `max_gain_db`,\nrespectively.\nSimilarly, `min_dist` and `max_dist` define the minimum and maximum\ndistance of the random positions to the transmitter `tx`.\n\nNote that due to the quantization of the coverage map into cells it is\nnot guaranteed that all above parameters are exactly fulfilled for a\nreturned position. This stems from the fact that every\nindividual cell of the coverage map describes the expected *average*\nbehavior of the surface within this cell. For instance, it may happen\nthat half of the selected cell is shadowed and, thus, no path to the\ntransmitter exists but the average path gain is still larger than the\ngiven threshold. Please use `center_pos` = <cite>True</cite> to sample only\npositions from the cell centers.\n\nThe above figure shows an example for random positions between 220m and\n250m from the transmitter and a `max_gain_db` of -100 dB.\nKeep in mind that the transmitter can have a different height than the\ncoverage map which also contributes to this distance.\nFor example if the transmitter is located 20m above the surface of the\ncoverage map and a `min_dist` of 20m is selected, also positions\ndirectly below the transmitter are sampled.\nInput\n\n- **batch_size** (*int*)  Number of returned random positions\n- **min_gain_db** (*float | None*)  Minimum path gain [dB]. Positions are only sampled from cells where\nthe path gain is larger or equal to this value.\nIgnored if <cite>None</cite>.\nDefaults to <cite>None</cite>.\n- **max_gain_db** (*float | None*)  Maximum path gain [dB]. Positions are only sampled from cells where\nthe path gain is smaller or equal to this value.\nIgnored if <cite>None</cite>.\nDefaults to <cite>None</cite>.\n- **min_dist** (*float | None*)  Minimum distance [m] from transmitter for all random positions.\nIgnored if <cite>None</cite>.\nDefaults to <cite>None</cite>.\n- **max_dist** (*float | None*)  Maximum distance [m] from transmitter for all random positions.\nIgnored if <cite>None</cite>.\nDefaults to <cite>None</cite>.\n- **tx** (*int | str*)  Index or name of the transmitter from whose coverage map\npositions are sampled\n- **center_pos** (*bool*)  If <cite>True</cite>, all returned positions are sampled from the cell center\n(i.e., the grid of the coverage map). Otherwise, the positions are\nrandomly drawn from the surface of the cell.\nDefaults to <cite>False</cite>.\n\n\nOutput\n\n*[batch_size, 3], tf.float*  Random positions $(x,y,z)$ [m] that are in cells fulfilling the\nabove constraints w.r.t. distance and path gain\n\n\n`show`(*`tx``=``0`*, *`vmin``=``None`*, *`vmax``=``None`*, *`show_tx``=``True`*)[`[source]`](../_modules/sionna/rt/coverage_map.html#CoverageMap.show)\n\nVisualizes a coverage map\n\nThe position of the transmitter is indicated by a red + marker.\nInput\n\n- **tx** (*int | str*)  Index or name of the transmitter for which to show the coverage map\nDefaults to 0.\n- **vmin,vmax** (float | <cite>None</cite>)  Define the range of path gains that the colormap covers.\nIf set to <cite>None</cite>, then covers the complete range.\nDefaults to <cite>None</cite>.\n- **show_tx** (*bool*)  If set to <cite>True</cite>, then the position of the transmitter is shown.\nDefaults to <cite>True</cite>.\n\n\nOutput\n\n`Figure`  Figure showing the coverage map\n\n\n`property` `size`\n\nGet the size of the coverage map\nType\n\n[2], tf.float"
"## Cameras\n\nA [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) defines a position and view direction\nfor rendering the scene.\n\nThe [`cameras`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.cameras) property of the [`Scene`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene)\nlist all the cameras currently available for rendering. Cameras can be either\ndefined through the scene file or instantiated using the API.\nThe following code snippet shows how to load a scene and list the available\ncameras:\n```python\nscene = load_scene(sionna.rt.scene.munich)\nprint(scene.cameras)\nscene.render(\"scene-cam-0\") # Use the first camera of the scene for rendering\n```\n\n\nA new camera can be instantiated as follows:\n```python\ncam = Camera(\"mycam\", position=[200., 0.0, 50.])\nscene.add(cam)\ncam.look_at([0.0,0.0,0.0])\nscene.render(cam) # Render using the Camera instance\nscene.render(\"mycam\") # or using the name of the camera\n```"
"### Camera\n\n`class` `sionna.rt.``Camera`(*`name`*, *`position`*, *`orientation``=``[0.,` `0.,` `0.]`*, *`look_at``=``None`*)[`[source]`](../_modules/sionna/rt/camera.html#Camera)\n\nA camera defines a position and view direction for rendering the scene.\n\nIn its local coordinate system, a camera looks toward the positive X-axis\nwith the positive Z-axis being the upward direction.\nInput\n\n- **name** (*str*)  Name.\nCannot be <cite>preview</cite>, as it is reserved for the viewpoint of the\ninteractive viewer.\n- **position** (*[3], float*)  Position $(x,y,z)$ [m] as three-dimensional vector\n- **orientation** (*[3], float*)  Orientation $(\\alpha, \\beta, \\gamma)$ specified\nthrough three angles corresponding to a 3D rotation\nas defined in [(3)](../em_primer.html#equation-rotation).\nThis parameter is ignored if `look_at` is not <cite>None</cite>.\nDefaults to <cite>[0,0,0]</cite>.\n- **look_at** ([3], float | [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter) | [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver) | [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) | None)  A position or instance of [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter),\n[`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver), or [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) to look at.\nIf set to <cite>None</cite>, then `orientation` is used to orientate the camera.\n\n\n`look_at`(*`target`*)[`[source]`](../_modules/sionna/rt/camera.html#Camera.look_at)\n\nSets the orientation so that the camera looks at a position, radio\ndevice, or another camera.\n\nGiven a point $\\mathbf{x}\\in\\mathbb{R}^3$ with spherical angles\n$\\theta$ and $\\varphi$, the orientation of the camera\nwill be set equal to $(\\varphi, \\frac{\\pi}{2}-\\theta, 0.0)$.\nInput\n\n**target** ([3], float | [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter) | [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver) | [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) | str)  A position or the name or instance of a\n[`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter), [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver), or\n[`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) in the scene to look at.\n\n\n`property` `orientation`\n\nGet/set the orientation $(\\alpha, \\beta, \\gamma)$\nspecified through three angles corresponding to a 3D rotation\nas defined in [(3)](../em_primer.html#equation-rotation).\nType\n\n[3], float\n\n\n`property` `position`\n\nGet/set the position $(x,y,z)$ as three-dimensional\nvector\nType\n\n[3], float"
"## Scene Objects\n\nA scene is made of scene objects. Examples include cars, trees,\nbuildings, furniture, etc.\nA scene object is characterized by its geometry and material ([`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial))\nand implemented as an instance of the [`SceneObject`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.SceneObject) class.\n\nScene objects are uniquely identified by their name.\nTo access a scene object, the [`get()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.get) method of\n[`Scene`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene) may be used.\nFor example, the following code snippet shows how to load a scene and list its scene objects:\n```python\nscene = load_scene(sionna.rt.scene.munich)\nprint(scene.objects)\n```\n\n\nTo select an object, e.g., named <cite>Schrannenhalle-itu_metal</cite>, you can run:\n```python\nmy_object = scene.get(\"Schrannenhalle-itu_metal\")\n```\n\n\nYou can then set the [`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial)\nof `my_object` as follows:\n```python\nmy_object.radio_material = \"itu_wood\"\n```\n\n\nMost scene objects names have postfixes of the form -material_name. These are used during loading of a scene\nto assign a [`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial) to each of them. This [tutorial video](https://youtu.be/7xHLDxUaQ7c)\nexplains how you can assign radio materials to objects when you create your own scenes."
"### SceneObject\n\n`class` `sionna.rt.``SceneObject`[`[source]`](../_modules/sionna/rt/scene_object.html#SceneObject)\n\nEvery object in the scene is implemented by an instance of this class\n\n`property` `name`\n\nName\nType\n\nstr (read-only)\n\n\n`property` `radio_material`\n\nGet/set the radio material of the\nobject. Setting can be done by using either an instance of\n[`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial) or the material name (<cite>str</cite>).\nIf the radio material is not part of the scene, it will be added. This\ncan raise an error if a different radio material with the same name was\nalready added to the scene.\nType\n\n[`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial)"
"## Radio Materials\n\nA [`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial) contains everything that is needed to enable the simulation\nof the interaction of a radio wave with an object made of a particular material.\nMore precisely, it consists of the real-valued relative permittivity $\\varepsilon_r$,\nthe conductivity $\\sigma$, and the relative\npermeability $\\mu_r$. For more details, see [(7)](../em_primer.html#equation-epsilon), [(8)](../em_primer.html#equation-mu), [(9)](../em_primer.html#equation-eta).\nThese quantities can possibly depend on the frequency of the incident radio\nwave. Note that Sionna currently only allows non-magnetic materials with $\\mu_r=1$.\n\nAdditionally, a [`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial) can have an effective roughness (ER)\nassociated with it, leading to diffuse reflections (see, e.g., [[Degli-Esposti11]](../em_primer.html#degli-esposti11)).\nThe ER model requires a scattering coefficient $S\\in[0,1]$ [(37)](../em_primer.html#equation-scattering-coefficient),\na cross-polarization discrimination coefficient $K_x$ [(39)](../em_primer.html#equation-xpd), as well as a scattering pattern\n$f_\\text{s}(\\hat{\\mathbf{k}}_\\text{i}, \\hat{\\mathbf{k}}_\\text{s})$ [(40)](../em_primer.html#equation-lambertian-model)[(42)](../em_primer.html#equation-backscattering-model), such as the\n[`LambertianPattern`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.LambertianPattern) or [`DirectivePattern`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.DirectivePattern). The meaning of\nthese parameters is explained in [Scattering](../em_primer.html#scattering).\n\nSimilarly to scene objects ([`SceneObject`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.SceneObject)), all radio\nmaterials are uniquely identified by their name.\nFor example, specifying that a scene object named <cite>wall</cite> is made of the\nmaterial named <cite>itu-brick</cite> is done as follows:"
"```python\nobj = scene.get(\"wall\") # obj is a SceneObject\nobj.radio_material = \"itu_brick\" # \"wall\" is made of \"itu_brick\"\n```\n\n\nSionna provides the\n[ITU models of several materials](https://nvlabs.github.io/sionna/api/rt.html#provided-materials) whose properties\nare automatically updated according to the configured [`frequency`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.frequency).\nIt is also possible to\n[define custom radio materials](https://nvlabs.github.io/sionna/api/rt.html#custom-radio-materials).\n *Radio materials provided with Sionna**\n\nSionna provides the models of all of the materials defined in the ITU-R P.2040-2\nrecommendation [[ITUR_P2040_2]](https://nvlabs.github.io/sionna/api/rt.html#itur-p2040-2). These models are based on curve fitting to\nmeasurement results and assume non-ionized and non-magnetic materials\n($\\mu_r = 1$).\nFrequency dependence is modeled by\n\n$$\n\\begin{split}\\begin{align}\n   \\varepsilon_r &= a f_{\\text{GHz}}^b\\\\\n   \\sigma &= c f_{\\text{GHz}}^d\n\\end{align}\\end{split}\n$$\n\nwhere $f_{\\text{GHz}}$ is the frequency in GHz, and the constants\n$a$, $b$, $c$, and $d$ characterize the material.\nThe table below provides their values which are used in Sionna\n(from [[ITUR_P2040_2]](https://nvlabs.github.io/sionna/api/rt.html#itur-p2040-2)).\nNote that the relative permittivity $\\varepsilon_r$ and\nconductivity $\\sigma$ of all materials are updated automatically when\nthe frequency is set through the scenes property [`frequency`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.frequency).\nMoreover, by default, the scattering coefficient, $S$, of these materials is set to\n0, leading to no diffuse reflection.\n<table class=\"docutils align-default\">\n<colgroup>\n<col style=\"width: 25%\" />\n<col style=\"width: 17%\" />\n<col style=\"width: 15%\" />\n<col style=\"width: 14%\" />\n<col style=\"width: 9%\" />\n<col style=\"width: 21%\" />\n</colgroup>\n<tbody>\n<tr class=\"row-odd\"><td rowspan=\"2\">\nMaterial name</td>\n<td colspan=\"2\">\nReal part of relative permittivity</td>\n<td colspan=\"2\">\nConductivity [S/m]</td>\n<td rowspan=\"2\">\nFrequency range (GHz)</td>\n</tr>\n<tr class=\"row-even\"><td>\na</td>\n<td>\nb</td>\n<td>\nc</td>\n<td>\nd</td>\n</tr>\n<tr class=\"row-odd\"><td>\nvacuum</td>\n<td>\n1</td>\n<td>\n0</td>\n<td>\n0</td>\n<td>\n0</td>\n<td>\n0.001  100</td>\n</tr>\n<tr class=\"row-even\"><td>\nitu_concrete</td>\n<td>\n5.24</td>\n<td>\n0</td>\n<td>\n0.0462</td>\n<td>\n0.7822</td>\n<td>\n1  100</td>\n</tr>\n<tr class=\"row-odd\"><td>\nitu_brick</td>\n<td>\n3.91</td>\n<td>\n0</td>\n<td>\n0.0238</td>\n<td>\n0.16</td>\n<td>\n1  40</td>\n</tr>\n<tr class=\"row-even\"><td>\nitu_plasterboard</td>\n<td>\n2.73</td>\n<td>\n0</td>\n<td>\n0.0085</td>\n<td>\n0.9395</td>\n<td>\n1  100</td>\n</tr>\n<tr class=\"row-odd\"><td>\nitu_wood</td>\n<td>\n1.99</td>\n<td>\n0</td>\n<td>\n0.0047</td>\n<td>\n1.0718</td>\n<td>\n0.001  100</td>\n</tr>\n<tr class=\"row-even\"><td rowspan=\"2\">\nitu_glass</td>\n<td>\n6.31</td>\n<td>\n0</td>\n<td>\n0.0036</td>\n<td>\n1.3394</td>\n<td>\n0.1  100</td>\n</tr>\n<tr class=\"row-odd\"><td>\n5.79</td>\n<td>\n0</td>\n<td>\n0.0004</td>\n<td>\n1.658</td>\n<td>\n220  450</td>\n</tr>\n<tr class=\"row-even\"><td rowspan=\"2\">\nitu_ceiling_board</td>\n<td>\n1.48</td>\n<td>\n0</td>\n<td>\n0.0011</td>\n<td>\n1.0750</td>\n<td>\n1  100</td>\n</tr>\n<tr class=\"row-odd\"><td>\n1.52</td>\n<td>\n0</td>\n<td>\n0.0029</td>\n<td>\n1.029</td>\n<td>\n220  450</td>\n</tr>\n<tr class=\"row-even\"><td>\nitu_chipboard</td>\n<td>\n2.58</td>\n<td>\n0</td>\n<td>\n0.0217</td>\n<td>\n0.7800</td>\n<td>\n1  100</td>\n</tr>\n<tr class=\"row-odd\"><td>\nitu_plywood</td>\n<td>\n2.71</td>\n<td>\n0</td>\n<td>\n0.33</td>\n<td>\n0</td>\n<td>\n1  40</td>\n</tr>\n<tr class=\"row-even\"><td>\nitu_marble</td>\n<td>\n7.074</td>\n<td>\n0</td>\n<td>\n0.0055</td>\n<td>\n0.9262</td>\n<td>\n1  60</td>\n</tr>\n<tr class=\"row-odd\"><td>\nitu_floorboard</td>\n<td>\n3.66</td>\n<td>\n0</td>\n<td>\n0.0044</td>\n<td>\n1.3515</td>\n<td>\n50  100</td>\n</tr>\n<tr class=\"row-even\"><td>\nitu_metal</td>\n<td>\n1</td>\n<td>\n0</td>\n<td>\n$10^7$</td>\n<td>\n0</td>\n<td>\n1  100</td>\n</tr>\n<tr class=\"row-odd\"><td>\nitu_very_dry_ground</td>\n<td>\n3</td>\n<td>\n0</td>\n<td>\n0.00015</td>\n<td>\n2.52</td>\n<td>\n1  10</td>\n</tr>\n<tr class=\"row-even\"><td>\nitu_medium_dry_ground</td>\n<td>\n15</td>\n<td>\n-0.1</td>\n<td>\n0.035</td>\n<td>\n1.63</td>\n<td>\n1  10</td>\n</tr>\n<tr class=\"row-odd\"><td>\nitu_wet_ground</td>\n<td>\n30</td>\n<td>\n-0.4</td>\n<td>\n0.15</td>\n<td>\n1.30</td>\n<td>\n1  10</td>\n</tr>\n</tbody>\n</table>\n *Defining custom radio materials**\n\nCustom radio materials can be implemented using the\n[`RadioMaterial`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.RadioMaterial) class by specifying a relative permittivity\n$\\varepsilon_r$ and conductivity $\\sigma$, as well as optional\nparameters related to diffuse scattering, such as the scattering coefficient $S$,\ncross-polarization discrimination coefficient $K_x$, and scattering pattern $f_\\text{s}(\\hat{\\mathbf{k}}_\\text{i}, \\hat{\\mathbf{k}}_\\text{s})$.\nNote that only non-magnetic materials with $\\mu_r=1$ are currently allowed.\nThe following code snippet shows how to create a custom radio material."
"```python\nload_scene() # Load empty scene\ncustom_material = RadioMaterial(\"my_material\",\n                                relative_permittivity=2.0,\n                                conductivity=5.0,\n                                scattering_coefficient=0.3,\n                                xpd_coefficient=0.1,\n                                scattering_pattern=LambertianPattern())\n```\n\n\nIt is also possible to define the properties of a material through a callback\nfunction that computes the material properties\n$(\\varepsilon_r, \\sigma)$ from the frequency:\n```python\ndef my_material_callback(f_hz):\n   relative_permittivity = compute_relative_permittivity(f_hz)\n   conductivity = compute_conductivity(f_hz)\n   return (relative_permittivity, conductivity)\ncustom_material = RadioMaterial(\"my_material\",\n                                frequency_update_callback=my_material_callback)\nscene.add(custom_material)\n```\n\n\nOnce defined, the custom material can be assigned to a [`SceneObject`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.SceneObject) using its name:\n```python\nobj = scene.get(\"my_object\") # obj is a SceneObject\nobj.radio_material = \"my_material\" # \"my_object\" is made of \"my_material\"\n```\n\n\nor the material instance:\n```python\nobj = scene.get(\"my_object\") # obj is a SceneObject\nobj.radio_material = custom_material # \"my_object\" is made of \"my_material\"\n```\n\n\nThe material parameters can be assigned to TensorFlow variables or tensors, such as\nthe output of a Keras layer defining a neural network. This allows one to make materials\ntrainable:\n```python\nmat = RadioMaterial(\"my_mat\",\n                    relative_permittivity= tf.Variable(2.1, dtype=tf.float32))\nmat.conductivity = tf.Variable(0.0, dtype=tf.float32)\n```"
"### RadioMaterial\n\n`class` `sionna.rt.``RadioMaterial`(*`name`*, *`relative_permittivity``=``1.0`*, *`conductivity``=``0.0`*, *`scattering_coefficient``=``0.0`*, *`xpd_coefficient``=``0.0`*, *`scattering_pattern``=``None`*, *`frequency_update_callback``=``None`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/radio_material.html#RadioMaterial)\n\nClass implementing a radio material\n\nA radio material is defined by its relative permittivity\n$\\varepsilon_r$ and conductivity $\\sigma$ (see [(9)](../em_primer.html#equation-eta)),\nas well as optional parameters related to diffuse scattering, such as the\nscattering coefficient $S$, cross-polarization discrimination\ncoefficient $K_x$, and scattering pattern $f_\\text{s}(\\hat{\\mathbf{k}}_\\text{i}, \\hat{\\mathbf{k}}_\\text{s})$.\n\nWe assume non-ionized and non-magnetic materials, and therefore the\npermeability $\\mu$ of the material is assumed to be equal\nto the permeability of vacuum i.e., $\\mu_r=1.0$.\n\nFor frequency-dependent materials, it is possible to\nspecify a callback function `frequency_update_callback` that computes\nthe material properties $(\\varepsilon_r, \\sigma)$ from the\nfrequency. If a callback function is specified, the material properties\ncannot be set and the values specified at instantiation are ignored.\nThe callback should return <cite>-1</cite> for both the relative permittivity and\nthe conductivity if these are not defined for the given carrier frequency.\n\nThe material properties can be assigned to a TensorFlow variable or\ntensor. In the latter case, the tensor could be the output of a callable,\nsuch as a Keras layer implementing a neural network. In the former case, it\ncould be set to a trainable variable:\n```python\nmat = RadioMaterial(\"my_mat\")\nmat.conductivity = tf.Variable(0.0, dtype=tf.float32)\n```\n\nParameters\n\n- **name** (*str*)  Unique name of the material\n- **relative_permittivity** (float | <cite>None</cite>)  Relative permittivity of the material.\nMust be larger or equal to 1.\nDefaults to 1. Ignored if `frequency_update_callback`\nis provided.\n- **conductivity** (float | <cite>None</cite>)  Conductivity of the material [S/m].\nMust be non-negative.\nDefaults to 0.\nIgnored if `frequency_update_callback`\nis provided.\n- **scattering_coefficient** (*float*)  Scattering coefficient $S\\in[0,1]$ as defined in\n[(37)](../em_primer.html#equation-scattering-coefficient).\nDefaults to 0.\n- **xpd_coefficient** (*float*)  Cross-polarization discrimination coefficient $K_x\\in[0,1]$ as\ndefined in [(39)](../em_primer.html#equation-xpd).\nOnly relevant if `scattering_coefficient`>0.\nDefaults to 0.\n- **scattering_pattern** (*ScatteringPattern*)  `ScatteringPattern` to be applied.\nOnly relevant if `scattering_coefficient`>0.\nDefaults to <cite>None</cite>, which implies a [`LambertianPattern`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.LambertianPattern).\n- **frequency_update_callback** (callable | <cite>None</cite>)\nAn optional callable object used to obtain the material parameters\nfrom the scenes [`frequency`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.frequency).\nThis callable must take as input the frequency [Hz] and\nmust return the material properties as a tuple:\n\n`(relative_permittivity,` `conductivity)`.\n\nIf set to <cite>None</cite>, the material properties are constant and equal\nto `relative_permittivity` and `conductivity`.\nDefaults to <cite>None</cite>.\n\n- **dtype** (*tf.complex64** or **tf.complex128*)  Datatype.\nDefaults to <cite>tf.complex64</cite>.\n\n\n`property` `complex_relative_permittivity`\n\nComplex relative permittivity\n$\\eta$ [(9)](../em_primer.html#equation-eta)\nType\n\ntf.complex (read-only)\n\n\n`property` `conductivity`\n\nGet/set the conductivity\n$\\sigma$ [S/m] [(9)](../em_primer.html#equation-eta)\nType\n\ntf.float\n\n\n`property` `frequency_update_callback`\n\nGet/set frequency update callback function\nType\n\ncallable\n\n\n`property` `is_used`\n\nIndicator if the material is used by at least one object of\nthe scene\nType\n\nbool\n\n\n`property` `name`\n\nName of the radio material\nType\n\nstr (read-only)\n\n\n`property` `relative_permeability`\n\nRelative permeability\n$\\mu_r$ [(8)](../em_primer.html#equation-mu).\nDefaults to 1.\nType\n\ntf.float (read-only)\n\n\n`property` `relative_permittivity`\n\nGet/set the relative permittivity\n$\\varepsilon_r$ [(9)](../em_primer.html#equation-eta)\nType\n\ntf.float\n\n\n`property` `scattering_coefficient`\n\nGet/set the scattering coefficient\n$S\\in[0,1]$ [(37)](../em_primer.html#equation-scattering-coefficient).\nType\n\ntf.float\n\n\n`property` `scattering_pattern`\n\nGet/set the ScatteringPattern.\nType\n\nScatteringPattern\n\n\n`property` `use_counter`\n\nNumber of scene objects using this material\nType\n\nint\n\n\n`property` `using_objects`\n\nIdentifiers of the objects using this\nmaterial\nType\n\n[num_using_objects], tf.int\n\n\n`property` `well_defined`\n\nGet if the material is well-defined\nType\n\nbool\n\n\n`property` `xpd_coefficient`\n\nGet/set the cross-polarization discrimination coefficient\n$K_x\\in[0,1]$ [(39)](../em_primer.html#equation-xpd).\nType\n\ntf.float"
"### ScatteringPattern\n\n`class` `sionna.rt.``LambertianPattern`(*`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/scattering_pattern.html#LambertianPattern)\n\nLambertian scattering model from [[Degli-Esposti07]](../em_primer.html#degli-esposti07) as given in [(40)](../em_primer.html#equation-lambertian-model)\nParameters\n\n**dtype** (*tf.complex64** or **tf.complex128*)  Datatype used for all computations.\nDefaults to <cite>tf.complex64</cite>.\n\nInput\n\n- **k_i** (*[batch_size, 3], dtype.real_dtype*)  Incoming directions\n- **k_s** (*[batch_size,3], dtype.real_dtype*)  Outgoing directions\n\n\nOutput\n\n**pattern** (*[batch_size], dtype.real_dtype*)  Scattering pattern\n\n\n xample\n```python\n>>> LambertianPattern().visualize()\n```\n\n\n`visualize`(*`k_i``=``(0.7071,` `0.0,` `-` `0.7071)`*, *`show_directions``=``False`*)\n\nVisualizes the scattering pattern\n\nIt is assumed that the surface normal points toward the\npositive z-axis.\nInput\n\n- **k_i** (*[3], array_like*)  Incoming direction\n- **show_directions** (*bool*)  If <cite>True</cite>, the incoming and specular reflection directions\nare shown.\nDefaults to <cite>False</cite>.\n\n\nOutput\n\n- `matplotlib.pyplot.Figure`  3D visualization of the scattering pattern\n- `matplotlib.pyplot.Figure`  Visualization of the incident plane cut through\nthe scattering pattern\n\n\n`class` `sionna.rt.``DirectivePattern`(*`alpha_r`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/scattering_pattern.html#DirectivePattern)\n\nDirective scattering model from [[Degli-Esposti07]](../em_primer.html#degli-esposti07) as given in [(41)](../em_primer.html#equation-directive-model)\nParameters\n\n- **alpha_r** (*int**, **[**1**,**2**,**...**]*)  Parameter related to the width of the scattering lobe in the\ndirection of the specular reflection.\n- **dtype** (*tf.complex64** or **tf.complex128*)  Datatype used for all computations.\nDefaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n- **k_i** (*[batch_size, 3], dtype.real_dtype*)  Incoming directions\n- **k_s** (*[batch_size,3], dtype.real_dtype*)  Outgoing directions\n\n\nOutput\n\n**pattern** (*[batch_size], dtype.real_dtype*)  Scattering pattern\n\n\n xample"
"```python\n>>> DirectivePattern(alpha_r=10).visualize()\n```\n\n\n`property` `alpha_r`\n\nGet/set `alpha_r`\nType\n\nbool\n\n\n`visualize`(*`k_i``=``(0.7071,` `0.0,` `-` `0.7071)`*, *`show_directions``=``False`*)\n\nVisualizes the scattering pattern\n\nIt is assumed that the surface normal points toward the\npositive z-axis.\nInput\n\n- **k_i** (*[3], array_like*)  Incoming direction\n- **show_directions** (*bool*)  If <cite>True</cite>, the incoming and specular reflection directions\nare shown.\nDefaults to <cite>False</cite>.\n\n\nOutput\n\n- `matplotlib.pyplot.Figure`  3D visualization of the scattering pattern\n- `matplotlib.pyplot.Figure`  Visualization of the incident plane cut through\nthe scattering pattern\n\n\n`class` `sionna.rt.``BackscatteringPattern`(*`alpha_r`*, *`alpha_i`*, *`lambda_`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/scattering_pattern.html#BackscatteringPattern)\n\nBackscattering model from [[Degli-Esposti07]](../em_primer.html#degli-esposti07) as given in [(42)](../em_primer.html#equation-backscattering-model)\n\nThe parameter `lambda_` can be assigned to a TensorFlow variable\nor tensor.  In the latter case, the tensor can be the output of a callable, such as\na Keras layer implementing a neural network.\nIn the former case, it can be set to a trainable variable:\n```python\nsp = BackscatteringPattern(alpha_r=3,\n                           alpha_i=5,\n                           lambda_=tf.Variable(0.3, dtype=tf.float32))\n```\n\nParameters\n\n- **alpha_r** (*int**, **[**1**,**2**,**...**]*)  Parameter related to the width of the scattering lobe in the\ndirection of the specular reflection.\n- **alpha_i** (*int**, **[**1**,**2**,**...**]*)  Parameter related to the width of the scattering lobe in the\nincoming direction.\n- **lambda** (*float**, **[**0**,**1**]*)  Parameter determining the percentage of the diffusely\nreflected energy in the lobe around the specular reflection.\n- **dtype** (*tf.complex64** or **tf.complex128*)  Datatype used for all computations.\nDefaults to <cite>tf.complex64</cite>.\n\n\nInput\n\n- **k_i** (*[batch_size, 3], dtype.real_dtype*)  Incoming directions\n- **k_s** (*[batch_size,3], dtype.real_dtype*)  Outgoing directions\n\n\nOutput\n\n**pattern** (*[batch_size], dtype.real_dtype*)  Scattering pattern\n\n\n xample"
"```python\n>>> BackscatteringPattern(alpha_r=20, alpha_i=30, lambda_=0.7).visualize()\n```\n\n\n`property` `alpha_i`\n\nGet/set `alpha_i`\nType\n\nbool\n\n\n`property` `alpha_r`\n\nGet/set `alpha_r`\nType\n\nbool\n\n\n`property` `lambda_`\n\nGet/set `lambda_`\nType\n\nbool\n\n\n`visualize`(*`k_i``=``(0.7071,` `0.0,` `-` `0.7071)`*, *`show_directions``=``False`*)\n\nVisualizes the scattering pattern\n\nIt is assumed that the surface normal points toward the\npositive z-axis.\nInput\n\n- **k_i** (*[3], array_like*)  Incoming direction\n- **show_directions** (*bool*)  If <cite>True</cite>, the incoming and specular reflection directions\nare shown.\nDefaults to <cite>False</cite>.\n\n\nOutput\n\n- `matplotlib.pyplot.Figure`  3D visualization of the scattering pattern\n- `matplotlib.pyplot.Figure`  Visualization of the incident plane cut through\nthe scattering pattern"
"## Radio Devices\n\nA radio device refers to a [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter) or [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver) equipped\nwith an [`AntennaArray`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.AntennaArray) as specified by the [`Scene`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene)s properties\n[`tx_array`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.tx_array) and [`rx_array`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.rx_array), respectively.\n\nThe following code snippet shows how to instantiate a [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter)\nequipped with a $4 \\times 2$ [`PlanarArray`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.PlanarArray) with cross-polarized isotropic antennas:\n```python\n scene.tx_array = PlanarArray(num_rows=4,\n                              num_cols=2,\n                              vertical_spacing=0.5,\n                              horizontal_spacing=0.5,\n                              pattern=\"iso\",\n                              polarization=\"cross\")\n my_tx = Transmitter(name=\"my_tx\",\n                     position=(0,0,0),\n                     orientation=(0,0,0))\nscene.add(my_tx)\n```\n\n\nThe position $(x,y,z)$ and orientation $(\\alpha, \\beta, \\gamma)$ of a radio device\ncan be freely configured. The latter is specified through three angles corresponding to a 3D\nrotation as defined in [(3)](../em_primer.html#equation-rotation).\nBoth can be assigned to TensorFlow variables or tensors. In the latter case,\nthe tensor can be the output of a callable, such as a Keras layer implementing a neural network.\nIn the former case, it can be set to a trainable variable.\n\nRadio devices need to be explicitly added to the scene using the scenes method [`add()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.add)\nand can be removed from it using [`remove()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.remove):"
"```python\nscene = load_scene()\nscene.add(Transmitter(\"tx\", [10.0, 0.0, 1.5], [0.0,0.0,0.0]))\nscene.remove(\"tx\")\n```"
"### Transmitter\n\n`class` `sionna.rt.``Transmitter`(*`name`*, *`position`*, *`orientation``=``(0.0,` `0.0,` `0.0)`*, *`look_at``=``None`*, *`color``=``(0.16,` `0.502,` `0.725)`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/transmitter.html#Transmitter)\n\nClass defining a transmitter\n\nThe `position` and `orientation` properties can be assigned to a TensorFlow\nvariable or tensor. In the latter case, the tensor can be the output of a callable,\nsuch as a Keras layer implementing a neural network. In the former case, it\ncan be set to a trainable variable:\n```python\ntx = Transmitter(name=\"my_tx\",\n                 position=tf.Variable([0, 0, 0], dtype=tf.float32),\n                 orientation=tf.Variable([0, 0, 0], dtype=tf.float32))\n```\n\nParameters\n\n- **name** (*str*)  Name\n- **position** (*[**3**]**, **float*)  Position $(x,y,z)$ [m] as three-dimensional vector\n- **orientation** (*[**3**]**, **float*)  Orientation $(\\alpha, \\beta, \\gamma)$ [rad] specified\nthrough three angles corresponding to a 3D rotation\nas defined in [(3)](../em_primer.html#equation-rotation).\nThis parameter is ignored if `look_at` is not <cite>None</cite>.\nDefaults to [0,0,0].\n- **look_at** ([3], float | [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter) | [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver) | [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) | None)  A position or the instance of a [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter),\n[`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver), or [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) to look at.\nIf set to <cite>None</cite>, then `orientation` is used to orientate the device.\n- **color** (*[**3**]**, **float*)  Defines the RGB (red, green, blue) `color` parameter for the device as displayed in the previewer and renderer.\nEach RGB component must have a value within the range $\\in [0,1]$.\nDefaults to <cite>[0.160, 0.502, 0.725]</cite>.\n- **dtype** (*tf.complex*)  Datatype to be used in internal calculations.\nDefaults to <cite>tf.complex64</cite>.\n\n\n`property` `color`\n\nGet/set the the RGB (red, green, blue) color for the device as displayed in the previewer and renderer.\nEach RGB component must have a value within the range $\\in [0,1]$.\nType\n\n[3], float\n\n\n`look_at`(*`target`*)\n\nSets the orientation so that the x-axis points toward a\nposition, radio device, or camera.\n\nGiven a point $\\mathbf{x}\\in\\mathbb{R}^3$ with spherical angles\n$\\theta$ and $\\varphi$, the orientation of the radio device\nwill be set equal to $(\\varphi, \\frac{\\pi}{2}-\\theta, 0.0)$.\nInput\n\n**target** ([3], float | [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter) | [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver) | [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) | str)  A position or the name or instance of a\n[`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter), [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver), or\n[`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) in the scene to look at.\n\n\n`property` `name`\n\nName\nType\n\nstr (read-only)\n\n\n`property` `orientation`\n\nGet/set the orientation\nType\n\n[3], tf.float\n\n\n`property` `position`\n\nGet/set the position\nType\n\n[3], tf.float"
"### Receiver\n\n`class` `sionna.rt.``Receiver`(*`name`*, *`position`*, *`orientation``=``(0.0,` `0.0,` `0.0)`*, *`look_at``=``None`*, *`color``=``(0.153,` `0.682,` `0.375)`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/receiver.html#Receiver)\n\nClass defining a receiver\n\nThe `position` and `orientation` properties can be assigned to a TensorFlow\nvariable or tensor. In the latter case, the tensor can be the output of a callable,\nsuch as a Keras layer implementing a neural network. In the former case, it\ncan be set to a trainable variable:\n```python\nrx = Transmitter(name=\"my_rx\",\n                 position=tf.Variable([0, 0, 0], dtype=tf.float32),\n                 orientation=tf.Variable([0, 0, 0], dtype=tf.float32))\n```\n\nParameters\n\n- **name** (*str*)  Name\n- **position** (*[**3**]**, **float*)  Position $(x,y,z)$ as three-dimensional vector\n- **orientation** (*[**3**]**, **float*)  Orientation $(\\alpha, \\beta, \\gamma)$ [rad] specified\nthrough three angles corresponding to a 3D rotation\nas defined in [(3)](../em_primer.html#equation-rotation).\nThis parameter is ignored if `look_at` is not <cite>None</cite>.\nDefaults to [0,0,0].\n- **look_at** ([3], float | [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter) | [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver) | [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) | None)  A position or the instance of a [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter),\n[`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver), or [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) to look at.\nIf set to <cite>None</cite>, then `orientation` is used to orientate the device.\n- **color** (*[**3**]**, **float*)  Defines the RGB (red, green, blue) `color` parameter for the device as displayed in the previewer and renderer.\nEach RGB component must have a value within the range $\\in [0,1]$.\nDefaults to <cite>[0.153, 0.682, 0.375]</cite>.\n- **dtype** (*tf.complex*)  Datatype to be used in internal calculations.\nDefaults to <cite>tf.complex64</cite>.\n\n\n`property` `color`\n\nGet/set the the RGB (red, green, blue) color for the device as displayed in the previewer and renderer.\nEach RGB component must have a value within the range $\\in [0,1]$.\nType\n\n[3], float\n\n\n`look_at`(*`target`*)\n\nSets the orientation so that the x-axis points toward a\nposition, radio device, or camera.\n\nGiven a point $\\mathbf{x}\\in\\mathbb{R}^3$ with spherical angles\n$\\theta$ and $\\varphi$, the orientation of the radio device\nwill be set equal to $(\\varphi, \\frac{\\pi}{2}-\\theta, 0.0)$.\nInput\n\n**target** ([3], float | [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter) | [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver) | [`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) | str)  A position or the name or instance of a\n[`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter), [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver), or\n[`Camera`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Camera) in the scene to look at.\n\n\n`property` `name`\n\nName\nType\n\nstr (read-only)\n\n\n`property` `orientation`\n\nGet/set the orientation\nType\n\n[3], tf.float\n\n\n`property` `position`\n\nGet/set the position\nType\n\n[3], tf.float"
"## Antenna Arrays\n\nTransmitters ([`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter)) and receivers ([`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver)) are equipped with an [`AntennaArray`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.AntennaArray) that is composed of one or more antennas. All transmitters and all receivers share the same [`AntennaArray`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.AntennaArray) which can be set through the scene properties [`tx_array`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.tx_array) and [`rx_array`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.rx_array), respectively."
"### AntennaArray\n\n`class` `sionna.rt.``AntennaArray`(*`antenna`*, *`positions`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/antenna_array.html#AntennaArray)\n\nClass implementing an antenna array\n\nAn antenna array is composed of identical antennas that are placed\nat different positions. The `positions` parameter can be assigned\nto a TensorFlow variable or tensor.\n```python\narray = AntennaArray(antenna=Antenna(\"tr38901\", \"V\"),\n                     positions=tf.Variable([[0,0,0], [0, 1, 1]]))\n```\n\nParameters\n\n- **antenna** ([`Antenna`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Antenna))  Antenna instance\n- **positions** (*[**array_size**, **3**]**, **array_like*)  Array of relative positions $(x,y,z)$ [m] of each\nantenna (dual-polarized antennas are counted as a single antenna\nand share the same position).\nThe absolute position of the antennas is obtained by\nadding the position of the [`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter)\nor [`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver) using it.\n- **dtype** (*tf.complex64** or **tf.complex128*)  Data type used for all computations.\nDefaults to <cite>tf.complex64</cite>.\n\n\n`property` `antenna`\n\nGet/set the antenna\nType\n\n[`Antenna`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Antenna)\n\n\n`property` `array_size`\n\nNumber of antennas in the array.\nDual-polarized antennas are counted as a single antenna.\nType\n\nint (read-only)\n\n\n`property` `num_ant`\n\nNumber of linearly polarized antennas in the array.\nDual-polarized antennas are counted as two linearly polarized\nantennas.\nType\n\nint (read-only)\n\n\n`property` `positions`\n\nGet/set  array of relative positions\n$(x,y,z)$ [m] of each antenna (dual-polarized antennas are\ncounted as a single antenna and share the same position).\nType\n\n[array_size, 3], <cite>tf.float</cite>\n\n\n`rotated_positions`(*`orientation`*)[`[source]`](../_modules/sionna/rt/antenna_array.html#AntennaArray.rotated_positions)\n\nGet the antenna positions rotated according to `orientation`\nInput\n\n**orientation** (*[3], tf.float*)  Orientation $(\\alpha, \\beta, \\gamma)$ [rad] specified\nthrough three angles corresponding to a 3D rotation\nas defined in [(3)](../em_primer.html#equation-rotation).\n\nOutput\n\n*[array_size, 3]*  Rotated positions"
"### PlanarArray\n\n`class` `sionna.rt.``PlanarArray`(*`num_rows`*, *`num_cols`*, *`vertical_spacing`*, *`horizontal_spacing`*, *`pattern`*, *`polarization``=``None`*, *`polarization_model``=``2`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/antenna_array.html#PlanarArray)\n\nClass implementing a planar antenna array\n\nThe antennas are regularly spaced, located in the y-z plane, and\nnumbered column-first from the top-left to bottom-right corner.\nParameters\n\n- **num_rows** (*int*)  Number of rows\n- **num_cols** (*int*)  Number of columns\n- **vertical_spacing** (*float*)  Vertical antenna spacing [multiples of wavelength].\n- **horizontal_spacing** (*float*)  Horizontal antenna spacing [multiples of wavelength].\n- **pattern** (*str**, **callable**, or **length-2 sequence of callables*)  Antenna pattern. Either one of\n[iso, dipole, hw_dipole, tr38901],\nor a callable, or a length-2 sequence of callables defining\nantenna patterns. In the latter case, the antennas are dual\npolarized and each callable defines the antenna pattern\nin one of the two orthogonal polarization directions.\nAn antenna pattern is a callable that takes as inputs vectors of\nzenith and azimuth angles of the same length and returns for each\npair the corresponding zenith and azimuth patterns. See [(14)](../em_primer.html#equation-c) for\nmore detail.\n- **polarization** (*str** or **None*)  Type of polarization. For single polarization, must be V (vertical)\nor H (horizontal). For dual polarization, must be VH or cross.\nOnly needed if `pattern` is a string.\n- **polarization_model** (*int**, **one of** [**1**,**2**]*)  Polarization model to be used. Options <cite>1</cite> and <cite>2</cite>\nrefer to [`polarization_model_1()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.antenna.polarization_model_1)\nand [`polarization_model_2()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.antenna.polarization_model_2),\nrespectively.\nDefaults to <cite>2</cite>.\n- **dtype** (*tf.complex64** or **tf.complex128*)  Datatype used for all computations.\nDefaults to <cite>tf.complex64</cite>.\n\n\n xample"
"```python\narray = PlanarArray(8,4, 0.5, 0.5, \"tr38901\", \"VH\")\narray.show()\n```\n\n\n`property` `antenna`\n\nGet/set the antenna\nType\n\n[`Antenna`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Antenna)\n\n\n`property` `array_size`\n\nNumber of antennas in the array.\nDual-polarized antennas are counted as a single antenna.\nType\n\nint (read-only)\n\n\n`property` `num_ant`\n\nNumber of linearly polarized antennas in the array.\nDual-polarized antennas are counted as two linearly polarized\nantennas.\nType\n\nint (read-only)\n\n\n`property` `positions`\n\nGet/set  array of relative positions\n$(x,y,z)$ [m] of each antenna (dual-polarized antennas are\ncounted as a single antenna and share the same position).\nType\n\n[array_size, 3], <cite>tf.float</cite>\n\n\n`rotated_positions`(*`orientation`*)\n\nGet the antenna positions rotated according to `orientation`\nInput\n\n**orientation** (*[3], tf.float*)  Orientation $(\\alpha, \\beta, \\gamma)$ [rad] specified\nthrough three angles corresponding to a 3D rotation\nas defined in [(3)](../em_primer.html#equation-rotation).\n\nOutput\n\n*[array_size, 3]*  Rotated positions\n\n\n`show`()[`[source]`](../_modules/sionna/rt/antenna_array.html#PlanarArray.show)\n\nVisualizes the antenna array\n\nAntennas are depicted by markers that are annotated with the antenna\nnumber. The marker is not related to the polarization of an antenna.\nOutput\n\n`matplotlib.pyplot.Figure`  Figure depicting the antenna array"
"## Antennas\n\nWe refer the user to the section [Far Field of a Transmitting Antenna](../em_primer.html#far-field) for various useful definitions and background on antenna modeling.\nAn [`Antenna`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Antenna) can be single- or dual-polarized and has for each polarization direction a possibly different antenna pattern.\n\nAn antenna pattern is defined as a function $f:(\\theta,\\varphi)\\mapsto (C_\\theta(\\theta, \\varphi), C_\\varphi(\\theta, \\varphi))$\nthat maps a pair of zenith and azimuth angles to zenith and azimuth pattern values.\nYou can easily define your own pattern or use one of the predefined [patterns](https://nvlabs.github.io/sionna/api/rt.html#patterns) below.\n\nTransmitters ([`Transmitter`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Transmitter)) and receivers ([`Receiver`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Receiver)) are not equipped with an [`Antenna`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Antenna) but an [`AntennaArray`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.AntennaArray) that is composed of one or more antennas. All transmitters in a scene share the same [`AntennaArray`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.AntennaArray) which can be set through the scene property [`tx_array`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.tx_array). The same holds for all receivers whose [`AntennaArray`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.AntennaArray) can be set through [`rx_array`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Scene.rx_array)."
"### Antenna\n\n`class` `sionna.rt.``Antenna`(*`pattern`*, *`polarization``=``None`*, *`polarization_model``=``2`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/antenna.html#Antenna)\n\nClass implementing an antenna\n\nCreates an antenna object with an either predefined or custom antenna\npattern. Can be single or dual polarized.\nParameters\n\n- **pattern** (*str**, **callable**, or **length-2 sequence of callables*)  Antenna pattern. Either one of\n[iso, dipole, hw_dipole, tr38901],\nor a callable, or a length-2 sequence of callables defining\nantenna patterns. In the latter case, the antenna is dual\npolarized and each callable defines the antenna pattern\nin one of the two orthogonal polarization directions.\nAn antenna pattern is a callable that takes as inputs vectors of\nzenith and azimuth angles of the same length and returns for each\npair the corresponding zenith and azimuth patterns.\n- **polarization** (*str** or **None*)  Type of polarization. For single polarization, must be V (vertical)\nor H (horizontal). For dual polarization, must be VH or cross.\nOnly needed if `pattern` is a string.\n- **polarization_model** (*int**, **one of** [**1**,**2**]*)  Polarization model to be used. Options <cite>1</cite> and <cite>2</cite>\nrefer to [`polarization_model_1()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.antenna.polarization_model_1)\nand [`polarization_model_2()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.antenna.polarization_model_2),\nrespectively.\nDefaults to <cite>2</cite>.\n- **dtype** (*tf.complex64** or **tf.complex128*)  Datatype used for all computations.\nDefaults to <cite>tf.complex64</cite>.\n\n\n xample\n```python\n>>> Antenna(\"tr38901\", \"VH\")\n```\n`property` `patterns`\n\nAntenna patterns for one or two\npolarization directions\nType\n\n<cite>list</cite>, <cite>callable</cite>"
"### compute_gain\n\n`sionna.rt.antenna.``compute_gain`(*`pattern`*)[`[source]`](../_modules/sionna/rt/antenna.html#compute_gain)\n\nComputes the directivity, gain, and radiation efficiency of an antenna pattern\n\nGiven a function $f:(\\theta,\\varphi)\\mapsto (C_\\theta(\\theta, \\varphi), C_\\varphi(\\theta, \\varphi))$\ndescribing an antenna pattern [(14)](../em_primer.html#equation-c), this function computes the gain $G$,\ndirectivity $D$, and radiation efficiency $\\eta_\\text{rad}=G/D$\n(see [(12)](../em_primer.html#equation-g) and text below).\nInput\n\n**pattern** (*callable*)  A callable that takes as inputs vectors of zenith and azimuth angles of the same\nlength and returns for each pair the corresponding zenith and azimuth patterns.\n\nOutput\n\n- **D** (*float*)  Directivity $D$\n- **G** (*float*)  Gain $G$\n- **eta_rad** (*float*)  Radiation efficiency $\\eta_\\text{rad}$\n\n\n xamples\n```python\n>>> compute_gain(tr38901_pattern)\n(<tf.Tensor: shape=(), dtype=float32, numpy=9.606758>,\n <tf.Tensor: shape=(), dtype=float32, numpy=6.3095527>,\n <tf.Tensor: shape=(), dtype=float32, numpy=0.65678275>)\n```"
"### visualize\n\n`sionna.rt.antenna.``visualize`(*`pattern`*)[`[source]`](../_modules/sionna/rt/antenna.html#visualize)\n\nVisualizes an antenna pattern\n\nThis function visualizes an antenna pattern with the help of three\nfigures showing the vertical and horizontal cuts as well as a\nthree-dimensional visualization of the antenna gain.\nInput\n\n**pattern** (*callable*)  A callable that takes as inputs vectors of zenith and azimuth angles\nof the same length and returns for each pair the corresponding zenith\nand azimuth patterns.\n\nOutput\n\n- `matplotlib.pyplot.Figure`  Vertical cut of the antenna gain\n- `matplotlib.pyplot.Figure`  Horizontal cut of the antenna gain\n- `matplotlib.pyplot.Figure`  3D visualization of the antenna gain\n\n\n xamples\n```python\n>>> fig_v, fig_h, fig_3d = visualize(hw_dipole_pattern)\n```"
"### dipole_pattern\n\n`sionna.rt.antenna.``dipole_pattern`(*`theta`*, *`phi`*, *`slant_angle``=``0.0`*, *`polarization_model``=``2`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/antenna.html#dipole_pattern)\n\nShort dipole pattern with linear polarizarion (Eq. 4-26a) [[Balanis97]](https://nvlabs.github.io/sionna/api/rt.html#balanis97)\nInput\n\n- **theta** (*array_like, float*)  Zenith angles wrapped within [0,pi] [rad]\n- **phi** (*array_like, float*)  Azimuth angles wrapped within [-pi, pi) [rad]\n- **slant_angle** (*float*)  Slant angle of the linear polarization [rad].\nA slant angle of zero means vertical polarization.\n- **polarization_model** (*int, one of [1,2]*)  Polarization model to be used. Options <cite>1</cite> and <cite>2</cite>\nrefer to [`polarization_model_1()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.antenna.polarization_model_1)\nand [`polarization_model_2()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.antenna.polarization_model_2),\nrespectively.\nDefaults to <cite>2</cite>.\n- **dtype** (*tf.complex64 or tf.complex128*)  Datatype.\nDefaults to <cite>tf.complex64</cite>.\n\n\nOutput\n\n- **c_theta** (*array_like, complex*)  Zenith pattern\n- **c_phi** (*array_like, complex*)  Azimuth pattern"
"### hw_dipole_pattern\n\n`sionna.rt.antenna.``hw_dipole_pattern`(*`theta`*, *`phi`*, *`slant_angle``=``0.0`*, *`polarization_model``=``2`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/antenna.html#hw_dipole_pattern)\n\nHalf-wavelength dipole pattern with linear polarizarion (Eq. 4-84) [[Balanis97]](https://nvlabs.github.io/sionna/api/rt.html#balanis97)\nInput\n\n- **theta** (*array_like, float*)  Zenith angles wrapped within [0,pi] [rad]\n- **phi** (*array_like, float*)  Azimuth angles wrapped within [-pi, pi) [rad]\n- **slant_angle** (*float*)  Slant angle of the linear polarization [rad].\nA slant angle of zero means vertical polarization.\n- **polarization_model** (*int, one of [1,2]*)  Polarization model to be used. Options <cite>1</cite> and <cite>2</cite>\nrefer to [`polarization_model_1()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.antenna.polarization_model_1)\nand [`polarization_model_2()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.antenna.polarization_model_2),\nrespectively.\nDefaults to <cite>2</cite>.\n- **dtype** (*tf.complex64 or tf.complex128*)  Datatype.\nDefaults to <cite>tf.complex64</cite>.\n\n\nOutput\n\n- **c_theta** (*array_like, complex*)  Zenith pattern\n- **c_phi** (*array_like, complex*)  Azimuth pattern"
"### iso_pattern\n\n`sionna.rt.antenna.``iso_pattern`(*`theta`*, *`phi`*, *`slant_angle``=``0.0`*, *`polarization_model``=``2`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/antenna.html#iso_pattern)\n\nIsotropic antenna pattern with linear polarizarion\nInput\n\n- **theta** (*array_like, float*)  Zenith angles wrapped within [0,pi] [rad]\n- **phi** (*array_like, float*)  Azimuth angles wrapped within [-pi, pi) [rad]\n- **slant_angle** (*float*)  Slant angle of the linear polarization [rad].\nA slant angle of zero means vertical polarization.\n- **polarization_model** (*int, one of [1,2]*)  Polarization model to be used. Options <cite>1</cite> and <cite>2</cite>\nrefer to [`polarization_model_1()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.antenna.polarization_model_1)\nand [`polarization_model_2()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.antenna.polarization_model_2),\nrespectively.\nDefaults to <cite>2</cite>.\n- **dtype** (*tf.complex64 or tf.complex128*)  Datatype.\nDefaults to <cite>tf.complex64</cite>.\n\n\nOutput\n\n- **c_theta** (*array_like, complex*)  Zenith pattern\n- **c_phi** (*array_like, complex*)  Azimuth pattern"
"### tr38901_pattern\n\n`sionna.rt.antenna.``tr38901_pattern`(*`theta`*, *`phi`*, *`slant_angle``=``0.0`*, *`polarization_model``=``2`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/rt/antenna.html#tr38901_pattern)\n\nAntenna pattern from 3GPP TR 38.901 (Table 7.3-1) [[TR38901]](channel.wireless.html#tr38901)\nInput\n\n- **theta** (*array_like, float*)  Zenith angles wrapped within [0,pi] [rad]\n- **phi** (*array_like, float*)  Azimuth angles wrapped within [-pi, pi) [rad]\n- **slant_angle** (*float*)  Slant angle of the linear polarization [rad].\nA slant angle of zero means vertical polarization.\n- **polarization_model** (*int, one of [1,2]*)  Polarization model to be used. Options <cite>1</cite> and <cite>2</cite>\nrefer to [`polarization_model_1()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.antenna.polarization_model_1)\nand [`polarization_model_2()`](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.antenna.polarization_model_2),\nrespectively.\nDefaults to <cite>2</cite>.\n- **dtype** (*tf.complex64 or tf.complex128*)  Datatype.\nDefaults to <cite>tf.complex64</cite>.\n\n\nOutput\n\n- **c_theta** (*array_like, complex*)  Zenith pattern\n- **c_phi** (*array_like, complex*)  Azimuth pattern"
"### polarization_model_1\n\n`sionna.rt.antenna.``polarization_model_1`(*`c_theta`*, *`theta`*, *`phi`*, *`slant_angle`*)[`[source]`](../_modules/sionna/rt/antenna.html#polarization_model_1)\n\nModel-1 for polarized antennas from 3GPP TR 38.901\n\nTransforms a vertically polarized antenna pattern $\\tilde{C}_\\theta(\\theta, \\varphi)$\ninto a linearly polarized pattern whose direction\nis specified by a slant angle $\\zeta$. For example,\n$\\zeta=0$ and $\\zeta=\\pi/2$ correspond\nto vertical and horizontal polarization, respectively,\nand $\\zeta=\\pm \\pi/4$ to a pair of cross polarized\nantenna elements.\n\nThe transformed antenna pattern is given by (7.3-3) [[TR38901]](channel.wireless.html#tr38901):\n\n$$\n\\begin{split}\\begin{align}\n    \\begin{bmatrix}\n        C_\\theta(\\theta, \\varphi) \\\\\n        C_\\varphi(\\theta, \\varphi)\n    \\end{bmatrix} &= \\begin{bmatrix}\n     \\cos(\\psi) \\\\\n     \\sin(\\psi)\n    \\end{bmatrix} \\tilde{C}_\\theta(\\theta, \\varphi)\\\\\n    \\cos(\\psi) &= \\frac{\\cos(\\zeta)\\sin(\\theta)+\\sin(\\zeta)\\sin(\\varphi)\\cos(\\theta)}{\\sqrt{1-\\left(\\cos(\\zeta)\\cos(\\theta)-\\sin(\\zeta)\\sin(\\varphi)\\sin(\\theta)\\right)^2}} \\\\\n    \\sin(\\psi) &= \\frac{\\sin(\\zeta)\\cos(\\varphi)}{\\sqrt{1-\\left(\\cos(\\zeta)\\cos(\\theta)-\\sin(\\zeta)\\sin(\\varphi)\\sin(\\theta)\\right)^2}}\n\\end{align}\\end{split}\n$$\n\nInput\n\n- **c_tilde_theta** (*array_like, complex*)  Zenith pattern\n- **theta** (*array_like, float*)  Zenith angles wrapped within [0,pi] [rad]\n- **phi** (*array_like, float*)  Azimuth angles wrapped within [-pi, pi) [rad]\n- **slant_angle** (*float*)  Slant angle of the linear polarization [rad].\nA slant angle of zero means vertical polarization.\n\n\nOutput\n\n- **c_theta** (*array_like, complex*)  Zenith pattern\n- **c_phi** (*array_like, complex*)  Azimuth pattern"
"### polarization_model_2\n\n`sionna.rt.antenna.``polarization_model_2`(*`c`*, *`slant_angle`*)[`[source]`](../_modules/sionna/rt/antenna.html#polarization_model_2)\n\nModel-2 for polarized antennas from 3GPP TR 38.901\n\nTransforms a vertically polarized antenna pattern $\\tilde{C}_\\theta(\\theta, \\varphi)$\ninto a linearly polarized pattern whose direction\nis specified by a slant angle $\\zeta$. For example,\n$\\zeta=0$ and $\\zeta=\\pi/2$ correspond\nto vertical and horizontal polarization, respectively,\nand $\\zeta=\\pm \\pi/4$ to a pair of cross polarized\nantenna elements.\n\nThe transformed antenna pattern is given by (7.3-4/5) [[TR38901]](channel.wireless.html#tr38901):\n\n$$\n\\begin{split}\\begin{align}\n    \\begin{bmatrix}\n        C_\\theta(\\theta, \\varphi) \\\\\n        C_\\varphi(\\theta, \\varphi)\n    \\end{bmatrix} &= \\begin{bmatrix}\n     \\cos(\\zeta) \\\\\n     \\sin(\\zeta)\n    \\end{bmatrix} \\tilde{C}_\\theta(\\theta, \\varphi)\n\\end{align}\\end{split}\n$$\n\nInput\n\n- **c_tilde_theta** (*array_like, complex*)  Zenith pattern\n- **slant_angle** (*float*)  Slant angle of the linear polarization [rad].\nA slant angle of zero means vertical polarization.\n\n\nOutput\n\n- **c_theta** (*array_like, complex*)  Zenith pattern\n- **c_phi** (*array_like, complex*)  Azimuth pattern"
"### cross\n\n`sionna.rt.``cross`(*`u`*, *`v`*)[`[source]`](../_modules/sionna/rt/utils.html#cross)\n\nComputes the cross (or vector) product between u and v\nInput\n\n- **u** (*[,3]*)  First vector\n- **v** (*[,3]*)  Second vector\n\n\nOutput\n\n*[,3]*  Cross product between `u` and `v`"
"### dot\n\n`sionna.rt.``dot`(*`u`*, *`v`*, *`keepdim``=``False`*, *`clip``=``False`*)[`[source]`](../_modules/sionna/rt/utils.html#dot)\n\nComputes and the dot (or scalar) product between u and v\nInput\n\n- **u** (*[,3]*)  First vector\n- **v** (*[,3]*)  Second vector\n- **keepdim** (*bool*)  If <cite>True</cite>, keep the last dimension.\nDefaults to <cite>False</cite>.\n- **clip** (*bool*)  If <cite>True</cite>, clip output to [-1,1].\nDefaults to <cite>False</cite>.\n\n\nOutput\n\n*[,1] or []*  Dot product between `u` and `v`.\nThe last dimension is removed if `keepdim`\nis set to <cite>False</cite>."
"### normalize\n\n`sionna.rt.``normalize`(*`v`*)[`[source]`](../_modules/sionna/rt/utils.html#normalize)\n\nNormalizes `v` to unit norm\nInput\n\n**v** (*[,3], tf.float*)  Vector\n\nOutput\n\n- *[,3], tf.float*  Normalized vector\n- *[], tf.float*  Norm of the unnormalized vector"
"### phi_hat\n\n`sionna.rt.``phi_hat`(*`phi`*)[`[source]`](../_modules/sionna/rt/utils.html#phi_hat)\n\nComputes the spherical unit vector\n$\\hat{\\boldsymbol{\\varphi}}(\\theta, \\varphi)$\nas defined in [(1)](../em_primer.html#equation-spherical-vecs)\nInput\n\n**phi** (same shape as `theta`, tf.float)  Azimuth angles $\\varphi$ [rad]\n\nOutput\n\n**theta_hat** (`phi.shape` + [3], tf.float)  Vector $\\hat{\\boldsymbol{\\varphi}}(\\theta, \\varphi)$"
"### rotate\n\n`sionna.rt.``rotate`(*`p`*, *`angles`*)[`[source]`](../_modules/sionna/rt/utils.html#rotate)\n\nRotates points `p` by the `angles` according\nto the 3D rotation defined in [(3)](../em_primer.html#equation-rotation)\nInput\n\n- **p** (*[,3], tf.float*)  Points to rotate\n- **angles** (*[, 3]*)  Angles for the rotations [rad].\nThe last dimension corresponds to the angles\n$(\\alpha,\\beta,\\gamma)$ that define\nrotations about the axes $(z, y, x)$,\nrespectively.\n\n\nOutput\n\n*[,3]*  Rotated points `p`"
"### rotation_matrix\n\n`sionna.rt.``rotation_matrix`(*`angles`*)[`[source]`](../_modules/sionna/rt/utils.html#rotation_matrix)\n\nComputes rotation matrices as defined in [(3)](../em_primer.html#equation-rotation)\n\nThe closed-form expression in (7.1-4) [[TR38901]](channel.wireless.html#tr38901) is used.\nInput\n\n**angles** (*[,3], tf.float*)  Angles for the rotations [rad].\nThe last dimension corresponds to the angles\n$(\\alpha,\\beta,\\gamma)$ that define\nrotations about the axes $(z, y, x)$,\nrespectively.\n\nOutput\n\n*[,3,3], tf.float*  Rotation matrices"
"### rot_mat_from_unit_vecs\n\n`sionna.rt.``rot_mat_from_unit_vecs`(*`a`*, *`b`*)[`[source]`](../_modules/sionna/rt/utils.html#rot_mat_from_unit_vecs)\n\nComputes Rodrigues` rotation formula [(6)](../em_primer.html#equation-rodrigues-matrix)\nInput\n\n- **a** (*[,3], tf.float*)  First unit vector\n- **b** (*[,3], tf.float*)  Second unit vector\n\n\nOutput\n\n*[,3,3], tf.float*  Rodrigues rotation matrix"
"### r_hat\n\n`sionna.rt.``r_hat`(*`theta`*, *`phi`*)[`[source]`](../_modules/sionna/rt/utils.html#r_hat)\n\nComputes the spherical unit vetor $\\hat{\\mathbf{r}}(\\theta, \\phi)$\nas defined in [(1)](../em_primer.html#equation-spherical-vecs)\nInput\n\n- **theta** (*arbitrary shape, tf.float*)  Zenith angles $\\theta$ [rad]\n- **phi** (same shape as `theta`, tf.float)  Azimuth angles $\\varphi$ [rad]\n\n\nOutput\n\n**rho_hat** (`phi.shape` + [3], tf.float)  Vector $\\hat{\\mathbf{r}}(\\theta, \\phi)$  on unit sphere"
"### sample_points_on_hemisphere\n\n`sionna.rt.``sample_points_on_hemisphere`(*`normals`*, *`num_samples``=``1`*)[`[source]`](../_modules/sionna/rt/utils.html#sample_points_on_hemisphere)\n\nRandomly sample points on hemispheres defined by their normal vectors\nInput\n\n- **normals** (*[batch_size, 3], tf.float*)  Normal vectors defining hemispheres\n- **num_samples** (*int*)  Number of random samples to draw for each hemisphere\ndefined by its normal vector.\nDefaults to 1.\n\n\nOutput\n\n**points** (*[batch_size, num_samples, 3], tf.float or [batch_size, 3], tf.float if num_samples=1.*)  Random points on the hemispheres"
"### theta_hat\n\n`sionna.rt.``theta_hat`(*`theta`*, *`phi`*)[`[source]`](../_modules/sionna/rt/utils.html#theta_hat)\n\nComputes the spherical unit vector\n$\\hat{\\boldsymbol{\\theta}}(\\theta, \\varphi)$\nas defined in [(1)](../em_primer.html#equation-spherical-vecs)\nInput\n\n- **theta** (*arbitrary shape, tf.float*)  Zenith angles $\\theta$ [rad]\n- **phi** (same shape as `theta`, tf.float)  Azimuth angles $\\varphi$ [rad]\n\n\nOutput\n\n**theta_hat** (`phi.shape` + [3], tf.float)  Vector $\\hat{\\boldsymbol{\\theta}}(\\theta, \\varphi)$"
"### theta_phi_from_unit_vec\n\n`sionna.rt.``theta_phi_from_unit_vec`(*`v`*)[`[source]`](../_modules/sionna/rt/utils.html#theta_phi_from_unit_vec)\n\nComputes zenith and azimuth angles ($\\theta,\\varphi$)\nfrom unit-norm vectors as described in [(2)](../em_primer.html#equation-theta-phi)\nInput\n\n**v** (*[,3], tf.float*)  Tensor with unit-norm vectors in the last dimension\n\nOutput\n\n- **theta** (*[], tf.float*)  Zenith angles $\\theta$\n- **phi** (*[], tf.float*)  Azimuth angles $\\varphi$\n\n\nReferences:\nBalanis97([1](https://nvlabs.github.io/sionna/api/rt.html#id21),[2](https://nvlabs.github.io/sionna/api/rt.html#id22))\n<ol class=\"upperalpha simple\">\n- Balanis, Antenna Theory: Analysis and Design, 2nd Edition, John Wiley & Sons, 1997.\n</ol>\n\nITUR_P2040_2([1](https://nvlabs.github.io/sionna/api/rt.html#id16),[2](https://nvlabs.github.io/sionna/api/rt.html#id17))\n\nITU-R, Effects of building materials and structures on radiowave propagation above about 100 MHz, Recommendation ITU-R P.2040-2\n\n[SurfaceIntegral](https://nvlabs.github.io/sionna/api/rt.html#id2)\n\nWikipedia, [Surface integral](https://en.wikipedia.org/wiki/Surface_integral), accessed Jun. 22, 2023."
"# Signal\n\nThis module contains classes and functions for [filtering](https://nvlabs.github.io/sionna/api/signal.html#filter) (pulse shaping), [windowing](https://nvlabs.github.io/sionna/api/signal.html#window), and [up-](https://nvlabs.github.io/sionna/api/signal.html#upsampling) and [downsampling](https://nvlabs.github.io/sionna/api/signal.html#downsampling).\nThe following figure shows the different components that can be implemented using this module.\n\n\nThis module also contains [utility functions](https://nvlabs.github.io/sionna/api/signal.html#utility) for computing the (inverse) discrete Fourier transform ([FFT](https://nvlabs.github.io/sionna/api/signal.html#fft)/[IFFT](https://nvlabs.github.io/sionna/api/signal.html#ifft)), and for empirically computing the [power spectral density (PSD)](https://nvlabs.github.io/sionna/api/signal.html#empirical-psd) and [adjacent channel leakage ratio (ACLR)](https://nvlabs.github.io/sionna/api/signal.html#empirical-aclr) of a signal.\n\nThe following code snippet shows how to filter a sequence of QAM baseband symbols using a root-raised-cosine filter with a Hann window:\n```python\n# Create batch of QAM-16 sequences\nbatch_size = 128\nnum_symbols = 1000\nnum_bits_per_symbol = 4\nx = QAMSource(num_bits_per_symbol)([batch_size, num_symbols])\n# Create a root-raised-cosine filter with Hann windowing\nbeta = 0.22 # Roll-off factor\nspan_in_symbols = 32 # Filter span in symbols\nsamples_per_symbol = 4 # Number of samples per symbol, i.e., the oversampling factor\nrrcf_hann = RootRaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, window=\"hann\")\n# Create instance of the Upsampling layer\nus = Upsampling(samples_per_symbol)\n# Upsample the baseband x\nx_us = us(x)\n# Filter the upsampled sequence\nx_rrcf = rrcf_hann(x_us)\n```\n\n\nOn the receiver side, one would recover the baseband symbols as follows:\n```python\n# Instantiate a downsampling layer\nds = Downsampling(samples_per_symbol, rrcf_hann.length-1, num_symbols)\n# Apply the matched filter\nx_mf = rrcf_hann(x_rrcf)\n# Recover the transmitted symbol sequence\nx_hat = ds(x_mf)\n```"
"### SincFilter\n\n`class` `sionna.signal.``SincFilter`(*`span_in_symbols`*, *`samples_per_symbol`*, *`window``=``None`*, *`normalize``=``True`*, *`trainable``=``False`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/signal/filter.html#SincFilter)\n\nLayer for applying a sinc filter of `length` K\nto an input `x` of length N.\n\nThe sinc filter is defined by\n\n$$\nh(t) = \\frac{1}{T}\\text{sinc}\\left(\\frac{t}{T}\\right)\n$$\n\nwhere $T$ the symbol duration.\n\nThe filter length K is equal to the filter span in symbols (`span_in_symbols`)\nmultiplied by the oversampling factor (`samples_per_symbol`).\nIf this product is even, a value of one will be added.\n\nThe filter is applied through discrete convolution.\n\nAn optional windowing function `window` can be applied to the filter.\n\nThe <cite>dtype</cite> of the output is <cite>tf.float</cite> if both `x` and the filter coefficients have dtype <cite>tf.float</cite>.\nOtherwise, the dtype of the output is <cite>tf.complex</cite>.\n\nThree padding modes are available for applying the filter:\n\n- full (default): Returns the convolution at each point of overlap between `x` and the filter.\nThe length of the output is N + K - 1. Zero-padding of the input `x` is performed to\ncompute the convolution at the borders.\n- same: Returns an output of the same length as the input `x`. The convolution is computed such\nthat the coefficients of the input `x` are centered on the coefficient of the filter with index\n(K-1)/2. Zero-padding of the input signal is performed to compute the convolution at the borders.\n- valid: Returns the convolution only at points where `x` and the filter completely overlap.\nThe length of the output is N - K + 1.\n\nParameters\n\n- **span_in_symbols** (*int*)  Filter span as measured by the number of symbols.\n- **samples_per_symbol** (*int*)  Number of samples per symbol, i.e., the oversampling factor.\n- **window** (* or **string** (**[**\"hann\"**, **\"hamming\"**, **\"blackman\"**]**)*)  Instance of [`Window`](https://nvlabs.github.io/sionna/api/signal.html#sionna.signal.Window) that is applied to the filter coefficients.\nAlternatively, a string indicating the window name can be provided. In this case,\nthe chosen window will be instantiated with the default parameters. Custom windows\nmust be provided as instance.\n- **normalize** (*bool*)  If <cite>True</cite>, the filter is normalized to have unit power.\nDefaults to <cite>True</cite>.\n- **trainable** (*bool*)  If <cite>True</cite>, the filter coefficients are trainable variables.\nDefaults to <cite>False</cite>.\n- **dtype** (*tf.DType*)  The <cite>dtype</cite> of the filter coefficients.\nDefaults to <cite>tf.float32</cite>.\n\n\nInput\n\n- **x** (*[, N], tf.complex or tf.float*)  The input to which the filter is applied.\nThe filter is applied along the last dimension.\n- **padding** (*string ([full, valid, same])*)  Padding mode for convolving `x` and the filter.\nMust be one of full, valid, or same. Case insensitive.\nDefaults to full.\n- **conjugate** (*bool*)  If <cite>True</cite>, the complex conjugate of the filter is applied.\nDefaults to <cite>False</cite>.\n\n\nOutput\n\n**y** (*[,M], tf.complex or tf.float*)  Filtered input.\nIt is <cite>tf.float</cite> only if both `x` and the filter are <cite>tf.float</cite>.\nIt is <cite>tf.complex</cite> otherwise.\nThe length M depends on the `padding`.\n\n\n`property` `aclr`\n\nACLR of the filter\n\nThis ACLR corresponds to what one would obtain from using\nthis filter as pulse shaping filter on an i.i.d. sequence of symbols.\nThe in-band is assumed to range from [-0.5, 0.5] in normalized\nfrequency.\n\n\n`property` `coefficients`\n\nThe filter coefficients (after normalization)\n\n\n`property` `length`\n\nThe filter length in samples\n\n\n`property` `normalize`\n\n<cite>True</cite> if the filter is normalized to have unit power. <cite>False</cite> otherwise.\n\n\n`property` `sampling_times`\n\nSampling times in multiples of the symbol duration\n\n\n`show`(*`response``=``'impulse'`*, *`scale``=``'lin'`*)\n\nPlot the impulse or magnitude response\n\nPlots the impulse response (time domain) or magnitude response\n(frequency domain) of the filter.\n\nFor the computation of the magnitude response, a minimum DFT size\nof 1024 is assumed which is obtained through zero padding of\nthe filter coefficients in the time domain.\nInput\n\n- **response** (*str, one of [impulse, magnitude]*)  The desired response type.\nDefaults to impulse\n- **scale** (*str, one of [lin, db]*)  The y-scale of the magnitude response.\nCan be lin (i.e., linear) or db (, i.e., Decibel).\nDefaults to lin.\n\n\n`property` `trainable`\n\n<cite>True</cite> if the filter coefficients are trainable. <cite>False</cite> otherwise.\n\n\n`property` `window`\n\nThe window function that is applied to the filter coefficients. <cite>None</cite> if no window is applied."
"### RaisedCosineFilter\n\n`class` `sionna.signal.``RaisedCosineFilter`(*`span_in_symbols`*, *`samples_per_symbol`*, *`beta`*, *`window``=``None`*, *`normalize``=``True`*, *`trainable``=``False`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/signal/filter.html#RaisedCosineFilter)\n\nLayer for applying a raised-cosine filter of `length` K\nto an input `x` of length N.\n\nThe raised-cosine filter is defined by\n\n$$\n\\begin{split}h(t) =\n\\begin{cases}\n\\frac{\\pi}{4T} \\text{sinc}\\left(\\frac{1}{2\\beta}\\right), & \\text { if }t = \\pm \\frac{T}{2\\beta}\\\\\n\\frac{1}{T}\\text{sinc}\\left(\\frac{t}{T}\\right)\\frac{\\cos\\left(\\frac{\\pi\\beta t}{T}\\right)}{1-\\left(\\frac{2\\beta t}{T}\\right)^2}, & \\text{otherwise}\n\\end{cases}\\end{split}\n$$\n\nwhere $\\beta$ is the roll-off factor and $T$ the symbol duration.\n\nThe filter length K is equal to the filter span in symbols (`span_in_symbols`)\nmultiplied by the oversampling factor (`samples_per_symbol`).\nIf this product is even, a value of one will be added.\n\nThe filter is applied through discrete convolution.\n\nAn optional windowing function `window` can be applied to the filter.\n\nThe <cite>dtype</cite> of the output is <cite>tf.float</cite> if both `x` and the filter coefficients have dtype <cite>tf.float</cite>.\nOtherwise, the dtype of the output is <cite>tf.complex</cite>.\n\nThree padding modes are available for applying the filter:\n\n- full (default): Returns the convolution at each point of overlap between `x` and the filter.\nThe length of the output is N + K - 1. Zero-padding of the input `x` is performed to\ncompute the convolution at the borders.\n- same: Returns an output of the same length as the input `x`. The convolution is computed such\nthat the coefficients of the input `x` are centered on the coefficient of the filter with index\n(K-1)/2. Zero-padding of the input signal is performed to compute the convolution at the borders.\n- valid: Returns the convolution only at points where `x` and the filter completely overlap.\nThe length of the output is N - K + 1.\n\nParameters\n\n- **span_in_symbols** (*int*)  Filter span as measured by the number of symbols.\n- **samples_per_symbol** (*int*)  Number of samples per symbol, i.e., the oversampling factor.\n- **beta** (*float*)  Roll-off factor.\nMust be in the range $[0,1]$.\n- **window** (* or **string** (**[**\"hann\"**, **\"hamming\"**, **\"blackman\"**]**)*)  Instance of [`Window`](https://nvlabs.github.io/sionna/api/signal.html#sionna.signal.Window) that is applied to the filter coefficients.\nAlternatively, a string indicating the window name can be provided. In this case,\nthe chosen window will be instantiated with the default parameters. Custom windows\nmust be provided as instance.\n- **normalize** (*bool*)  If <cite>True</cite>, the filter is normalized to have unit power.\nDefaults to <cite>True</cite>.\n- **trainable** (*bool*)  If <cite>True</cite>, the filter coefficients are trainable variables.\nDefaults to <cite>False</cite>.\n- **dtype** (*tf.DType*)  The <cite>dtype</cite> of the filter coefficients.\nDefaults to <cite>tf.float32</cite>.\n\n\nInput\n\n- **x** (*[, N], tf.complex or tf.float*)  The input to which the filter is applied.\nThe filter is applied along the last dimension.\n- **padding** (*string ([full, valid, same])*)  Padding mode for convolving `x` and the filter.\nMust be one of full, valid, or same.\nDefaults to full.\n- **conjugate** (*bool*)  If <cite>True</cite>, the complex conjugate of the filter is applied.\nDefaults to <cite>False</cite>.\n\n\nOutput\n\n**y** (*[,M], tf.complex or tf.float*)  Filtered input.\nIt is <cite>tf.float</cite> only if both `x` and the filter are <cite>tf.float</cite>.\nIt is <cite>tf.complex</cite> otherwise.\nThe length M depends on the `padding`.\n\n\n`property` `aclr`\n\nACLR of the filter\n\nThis ACLR corresponds to what one would obtain from using\nthis filter as pulse shaping filter on an i.i.d. sequence of symbols.\nThe in-band is assumed to range from [-0.5, 0.5] in normalized\nfrequency.\n\n\n`property` `beta`\n\nRoll-off factor\n\n\n`property` `coefficients`\n\nThe filter coefficients (after normalization)\n\n\n`property` `length`\n\nThe filter length in samples\n\n\n`property` `normalize`\n\n<cite>True</cite> if the filter is normalized to have unit power. <cite>False</cite> otherwise.\n\n\n`property` `sampling_times`\n\nSampling times in multiples of the symbol duration\n\n\n`show`(*`response``=``'impulse'`*, *`scale``=``'lin'`*)\n\nPlot the impulse or magnitude response\n\nPlots the impulse response (time domain) or magnitude response\n(frequency domain) of the filter.\n\nFor the computation of the magnitude response, a minimum DFT size\nof 1024 is assumed which is obtained through zero padding of\nthe filter coefficients in the time domain.\nInput\n\n- **response** (*str, one of [impulse, magnitude]*)  The desired response type.\nDefaults to impulse\n- **scale** (*str, one of [lin, db]*)  The y-scale of the magnitude response.\nCan be lin (i.e., linear) or db (, i.e., Decibel).\nDefaults to lin.\n\n\n`property` `trainable`\n\n<cite>True</cite> if the filter coefficients are trainable. <cite>False</cite> otherwise.\n\n\n`property` `window`\n\nThe window function that is applied to the filter coefficients. <cite>None</cite> if no window is applied."
"### RootRaisedCosineFilter\n\n`class` `sionna.signal.``RootRaisedCosineFilter`(*`span_in_symbols`*, *`samples_per_symbol`*, *`beta`*, *`window``=``None`*, *`normalize``=``True`*, *`trainable``=``False`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/signal/filter.html#RootRaisedCosineFilter)\n\nLayer for applying a root-raised-cosine filter of `length` K\nto an input `x` of length N.\n\nThe root-raised-cosine filter is defined by\n\n$$\n\\begin{split}h(t) =\n\\begin{cases}\n\\frac{1}{T} \\left(1 + \\beta\\left(\\frac{4}{\\pi}-1\\right) \\right), & \\text { if }t = 0\\\\\n\\frac{\\beta}{T\\sqrt{2}} \\left[ \\left(1+\\frac{2}{\\pi}\\right)\\sin\\left(\\frac{\\pi}{4\\beta}\\right) + \\left(1-\\frac{2}{\\pi}\\right)\\cos\\left(\\frac{\\pi}{4\\beta}\\right) \\right], & \\text { if }t = \\pm\\frac{T}{4\\beta} \\\\\n\\frac{1}{T} \\frac{\\sin\\left(\\pi\\frac{t}{T}(1-\\beta)\\right) + 4\\beta\\frac{t}{T}\\cos\\left(\\pi\\frac{t}{T}(1+\\beta)\\right)}{\\pi\\frac{t}{T}\\left(1-\\left(4\\beta\\frac{t}{T}\\right)^2\\right)}, & \\text { otherwise}\n\\end{cases}\\end{split}\n$$\n\nwhere $\\beta$ is the roll-off factor and $T$ the symbol duration.\n\nThe filter length K is equal to the filter span in symbols (`span_in_symbols`)\nmultiplied by the oversampling factor (`samples_per_symbol`).\nIf this product is even, a value of one will be added.\n\nThe filter is applied through discrete convolution.\n\nAn optional windowing function `window` can be applied to the filter.\n\nThe <cite>dtype</cite> of the output is <cite>tf.float</cite> if both `x` and the filter coefficients have dtype <cite>tf.float</cite>.\nOtherwise, the dtype of the output is <cite>tf.complex</cite>.\n\nThree padding modes are available for applying the filter:\n\n- full (default): Returns the convolution at each point of overlap between `x` and the filter.\nThe length of the output is N + K - 1. Zero-padding of the input `x` is performed to\ncompute the convolution at the borders.\n- same: Returns an output of the same length as the input `x`. The convolution is computed such\nthat the coefficients of the input `x` are centered on the coefficient of the filter with index\n(K-1)/2. Zero-padding of the input signal is performed to compute the convolution at the borders.\n- valid: Returns the convolution only at points where `x` and the filter completely overlap.\nThe length of the output is N - K + 1.\n\nParameters\n\n- **span_in_symbols** (*int*)  Filter span as measured by the number of symbols.\n- **samples_per_symbol** (*int*)  Number of samples per symbol, i.e., the oversampling factor.\n- **beta** (*float*)  Roll-off factor.\nMust be in the range $[0,1]$.\n- **window** (* or **string** (**[**\"hann\"**, **\"hamming\"**, **\"blackman\"**]**)*)  Instance of [`Window`](https://nvlabs.github.io/sionna/api/signal.html#sionna.signal.Window) that is applied to the filter coefficients.\nAlternatively, a string indicating the window name can be provided. In this case,\nthe chosen window will be instantiated with the default parameters. Custom windows\nmust be provided as instance.\n- **normalize** (*bool*)  If <cite>True</cite>, the filter is normalized to have unit power.\nDefaults to <cite>True</cite>.\n- **trainable** (*bool*)  If <cite>True</cite>, the filter coefficients are trainable variables.\nDefaults to <cite>False</cite>.\n- **dtype** (*tf.DType*)  The <cite>dtype</cite> of the filter coefficients.\nDefaults to <cite>tf.float32</cite>.\n\n\nInput\n\n- **x** (*[, N], tf.complex or tf.float*)  The input to which the filter is applied.\nThe filter is applied along the last dimension.\n- **padding** (*string ([full, valid, same])*)  Padding mode for convolving `x` and the filter.\nMust be one of full, valid, or same. Case insensitive.\nDefaults to full.\n- **conjugate** (*bool*)  If <cite>True</cite>, the complex conjugate of the filter is applied.\nDefaults to <cite>False</cite>.\n\n\nOutput\n\n**y** (*[,M], tf.complex or tf.float*)  Filtered input.\nIt is <cite>tf.float</cite> only if both `x` and the filter are <cite>tf.float</cite>.\nIt is <cite>tf.complex</cite> otherwise.\nThe length M depends on the `padding`.\n\n\n`property` `aclr`\n\nACLR of the filter\n\nThis ACLR corresponds to what one would obtain from using\nthis filter as pulse shaping filter on an i.i.d. sequence of symbols.\nThe in-band is assumed to range from [-0.5, 0.5] in normalized\nfrequency.\n\n\n`property` `beta`\n\nRoll-off factor\n\n\n`property` `coefficients`\n\nThe filter coefficients (after normalization)\n\n\n`property` `length`\n\nThe filter length in samples\n\n\n`property` `normalize`\n\n<cite>True</cite> if the filter is normalized to have unit power. <cite>False</cite> otherwise.\n\n\n`property` `sampling_times`\n\nSampling times in multiples of the symbol duration\n\n\n`show`(*`response``=``'impulse'`*, *`scale``=``'lin'`*)\n\nPlot the impulse or magnitude response\n\nPlots the impulse response (time domain) or magnitude response\n(frequency domain) of the filter.\n\nFor the computation of the magnitude response, a minimum DFT size\nof 1024 is assumed which is obtained through zero padding of\nthe filter coefficients in the time domain.\nInput\n\n- **response** (*str, one of [impulse, magnitude]*)  The desired response type.\nDefaults to impulse\n- **scale** (*str, one of [lin, db]*)  The y-scale of the magnitude response.\nCan be lin (i.e., linear) or db (, i.e., Decibel).\nDefaults to lin.\n\n\n`property` `trainable`\n\n<cite>True</cite> if the filter coefficients are trainable. <cite>False</cite> otherwise.\n\n\n`property` `window`\n\nThe window function that is applied to the filter coefficients. <cite>None</cite> if no window is applied."
"### CustomFilter\n\n`class` `sionna.signal.``CustomFilter`(*`span_in_symbols``=``None`*, *`samples_per_symbol``=``None`*, *`coefficients``=``None`*, *`window``=``None`*, *`normalize``=``True`*, *`trainable``=``False`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/signal/filter.html#CustomFilter)\n\nLayer for applying a custom filter of `length` K\nto an input `x` of length N.\n\nThe filter length K is equal to the filter span in symbols (`span_in_symbols`)\nmultiplied by the oversampling factor (`samples_per_symbol`).\nIf this product is even, a value of one will be added.\n\nThe filter is applied through discrete convolution.\n\nAn optional windowing function `window` can be applied to the filter.\n\nThe <cite>dtype</cite> of the output is <cite>tf.float</cite> if both `x` and the filter coefficients have dtype <cite>tf.float</cite>.\nOtherwise, the dtype of the output is <cite>tf.complex</cite>.\n\nThree padding modes are available for applying the filter:\n\n- full (default): Returns the convolution at each point of overlap between `x` and the filter.\nThe length of the output is N + K - 1. Zero-padding of the input `x` is performed to\ncompute the convolution at the borders.\n- same: Returns an output of the same length as the input `x`. The convolution is computed such\nthat the coefficients of the input `x` are centered on the coefficient of the filter with index\n(K-1)/2. Zero-padding of the input signal is performed to compute the convolution at the borders.\n- valid: Returns the convolution only at points where `x` and the filter completely overlap.\nThe length of the output is N - K + 1.\n\nParameters\n\n- **span_in_symbols** (*int*)  Filter span as measured by the number of symbols.\nOnly needs to be provided if `coefficients` is None.\n- **samples_per_symbol** (*int*)  Number of samples per symbol, i.e., the oversampling factor.\nMust always be provided.\n- **coefficients** (*[**K**]**, **tf.float** or **tf.complex*)  Optional filter coefficients.\nIf set to <cite>None</cite>, then a random filter of K is generated\nby sampling a Gaussian distribution. Defaults to <cite>None</cite>.\n- **window** (* or **string** (**[**\"hann\"**, **\"hamming\"**, **\"blackman\"**]**)*)  Instance of [`Window`](https://nvlabs.github.io/sionna/api/signal.html#sionna.signal.Window) that is applied to the filter coefficients.\nAlternatively, a string indicating the window name can be provided. In this case,\nthe chosen window will be instantiated with the default parameters. Custom windows\nmust be provided as instance.\n- **normalize** (*bool*)  If <cite>True</cite>, the filter is normalized to have unit power.\nDefaults to <cite>True</cite>.\n- **trainable** (*bool*)  If <cite>True</cite>, the filter coefficients are trainable variables.\nDefaults to <cite>False</cite>.\n- **dtype** (*tf.DType*)  The <cite>dtype</cite> of the filter coefficients.\nDefaults to <cite>tf.float32</cite>.\n\n\nInput\n\n- **x** (*[, N], tf.complex or tf.float*)  The input to which the filter is applied.\nThe filter is applied along the last dimension.\n- **padding** (*string ([full, valid, same])*)  Padding mode for convolving `x` and the filter.\nMust be one of full, valid, or same. Case insensitive.\nDefaults to full.\n- **conjugate** (*bool*)  If <cite>True</cite>, the complex conjugate of the filter is applied.\nDefaults to <cite>False</cite>.\n\n\nOutput\n\n**y** (*[,M], tf.complex or tf.float*)  Filtered input.\nIt is <cite>tf.float</cite> only if both `x` and the filter are <cite>tf.float</cite>.\nIt is <cite>tf.complex</cite> otherwise.\nThe length M depends on the `padding`.\n\n\n`property` `aclr`\n\nACLR of the filter\n\nThis ACLR corresponds to what one would obtain from using\nthis filter as pulse shaping filter on an i.i.d. sequence of symbols.\nThe in-band is assumed to range from [-0.5, 0.5] in normalized\nfrequency.\n\n\n`property` `coefficients`\n\nThe filter coefficients (after normalization)\n\n\n`property` `length`\n\nThe filter length in samples\n\n\n`property` `normalize`\n\n<cite>True</cite> if the filter is normalized to have unit power. <cite>False</cite> otherwise.\n\n\n`property` `sampling_times`\n\nSampling times in multiples of the symbol duration\n\n\n`show`(*`response``=``'impulse'`*, *`scale``=``'lin'`*)\n\nPlot the impulse or magnitude response\n\nPlots the impulse response (time domain) or magnitude response\n(frequency domain) of the filter.\n\nFor the computation of the magnitude response, a minimum DFT size\nof 1024 is assumed which is obtained through zero padding of\nthe filter coefficients in the time domain.\nInput\n\n- **response** (*str, one of [impulse, magnitude]*)  The desired response type.\nDefaults to impulse\n- **scale** (*str, one of [lin, db]*)  The y-scale of the magnitude response.\nCan be lin (i.e., linear) or db (, i.e., Decibel).\nDefaults to lin.\n\n\n`property` `trainable`\n\n<cite>True</cite> if the filter coefficients are trainable. <cite>False</cite> otherwise.\n\n\n`property` `window`\n\nThe window function that is applied to the filter coefficients. <cite>None</cite> if no window is applied."
"### Filter\n\n`class` `sionna.signal.``Filter`(*`span_in_symbols`*, *`samples_per_symbol`*, *`window``=``None`*, *`normalize``=``True`*, *`trainable``=``False`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/signal/filter.html#Filter)\n\nThis is an abtract class for defining a filter of `length` K which can be\napplied to an input `x` of length N.\n\nThe filter length K is equal to the filter span in symbols (`span_in_symbols`)\nmultiplied by the oversampling factor (`samples_per_symbol`).\nIf this product is even, a value of one will be added.\n\nThe filter is applied through discrete convolution.\n\nAn optional windowing function `window` can be applied to the filter.\n\nThe <cite>dtype</cite> of the output is <cite>tf.float</cite> if both `x` and the filter coefficients have dtype <cite>tf.float</cite>.\nOtherwise, the dtype of the output is <cite>tf.complex</cite>.\n\nThree padding modes are available for applying the filter:\n\n- full (default): Returns the convolution at each point of overlap between `x` and the filter.\nThe length of the output is N + K - 1. Zero-padding of the input `x` is performed to\ncompute the convolution at the borders.\n- same: Returns an output of the same length as the input `x`. The convolution is computed such\nthat the coefficients of the input `x` are centered on the coefficient of the filter with index\n(K-1)/2. Zero-padding of the input signal is performed to compute the convolution at the borders.\n- valid: Returns the convolution only at points where `x` and the filter completely overlap.\nThe length of the output is N - K + 1.\n\nParameters\n\n- **span_in_symbols** (*int*)  Filter span as measured by the number of symbols.\n- **samples_per_symbol** (*int*)  Number of samples per symbol, i.e., the oversampling factor.\n- **window** (* or **string** (**[**\"hann\"**, **\"hamming\"**, **\"blackman\"**]**)*)  Instance of [`Window`](https://nvlabs.github.io/sionna/api/signal.html#sionna.signal.Window) that is applied to the filter coefficients.\nAlternatively, a string indicating the window name can be provided. In this case,\nthe chosen window will be instantiated with the default parameters. Custom windows\nmust be provided as instance.\n- **normalize** (*bool*)  If <cite>True</cite>, the filter is normalized to have unit power.\nDefaults to <cite>True</cite>.\n- **trainable** (*bool*)  If <cite>True</cite>, the filter coefficients are trainable.\nDefaults to <cite>False</cite>.\n- **dtype** (*tf.DType*)  The <cite>dtype</cite> of the filter coefficients.\nDefaults to <cite>tf.float32</cite>.\n\n\nInput\n\n- **x** (*[, N], tf.complex or tf.float*)  The input to which the filter is applied.\nThe filter is applied along the last dimension.\n- **padding** (*string ([full, valid, same])*)  Padding mode for convolving `x` and the filter.\nMust be one of full, valid, or same. Case insensitive.\nDefaults to full.\n- **conjugate** (*bool*)  If <cite>True</cite>, the complex conjugate of the filter is applied.\nDefaults to <cite>False</cite>.\n\n\nOutput\n\n**y** (*[,M], tf.complex or tf.float*)  Filtered input.\nIt is <cite>tf.float</cite> only if both `x` and the filter are <cite>tf.float</cite>.\nIt is <cite>tf.complex</cite> otherwise.\nThe length M depends on the `padding`.\n\n\n`property` `aclr`\n\nACLR of the filter\n\nThis ACLR corresponds to what one would obtain from using\nthis filter as pulse shaping filter on an i.i.d. sequence of symbols.\nThe in-band is assumed to range from [-0.5, 0.5] in normalized\nfrequency.\n\n\n`property` `coefficients`\n\nThe filter coefficients (after normalization)\n\n\n`property` `length`\n\nThe filter length in samples\n\n\n`property` `normalize`\n\n<cite>True</cite> if the filter is normalized to have unit power. <cite>False</cite> otherwise.\n\n\n`property` `sampling_times`\n\nSampling times in multiples of the symbol duration\n\n\n`show`(*`response``=``'impulse'`*, *`scale``=``'lin'`*)[`[source]`](../_modules/sionna/signal/filter.html#Filter.show)\n\nPlot the impulse or magnitude response\n\nPlots the impulse response (time domain) or magnitude response\n(frequency domain) of the filter.\n\nFor the computation of the magnitude response, a minimum DFT size\nof 1024 is assumed which is obtained through zero padding of\nthe filter coefficients in the time domain.\nInput\n\n- **response** (*str, one of [impulse, magnitude]*)  The desired response type.\nDefaults to impulse\n- **scale** (*str, one of [lin, db]*)  The y-scale of the magnitude response.\nCan be lin (i.e., linear) or db (, i.e., Decibel).\nDefaults to lin.\n\n\n`property` `trainable`\n\n<cite>True</cite> if the filter coefficients are trainable. <cite>False</cite> otherwise.\n\n\n`property` `window`\n\nThe window function that is applied to the filter coefficients. <cite>None</cite> if no window is applied."
"### HannWindow\n\n`class` `sionna.signal.``HannWindow`(*`length`*, *`trainable``=``False`*, *`normalize``=``False`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/signal/window.html#HannWindow)\n\nLayer for applying a Hann window function of length `length` to an input `x` of the same length.\n\nThe window function is applied through element-wise multiplication.\n\nThe window function is real-valued, i.e., has <cite>tf.float</cite> as <cite>dtype</cite>.\nThe <cite>dtype</cite> of the output is the same as the <cite>dtype</cite> of the input `x` to which the window function is applied.\nThe window function and the input must have the same precision.\n\nThe Hann window is defined by\n\n$$\nw_n = \\sin^2 \\left( \\frac{\\pi n}{N} \\right), 0 \\leq n \\leq N-1\n$$\n\nwhere $N$ is the window length.\nParameters\n\n- **length** (*int*)  Window length (number of samples).\n- **trainable** (*bool*)  If <cite>True</cite>, the window coefficients are trainable variables.\nDefaults to <cite>False</cite>.\n- **normalize** (*bool*)  If <cite>True</cite>, the window is normalized to have unit average power\nper coefficient.\nDefaults to <cite>False</cite>.\n- **dtype** (*tf.DType*)  The <cite>dtype</cite> of the filter coefficients.\nMust be either <cite>tf.float32</cite> or <cite>tf.float64</cite>.\nDefaults to <cite>tf.float32</cite>.\n\n\nInput\n\n**x** (*[, N], tf.complex or tf.float*)  The input to which the window function is applied.\nThe window function is applied along the last dimension.\nThe length of the last dimension `N` must be the same as the `length` of the window function.\n\nOutput\n\n**y** (*[,N], tf.complex or tf.float*)  Output of the windowing operation.\nThe output has the same shape and <cite>dtype</cite> as the input `x`.\n\n\n`property` `coefficients`\n\nThe window coefficients (after normalization)\n\n\n`property` `length`\n\nWindow length in number of samples\n\n\n`property` `normalize`\n\n<cite>True</cite> if the window is normalized to have unit average power per coefficient. <cite>False</cite>\notherwise.\n\n\n`show`(*`samples_per_symbol`*, *`domain``=``'time'`*, *`scale``=``'lin'`*)\n\nPlot the window in time or frequency domain\n\nFor the computation of the Fourier transform, a minimum DFT size\nof 1024 is assumed which is obtained through zero padding of\nthe window coefficients in the time domain.\nInput\n\n- **samples_per_symbol** (*int*)  Number of samples per symbol, i.e., the oversampling factor.\n- **domain** (*str, one of [time, frequency]*)  The desired domain.\nDefaults to time\n- **scale** (*str, one of [lin, db]*)  The y-scale of the magnitude in the frequency domain.\nCan be lin (i.e., linear) or db (, i.e., Decibel).\nDefaults to lin.\n\n\n`property` `trainable`\n\n<cite>True</cite> if the window coefficients are trainable. <cite>False</cite> otherwise."
"### HammingWindow\n\n`class` `sionna.signal.``HammingWindow`(*`length`*, *`trainable``=``False`*, *`normalize``=``False`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/signal/window.html#HammingWindow)\n\nLayer for applying a Hamming window function of length `length` to an input `x` of the same length.\n\nThe window function is applied through element-wise multiplication.\n\nThe window function is real-valued, i.e., has <cite>tf.float</cite> as <cite>dtype</cite>.\nThe <cite>dtype</cite> of the output is the same as the <cite>dtype</cite> of the input `x` to which the window function is applied.\nThe window function and the input must have the same precision.\n\nThe Hamming window is defined by\n\n$$\nw_n = a_0 - (1-a_0) \\cos \\left( \\frac{2 \\pi n}{N} \\right), 0 \\leq n \\leq N-1\n$$\n\nwhere $N$ is the window length and $a_0 = \\frac{25}{46}$.\nParameters\n\n- **length** (*int*)  Window length (number of samples).\n- **trainable** (*bool*)  If <cite>True</cite>, the window coefficients are trainable variables.\nDefaults to <cite>False</cite>.\n- **normalize** (*bool*)  If <cite>True</cite>, the window is normalized to have unit average power\nper coefficient.\nDefaults to <cite>False</cite>.\n- **dtype** (*tf.DType*)  The <cite>dtype</cite> of the filter coefficients.\nMust be either <cite>tf.float32</cite> or <cite>tf.float64</cite>.\nDefaults to <cite>tf.float32</cite>.\n\n\nInput\n\n**x** (*[, N], tf.complex or tf.float*)  The input to which the window function is applied.\nThe window function is applied along the last dimension.\nThe length of the last dimension `N` must be the same as the `length` of the window function.\n\nOutput\n\n**y** (*[,N], tf.complex or tf.float*)  Output of the windowing operation.\nThe output has the same shape and <cite>dtype</cite> as the input `x`.\n\n\n`property` `coefficients`\n\nThe window coefficients (after normalization)\n\n\n`property` `length`\n\nWindow length in number of samples\n\n\n`property` `normalize`\n\n<cite>True</cite> if the window is normalized to have unit average power per coefficient. <cite>False</cite>\notherwise.\n\n\n`show`(*`samples_per_symbol`*, *`domain``=``'time'`*, *`scale``=``'lin'`*)\n\nPlot the window in time or frequency domain\n\nFor the computation of the Fourier transform, a minimum DFT size\nof 1024 is assumed which is obtained through zero padding of\nthe window coefficients in the time domain.\nInput\n\n- **samples_per_symbol** (*int*)  Number of samples per symbol, i.e., the oversampling factor.\n- **domain** (*str, one of [time, frequency]*)  The desired domain.\nDefaults to time\n- **scale** (*str, one of [lin, db]*)  The y-scale of the magnitude in the frequency domain.\nCan be lin (i.e., linear) or db (, i.e., Decibel).\nDefaults to lin.\n\n\n`property` `trainable`\n\n<cite>True</cite> if the window coefficients are trainable. <cite>False</cite> otherwise."
"### BlackmanWindow\n\n`class` `sionna.signal.``BlackmanWindow`(*`length`*, *`trainable``=``False`*, *`normalize``=``False`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/signal/window.html#BlackmanWindow)\n\nLayer for applying a Blackman window function of length `length` to an input `x` of the same length.\n\nThe window function is applied through element-wise multiplication.\n\nThe window function is real-valued, i.e., has <cite>tf.float</cite> as <cite>dtype</cite>.\nThe <cite>dtype</cite> of the output is the same as the <cite>dtype</cite> of the input `x` to which the window function is applied.\nThe window function and the input must have the same precision.\n\nThe Blackman window is defined by\n\n$$\nw_n = a_0 - a_1 \\cos \\left( \\frac{2 \\pi n}{N} \\right) + a_2 \\cos \\left( \\frac{4 \\pi n}{N} \\right), 0 \\leq n \\leq N-1\n$$\n\nwhere $N$ is the window length, $a_0 = \\frac{7938}{18608}$, $a_1 = \\frac{9240}{18608}$, and $a_2 = \\frac{1430}{18608}$.\nParameters\n\n- **length** (*int*)  Window length (number of samples).\n- **trainable** (*bool*)  If <cite>True</cite>, the window coefficients are trainable variables.\nDefaults to <cite>False</cite>.\n- **normalize** (*bool*)  If <cite>True</cite>, the window is normalized to have unit average power\nper coefficient.\nDefaults to <cite>False</cite>.\n- **dtype** (*tf.DType*)  The <cite>dtype</cite> of the filter coefficients.\nMust be either <cite>tf.float32</cite> or <cite>tf.float64</cite>.\nDefaults to <cite>tf.float32</cite>.\n\n\nInput\n\n**x** (*[, N], tf.complex or tf.float*)  The input to which the window function is applied.\nThe window function is applied along the last dimension.\nThe length of the last dimension `N` must be the same as the `length` of the window function.\n\nOutput\n\n**y** (*[,N], tf.complex or tf.float*)  Output of the windowing operation.\nThe output has the same shape and <cite>dtype</cite> as the input `x`.\n\n\n`property` `coefficients`\n\nThe window coefficients (after normalization)\n\n\n`property` `length`\n\nWindow length in number of samples\n\n\n`property` `normalize`\n\n<cite>True</cite> if the window is normalized to have unit average power per coefficient. <cite>False</cite>\notherwise.\n\n\n`show`(*`samples_per_symbol`*, *`domain``=``'time'`*, *`scale``=``'lin'`*)\n\nPlot the window in time or frequency domain\n\nFor the computation of the Fourier transform, a minimum DFT size\nof 1024 is assumed which is obtained through zero padding of\nthe window coefficients in the time domain.\nInput\n\n- **samples_per_symbol** (*int*)  Number of samples per symbol, i.e., the oversampling factor.\n- **domain** (*str, one of [time, frequency]*)  The desired domain.\nDefaults to time\n- **scale** (*str, one of [lin, db]*)  The y-scale of the magnitude in the frequency domain.\nCan be lin (i.e., linear) or db (, i.e., Decibel).\nDefaults to lin.\n\n\n`property` `trainable`\n\n<cite>True</cite> if the window coefficients are trainable. <cite>False</cite> otherwise."
"### CustomWindow\n\n`class` `sionna.signal.``CustomWindow`(*`length`*, *`coefficients``=``None`*, *`trainable``=``False`*, *`normalize``=``False`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/signal/window.html#CustomWindow)\n\nLayer for defining and applying a custom window function of length `length` to an input `x` of the same length.\n\nThe window function is applied through element-wise multiplication.\n\nThe window function is real-valued, i.e., has <cite>tf.float</cite> as <cite>dtype</cite>.\nThe <cite>dtype</cite> of the output is the same as the <cite>dtype</cite> of the input `x` to which the window function is applied.\nThe window function and the input must have the same precision.\n\nThe window coefficients can be set through the `coefficients` parameter.\nIf not provided, random window coefficients are generated by sampling a Gaussian distribution.\nParameters\n\n- **length** (*int*)  Window length (number of samples).\n- **coefficients** (*[**N**]**, **tf.float*)  Optional window coefficients.\nIf set to <cite>None</cite>, then a random window of length `length` is generated by sampling a Gaussian distribution.\nDefaults to <cite>None</cite>.\n- **trainable** (*bool*)  If <cite>True</cite>, the window coefficients are trainable variables.\nDefaults to <cite>False</cite>.\n- **normalize** (*bool*)  If <cite>True</cite>, the window is normalized to have unit average power\nper coefficient.\nDefaults to <cite>False</cite>.\n- **dtype** (*tf.DType*)  The <cite>dtype</cite> of the filter coefficients.\nMust be either <cite>tf.float32</cite> or <cite>tf.float64</cite>.\nDefaults to <cite>tf.float32</cite>.\n\n\nInput\n\n**x** (*[, N], tf.complex or tf.float*)  The input to which the window function is applied.\nThe window function is applied along the last dimension.\nThe length of the last dimension `N` must be the same as the `length` of the window function.\n\nOutput\n\n**y** (*[,N], tf.complex or tf.float*)  Output of the windowing operation.\nThe output has the same shape and <cite>dtype</cite> as the input `x`.\n\n\n`property` `coefficients`\n\nThe window coefficients (after normalization)\n\n\n`property` `length`\n\nWindow length in number of samples\n\n\n`property` `normalize`\n\n<cite>True</cite> if the window is normalized to have unit average power per coefficient. <cite>False</cite>\notherwise.\n\n\n`show`(*`samples_per_symbol`*, *`domain``=``'time'`*, *`scale``=``'lin'`*)\n\nPlot the window in time or frequency domain\n\nFor the computation of the Fourier transform, a minimum DFT size\nof 1024 is assumed which is obtained through zero padding of\nthe window coefficients in the time domain.\nInput\n\n- **samples_per_symbol** (*int*)  Number of samples per symbol, i.e., the oversampling factor.\n- **domain** (*str, one of [time, frequency]*)  The desired domain.\nDefaults to time\n- **scale** (*str, one of [lin, db]*)  The y-scale of the magnitude in the frequency domain.\nCan be lin (i.e., linear) or db (, i.e., Decibel).\nDefaults to lin.\n\n\n`property` `trainable`\n\n<cite>True</cite> if the window coefficients are trainable. <cite>False</cite> otherwise."
"### Window\n\n`class` `sionna.signal.``Window`(*`length`*, *`trainable``=``False`*, *`normalize``=``False`*, *`dtype``=``tf.float32`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/signal/window.html#Window)\n\nThis is an abtract class for defining and applying a window function of length `length` to an input `x` of the same length.\n\nThe window function is applied through element-wise multiplication.\n\nThe window function is real-valued, i.e., has <cite>tf.float</cite> as <cite>dtype</cite>.\nThe <cite>dtype</cite> of the output is the same as the <cite>dtype</cite> of the input `x` to which the window function is applied.\nThe window function and the input must have the same precision.\nParameters\n\n- **length** (*int*)  Window length (number of samples).\n- **trainable** (*bool*)  If <cite>True</cite>, the window coefficients are trainable variables.\nDefaults to <cite>False</cite>.\n- **normalize** (*bool*)  If <cite>True</cite>, the window is normalized to have unit average power\nper coefficient.\nDefaults to <cite>False</cite>.\n- **dtype** (*tf.DType*)  The <cite>dtype</cite> of the filter coefficients.\nMust be either <cite>tf.float32</cite> or <cite>tf.float64</cite>.\nDefaults to <cite>tf.float32</cite>.\n\n\nInput\n\n**x** (*[, N], tf.complex or tf.float*)  The input to which the window function is applied.\nThe window function is applied along the last dimension.\nThe length of the last dimension `N` must be the same as the `length` of the window function.\n\nOutput\n\n**y** (*[,N], tf.complex or tf.float*)  Output of the windowing operation.\nThe output has the same shape and <cite>dtype</cite> as the input `x`.\n\n\n`property` `coefficients`\n\nThe window coefficients (after normalization)\n\n\n`property` `length`\n\nWindow length in number of samples\n\n\n`property` `normalize`\n\n<cite>True</cite> if the window is normalized to have unit average power per coefficient. <cite>False</cite>\notherwise.\n\n\n`show`(*`samples_per_symbol`*, *`domain``=``'time'`*, *`scale``=``'lin'`*)[`[source]`](../_modules/sionna/signal/window.html#Window.show)\n\nPlot the window in time or frequency domain\n\nFor the computation of the Fourier transform, a minimum DFT size\nof 1024 is assumed which is obtained through zero padding of\nthe window coefficients in the time domain.\nInput\n\n- **samples_per_symbol** (*int*)  Number of samples per symbol, i.e., the oversampling factor.\n- **domain** (*str, one of [time, frequency]*)  The desired domain.\nDefaults to time\n- **scale** (*str, one of [lin, db]*)  The y-scale of the magnitude in the frequency domain.\nCan be lin (i.e., linear) or db (, i.e., Decibel).\nDefaults to lin.\n\n\n`property` `trainable`\n\n<cite>True</cite> if the window coefficients are trainable. <cite>False</cite> otherwise."
"### convolve\n\n`sionna.signal.``convolve`(*`inp`*, *`ker`*, *`padding``=``'full'`*, *`axis``=``-` `1`*)[`[source]`](../_modules/sionna/signal/utils.html#convolve)\n\nFilters an input `inp` of length <cite>N</cite> by convolving it with a kernel `ker` of length <cite>K</cite>.\n\nThe length of the kernel `ker` must not be greater than the one of the input sequence `inp`.\n\nThe <cite>dtype</cite> of the output is <cite>tf.float</cite> only if both `inp` and `ker` are <cite>tf.float</cite>. It is <cite>tf.complex</cite> otherwise.\n`inp` and `ker` must have the same precision.\n\nThree padding modes are available:\n\n- full (default): Returns the convolution at each point of overlap between `ker` and `inp`.\nThe length of the output is <cite>N + K - 1</cite>. Zero-padding of the input `inp` is performed to\ncompute the convolution at the border points.\n- same: Returns an output of the same length as the input `inp`. The convolution is computed such\nthat the coefficients of the input `inp` are centered on the coefficient of the kernel `ker` with index\n`(K-1)/2` for kernels of odd length, and `K/2` `-` `1` for kernels of even length.\nZero-padding of the input signal is performed to compute the convolution at the border points.\n- valid: Returns the convolution only at points where `inp` and `ker` completely overlap.\nThe length of the output is <cite>N - K + 1</cite>.\n\nInput\n\n- **inp** (*[,N], tf.complex or tf.real*)  Input to filter.\n- **ker** (*[K], tf.complex or tf.real*)  Kernel of the convolution.\n- **padding** (*string*)  Padding mode. Must be one of full, valid, or same. Case insensitive.\nDefaults to full.\n- **axis** (*int*)  Axis along which to perform the convolution.\nDefaults to <cite>-1</cite>.\n\n\nOutput\n\n**out** (*[,M], tf.complex or tf.float*)  Convolution output.\nIt is <cite>tf.float</cite> only if both `inp` and `ker` are <cite>tf.float</cite>. It is <cite>tf.complex</cite> otherwise.\nThe length <cite>M</cite> of the output depends on the `padding`."
"### fft\n\n`sionna.signal.``fft`(*`tensor`*, *`axis``=``-` `1`*)[`[source]`](../_modules/sionna/signal/utils.html#fft)\n\nComputes the normalized DFT along a specified axis.\n\nThis operation computes the normalized one-dimensional discrete Fourier\ntransform (DFT) along the `axis` dimension of a `tensor`.\nFor a vector $\\mathbf{x}\\in\\mathbb{C}^N$, the DFT\n$\\mathbf{X}\\in\\mathbb{C}^N$ is computed as\n\n$$\nX_m = \\frac{1}{\\sqrt{N}}\\sum_{n=0}^{N-1} x_n \\exp \\left\\{\n    -j2\\pi\\frac{mn}{N}\\right\\},\\quad m=0,\\dots,N-1.\n$$\n\nInput\n\n- **tensor** (*tf.complex*)  Tensor of arbitrary shape.\n- **axis** (*int*)  Indicates the dimension along which the DFT is taken.\n\n\nOutput\n\n*tf.complex*  Tensor of the same dtype and shape as `tensor`."
"### ifft\n\n`sionna.signal.``ifft`(*`tensor`*, *`axis``=``-` `1`*)[`[source]`](../_modules/sionna/signal/utils.html#ifft)\n\nComputes the normalized IDFT along a specified axis.\n\nThis operation computes the normalized one-dimensional discrete inverse\nFourier transform (IDFT) along the `axis` dimension of a `tensor`.\nFor a vector $\\mathbf{X}\\in\\mathbb{C}^N$, the IDFT\n$\\mathbf{x}\\in\\mathbb{C}^N$ is computed as\n\n$$\nx_n = \\frac{1}{\\sqrt{N}}\\sum_{m=0}^{N-1} X_m \\exp \\left\\{\n    j2\\pi\\frac{mn}{N}\\right\\},\\quad n=0,\\dots,N-1.\n$$\n\nInput\n\n- **tensor** (*tf.complex*)  Tensor of arbitrary shape.\n- **axis** (*int*)  Indicates the dimension along which the IDFT is taken.\n\n\nOutput\n\n*tf.complex*  Tensor of the same dtype and shape as `tensor`."
"### Upsampling\n\n`class` `sionna.signal.``Upsampling`(*`samples_per_symbol`*, *`axis``=``-` `1`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/signal/upsampling.html#Upsampling)\n\nUpsamples a tensor along a specified axis by inserting zeros\nbetween samples.\nParameters\n\n- **samples_per_symbol** (*int*)  The upsampling factor. If `samples_per_symbol` is equal to <cite>n</cite>,\nthen the upsampled axis will be <cite>n</cite>-times longer.\n- **axis** (*int*)  The dimension to be up-sampled. Must not be the first dimension.\n\n\nInput\n\n**x** (*[,n,], tf.DType*)  The tensor to be upsampled. <cite>n</cite> is the size of the <cite>axis</cite> dimension.\n\nOutput\n\n**y** ([,n*samples_per_symbol,], same dtype as `x`)  The upsampled tensor."
"### Downsampling\n\n`class` `sionna.signal.``Downsampling`(*`samples_per_symbol`*, *`offset``=``0`*, *`num_symbols``=``None`*, *`axis``=``-` `1`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/signal/downsampling.html#Downsampling)\n\nDownsamples a tensor along a specified axis by retaining one out of\n`samples_per_symbol` elements.\nParameters\n\n- **samples_per_symbol** (*int*)  The downsampling factor. If `samples_per_symbol` is equal to <cite>n</cite>, then the\ndownsampled axis will be <cite>n</cite>-times shorter.\n- **offset** (*int*)  Defines the index of the first element to be retained.\nDefaults to zero.\n- **num_symbols** (*int*)  Defines the total number of symbols to be retained after\ndownsampling.\nDefaults to None (i.e., the maximum possible number).\n- **axis** (*int*)  The dimension to be downsampled. Must not be the first dimension.\n\n\nInput\n\n**x** (*[,n,], tf.DType*)  The tensor to be downsampled. <cite>n</cite> is the size of the <cite>axis</cite> dimension.\n\nOutput\n\n**y** ([,k,], same dtype as `x`)  The downsampled tensor, where `k`\nis min((`n`-`offset`)//`samples_per_symbol`, `num_symbols`)."
"### empirical_psd\n\n`sionna.signal.``empirical_psd`(*`x`*, *`show``=``True`*, *`oversampling``=``1.0`*, *`ylim``=``(-` `30,` `3)`*)[`[source]`](../_modules/sionna/signal/utils.html#empirical_psd)\n\nComputes the empirical power spectral density.\n\nComputes the empirical power spectral density (PSD) of tensor `x`\nalong the last dimension by averaging over all other dimensions.\nNote that this function\nsimply returns the averaged absolute squared discrete Fourier\nspectrum of `x`.\nInput\n\n- **x** (*[,N], tf.complex*)  The signal of which to compute the PSD.\n- **show** (*bool*)  Indicates if a plot of the PSD should be generated.\nDefaults to True,\n- **oversampling** (*float*)  The oversampling factor. Defaults to 1.\n- **ylim** (*tuple of floats*)  The limits of the y axis. Defaults to [-30, 3].\nOnly relevant if `show` is True.\n\n\nOutput\n\n- **freqs** (*[N], float*)  The normalized frequencies at which the PSD was evaluated.\n- **psd** (*[N], float*)  The PSD."
"### empirical_aclr\n\n`sionna.signal.``empirical_aclr`(*`x`*, *`oversampling``=``1.0`*, *`f_min``=``-` `0.5`*, *`f_max``=``0.5`*)[`[source]`](../_modules/sionna/signal/utils.html#empirical_aclr)\n\nComputes the empirical ACLR.\n\nComputes the empirical adjacent channel leakgae ration (ACLR)\nof tensor `x` based on its empirical power spectral density (PSD)\nwhich is computed along the last dimension by averaging over\nall other dimensions.\n\nIt is assumed that the in-band ranges from [`f_min`, `f_max`] in\nnormalized frequency. The ACLR is then defined as\n\n$$\n\\text{ACLR} = \\frac{P_\\text{out}}{P_\\text{in}}\n$$\n\nwhere $P_\\text{in}$ and $P_\\text{out}$ are the in-band\nand out-of-band power, respectively.\nInput\n\n- **x** (*[,N],  complex*)  The signal for which to compute the ACLR.\n- **oversampling** (*float*)  The oversampling factor. Defaults to 1.\n- **f_min** (*float*)  The lower border of the in-band in normalized frequency.\nDefaults to -0.5.\n- **f_max** (*float*)  The upper border of the in-band in normalized frequency.\nDefaults to 0.5.\n\n\nOutput\n\n**aclr** (*float*)  The ACLR in linear scale."
"### BitErrorRate\n\n`class` `sionna.utils.``BitErrorRate`(*`name``=``'bit_error_rate'`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/utils/metrics.html#BitErrorRate)\n\nComputes the average bit error rate (BER) between two binary tensors.\n\nThis class implements a Keras metric for the bit error rate\nbetween two tensors of bits.\nInput\n\n- **b** (*tf.float32*)  A tensor of arbitrary shape filled with ones and\nzeros.\n- **b_hat** (*tf.float32*)  A tensor of the same shape as `b` filled with\nones and zeros.\n\n\nOutput\n\n*tf.float32*  A scalar, the BER."
"### BitwiseMutualInformation\n\n`class` `sionna.utils.``BitwiseMutualInformation`(*`name``=``'bitwise_mutual_information'`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/utils/metrics.html#BitwiseMutualInformation)\n\nComputes the bitwise mutual information between bits and LLRs.\n\nThis class implements a Keras metric for the bitwise mutual information\nbetween a tensor of bits and LLR (logits).\nInput\n\n- **bits** (*tf.float32*)  A tensor of arbitrary shape filled with ones and zeros.\n- **llr** (*tf.float32*)  A tensor of the same shape as `bits` containing logits.\n\n\nOutput\n\n*tf.float32*  A scalar, the bit-wise mutual information."
"### compute_ber\n\n`sionna.utils.``compute_ber`(*`b`*, *`b_hat`*)[`[source]`](../_modules/sionna/utils/metrics.html#compute_ber)\n\nComputes the bit error rate (BER) between two binary tensors.\nInput\n\n- **b** (*tf.float32*)  A tensor of arbitrary shape filled with ones and\nzeros.\n- **b_hat** (*tf.float32*)  A tensor of the same shape as `b` filled with\nones and zeros.\n\n\nOutput\n\n*tf.float64*  A scalar, the BER."
"### compute_bler\n\n`sionna.utils.``compute_bler`(*`b`*, *`b_hat`*)[`[source]`](../_modules/sionna/utils/metrics.html#compute_bler)\n\nComputes the block error rate (BLER) between two binary tensors.\n\nA block error happens if at least one element of `b` and `b_hat`\ndiffer in one block. The BLER is evaluated over the last dimension of\nthe input, i. e., all elements of the last dimension are considered to\ndefine a block.\n\nThis is also sometimes referred to as <cite>word error rate</cite> or <cite>frame error\nrate</cite>.\nInput\n\n- **b** (*tf.float32*)  A tensor of arbitrary shape filled with ones and\nzeros.\n- **b_hat** (*tf.float32*)  A tensor of the same shape as `b` filled with\nones and zeros.\n\n\nOutput\n\n*tf.float64*  A scalar, the BLER."
"### compute_ser\n\n`sionna.utils.``compute_ser`(*`s`*, *`s_hat`*)[`[source]`](../_modules/sionna/utils/metrics.html#compute_ser)\n\nComputes the symbol error rate (SER) between two integer tensors.\nInput\n\n- **s** (*tf.int*)  A tensor of arbitrary shape filled with integers indicating\nthe symbol indices.\n- **s_hat** (*tf.int*)  A tensor of the same shape as `s` filled with integers indicating\nthe estimated symbol indices.\n\n\nOutput\n\n*tf.float64*  A scalar, the SER."
"### count_errors\n\n`sionna.utils.``count_errors`(*`b`*, *`b_hat`*)[`[source]`](../_modules/sionna/utils/metrics.html#count_errors)\n\nCounts the number of bit errors between two binary tensors.\nInput\n\n- **b** (*tf.float32*)  A tensor of arbitrary shape filled with ones and\nzeros.\n- **b_hat** (*tf.float32*)  A tensor of the same shape as `b` filled with\nones and zeros.\n\n\nOutput\n\n*tf.int64*  A scalar, the number of bit errors."
"### count_block_errors\n\n`sionna.utils.``count_block_errors`(*`b`*, *`b_hat`*)[`[source]`](../_modules/sionna/utils/metrics.html#count_block_errors)\n\nCounts the number of block errors between two binary tensors.\n\nA block error happens if at least one element of `b` and `b_hat`\ndiffer in one block. The BLER is evaluated over the last dimension of\nthe input, i. e., all elements of the last dimension are considered to\ndefine a block.\n\nThis is also sometimes referred to as <cite>word error rate</cite> or <cite>frame error\nrate</cite>.\nInput\n\n- **b** (*tf.float32*)  A tensor of arbitrary shape filled with ones and\nzeros.\n- **b_hat** (*tf.float32*)  A tensor of the same shape as `b` filled with\nones and zeros.\n\n\nOutput\n\n*tf.int64*  A scalar, the number of block errors."
"### expand_to_rank\n\n`sionna.utils.``expand_to_rank`(*`tensor`*, *`target_rank`*, *`axis``=``-` `1`*)[`[source]`](../_modules/sionna/utils/tensors.html#expand_to_rank)\n\nInserts as many axes to a tensor as needed to achieve a desired rank.\n\nThis operation inserts additional dimensions to a `tensor` starting at\n`axis`, so that so that the rank of the resulting tensor has rank\n`target_rank`. The dimension index follows Python indexing rules, i.e.,\nzero-based, where a negative index is counted backward from the end.\nParameters\n\n- **tensor**  A tensor.\n- **target_rank** (*int*)  The rank of the output tensor.\nIf `target_rank` is smaller than the rank of `tensor`,\nthe function does nothing.\n- **axis** (*int*)  The dimension index at which to expand the\nshape of `tensor`. Given a `tensor` of <cite>D</cite> dimensions,\n`axis` must be within the range <cite>[-(D+1), D]</cite> (inclusive).\n\n\nReturns\n\nA tensor with the same data as `tensor`, with\n`target_rank`- rank(`tensor`) additional dimensions inserted at the\nindex specified by `axis`.\nIf `target_rank` <= rank(`tensor`), `tensor` is returned."
"### flatten_dims\n\n`sionna.utils.``flatten_dims`(*`tensor`*, *`num_dims`*, *`axis`*)[`[source]`](../_modules/sionna/utils/tensors.html#flatten_dims)\n\nFlattens a specified set of dimensions of a tensor.\n\nThis operation flattens `num_dims` dimensions of a `tensor`\nstarting at a given `axis`.\nParameters\n\n- **tensor**  A tensor.\n- **num_dims** (*int*)  The number of dimensions\nto combine. Must be larger than two and less or equal than the\nrank of `tensor`.\n- **axis** (*int*)  The index of the dimension from which to start.\n\n\nReturns\n\nA tensor of the same type as `tensor` with `num_dims`-1 lesser\ndimensions, but the same number of elements."
"### flatten_last_dims\n\n`sionna.utils.``flatten_last_dims`(*`tensor`*, *`num_dims``=``2`*)[`[source]`](../_modules/sionna/utils/tensors.html#flatten_last_dims)\n\nFlattens the last <cite>n</cite> dimensions of a tensor.\n\nThis operation flattens the last `num_dims` dimensions of a `tensor`.\nIt is a simplified version of the function `flatten_dims`.\nParameters\n\n- **tensor**  A tensor.\n- **num_dims** (*int*)  The number of dimensions\nto combine. Must be greater than or equal to two and less or equal\nthan the rank of `tensor`.\n\n\nReturns\n\nA tensor of the same type as `tensor` with `num_dims`-1 lesser\ndimensions, but the same number of elements."
"### insert_dims\n\n`sionna.utils.``insert_dims`(*`tensor`*, *`num_dims`*, *`axis``=``-` `1`*)[`[source]`](../_modules/sionna/utils/tensors.html#insert_dims)\n\nAdds multiple length-one dimensions to a tensor.\n\nThis operation is an extension to TensorFlow`s `expand_dims` function.\nIt inserts `num_dims` dimensions of length one starting from the\ndimension `axis` of a `tensor`. The dimension\nindex follows Python indexing rules, i.e., zero-based, where a negative\nindex is counted backward from the end.\nParameters\n\n- **tensor**  A tensor.\n- **num_dims** (*int*)  The number of dimensions to add.\n- **axis**  The dimension index at which to expand the\nshape of `tensor`. Given a `tensor` of <cite>D</cite> dimensions,\n`axis` must be within the range <cite>[-(D+1), D]</cite> (inclusive).\n\n\nReturns\n\nA tensor with the same data as `tensor`, with `num_dims` additional\ndimensions inserted at the index specified by `axis`."
"### split_dims\n\n`sionna.utils.``split_dim`(*`tensor`*, *`shape`*, *`axis`*)[`[source]`](../_modules/sionna/utils/tensors.html#split_dim)\n\nReshapes a dimension of a tensor into multiple dimensions.\n\nThis operation splits the dimension `axis` of a `tensor` into\nmultiple dimensions according to `shape`.\nParameters\n\n- **tensor**  A tensor.\n- **shape** (*list** or **TensorShape*)  The shape to which the dimension should\nbe reshaped.\n- **axis** (*int*)  The index of the axis to be reshaped.\n\n\nReturns\n\nA tensor of the same type as `tensor` with len(`shape`)-1\nadditional dimensions, but the same number of elements."
"### matrix_sqrt\n\n`sionna.utils.``matrix_sqrt`(*`tensor`*)[`[source]`](../_modules/sionna/utils/tensors.html#matrix_sqrt)\n\nComputes the square root of a matrix.\n\nGiven a batch of Hermitian positive semi-definite matrices\n$\\mathbf{A}$, returns matrices $\\mathbf{B}$,\nsuch that $\\mathbf{B}\\mathbf{B}^H = \\mathbf{A}$.\n\nThe two inner dimensions are assumed to correspond to the matrix rows\nand columns, respectively.\nParameters\n\n**tensor** (*[**...**, **M**, **M**]*)  A tensor of rank greater than or equal\nto two.\n\nReturns\n\nA tensor of the same shape and type as `tensor` containing\nthe matrix square root of its last two dimensions.\n\n\n**Note**\n\nIf you want to use this function in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.config.xla_compat=true`.\nSee `xla_compat`."
"### matrix_sqrt_inv\n\n`sionna.utils.``matrix_sqrt_inv`(*`tensor`*)[`[source]`](../_modules/sionna/utils/tensors.html#matrix_sqrt_inv)\n\nComputes the inverse square root of a Hermitian matrix.\n\nGiven a batch of Hermitian positive definite matrices\n$\\mathbf{A}$, with square root matrices $\\mathbf{B}$,\nsuch that $\\mathbf{B}\\mathbf{B}^H = \\mathbf{A}$, the function\nreturns $\\mathbf{B}^{-1}$, such that\n$\\mathbf{B}^{-1}\\mathbf{B}=\\mathbf{I}$.\n\nThe two inner dimensions are assumed to correspond to the matrix rows\nand columns, respectively.\nParameters\n\n**tensor** (*[**...**, **M**, **M**]*)  A tensor of rank greater than or equal\nto two.\n\nReturns\n\nA tensor of the same shape and type as `tensor` containing\nthe inverse matrix square root of its last two dimensions.\n\n\n**Note**\n\nIf you want to use this function in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### matrix_inv\n\n`sionna.utils.``matrix_inv`(*`tensor`*)[`[source]`](../_modules/sionna/utils/tensors.html#matrix_inv)\n\nComputes the inverse of a Hermitian matrix.\n\nGiven a batch of Hermitian positive definite matrices\n$\\mathbf{A}$, the function\nreturns $\\mathbf{A}^{-1}$, such that\n$\\mathbf{A}^{-1}\\mathbf{A}=\\mathbf{I}$.\n\nThe two inner dimensions are assumed to correspond to the matrix rows\nand columns, respectively.\nParameters\n\n**tensor** (*[**...**, **M**, **M**]*)  A tensor of rank greater than or equal\nto two.\n\nReturns\n\nA tensor of the same shape and type as `tensor`, containing\nthe inverse of its last two dimensions.\n\n\n**Note**\n\nIf you want to use this function in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.Config.xla_compat=true`.\nSee [`xla_compat`](config.html#sionna.Config.xla_compat)."
"### matrix_pinv\n\n`sionna.utils.``matrix_pinv`(*`tensor`*)[`[source]`](../_modules/sionna/utils/tensors.html#matrix_pinv)\n\nComputes the MoorePenrose (or pseudo) inverse of a matrix.\n\nGiven a batch of $M \\times K$ matrices $\\mathbf{A}$ with rank\n$K$ (i.e., linearly independent columns), the function returns\n$\\mathbf{A}^+$, such that\n$\\mathbf{A}^{+}\\mathbf{A}=\\mathbf{I}_K$.\n\nThe two inner dimensions are assumed to correspond to the matrix rows\nand columns, respectively.\nParameters\n\n**tensor** (*[**...**, **M**, **K**]*)  A tensor of rank greater than or equal\nto two.\n\nReturns\n\nA tensor of shape ([, K,K]) of the same type as `tensor`,\ncontaining the pseudo inverse of its last two dimensions.\n\n\n**Note**\n\nIf you want to use this function in Graph mode with XLA, i.e., within\na function that is decorated with `@tf.function(jit_compile=True)`,\nyou must set `sionna.config.xla_compat=true`.\nSee `xla_compat`."
"### BinarySource\n\n`class` `sionna.utils.``BinarySource`(*`dtype``=``tf.float32`*, *`seed``=``None`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/utils/misc.html#BinarySource)\n\nLayer generating random binary tensors.\nParameters\n\n- **dtype** (*tf.DType*)  Defines the output datatype of the layer.\nDefaults to <cite>tf.float32</cite>.\n- **seed** (*int** or **None*)  Set the seed for the random generator used to generate the bits.\nSet to <cite>None</cite> for random initialization of the RNG.\n\n\nInput\n\n**shape** (*1D tensor/array/list, int*)  The desired shape of the output tensor.\n\nOutput\n\n`shape`, `dtype`  Tensor filled with random binary values."
"### SymbolSource\n\n`class` `sionna.utils.``SymbolSource`(*`constellation_type``=``None`*, *`num_bits_per_symbol``=``None`*, *`constellation``=``None`*, *`return_indices``=``False`*, *`return_bits``=``False`*, *`seed``=``None`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/utils/misc.html#SymbolSource)\n\nLayer generating a tensor of arbitrary shape filled with random constellation symbols.\nOptionally, the symbol indices and/or binary representations of the\nconstellation symbols can be returned.\nParameters\n\n- **constellation_type** (*One of** [**\"qam\"**, **\"pam\"**, **\"custom\"**]**, **str*)  For custom, an instance of [`Constellation`](mapping.html#sionna.mapping.Constellation)\nmust be provided.\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation symbol.\nOnly required for `constellation_type` in [qam, pam].\n- **constellation** ()  An instance of [`Constellation`](mapping.html#sionna.mapping.Constellation) or\n<cite>None</cite>. In the latter case, `constellation_type`\nand `num_bits_per_symbol` must be provided.\n- **return_indices** (*bool*)  If enabled, the function also returns the symbol indices.\nDefaults to <cite>False</cite>.\n- **return_bits** (*bool*)  If enabled, the function also returns the binary symbol\nrepresentations (i.e., bit labels).\nDefaults to <cite>False</cite>.\n- **seed** (*int** or **None*)  The seed for the random generator.\n<cite>None</cite> leads to a random initialization of the RNG.\nDefaults to <cite>None</cite>.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**]**, **tf.DType*)  The output dtype. Defaults to tf.complex64.\n\n\nInput\n\n**shape** (*1D tensor/array/list, int*)  The desired shape of the output tensor.\n\nOutput\n\n- **symbols** (`shape`, `dtype`)  Tensor filled with random symbols of the chosen `constellation_type`.\n- **symbol_indices** (`shape`, tf.int32)  Tensor filled with the symbol indices.\nOnly returned if `return_indices` is <cite>True</cite>.\n- **bits** ([`shape`, `num_bits_per_symbol`], tf.int32)  Tensor filled with the binary symbol representations (i.e., bit labels).\nOnly returned if `return_bits` is <cite>True</cite>."
"### QAMSource\n\n`class` `sionna.utils.``QAMSource`(*`num_bits_per_symbol``=``None`*, *`return_indices``=``False`*, *`return_bits``=``False`*, *`seed``=``None`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/utils/misc.html#QAMSource)\n\nLayer generating a tensor of arbitrary shape filled with random QAM symbols.\nOptionally, the symbol indices and/or binary representations of the\nconstellation symbols can be returned.\nParameters\n\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation symbol, e.g., 4 for QAM16.\n- **return_indices** (*bool*)  If enabled, the function also returns the symbol indices.\nDefaults to <cite>False</cite>.\n- **return_bits** (*bool*)  If enabled, the function also returns the binary symbol\nrepresentations (i.e., bit labels).\nDefaults to <cite>False</cite>.\n- **seed** (*int** or **None*)  The seed for the random generator.\n<cite>None</cite> leads to a random initialization of the RNG.\nDefaults to <cite>None</cite>.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**]**, **tf.DType*)  The output dtype. Defaults to tf.complex64.\n\n\nInput\n\n**shape** (*1D tensor/array/list, int*)  The desired shape of the output tensor.\n\nOutput\n\n- **symbols** (`shape`, `dtype`)  Tensor filled with random QAM symbols.\n- **symbol_indices** (`shape`, tf.int32)  Tensor filled with the symbol indices.\nOnly returned if `return_indices` is <cite>True</cite>.\n- **bits** ([`shape`, `num_bits_per_symbol`], tf.int32)  Tensor filled with the binary symbol representations (i.e., bit labels).\nOnly returned if `return_bits` is <cite>True</cite>."
"### PAMSource\n\n`class` `sionna.utils.``PAMSource`(*`num_bits_per_symbol``=``None`*, *`return_indices``=``False`*, *`return_bits``=``False`*, *`seed``=``None`*, *`dtype``=``tf.complex64`*, *`**``kwargs`*)[`[source]`](../_modules/sionna/utils/misc.html#PAMSource)\n\nLayer generating a tensor of arbitrary shape filled with random PAM symbols.\nOptionally, the symbol indices and/or binary representations of the\nconstellation symbols can be returned.\nParameters\n\n- **num_bits_per_symbol** (*int*)  The number of bits per constellation symbol, e.g., 1 for BPSK.\n- **return_indices** (*bool*)  If enabled, the function also returns the symbol indices.\nDefaults to <cite>False</cite>.\n- **return_bits** (*bool*)  If enabled, the function also returns the binary symbol\nrepresentations (i.e., bit labels).\nDefaults to <cite>False</cite>.\n- **seed** (*int** or **None*)  The seed for the random generator.\n<cite>None</cite> leads to a random initialization of the RNG.\nDefaults to <cite>None</cite>.\n- **dtype** (*One of** [**tf.complex64**, **tf.complex128**]**, **tf.DType*)  The output dtype. Defaults to tf.complex64.\n\n\nInput\n\n**shape** (*1D tensor/array/list, int*)  The desired shape of the output tensor.\n\nOutput\n\n- **symbols** (`shape`, `dtype`)  Tensor filled with random PAM symbols.\n- **symbol_indices** (`shape`, tf.int32)  Tensor filled with the symbol indices.\nOnly returned if `return_indices` is <cite>True</cite>.\n- **bits** ([`shape`, `num_bits_per_symbol`], tf.int32)  Tensor filled with the binary symbol representations (i.e., bit labels).\nOnly returned if `return_bits` is <cite>True</cite>."
"### PlotBER\n\n`class` `sionna.utils.plotting.``PlotBER`(*`title``=``'Bit/Block` `Error` `Rate'`*)[`[source]`](../_modules/sionna/utils/plotting.html#PlotBER)\n\nProvides a plotting object to simulate and store BER/BLER curves.\nParameters\n\n**title** (*str*)  A string defining the title of the figure. Defaults to\n<cite>Bit/Block Error Rate</cite>.\n\nInput\n\n- **snr_db** (*float*)  Python array (or list of Python arrays) of additional SNR values to be\nplotted.\n- **ber** (*float*)  Python array (or list of Python arrays) of additional BERs\ncorresponding to `snr_db`.\n- **legend** (*str*)  String (or list of strings) of legends entries.\n- **is_bler** (*bool*)  A boolean (or list of booleans) defaults to False.\nIf True, `ber` will be interpreted as BLER.\n- **show_ber** (*bool*)  A boolean defaults to True. If True, BER curves will be plotted.\n- **show_bler** (*bool*)  A boolean defaults to True. If True, BLER curves will be plotted.\n- **xlim** (*tuple of floats*)  Defaults to None. A tuple of two floats defining x-axis limits.\n- **ylim** (*tuple of floats*)  Defaults to None. A tuple of two floats defining y-axis limits.\n- **save_fig** (*bool*)  A boolean defaults to False. If True, the figure\nis saved as file.\n- **path** (*str*)  A string defining where to save the figure (if `save_fig`\nis True).\n\n\n`add`(*`ebno_db`*, *`ber`*, *`is_bler``=``False`*, *`legend``=``''`*)[`[source]`](../_modules/sionna/utils/plotting.html#PlotBER.add)\n\nAdd static reference curves.\nInput\n\n- **ebno_db** (*float*)  Python array or list of floats defining the SNR points.\n- **ber** (*float*)  Python array or list of floats defining the BER corresponding\nto each SNR point.\n- **is_bler** (*bool*)  A boolean defaults to False. If True, `ber` is interpreted as\nBLER.\n- **legend** (*str*)  A string defining the text of the legend entry.\n\n\n`property` `ber`\n\nList containing all stored BER curves.\n\n\n`property` `is_bler`\n\nList of booleans indicating if ber shall be interpreted as BLER.\n\n\n`property` `legend`\n\nList containing all stored legend entries curves.\n\n\n`remove`(*`idx``=``-` `1`*)[`[source]`](../_modules/sionna/utils/plotting.html#PlotBER.remove)\n\nRemove curve with index `idx`.\nInput\n\n**idx** (*int*)  An integer defining the index of the dataset that should\nbe removed. Negative indexing is possible.\n\n\n`reset`()[`[source]`](../_modules/sionna/utils/plotting.html#PlotBER.reset)\n\nRemove all internal data.\n\n\n`simulate`(*`mc_fun`*, *`ebno_dbs`*, *`batch_size`*, *`max_mc_iter`*, *`legend``=``''`*, *`add_ber``=``True`*, *`add_bler``=``False`*, *`soft_estimates``=``False`*, *`num_target_bit_errors``=``None`*, *`num_target_block_errors``=``None`*, *`target_ber``=``None`*, *`target_bler``=``None`*, *`early_stop``=``True`*, *`graph_mode``=``None`*, *`distribute``=``None`*, *`add_results``=``True`*, *`forward_keyboard_interrupt``=``True`*, *`show_fig``=``True`*, *`verbose``=``True`*)[`[source]`](../_modules/sionna/utils/plotting.html#PlotBER.simulate)\n\nSimulate BER/BLER curves for given Keras model and saves the results.\n\nInternally calls [`sionna.utils.sim_ber`](https://nvlabs.github.io/sionna/api/utils.html#sionna.utils.sim_ber).\nInput\n\n- **mc_fun**  Callable that yields the transmitted bits <cite>b</cite> and the\nreceivers estimate <cite>b_hat</cite> for a given `batch_size` and\n`ebno_db`. If `soft_estimates` is True, b_hat is interpreted as\nlogit.\n- **ebno_dbs** (*ndarray of floats*)  SNR points to be evaluated.\n- **batch_size** (*tf.int32*)  Batch-size for evaluation.\n- **max_mc_iter** (*int*)  Max. number of Monte-Carlo iterations per SNR point.\n- **legend** (*str*)  Name to appear in legend.\n- **add_ber** (*bool*)  Defaults to True. Indicate if BER should be added to plot.\n- **add_bler** (*bool*)  Defaults to False. Indicate if BLER should be added\nto plot.\n- **soft_estimates** (*bool*)  A boolean, defaults to False. If True, `b_hat`\nis interpreted as logit and additional hard-decision is applied\ninternally.\n- **num_target_bit_errors** (*int*)  Target number of bit errors per SNR point until the simulation\nstops.\n- **num_target_block_errors** (*int*)  Target number of block errors per SNR point until the simulation\nstops.\n- **target_ber** (*tf.float32*)  Defaults to <cite>None</cite>. The simulation stops after the first SNR point\nwhich achieves a lower bit error rate as specified by\n`target_ber`. This requires `early_stop` to be <cite>True</cite>.\n- **target_bler** (*tf.float32*)  Defaults to <cite>None</cite>. The simulation stops after the first SNR point\nwhich achieves a lower block error rate as specified by\n`target_bler`.  This requires `early_stop` to be <cite>True</cite>.\n- **early_stop** (*bool*)  A boolean defaults to True. If True, the simulation stops after the\nfirst error-free SNR point (i.e., no error occurred after\n`max_mc_iter` Monte-Carlo iterations).\n- **graph_mode** (*One of [graph, xla], str*)  A string describing the execution mode of `mc_fun`.\nDefaults to <cite>None</cite>. In this case, `mc_fun` is executed as is.\n- **distribute** (<cite>None</cite> (default) | all | list of indices | <cite>tf.distribute.strategy</cite>)  Distributes simulation on multiple parallel devices. If <cite>None</cite>,\nmulti-device simulations are deactivated. If all, the workload\nwill be automatically distributed across all available GPUs via the\n<cite>tf.distribute.MirroredStrategy</cite>.\nIf an explicit list of indices is provided, only the GPUs with the\ngiven indices will be used. Alternatively, a custom\n<cite>tf.distribute.strategy</cite> can be provided. Note that the same\n<cite>batch_size</cite> will be used for all GPUs in parallel, but the number\nof Monte-Carlo iterations `max_mc_iter` will be scaled by the\nnumber of devices such that the same number of total samples is\nsimulated. However, all stopping conditions are still in-place\nwhich can cause slight differences in the total number of simulated\nsamples.\n- **add_results** (*bool*)  Defaults to True. If True, the simulation results will be appended\nto the internal list of results.\n- **show_fig** (*bool*)  Defaults to True. If True, a BER figure will be plotted.\n- **verbose** (*bool*)  A boolean defaults to True. If True, the current progress will be\nprinted.\n- **forward_keyboard_interrupt** (*bool*)  A boolean defaults to True. If False, <cite>KeyboardInterrupts</cite> will be\ncatched internally and not forwarded (e.g., will not stop outer\nloops). If False, the simulation ends and returns the intermediate\nsimulation results.\n\n\nOutput\n\n- **(ber, bler)**  Tuple:\n- **ber** (*float*)  The simulated bit-error rate.\n- **bler** (*float*)  The simulated block-error rate.\n\n\n`property` `snr`\n\nList containing all stored SNR curves.\n\n\n`property` `title`\n\nTitle of the plot."
"### sim_ber\n\n`sionna.utils.``sim_ber`(*`mc_fun`*, *`ebno_dbs`*, *`batch_size`*, *`max_mc_iter`*, *`soft_estimates``=``False`*, *`num_target_bit_errors``=``None`*, *`num_target_block_errors``=``None`*, *`target_ber``=``None`*, *`target_bler``=``None`*, *`early_stop``=``True`*, *`graph_mode``=``None`*, *`distribute``=``None`*, *`verbose``=``True`*, *`forward_keyboard_interrupt``=``True`*, *`callback``=``None`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/utils/misc.html#sim_ber)\n\nSimulates until target number of errors is reached and returns BER/BLER.\n\nThe simulation continues with the next SNR point if either\n`num_target_bit_errors` bit errors or `num_target_block_errors` block\nerrors is achieved. Further, it continues with the next SNR point after\n`max_mc_iter` batches of size `batch_size` have been simulated.\nEarly stopping allows to stop the simulation after the first error-free SNR\npoint or after reaching a certain `target_ber` or `target_bler`.\nInput\n\n- **mc_fun** (*callable*)  Callable that yields the transmitted bits <cite>b</cite> and the\nreceivers estimate <cite>b_hat</cite> for a given `batch_size` and\n`ebno_db`. If `soft_estimates` is True, <cite>b_hat</cite> is interpreted as\nlogit.\n- **ebno_dbs** (*tf.float32*)  A tensor containing SNR points to be evaluated.\n- **batch_size** (*tf.int32*)  Batch-size for evaluation.\n- **max_mc_iter** (*tf.int32*)  Maximum number of Monte-Carlo iterations per SNR point.\n- **soft_estimates** (*bool*)  A boolean, defaults to <cite>False</cite>. If <cite>True</cite>, <cite>b_hat</cite>\nis interpreted as logit and an additional hard-decision is applied\ninternally.\n- **num_target_bit_errors** (*tf.int32*)  Defaults to <cite>None</cite>. Target number of bit errors per SNR point until\nthe simulation continues to next SNR point.\n- **num_target_block_errors** (*tf.int32*)  Defaults to <cite>None</cite>. Target number of block errors per SNR point\nuntil the simulation continues\n- **target_ber** (*tf.float32*)  Defaults to <cite>None</cite>. The simulation stops after the first SNR point\nwhich achieves a lower bit error rate as specified by `target_ber`.\nThis requires `early_stop` to be <cite>True</cite>.\n- **target_bler** (*tf.float32*)  Defaults to <cite>None</cite>. The simulation stops after the first SNR point\nwhich achieves a lower block error rate as specified by `target_bler`.\nThis requires `early_stop` to be <cite>True</cite>.\n- **early_stop** (*bool*)  A boolean defaults to <cite>True</cite>. If <cite>True</cite>, the simulation stops after the\nfirst error-free SNR point (i.e., no error occurred after\n`max_mc_iter` Monte-Carlo iterations).\n- **graph_mode** (*One of [graph, xla], str*)  A string describing the execution mode of `mc_fun`.\nDefaults to <cite>None</cite>. In this case, `mc_fun` is executed as is.\n- **distribute** (<cite>None</cite> (default) | all | list of indices | <cite>tf.distribute.strategy</cite>)  Distributes simulation on multiple parallel devices. If <cite>None</cite>,\nmulti-device simulations are deactivated. If all, the workload will\nbe automatically distributed across all available GPUs via the\n<cite>tf.distribute.MirroredStrategy</cite>.\nIf an explicit list of indices is provided, only the GPUs with the given\nindices will be used. Alternatively, a custom <cite>tf.distribute.strategy</cite>\ncan be provided. Note that the same <cite>batch_size</cite> will be\nused for all GPUs in parallel, but the number of Monte-Carlo iterations\n`max_mc_iter` will be scaled by the number of devices such that the\nsame number of total samples is simulated. However, all stopping\nconditions are still in-place which can cause slight differences in the\ntotal number of simulated samples.\n- **verbose** (*bool*)  A boolean defaults to <cite>True</cite>. If <cite>True</cite>, the current progress will be\nprinted.\n- **forward_keyboard_interrupt** (*bool*)  A boolean defaults to <cite>True</cite>. If <cite>False</cite>, KeyboardInterrupts will be\ncatched internally and not forwarded (e.g., will not stop outer loops).\nIf <cite>False</cite>, the simulation ends and returns the intermediate simulation\nresults.\n- **callback** (<cite>None</cite> (default) | callable)  If specified, `callback` will be called after each Monte-Carlo step.\nCan be used for logging or advanced early stopping. Input signature of\n`callback` must match <cite>callback(mc_iter, snr_idx, ebno_dbs,\nbit_errors, block_errors, nb_bits, nb_blocks)</cite> where `mc_iter`\ndenotes the number of processed batches for the current SNR point,\n`snr_idx` is the index of the current SNR point, `ebno_dbs` is the\nvector of all SNR points to be evaluated, `bit_errors` the vector of\nnumber of bit errors for each SNR point, `block_errors` the vector of\nnumber of block errors, `nb_bits` the vector of number of simulated\nbits, `nb_blocks` the vector of number of simulated blocks,\nrespectively. If `callable` returns <cite>sim_ber.CALLBACK_NEXT_SNR</cite>, early\nstopping is detected and the simulation will continue with the\nnext SNR point. If `callable` returns\n<cite>sim_ber.CALLBACK_STOP</cite>, the simulation is stopped\nimmediately. For <cite>sim_ber.CALLBACK_CONTINUE</cite> continues with\nthe simulation.\n- **dtype** (*tf.complex64*)  Datatype of the callable `mc_fun` to be used as input/output.\n\n\nOutput\n\n- **(ber, bler)**  Tuple:\n- **ber** (*tf.float32*)  The bit-error rate.\n- **bler** (*tf.float32*)  The block-error rate.\n\n\nRaises\n\n- **AssertionError**  If `soft_estimates` is not bool.\n- **AssertionError**  If `dtype` is not <cite>tf.complex</cite>.\n\n\n**Note**\n\nThis function is implemented based on tensors to allow\nfull compatibility with tf.function(). However, to run simulations\nin graph mode, the provided `mc_fun` must use the <cite>@tf.function()</cite>\ndecorator."
"### ebnodb2no\n\n`sionna.utils.``ebnodb2no`(*`ebno_db`*, *`num_bits_per_symbol`*, *`coderate`*, *`resource_grid``=``None`*)[`[source]`](../_modules/sionna/utils/misc.html#ebnodb2no)\n\nCompute the noise variance <cite>No</cite> for a given <cite>Eb/No</cite> in dB.\n\nThe function takes into account the number of coded bits per constellation\nsymbol, the coderate, as well as possible additional overheads related to\nOFDM transmissions, such as the cyclic prefix and pilots.\n\nThe value of <cite>No</cite> is computed according to the following expression\n\n$$\nN_o = \\left(\\frac{E_b}{N_o} \\frac{r M}{E_s}\\right)^{-1}\n$$\n\nwhere $2^M$ is the constellation size, i.e., $M$ is the\naverage number of coded bits per constellation symbol,\n$E_s=1$ is the average energy per constellation per symbol,\n$r\\in(0,1]$ is the coderate,\n$E_b$ is the energy per information bit,\nand $N_o$ is the noise power spectral density.\nFor OFDM transmissions, $E_s$ is scaled\naccording to the ratio between the total number of resource elements in\na resource grid with non-zero energy and the number\nof resource elements used for data transmission. Also the additionally\ntransmitted energy during the cyclic prefix is taken into account, as\nwell as the number of transmitted streams per transmitter.\nInput\n\n- **ebno_db** (*float*)  The <cite>Eb/No</cite> value in dB.\n- **num_bits_per_symbol** (*int*)  The number of bits per symbol.\n- **coderate** (*float*)  The coderate used.\n- **resource_grid** (*ResourceGrid*)  An (optional) instance of [`ResourceGrid`](ofdm.html#sionna.ofdm.ResourceGrid)\nfor OFDM transmissions.\n\n\nOutput\n\n*float*  The value of $N_o$ in linear scale."
"### hard_decisions\n\n`sionna.utils.``hard_decisions`(*`llr`*)[`[source]`](../_modules/sionna/utils/misc.html#hard_decisions)\n\nTransforms LLRs into hard decisions.\n\nPositive values are mapped to $1$.\nNonpositive values are mapped to $0$.\nInput\n\n**llr** (*any non-complex tf.DType*)  Tensor of LLRs.\n\nOutput\n\nSame shape and dtype as `llr`  The hard decisions."
"### plot_ber\n\n`sionna.utils.plotting.``plot_ber`(*`snr_db`*, *`ber`*, *`legend``=``''`*, *`ylabel``=``'BER'`*, *`title``=``'Bit` `Error` `Rate'`*, *`ebno``=``True`*, *`is_bler``=``None`*, *`xlim``=``None`*, *`ylim``=``None`*, *`save_fig``=``False`*, *`path``=``''`*)[`[source]`](../_modules/sionna/utils/plotting.html#plot_ber)\n\nPlot error-rates.\nInput\n\n- **snr_db** (*ndarray*)  Array of floats defining the simulated SNR points.\nCan be also a list of multiple arrays.\n- **ber** (*ndarray*)  Array of floats defining the BER/BLER per SNR point.\nCan be also a list of multiple arrays.\n- **legend** (*str*)  Defaults to . Defining the legend entries. Can be\neither a string or a list of strings.\n- **ylabel** (*str*)  Defaults to BER. Defining the y-label.\n- **title** (*str*)  Defaults to Bit Error Rate. Defining the title of the figure.\n- **ebno** (*bool*)  Defaults to True. If True, the x-label is set to\nEbNo [dB] instead of EsNo [dB].\n- **is_bler** (*bool*)  Defaults to False. If True, the corresponding curve is dashed.\n- **xlim** (*tuple of floats*)  Defaults to None. A tuple of two floats defining x-axis limits.\n- **ylim** (*tuple of floats*)  Defaults to None. A tuple of two floats defining y-axis limits.\n- **save_fig** (*bool*)  Defaults to False. If True, the figure is saved as <cite>.png</cite>.\n- **path** (*str*)  Defaults to . Defining the path to save the figure\n(iff `save_fig` is True).\n\n\nOutput\n\n- **(fig, ax)**  Tuple:\n- **fig** (*matplotlib.figure.Figure*)  A matplotlib figure handle.\n- **ax** (*matplotlib.axes.Axes*)  A matplotlib axes object."
"### complex_normal\n\n`sionna.utils.``complex_normal`(*`shape`*, *`var``=``1.0`*, *`dtype``=``tf.complex64`*)[`[source]`](../_modules/sionna/utils/misc.html#complex_normal)\n\nGenerates a tensor of complex normal random variables.\nInput\n\n- **shape** (*tf.shape, or list*)  The desired shape.\n- **var** (*float*)  The total variance., i.e., each complex dimension has\nvariance `var/2`.\n- **dtype** (*tf.complex*)  The desired dtype. Defaults to <cite>tf.complex64</cite>.\n\n\nOutput\n\n`shape`, `dtype`  Tensor of complex normal random variables."
"### log2\n\n`sionna.utils.``log2`(*`x`*)[`[source]`](../_modules/sionna/utils/misc.html#log2)\n\nTensorFlow implementation of NumPys <cite>log2</cite> function.\n\nSimple extension to <cite>tf.experimental.numpy.log2</cite>\nwhich casts the result to the <cite>dtype</cite> of the input.\nFor more details see the [TensorFlow](https://www.tensorflow.org/api_docs/python/tf/experimental/numpy/log2) and [NumPy](https://numpy.org/doc/1.16/reference/generated/numpy.log2.html) documentation."
"### log10\n\n`sionna.utils.``log10`(*`x`*)[`[source]`](../_modules/sionna/utils/misc.html#log10)\n\nTensorFlow implementation of NumPys <cite>log10</cite> function.\n\nSimple extension to <cite>tf.experimental.numpy.log10</cite>\nwhich casts the result to the <cite>dtype</cite> of the input.\nFor more details see the [TensorFlow](https://www.tensorflow.org/api_docs/python/tf/experimental/numpy/log10) and [NumPy](https://numpy.org/doc/1.16/reference/generated/numpy.log10.html) documentation.\nFor more details see the [TensorFlow](https://www.tensorflow.org/api_docs/python/tf/experimental/numpy/log10) and [NumPy](https://numpy.org/doc/1.16/reference/generated/numpy.log10.html) documentation.\nFor more details see the [TensorFlow](https://www.tensorflow.org/api_docs/python/tf/experimental/numpy/log10) and [NumPy](https://numpy.org/doc/1.16/reference/generated/numpy.log10.html) documentation."
"# Discover Sionna\n\nThis example notebook will guide you through the basic principles and illustrates the key features of [Sionna](https://nvlabs.github.io/sionna). With only a few commands, you can simulate the PHY-layer link-level performance for many 5G-compliant components, including easy visualization of the results."
"## Load Required Packages\n\nThe Sionna python package must be [installed](https://nvlabs.github.io/sionna/installation.html).\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\nimport numpy as np\nimport tensorflow as tf\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\n# IPython \"magic function\" for inline plots\n%matplotlib inline\nimport matplotlib.pyplot as plt\n```\n\n\n**Tip**: you can run bash commands in Jupyter via the `!` operator.\n\n\n```python\n!nvidia-smi\n```\n\n\n```python\nWed Mar 16 14:05:36 2022\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n| 51%   65C    P2   208W / 350W |   5207MiB / 24267MiB |     39%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   1  NVIDIA GeForce ...  Off  | 00000000:4C:00.0 Off |                  N/A |\n|  0%   28C    P8    13W / 350W |  17371MiB / 24268MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+\n```"
"In case multiple GPUs are available, we restrict this notebook to single-GPU usage. You can ignore this command if only one GPU is available.\n\nFurther, we want to avoid that this notebook instantiates the whole GPU memory when initialized and set `memory_growth` as active.\n\n*Remark*: Sionna does not require a GPU. Everything can also run on your CPU - but you may need to wait a little longer.\n\n\n```python\n# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n# For more details, see https://www.tensorflow.org/guide/gpu\ngpus = tf.config.list_physical_devices('GPU')\nprint('Number of GPUs available :', len(gpus))\nif gpus:\n    gpu_num = 0 # Index of the GPU to be used\n    try:\n        #tf.config.set_visible_devices([], 'GPU')\n        tf.config.set_visible_devices(gpus[gpu_num], 'GPU')\n        print('Only GPU number', gpu_num, 'used.')\n        tf.config.experimental.set_memory_growth(gpus[gpu_num], True)\n    except RuntimeError as e:\n        print(e)\n```\n\n\n```python\nNumber of GPUs available : 2\nOnly GPU number 0 used.\n```"
"## Sionna Data-flow and Design Paradigms\n\nSionna inherently parallelizes simulations via *batching*, i.e., each element in the batch dimension is simulated independently.\n\nThis means the first tensor dimension is always used for *inter-frame* parallelization similar to an outer *for-loop* in Matlab/NumPy simulations.\n\nTo keep the dataflow efficient, Sionna follows a few simple design principles:\n\n- Signal-processing components are implemented as an individual [Keras layer](https://keras.io/api/layers/).\n- `tf.float32` is used as preferred datatype and `tf.complex64` for complex-valued datatypes, respectively.\nThis allows simpler re-use of components (e.g., the same scrambling layer can be used for binary inputs and LLR-values).\n- Models can be developed in *eager mode* allowing simple (and fast) modification of system parameters.\n- Number crunching simulations can be executed in the faster *graph mode* or even *XLA* acceleration is available for most components.\n- Whenever possible, components are automatically differentiable via [auto-grad](https://www.tensorflow.org/guide/autodiff) to simplify the deep learning design-flow.\n- Code is structured into sub-packages for different tasks such as channel coding, mapping, (see [API documentation](https://nvlabs.github.io/sionna/api/sionna.html) for details).\n\n\nThe division into individual blocks simplifies deployment and all layers and functions comes with unittests to ensure their correct behavior.\n\nThese paradigms simplify the re-useability and reliability of our components for a wide range of communications related applications."
"## Lets Get Started - The First Layers (*Eager Mode*)\n\nEvery layer needs to be initialized once before it can be used.\n\n**Tip**: use the [API documentation](https://nvlabs.github.io/sionna/api/sionna.html) to find an overview of all existing components.\n\nWe now want to transmit some symbols over an AWGN channel. First, we need to initialize the corresponding layer.\n\n\n```python\nchannel = sionna.channel.AWGN() # init AWGN channel layer\n```\n\n\nIn this first example, we want to add Gaussian noise to some given values of `x`.\n\nRemember - the first dimension is the *batch-dimension*.\n\nWe simulate 2 message frames each containing 4 symbols.\n\n*Remark*: the [AWGN channel](https://nvlabs.github.io/sionna/api/channel.html#awgn) is defined to be complex-valued.\n\n\n```python\n# define a (complex-valued) tensor to be transmitted\nx = tf.constant([[0., 1.5, 1., 0.],[-1., 0., -2, 3 ]], dtype=tf.complex64)\n# let's have look at the shape\nprint(\"Shape of x: \", x.shape)\nprint(\"Values of x: \", x)\n```\n\n\n```python\nShape of x:  (2, 4)\nValues of x:  tf.Tensor(\n[[ 0. +0.j  1.5+0.j  1. +0.j  0. +0.j]\n [-1. +0.j  0. +0.j -2. +0.j  3. +0.j]], shape=(2, 4), dtype=complex64)\n```\n\n\nWe want to simulate the channel at an SNR of 5 dB. For this, we can simply *call* the previously defined layer `channel`.\n\nIf you have never used [Keras](https://keras.io) you can think of a layer as of a function: it has an input and returns the processed output.\n\n*Remark*: Each time this cell is executed a new noise realization is drawn.\n\n\n```python\nebno_db = 5\n# calculate noise variance from given EbNo\nno = sionna.utils.ebnodb2no(ebno_db = ebno_db,\n                            num_bits_per_symbol=2, # QPSK\n                            coderate=1)\ny = channel([x, no])\nprint(\"Noisy symbols are: \", y)\n```"
"```python\nNoisy symbols are:  tf.Tensor(\n[[ 0.17642795-0.21076633j  1.540727  +0.2577709j   0.676615  -0.14763176j\n  -0.14807788-0.01961605j]\n [-0.9018068 -0.04732923j -0.55583185+0.41312575j -1.8852113 -0.23232108j\n   3.3803759 +0.2269492j ]], shape=(2, 4), dtype=complex64)\n```"
"## Batches and Multi-dimensional Tensors\n\nSionna natively supports multi-dimensional tensors.\n\nMost layers operate at the last dimension and can have arbitrary input shapes (preserved at output).\n\nLet us assume we want to add a CRC-24 check to 64 codewords of length 500 (e.g., different CRC per sub-carrier). Further, we want to parallelize the simulation over a batch of 100 samples.\n\n\n```python\nbatch_size = 100 # outer level of parallelism\nnum_codewords = 64 # codewords per batch sample\ninfo_bit_length = 500 # info bits PER codeword\nsource = sionna.utils.BinarySource() # yields random bits\nu = source([batch_size, num_codewords, info_bit_length]) # call the source layer\nprint(\"Shape of u: \", u.shape)\n# initialize an CRC encoder with the standard compliant \"CRC24A\" polynomial\nencoder_crc = sionna.fec.crc.CRCEncoder(\"CRC24A\")\ndecoder_crc = sionna.fec.crc.CRCDecoder(encoder_crc) # connect to encoder\n# add the CRC to the information bits u\nc = encoder_crc(u) # returns a list [c, crc_valid]\nprint(\"Shape of c: \", c.shape)\nprint(\"Processed bits: \", np.size(c.numpy()))\n# we can also verify the results\n# returns list of [info bits without CRC bits, indicator if CRC holds]\nu_hat, crc_valid = decoder_crc(c)\nprint(\"Shape of u_hat: \", u_hat.shape)\nprint(\"Shape of crc_valid: \", crc_valid.shape)\nprint(\"Valid CRC check of first codeword: \", crc_valid.numpy()[0,0,0])\n```\n\n\n```python\nShape of u:  (100, 64, 500)\nShape of c:  (100, 64, 524)\nProcessed bits:  3353600\nShape of u_hat:  (100, 64, 500)\nShape of crc_valid:  (100, 64, 1)\nValid CRC check of first codeword:  True\n```\n\n\nWe want to do another simulation but for 5 independent users.\n\nInstead of defining 5 different tensors, we can simply add another dimension.\n\n\n```python\nnum_users = 5\nu = source([batch_size, num_users, num_codewords, info_bit_length])\nprint(\"New shape of u: \", u.shape)\n# We can re-use the same encoder as before\nc = encoder_crc(u)\nprint(\"New shape of c: \", c.shape)\nprint(\"Processed bits: \", np.size(c.numpy()))\n```"
"```python\nNew shape of u:  (100, 5, 64, 500)\nNew shape of c:  (100, 5, 64, 524)\nProcessed bits:  16768000\n```\n\n\nOften a good visualization of results helps to get new research ideas. Thus, Sionna has built-in plotting functions.\n\nLets have look at a 16-QAM constellation.\n\n\n```python\nconstellation = sionna.mapping.Constellation(\"qam\", num_bits_per_symbol=4)\nconstellation.show();\n```"
"## First Link-level Simulation\n\nWe can already build powerful code with a few simple commands.\n\nAs mentioned earlier, Sionna aims at hiding system complexity into Keras layers. However, we still want to provide as much flexibility as possible. Thus, most layers have several choices of init parameters, but often the default choice is a good start.\n\n**Tip**: the [API documentation](https://nvlabs.github.io/sionna/api/sionna.html) provides many helpful references and implementation details.\n\n\n```python\n# system parameters\nn_ldpc = 500 # instruction_answer codeword length\nk_ldpc = 250 # number of info bits per instruction_answer codeword\ncoderate = k_ldpc / n_ldpc\nnum_bits_per_symbol = 4 # number of bits mapped to one symbol (cf. QAM)\n```\n\n\nOften, several different algorithms are implemented, e.g., the demapper supports *true app* demapping, but also *max-log* demapping.\n\nThe check-node (CN) update function of the LDPC BP decoder also supports multiple algorithms.\n\n\n```python\ndemapping_method = \"app\" # try \"max-log\"\nldpc_cn_type = \"boxplus\" # try also \"minsum\"\n```\n\n\nLet us initialize all required components for the given system parameters.\n\n\n```python\nbinary_source = sionna.utils.BinarySource()\nencoder = sionna.fec.ldpc.encoding.LDPC5GEncoder(k_ldpc, n_ldpc)\nconstellation = sionna.mapping.Constellation(\"qam\", num_bits_per_symbol)\nmapper = sionna.mapping.Mapper(constellation=constellation)\nchannel = sionna.channel.AWGN()\ndemapper = sionna.mapping.Demapper(demapping_method,\n                                   constellation=constellation)\ndecoder = sionna.fec.ldpc.decoding.LDPC5GDecoder(encoder,\n                                                 hard_out=True, cn_type=ldpc_cn_type,\n                                                 num_iter=20)\n```\n\n\nWe can now run the code in *eager mode*. This allows us to modify the structure at any time - you can try a different `batch_size` or a different SNR `ebno_db`.\n\n\n```python\n# simulation parameters\nbatch_size = 1000\nebno_db = 4\n# Generate a batch of random bit vectors\nb = binary_source([batch_size, k_ldpc])\n# Encode the bits using 5G instruction_answer code\nprint(\"Shape before encoding: \", b.shape)\nc = encoder(b)\nprint(\"Shape after encoding: \", c.shape)\n# Map bits to constellation symbols\nx = mapper(c)\nprint(\"Shape after mapping: \", x.shape)\n# Transmit over an AWGN channel at SNR 'ebno_db'\nno = sionna.utils.ebnodb2no(ebno_db, num_bits_per_symbol, coderate)\ny = channel([x, no])\nprint(\"Shape after channel: \", y.shape)\n# Demap to LLRs\nllr = demapper([y, no])\nprint(\"Shape after demapping: \", llr.shape)\n# instruction_answer decoding using 20 BP iterations\nb_hat = decoder(llr)\nprint(\"Shape after decoding: \", b_hat.shape)\n# calculate BERs\nc_hat = tf.cast(tf.less(0.0, llr), tf.float32) # hard-decided bits before dec.\nber_uncoded = sionna.utils.metrics.compute_ber(c, c_hat)\nber_coded = sionna.utils.metrics.compute_ber(b, b_hat)\nprint(\"BER uncoded = {:.3f} at EbNo = {:.1f} dB\".format(ber_uncoded, ebno_db))\nprint(\"BER after decoding = {:.3f} at EbNo = {:.1f} dB\".format(ber_coded, ebno_db))\nprint(\"In total {} bits were simulated\".format(np.size(b.numpy())))\n```"
"```python\nShape before encoding:  (1000, 250)\nShape after encoding:  (1000, 500)\nShape after mapping:  (1000, 125)\nShape after channel:  (1000, 125)\nShape after demapping:  (1000, 500)\nShape after decoding:  (1000, 250)\nBER uncoded = 0.119 at EbNo = 4.0 dB\nBER after decoding = 0.010 at EbNo = 4.0 dB\nIn total 250000 bits were simulated\n```\n\n\nJust to summarize: we have simulated the transmission of 250,000 bits including higher-order modulation and channel coding!\n\nBut we can go even faster with the *TF graph execution*!"
"## Setting up the End-to-end Model\n\nWe now define a *Keras model* that is more convenient for training and Monte-Carlo simulations.\n\nWe simulate the transmission over a time-varying multi-path channel (the *TDL-A* model from 3GPP TR38.901). For this, OFDM and a *conventional* bit-interleaved coded modulation (BICM) scheme with higher order modulation is used. The information bits are protected by a 5G-compliant LDPC code.\n\n*Remark*: Due to the large number of parameters, we define them as dictionary.\n\n\n```python\nclass e2e_model(tf.keras.Model): # inherits from keras.model\n    \"\"\"Example model for end-to-end link-level simulations.\n    Parameters\n    ----------\n    params: dict\n        A dictionary defining the system parameters.\n    Input\n    -----\n    batch_size: int or tf.int\n        The batch_sizeused for the simulation.\n    ebno_db: float or tf.float\n        A float defining the simulation SNR.\n    Output\n    ------\n    (b, b_hat):\n        Tuple:\n    b: tf.float32\n        A tensor of shape `[batch_size, k]` containing the transmitted\n        information bits.\n    b_hat: tf.float32\n        A tensor of shape `[batch_size, k]` containing the receiver's\n        estimate of the transmitted information bits.\n    \"\"\"\n    def __init__(self,\n                params):\n        super().__init__()\n\n        # Define an OFDM Resource Grid Object\n        self.rg = sionna.ofdm.ResourceGrid(\n                            num_ofdm_symbols=params[\"num_ofdm_symbols\"],\n                            fft_size=params[\"fft_size\"],\n                            subcarrier_spacing=params[\"subcarrier_spacing\"],\n                            num_tx=1,\n                            num_streams_per_tx=1,\n                            cyclic_prefix_length=params[\"cyclic_prefix_length\"],\n                            pilot_pattern=\"kronecker\",\n                            pilot_ofdm_symbol_indices=params[\"pilot_ofdm_symbol_indices\"])\n        # Create a Stream Management object\n        self.sm = sionna.mimo.StreamManagement(rx_tx_association=np.array([[1]]),\n                                               num_streams_per_tx=1)\n        self.coderate = params[\"coderate\"]\n        self.num_bits_per_symbol = params[\"num_bits_per_symbol\"]\n        self.n = int(self.rg.num_data_symbols*self.num_bits_per_symbol)\n        self.k = int(self.n*coderate)\n        # Init layers\n        self.binary_source = sionna.utils.BinarySource()\n        self.encoder = sionna.fec.ldpc.encoding.LDPC5GEncoder(self.k, self.n)\n        self.interleaver = sionna.fec.interleaving.RowColumnInterleaver(\n                                        row_depth=self.num_bits_per_symbol)\n        self.deinterleaver = sionna.fec.interleaving.Deinterleaver(self.interleaver)\n        self.mapper = sionna.mapping.Mapper(\"qam\", self.num_bits_per_symbol)\n        self.rg_mapper = sionna.ofdm.ResourceGridMapper(self.rg)\n        self.tdl = sionna.channel.tr38901.TDL(model=\"A\",\n                           delay_spread=params[\"delay_spread\"],\n                           carrier_frequency=params[\"carrier_frequency\"],\n                           min_speed=params[\"min_speed\"],\n                           max_speed=params[\"max_speed\"])\n        self.channel = sionna.channel.OFDMChannel(self.tdl, self.rg, add_awgn=True, normalize_channel=True)\n        self.ls_est = sionna.ofdm.LSChannelEstimator(self.rg, interpolation_type=\"nn\")\n        self.lmmse_equ = sionna.ofdm.LMMSEEqualizer(self.rg, self.sm)\n        self.demapper = sionna.mapping.Demapper(params[\"demapping_method\"],\n                                                \"qam\", self.num_bits_per_symbol)\n        self.decoder = sionna.fec.ldpc.decoding.LDPC5GDecoder(self.encoder,\n                                                    hard_out=True,\n                                                    cn_type=params[\"cn_type\"],\n                                                    num_iter=params[\"bp_iter\"])\n        print(\"Number of pilots: {}\".format(self.rg.num_pilot_symbols))\n        print(\"Number of data symbols: {}\".format(self.rg.num_data_symbols))\n        print(\"Number of resource elements: {}\".format(\n                                    self.rg.num_resource_elements))\n        print(\"Pilot overhead: {:.2f}%\".format(\n                                    self.rg.num_pilot_symbols /\n                                    self.rg.num_resource_elements*100))\n        print(\"Cyclic prefix overhead: {:.2f}%\".format(\n                                    params[\"cyclic_prefix_length\"] /\n                                    (params[\"cyclic_prefix_length\"]\n                                    +params[\"fft_size\"])*100))\n        print(\"Each frame contains {} information bits\".format(self.k))\n    def call(self, batch_size, ebno_db):\n        # Generate a batch of random bit vectors\n        # We need two dummy dimension representing the number of\n        # transmitters and streams per transmitter, respectively.\n        b = self.binary_source([batch_size, 1, 1, self.k])\n        # Encode the bits using the all-zero dummy encoder\n        c = self.encoder(b)\n        # Interleave the bits before mapping (BICM)\n        c_int = self.interleaver(c)\n        # Map bits to constellation symbols\n        s = self.mapper(c_int)\n        # Map symbols onto OFDM ressource grid\n        x_rg = self.rg_mapper(s)\n        # Transmit over noisy multi-path channel\n        no = sionna.utils.ebnodb2no(ebno_db, self.num_bits_per_symbol, self.coderate, self.rg)\n        y = self.channel([x_rg, no])\n        # LS Channel estimation with nearest pilot interpolation\n        h_hat, err_var = self.ls_est ([y, no])\n        # LMMSE Equalization\n        x_hat, no_eff = self.lmmse_equ([y, h_hat, err_var, no])\n        # Demap to LLRs\n        llr = self.demapper([x_hat, no_eff])\n        # Deinterleave before decoding\n        llr_int = self.deinterleaver(llr)\n        # Decode\n        b_hat = self.decoder(llr_int)\n        # number of simulated bits\n        nb_bits = batch_size*self.k\n        # transmitted bits and the receiver's estimate after decoding\n        return b, b_hat\n```"
"Let us define the system parameters for our simulation as dictionary:\n\n\n```python\nsys_params = {\n    # Channel\n    \"carrier_frequency\" : 3.5e9,\n    \"delay_spread\" : 100e-9,\n    \"min_speed\" : 3,\n    \"max_speed\" : 3,\n    \"tdl_model\" : \"A\",\n    # OFDM\n    \"fft_size\" : 256,\n    \"subcarrier_spacing\" : 30e3,\n    \"num_ofdm_symbols\" : 14,\n    \"cyclic_prefix_length\" : 16,\n    \"pilot_ofdm_symbol_indices\" : [2, 11],\n    # Code & Modulation\n    \"coderate\" : 0.5,\n    \"num_bits_per_symbol\" : 4,\n    \"demapping_method\" : \"app\",\n    \"cn_type\" : \"boxplus\",\n    \"bp_iter\" : 20\n}\n```\n\n\nand initialize the model:\n\n\n```python\nmodel = e2e_model(sys_params)\n```\n\n\n```python\nNumber of pilots: 512\nNumber of data symbols: 3072\nNumber of resource elements: 3584\nPilot overhead: 14.29%\nCyclic prefix overhead: 5.88%\nEach frame contains 6144 information bits\n```\n\n\nAs before, we can simply *call* the model to simulate the BER for the given simulation parameters.\n\n\n```python\n#simulation parameters\nebno_db = 10\nbatch_size = 200\n# and call the model\nb, b_hat = model(batch_size, ebno_db)\nber = sionna.utils.metrics.compute_ber(b, b_hat)\nnb_bits = np.size(b.numpy())\nprint(\"BER: {:.4} at Eb/No of {} dB and {} simulated bits\".format(ber.numpy(), ebno_db, nb_bits))\n```\n\n\n```python\nBER: 0.006234 at Eb/No of 10 dB and 1228800 simulated bits\n```"
"## Run some Throughput Tests (Graph Mode)\n\nSionna is not just an easy-to-use library, but also incredibly fast. Let us measure the throughput of the model defined above.\n\nWe compare *eager* and *graph* execution modes (see [Tensorflow Doc](https://www.tensorflow.org/guide/intro_to_graphs) for details), as well as *eager with XLA* (see [https://www.tensorflow.org/xla#enable_xla_for_tensorflow_models](https://www.tensorflow.org/xla#enable_xla_for_tensorflow_models)). Note that we need to activate the [sionna.config.xla_compat](https://nvlabs.github.io/sionna/api/config.html#sionna.Config.xla_compat) feature for XLA to work.\n\n**Tip**: change the `batch_size` to see how the batch parallelism enhances the throughput. Depending on your machine, the `batch_size` may be too large.\n\n\n```python\nimport time # this block requires the timeit library\nbatch_size = 200\nebno_db = 5 # evalaute SNR point\nrepetitions = 4 # throughput is averaged over multiple runs\ndef get_throughput(batch_size, ebno_db, model, repetitions=1):\n    \"\"\" Simulate throughput in bit/s per ebno_db point.\n    The results are average over `repetition` trials.\n    Input\n    -----\n    batch_size: int or tf.int32\n        Batch-size for evaluation.\n    ebno_db: float or tf.float32\n        A tensor containing the SNR points be evaluated\n    model:\n        Function or model that yields the transmitted bits `u` and the\n        receiver's estimate `u_hat` for a given ``batch_size`` and\n        ``ebno_db``.\n    repetitions: int\n        An integer defining how many trails of the throughput\n        simulation are averaged.\n    \"\"\"\n\n    # call model once to be sure it is compile properly\n    # otherwise time to build graph is measured as well.\n    u, u_hat = model(tf.constant(batch_size, tf.int32),\n                     tf.constant(ebno_db, tf.float32))\n    t_start = time.perf_counter()\n    # average over multiple runs\n    for _ in range(repetitions):\n        u, u_hat = model(tf.constant(batch_size, tf.int32),\n                            tf.constant(ebno_db, tf. float32))\n    t_stop = time.perf_counter()\n    # throughput in bit/s\n    throughput = np.size(u.numpy())*repetitions / (t_stop - t_start)\n    return throughput\n# eager mode - just call the model\ndef run_eager(batch_size, ebno_db):\n    return model(batch_size, ebno_db)\ntime_eager = get_throughput(batch_size, ebno_db, run_eager, repetitions=4)\n# the decorator \"@tf.function\" enables the graph mode\n@tf.function\ndef run_graph(batch_size, ebno_db):\n    return model(batch_size, ebno_db)\ntime_graph = get_throughput(batch_size, ebno_db, run_graph, repetitions=4)\n# the decorator \"@tf.function(jit_compile=True)\" enables the graph mode with XLA\n# we need to activate the sionna.config.xla_compat feature for this to work\nsionna.config.xla_compat=True\n@tf.function(jit_compile=True)\ndef run_graph_xla(batch_size, ebno_db):\n    return model(batch_size, ebno_db)\ntime_graph_xla = get_throughput(batch_size, ebno_db, run_graph_xla, repetitions=4)\n# we deactivate the sionna.config.xla_compat so that the cell can be run mutiple times\nsionna.config.xla_compat=False\nprint(f\"Throughput in eager execution: {time_eager/1e6:.2f} Mb/s\")\nprint(f\"Throughput in graph execution: {time_graph/1e6:.2f} Mb/s\")\nprint(f\"Throughput in graph execution with XLA: {time_graph_xla/1e6:.2f} Mb/s\")\n```"
"```python\nWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\nInstructions for updating:\nThe `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\nThroughput in eager execution: 0.51 Mb/s\nThroughput in graph execution: 4.10 Mb/s\nThroughput in graph execution with XLA: 43.72 Mb/s\n```\n\n\nObviously, *graph* execution (with XLA) yields much higher throughputs (at least if a fast GPU is available). Thus, for exhaustive training and Monte-Carlo simulations the *graph* mode (with XLA and GPU acceleration) is the preferred choice."
"## Bit-Error Rate (BER) Monte-Carlo Simulations\n\nMonte-Carlo simulations are omnipresent in todays communications research and development. Due its performant implementation, Sionna can be directly used to simulate BER at a performance that competes with compiled languages  but still keeps the flexibility of a script language.\n\n\n```python\nebno_dbs = np.arange(0, 15, 1.)\nbatch_size = 200 # reduce in case you receive an out-of-memory (OOM) error\nmax_mc_iter = 1000 # max number of Monte-Carlo iterations before going to next SNR point\nnum_target_block_errors = 500 # continue with next SNR point after target number of block errors\n# we use the built-in ber simulator function from Sionna which uses and early stop after reaching num_target_errors\nsionna.config.xla_compat=True\nber_mc,_ = sionna.utils.sim_ber(run_graph_xla, # you can also evaluate the model directly\n                                ebno_dbs,\n                                batch_size=batch_size,\n                                num_target_block_errors=num_target_block_errors,\n                                max_mc_iter=max_mc_iter,\n                                verbose=True) # print status and summary\nsionna.config.xla_compat=False\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 3.4157e-01 | 1.0000e+00 |     1259148 |     3686400 |          600 |         600 |         0.1 |reached target block errors\n      1.0 | 3.1979e-01 | 1.0000e+00 |     1178870 |     3686400 |          600 |         600 |         0.1 |reached target block errors\n      2.0 | 2.9844e-01 | 1.0000e+00 |     1100177 |     3686400 |          600 |         600 |         0.1 |reached target block errors\n      3.0 | 2.7401e-01 | 1.0000e+00 |     1010102 |     3686400 |          600 |         600 |         0.1 |reached target block errors\n      4.0 | 2.4763e-01 | 1.0000e+00 |      912849 |     3686400 |          600 |         600 |         0.1 |reached target block errors\n      5.0 | 2.2038e-01 | 1.0000e+00 |      812407 |     3686400 |          600 |         600 |         0.1 |reached target block errors\n      6.0 | 1.8646e-01 | 1.0000e+00 |      687378 |     3686400 |          600 |         600 |         0.1 |reached target block errors\n      7.0 | 1.1909e-01 | 9.9000e-01 |      439008 |     3686400 |          594 |         600 |         0.1 |reached target block errors\n      8.0 | 4.1536e-02 | 4.7667e-01 |      306236 |     7372800 |          572 |        1200 |         0.2 |reached target block errors\n      9.0 | 1.2096e-02 | 1.4028e-01 |      267553 |    22118400 |          505 |        3600 |         0.6 |reached target block errors\n     10.0 | 3.2914e-03 | 3.5278e-02 |      291203 |    88473600 |          508 |       14400 |         2.5 |reached target block errors\n     11.0 | 9.5878e-04 | 9.8814e-03 |      298073 |   310886400 |          500 |       50600 |         8.5 |reached target block errors\n     12.0 | 2.6973e-04 | 2.7933e-03 |      296647 |  1099776000 |          500 |      179000 |        29.6 |reached target block errors\n     13.0 | 9.2277e-05 | 9.6000e-04 |      113390 |  1228800000 |          192 |      200000 |        32.9 |reached max iter\n     14.0 | 3.3341e-05 | 3.8000e-04 |       40970 |  1228800000 |           76 |      200000 |        32.6 |reached max iter\n```"
"Lets look at the results.\n\n\n```python\nsionna.utils.plotting.plot_ber(ebno_dbs,\n                               ber_mc,\n                               legend=\"E2E Model\",\n                               ylabel=\"Coded BER\");\n```"
"## Conclusion\n\nWe hope you are excited about Sionna - there is much more to be discovered:\n\n- TensorBoard debugging available\n- Scaling to multi-GPU simulation is simple\n- See the [available tutorials](https://nvlabs.github.io/sionna/tutorials.html) for more advanced examples.\n\n\nAnd if something is still missing - the project is [open-source](https://github.com/nvlabs/sionna/): you can modify, add, and extend any component at any time.And if something is still missing - the project is [open-source](https://github.com/nvlabs/sionna/): you can modify, add, and extend any component at any time.And if something is still missing - the project is [open-source](https://github.com/nvlabs/sionna/): you can modify, add, and extend any component at any time.And if something is still missing - the project is [open-source](https://github.com/nvlabs/sionna/): you can modify, add, and extend any component at any time."
"# Made with Sionna\n\nWe love to see how Sionna is used by other researchers! For this reason, you find below links to papers whose authors have also published Sionna-based simulation code."
"### .\nOpenStreetMap to Sionna Scene in Python\nManoj Kumar Joshi eleased in January 2024 and based on Sionna v0.15. [ View on GitHub](https://github.com/manoj-kumar-joshi/sionna_osm_scene)    \nThis Jupyter notebook shows how to create a Sionna scene (Mitsuba format) in Python code from OpenStreetMap data. Buildings are extruded and meshes for roads are created in a region specified by the user. It is an alternative to the Blender-based workflow presented [in this video](https://youtu.be/7xHLDxUaQ7c)."
"## List of Projects\n\nIf you want your paper and code be listed here, please send an email to [sionna@nvidia&#46;com](mailto:sionna&#37;&#52;&#48;nvidia&#46;com) with links to the paper (e.g., [arXiv](https://arxiv.org)) and code repository (e.g., [GitHub](https://github.com))."
"### .\nGraph Neural Networks for Enhanced Decoding of Quantum LDPC Codes\nAnqi Gong, Sebastian Cammerer, Joseph M. Renes eleased in 2023 and based on Sionna v0.15. [ View on GitHub](https://github.com/gongaa/Feedback-GNN)\nIn this work, we propose a fully differentiable iterative decoder for quantum low-density parity-check (LDPC) codes. The proposed algorithm is composed of classical belief propagation (BP) decoding stages and intermediate graph neural network (GNN) layers. Both component decoders are defined over the same sparse decoding graph enabling a seamless integration and scalability to large codes. The core idea is to use the GNN component between consecutive BP runs, so that the knowledge from the previous BP run, if stuck in a local minima caused by trapping sets or short cycles in the decoding graph, can be leveraged to better initialize the next BP run. By doing so, the proposed decoder can learn to compensate for sub-optimal BP decoding graphs that result from the design constraints of quantum LDPC codes. Since the entire decoder remains differentiable, gradient descent-based training is possible. We compare the error rate performance of the proposed decoder against various post-processing methods such as random perturbation, enhanced feedback, augmentation, and ordered-statistics decoding (OSD) and show that a carefully designed training process lowers the error-floor significantly. As a result, our proposed decoder outperforms the former three methods using significantly fewer post-processing attempts.Sionna RT: Differentiable Ray Tracing for Radio Propagation Modeling\nJakob Hoydis, Fayal At Aoudia, Sebastian Cammerer, Merlin Nimier-David, Nikolaus Binder, Guillermo Marcus, Alexander Keller eleased in 2023 and based on Sionna v0.16. [Run in Google Colab](https://colab.research.google.com/github/NVlabs/diff-rt/blob/master/Learning_Materials.ipynb)\nSionna is a GPU-accelerated open-source library for link-level simulations based on TensorFlow. Its latest release (v0.14) integrates a differentiable ray tracer (RT) for the simulation of radio wave propagation. This unique feature allows for the computation of gradients of the channel impulse response and other related quantities with respect to many system  and environment parameters, such as material properties, antenna patterns, array geometries, as well as transmitter and receiver orientations and positions. In this paper, we outline the key components of Sionna RT and showcase example applications such as learning of radio materials and optimizing transmitter orientations by gradient descent. While classic ray tracing is a crucial tool for 6G research topics like reconfigurable intelligent surfaces, integrated sensing and communications, as well as user localization, differentiable ray tracing is a key enabler for many novel and exciting research directions, for example, digital twins.DUIDD: Deep-Unfolded Interleaved Detection and Decoding for MIMO Wireless Systems\nReinhard Wiesmayr, Chris Dick, Jakob Hoydis, Christoph Studer eleased in 2022 and based on Sionna v0.11. [ View on GitHub](https://github.com/IIP-Group/DUIDD)\nIterative detection and decoding (IDD) is known to achieve near-capacity performance in multi-antenna wireless systems. We propose deep-unfolded interleaved detection and decoding (DUIDD), a new paradigm that reduces the complexity of IDD while achieving even lower error rates. DUIDD interleaves the inner stages of the data detector and channel decoder, which expedites convergence and reduces complexity. Furthermore, DUIDD applies deep unfolding to automatically optimize algorithmic hyperparameters, soft-information exchange, message damping, and state forwarding. We demonstrate the efficacy of DUIDD using NVIDIA's Sionna link-level simulator in a 5G-near multi-user MIMO-OFDM wireless system with a novel low-complexity soft-input soft-output data detector, an optimized low-density parity-check decoder, and channel vectors from a commercial ray-tracer. Our results show that DUIDD outperforms classical IDD both in terms of block error rate and computational complexity.Bit Error and Block Error Rate Training for ML-Assisted Communication\nReinhard Wiesmayr, Gian Marti, Chris Dick, Haochuan Song, Christoph Studer eleased in 2022 and based on Sionna v0.11. [ View on GitHub](https://github.com/IIP-Group/BLER_Training)\nEven though machine learning (ML) techniques are being\nwidely used in communications, the question of how to train\ncommunication systems has received surprisingly little\nattention. In this paper, we show that the commonly used binary\ncross-entropy (BCE) loss is a sensible choice in uncoded\nsystems, e.g., for training ML-assisted data detectors, but may\nnot be optimal in coded systems. We propose new loss functions\ntargeted at minimizing the block error rate and SNR deweighting,\na novel method that trains communication systems for optimal\nperformance over a range of signal-to-noise ratios. The utility\nof the proposed loss functions as well as of SNR deweighting is\nshown through simulations in NVIDIA Sionna.Graph Neural Networks for Channel Decoding\nSebastian Cammerer, Jakob Hoydis, Fayal At Aoudia, Alexander Keller eleased in 2022 and based on Sionna v0.11. [Run in Google Colab](https://colab.research.google.com/github/NVlabs/gnn-decoder/blob/master/GNN_decoder_standalone.ipynb)\nWe propose a fully differentiable graph neural network (GNN)-based architecture for channel decoding and showcase competitive decoding performance for various coding schemes, such as low-density parity-check (LDPC) and BCH codes. The idea is to let a neural network (NN) learn a generalized message passing algorithm over a given graph that represents the forward error correction code structure by replacing node and edge message updates with trainable functions.Deep Learning-Based Synchronization for Uplink NB-IoT\nFayal At Aoudia, Jakob Hoydis, Sebastian Cammerer, Matthijs Van Keirsbilck, Alexander Keller eleased in 2022 and based on Sionna v0.11. [ View on GitHub](https://github.com/NVlabs/nprach_synch)\nWe propose a neural network (NN)-based algorithm for device detection and time of arrival (ToA) and carrier frequency offset (CFO) estimation for the narrowband physical random-access channel (NPRACH) of narrowband internet of things (NB-IoT). The introduced NN architecture leverages residual convolutional networks as well as knowledge of the preamble structure of the 5G New Radio (5G NR) specifications.We propose a neural network (NN)-based algorithm for device detection and time of arrival (ToA) and carrier frequency offset (CFO) estimation for the narrowband physical random-access channel (NPRACH) of narrowband internet of things (NB-IoT). The introduced NN architecture leverages residual convolutional networks as well as knowledge of the preamble structure of the 5G New Radio (5G NR) specifications.\nWe propose a neural network (NN)-based algorithm for device detection and time of arrival (ToA) and carrier frequency offset (CFO) estimation for the narrowband physical random-access channel (NPRACH) of narrowband internet of things (NB-IoT). The introduced NN architecture leverages residual convolutional networks as well as knowledge of the preamble structure of the 5G New Radio (5G NR) specifications.We propose a neural network (NN)-based algorithm for device detection and time of arrival (ToA) and carrier frequency offset (CFO) estimation for the narrowband physical random-access channel (NPRACH) of narrowband internet of things (NB-IoT). The introduced NN architecture leverages residual convolutional networks as well as knowledge of the preamble structure of the 5G New Radio (5G NR) specifications."
"# Primer on Electromagnetics\n\nThis section provides useful background for the general understanding of ray tracing for wireless propagation modelling. In particular, our goal is to provide a concise definition of a <cite>channel impulse response</cite> between a transmitting and receiving antenna, as done in (Ch. 2 & 3) [[Wiesbeck]](https://nvlabs.github.io/sionna/em_primer.html#wiesbeck). The notations and definitions will be used in the API documentation of Sionnas [Ray Tracing module](api/rt.html)."
"## Coordinate system, rotations, and vector fields\n\nWe consider a global coordinate system (GCS) with Cartesian standard basis $\\hat{\\mathbf{x}}$, $\\hat{\\mathbf{y}}$, $\\hat{\\mathbf{z}}$.\nThe spherical unit vectors are defined as\n\n$$\n\\begin{split}\\begin{align}\n    \\hat{\\mathbf{r}}          (\\theta, \\varphi) &= \\sin(\\theta)\\cos(\\varphi) \\hat{\\mathbf{x}} + \\sin(\\theta)\\sin(\\varphi) \\hat{\\mathbf{y}} + \\cos(\\theta)\\hat{\\mathbf{z}}\\\\\n    \\hat{\\boldsymbol{\\theta}} (\\theta, \\varphi) &= \\cos(\\theta)\\cos(\\varphi) \\hat{\\mathbf{x}} + \\cos(\\theta)\\sin(\\varphi) \\hat{\\mathbf{y}} - \\sin(\\theta)\\hat{\\mathbf{z}}\\\\\n    \\hat{\\boldsymbol{\\varphi}}(\\theta, \\varphi) &=            -\\sin(\\varphi) \\hat{\\mathbf{x}} +             \\cos(\\varphi) \\hat{\\mathbf{y}}.\n\\end{align}\\end{split}\n$$\n\nFor an arbitrary unit norm vector $\\hat{\\mathbf{v}} = (x, y, z)$, the elevation and azimuth angles $\\theta$ and $\\varphi$ can be computed as\n\n$$\n\\begin{split}\\theta  &= \\cos^{-1}(z) \\\\\n\\varphi &= \\mathop{\\text{atan2}}(y, x)\\end{split}\n$$\n\nwhere $\\mathop{\\text{atan2}}(y, x)$ is the two-argument inverse tangent function [[atan2]](https://nvlabs.github.io/sionna/em_primer.html#atan2). As any vector uniquely determines $\\theta$ and $\\varphi$, we sometimes also\nwrite $\\hat{\\boldsymbol{\\theta}}(\\hat{\\mathbf{v}})$ and $\\hat{\\boldsymbol{\\varphi}}(\\hat{\\mathbf{v}})$ instead of $\\hat{\\boldsymbol{\\theta}} (\\theta, \\varphi)$ and $\\hat{\\boldsymbol{\\varphi}}(\\theta, \\varphi)$.\n\nA 3D rotation with yaw, pitch, and roll angles $\\alpha$, $\\beta$, and $\\gamma$, respectively, is expressed by the matrix\n\n$$\n\\begin{align}\n    \\mathbf{R}(\\alpha, \\beta, \\gamma) = \\mathbf{R}_z(\\alpha)\\mathbf{R}_y(\\beta)\\mathbf{R}_x(\\gamma)\n\\end{align}\n$$\n\nwhere $\\mathbf{R}_z(\\alpha)$, $\\mathbf{R}_y(\\beta)$, and $\\mathbf{R}_x(\\gamma)$ are rotation matrices around the $z$, $y$, and $x$ axes, respectively, which are defined as\n\n$$\n\\begin{split}\\begin{align}\n    \\mathbf{R}_z(\\alpha) &= \\begin{pmatrix}\n                    \\cos(\\alpha) & -\\sin(\\alpha) & 0\\\\\n                    \\sin(\\alpha) & \\cos(\\alpha) & 0\\\\\n                    0 & 0 & 1\n                  \\end{pmatrix}\\\\\n    \\mathbf{R}_y(\\beta) &= \\begin{pmatrix}\n                    \\cos(\\beta) & 0 & \\sin(\\beta)\\\\\n                    0 & 1 & 0\\\\\n                    -\\sin(\\beta) & 0 & \\cos(\\beta)\n                  \\end{pmatrix}\\\\\n    \\mathbf{R}_x(\\gamma) &= \\begin{pmatrix}\n                        1 & 0 & 0\\\\\n                        0 & \\cos(\\gamma) & -\\sin(\\gamma)\\\\\n                        0 & \\sin(\\gamma) & \\cos(\\gamma)\n                  \\end{pmatrix}.\n\\end{align}\\end{split}\n$$\n\nA closed-form expression for $\\mathbf{R}(\\alpha, \\beta, \\gamma)$ can be found in (7.1-4) [[TR38901]](api/channel.wireless.html#tr38901).\nThe reverse rotation is simply defined by $\\mathbf{R}^{-1}(\\alpha, \\beta, \\gamma)=\\mathbf{R}^\\mathsf{T}(\\alpha, \\beta, \\gamma)$.\nA vector $\\mathbf{x}$ defined in a first coordinate system is represented in a second coordinate system rotated by $\\mathbf{R}(\\alpha, \\beta, \\gamma)$ with respect to the first one as $\\mathbf{x}'=\\mathbf{R}^\\mathsf{T}(\\alpha, \\beta, \\gamma)\\mathbf{x}$.\nIf a point in the first coordinate system has spherical angles $(\\theta, \\varphi)$, the corresponding angles $(\\theta', \\varphi')$ in the second coordinate system can be found to be\n\n$$\n\\begin{split}\\begin{align}\n    \\theta' &= \\cos^{-1}\\left( \\mathbf{z}^\\mathsf{T} \\mathbf{R}^\\mathsf{T}(\\alpha, \\beta, \\gamma)\\hat{\\mathbf{r}}(\\theta, \\varphi)          \\right)\\\\\n    \\varphi' &= \\arg\\left( \\left( \\mathbf{x} + j\\mathbf{y}\\right)^\\mathsf{T} \\mathbf{R}^\\mathsf{T}(\\alpha, \\beta, \\gamma)\\hat{\\mathbf{r}}(\\theta, \\varphi) \\right).\n\\end{align}\\end{split}\n$$\n\nFor a vector field $\\mathbf{F}'(\\theta',\\varphi')$ expressed in local spherical coordinates\n\n$$\n\\mathbf{F}'(\\theta',\\varphi') = F_{\\theta'}(\\theta',\\varphi')\\hat{\\boldsymbol{\\theta}}'(\\theta',\\varphi') + F_{\\varphi'}(\\theta',\\varphi')\\hat{\\boldsymbol{\\varphi}}'(\\theta',\\varphi')\n$$\n\nthat are rotated by $\\mathbf{R}=\\mathbf{R}(\\alpha, \\beta, \\gamma)$ with respect to the GCS, the spherical field components in the GCS can be expressed as\n\n$$\n\\begin{split}\\begin{bmatrix}\n    F_\\theta(\\theta, \\varphi) \\\\\n    F_\\varphi(\\theta, \\varphi)\n\\end{bmatrix} =\n\\begin{bmatrix}\n    \\hat{\\boldsymbol{\\theta}}(\\theta,\\varphi)^\\mathsf{T}\\mathbf{R}\\hat{\\boldsymbol{\\theta}}'(\\theta',\\varphi') & \\hat{\\boldsymbol{\\theta}}(\\theta,\\varphi)^\\mathsf{T}\\mathbf{R}\\hat{\\boldsymbol{\\varphi}}'(\\theta',\\varphi') \\\\\n    \\hat{\\boldsymbol{\\varphi}}(\\theta,\\varphi)^\\mathsf{T}\\mathbf{R}\\hat{\\boldsymbol{\\theta}}'(\\theta',\\varphi') & \\hat{\\boldsymbol{\\varphi}}(\\theta,\\varphi)^\\mathsf{T}\\mathbf{R}\\hat{\\boldsymbol{\\varphi}}'(\\theta',\\varphi')\n\\end{bmatrix}\n\\begin{bmatrix}\n    F_{\\theta'}(\\theta', \\varphi') \\\\\n    F_{\\varphi'}(\\theta', \\varphi')\n\\end{bmatrix}\\end{split}\n$$\n\nso that\n\n$$\n\\mathbf{F}(\\theta,\\varphi) = F_{\\theta}(\\theta,\\varphi)\\hat{\\boldsymbol{\\theta}}(\\theta,\\varphi) + F_{\\varphi}(\\theta,\\varphi)\\hat{\\boldsymbol{\\varphi}}(\\theta,\\varphi).\n$$\n\nIt sometimes also useful to find the rotation matrix that maps a unit vector $\\hat{\\mathbf{a}}$ to $\\hat{\\mathbf{b}}$. This can be achieved with the help of Rodrigues rotation formula [[Wikipedia_Rodrigues]](https://nvlabs.github.io/sionna/em_primer.html#wikipedia-rodrigues) which defines the matrix\n\n$$\n\\mathbf{R}(\\hat{\\mathbf{a}}, \\hat{\\mathbf{b}}) = \\mathbf{I} + \\sin(\\theta)\\mathbf{K} + (1-\\cos(\\theta)) \\mathbf{K}^2\n$$\n\nwhere\n\n$$\n\\begin{split}\\mathbf{K} &= \\begin{bmatrix}\n                        0 & -\\hat{k}_z &  \\hat{k}_y \\\\\n                \\hat{k}_z &          0 & -\\hat{k}_x \\\\\n               -\\hat{k}_y &  \\hat{k}_x &          0\n             \\end{bmatrix}\\\\\n\\hat{\\mathbf{k}} &= \\frac{\\hat{\\mathbf{a}} \\times \\hat{\\mathbf{b}}}{\\lVert \\hat{\\mathbf{a}} \\times \\hat{\\mathbf{b}} \\rVert}\\\\\n\\theta &=\\hat{\\mathbf{a}}^\\mathsf{T}\\hat{\\mathbf{b}}\\end{split}\n$$\n\nsuch that $\\mathbf{R}(\\hat{\\mathbf{a}}, \\hat{\\mathbf{b}})\\hat{\\mathbf{a}}=\\hat{\\mathbf{b}}$."
"## Planar Time-Harmonic Waves\n\nA time-harmonic planar electric wave $\\mathbf{E}(\\mathbf{x}, t)\\in\\mathbb{C}^3$ travelling in a homogeneous medium with wave vector $\\mathbf{k}\\in\\mathbb{C}^3$ can be described at position $\\mathbf{x}\\in\\mathbb{R}^3$ and time $t$ as\n\n$$\n\\begin{split}\\begin{align}\n    \\mathbf{E}(\\mathbf{x}, t) &= \\mathbf{E}_0 e^{j(\\omega t -\\mathbf{k}^{\\mathsf{H}}\\mathbf{x})}\\\\\n                              &= \\mathbf{E}(\\mathbf{x}) e^{j\\omega t}\n\\end{align}\\end{split}\n$$\n\nwhere $\\mathbf{E}_0\\in\\mathbb{C}^3$ is the field phasor. The wave vector can be decomposed as $\\mathbf{k}=k \\hat{\\mathbf{k}}$, where $\\hat{\\mathbf{k}}$ is a unit norm vector, $k=\\omega\\sqrt{\\varepsilon\\mu}$ is the wave number, and $\\omega=2\\pi f$ is the angular frequency. The permittivity $\\varepsilon$ and permeability $\\mu$ are defined as\n\n$$\n\\varepsilon = \\eta \\varepsilon_0\n$$\n\n$$\n\\mu = \\mu_r \\mu_0\n$$\n\nwhere $\\eta$ and $\\varepsilon_0$ are the complex relative and vacuum permittivities, $\\mu_r$ and $\\mu_0$ are the relative and vacuum permeabilities, and $\\sigma$ is the conductivity.\nThe complex relative permittivity $\\eta$ is given as\n\n$$\n\\eta = \\varepsilon_r - j\\frac{\\sigma}{\\varepsilon_0\\omega}\n$$\n\nwhere $\\varepsilon_r$ is the real relative permittivity of a non-conducting dielectric.\n\nWith these definitions, the speed of light is given as (Eq. 4-28d) [[Balanis]](https://nvlabs.github.io/sionna/em_primer.html#balanis)\n\n$$\nc=\\frac{1}{\\sqrt{\\varepsilon_0\\varepsilon_r\\mu}}\\left\\{\\frac12\\left(\\sqrt{1+\\left(\\frac{\\sigma}{\\omega\\varepsilon_0\\varepsilon_r}\\right)^2}+1\\right)\\right\\}^{-\\frac{1}{2}}\n$$\n\nwhere the factor in curly brackets vanishes for non-conducting materials. The speed of light in vacuum is denoted $c_0=\\frac{1}{\\sqrt{\\varepsilon_0 \\mu_0}}$ and the vacuum wave number $k_0=\\frac{\\omega}{c_0}$. In conducting materials, the wave number is complex which translates to propagation losses.\n\nThe associated magnetic field $\\mathbf{H}(\\mathbf{x}, t)\\in\\mathbb{C}^3$ is\n\n$$\n\\mathbf{H}(\\mathbf{x}, t) = \\frac{\\hat{\\mathbf{k}}\\times  \\mathbf{E}(\\mathbf{x}, t)}{Z} = \\mathbf{H}(\\mathbf{x})e^{j\\omega t}\n$$\n\nwhere $Z=\\sqrt{\\mu/\\varepsilon}$ is the wave impedance. The vacuum impedance is denoted by $Z_0=\\sqrt{\\mu_0/\\varepsilon_0}\\approx 376.73\\,\\Omega$.\n\nThe time-averaged Poynting vector is defined as\n\n$$\n\\mathbf{S}(\\mathbf{x}) = \\frac{1}{2} \\Re\\left\\{\\mathbf{E}(\\mathbf{x})\\times  \\mathbf{H}(\\mathbf{x})\\right\\}\n                       = \\frac{1}{2} \\Re\\left\\{\\frac{1}{Z} \\right\\} \\lVert \\mathbf{E}(\\mathbf{x})  \\rVert^2 \\hat{\\mathbf{k}}\n$$\n\nwhich describes the directional energy flux (W/m), i.e., energy transfer per unit area per unit time.\n\nNote that the actual electromagnetic waves are the real parts of $\\mathbf{E}(\\mathbf{x}, t)$ and $\\mathbf{H}(\\mathbf{x}, t)$."
"## Far Field of a Transmitting Antenna\n\nWe assume that the electric far field of an antenna in free space can be described by a spherical wave originating from the center of the antenna:\n\n$$\n\\mathbf{E}(r, \\theta, \\varphi, t) = \\mathbf{E}(r,\\theta, \\varphi) e^{j\\omega t} = \\mathbf{E}_0(\\theta, \\varphi) \\frac{e^{-jk_0r}}{r} e^{j\\omega t}\n$$\n\nwhere $\\mathbf{E}_0(\\theta, \\varphi)$ is the electric field phasor, $r$ is the distance (or radius), $\\theta$ the zenith angle, and $\\varphi$ the azimuth angle.\nIn contrast to a planar wave, the field strength decays as $1/r$.\n\nThe complex antenna field pattern $\\mathbf{F}(\\theta, \\varphi)$ is defined as\n\n$$\n\\begin{align}\n    \\mathbf{F}(\\theta, \\varphi) = \\frac{ \\mathbf{E}_0(\\theta, \\varphi)}{\\max_{\\theta,\\varphi}\\lVert  \\mathbf{E}_0(\\theta, \\varphi) \\rVert}.\n\\end{align}\n$$\n\nThe time-averaged Poynting vector for such a spherical wave is\n\n$$\n\\mathbf{S}(r, \\theta, \\varphi) = \\frac{1}{2Z_0}\\lVert \\mathbf{E}(r, \\theta, \\varphi) \\rVert^2 \\hat{\\mathbf{r}}\n$$\n\nwhere $\\hat{\\mathbf{r}}$ is the radial unit vector. It simplifies for an ideal isotropic antenna with input power $P_\\text{T}$ to\n\n$$\n\\mathbf{S}_\\text{iso}(r, \\theta, \\varphi) = \\frac{P_\\text{T}}{4\\pi r^2} \\hat{\\mathbf{r}}.\n$$\n\nThe antenna gain $G$ is the ratio of the maximum radiation power density of the antenna in radial direction and that of an ideal isotropic radiating antenna:\n\n$$\n    G = \\frac{\\max_{\\theta,\\varphi}\\lVert \\mathbf{S}(r, \\theta, \\varphi)\\rVert}{ \\lVert\\mathbf{S}_\\text{iso}(r, \\theta, \\varphi)\\rVert}\n      = \\frac{2\\pi}{Z_0 P_\\text{T}} \\max_{\\theta,\\varphi}\\lVert \\mathbf{E}_0(\\theta, \\varphi) \\rVert^2.\n$$\n\nOne can similarly define a gain with directional dependency by ignoring the computation of the maximum the last equation:\n\n$$\n    G(\\theta, \\varphi) = \\frac{2\\pi}{Z_0 P_\\text{T}} \\lVert \\mathbf{E}_0(\\theta, \\varphi) \\rVert^2 = G \\lVert \\mathbf{F}(\\theta, \\varphi) \\rVert^2.\n$$\n\nIf one uses in the last equation the radiated power $P=\\eta_\\text{rad} P_\\text{T}$, where $\\eta_\\text{rad}$ is the radiation efficiency, instead of the input power $P_\\text{T}$, one obtains the directivity $D(\\theta,\\varphi)$. Both are related through $G(\\theta, \\varphi)=\\eta_\\text{rad} D(\\theta, \\varphi)$.\n\n**Antenna pattern**\n\nSince $\\mathbf{F}(\\theta, \\varphi)$ contains no information about the maximum gain $G$ and $G(\\theta, \\varphi)$ does not carry any phase information, we define the <cite>antenna pattern</cite> $\\mathbf{C}(\\theta, \\varphi)$ as\n\n$$\n\\mathbf{C}(\\theta, \\varphi) = \\sqrt{G}\\mathbf{F}(\\theta, \\varphi)\n$$\n\nsuch that $G(\\theta, \\varphi)= \\lVert\\mathbf{C}(\\theta, \\varphi) \\rVert^2$.\n\nUsing the spherical unit vectors $\\hat{\\boldsymbol{\\theta}}\\in\\mathbb{R}^3$\nand $\\hat{\\boldsymbol{\\varphi}}\\in\\mathbb{R}^3$,\nwe can rewrite $\\mathbf{C}(\\theta, \\varphi)$ as\n\n$$\n\\mathbf{C}(\\theta, \\varphi) = C_\\theta(\\theta,\\varphi) \\hat{\\boldsymbol{\\theta}} + C_\\varphi(\\theta,\\varphi) \\hat{\\boldsymbol{\\varphi}}\n$$\n\nwhere $C_\\theta(\\theta,\\varphi)\\in\\mathbb{C}$ and $C_\\varphi(\\theta,\\varphi)\\in\\mathbb{C}$ are the\n<cite>zenith pattern</cite> and <cite>azimuth pattern</cite>, respectively.\n\nCombining [(10)](https://nvlabs.github.io/sionna/em_primer.html#equation-f) and [(12)](https://nvlabs.github.io/sionna/em_primer.html#equation-g), we can obtain the following expression of the electric far field\n\n$$\n\\mathbf{E}_\\text{T}(r,\\theta_\\text{T},\\varphi_\\text{T}) = \\sqrt{ \\frac{P_\\text{T} G_\\text{T} Z_0}{2\\pi}} \\frac{e^{-jk_0 r}}{r} \\mathbf{F}_\\text{T}(\\theta_\\text{T}, \\varphi_\\text{T})\n$$\n\nwhere we have added the subscript $\\text{T}$ to all quantities that are specific to the transmitting antenna.\n\nThe input power $P_\\text{T}$ of an antenna with (conjugate matched) impedance $Z_\\text{T}$, fed by a voltage source with complex amplitude $V_\\text{T}$, is given by (see, e.g., [[Wikipedia]](https://nvlabs.github.io/sionna/em_primer.html#wikipedia))\n\n$$\nP_\\text{T} = \\frac{|V_\\text{T}|^2}{8\\Re\\{Z_\\text{T}\\}}.\n$$\n\n**Normalization of antenna patterns**\n\nThe radiated power $\\eta_\\text{rad} P_\\text{T}$ of an antenna can be obtained by integrating the Poynting vector over the surface of a closed sphere of radius $r$ around the antenna:\n\n$$\n\\begin{split}\\begin{align}\n    \\eta_\\text{rad} P_\\text{T} &=  \\int_0^{2\\pi}\\int_0^{\\pi} \\mathbf{S}(r, \\theta, \\varphi)^\\mathsf{T} \\hat{\\mathbf{r}} r^2 \\sin(\\theta)d\\theta d\\varphi \\\\\n                    &= \\int_0^{2\\pi}\\int_0^{\\pi} \\frac{1}{2Z_0} \\lVert \\mathbf{E}(r, \\theta, \\varphi) \\rVert^2 r^2\\sin(\\theta)d\\theta d\\varphi \\\\\n                    &= \\frac{P_\\text{T}}{4 \\pi} \\int_0^{2\\pi}\\int_0^{\\pi} G(\\theta, \\varphi) \\sin(\\theta)d\\theta d\\varphi.\n\\end{align}\\end{split}\n$$\n\nWe can see from the last equation that the directional gain of any antenna must satisfy\n\n$$\n\\int_0^{2\\pi}\\int_0^{\\pi} G(\\theta, \\varphi) \\sin(\\theta)d\\theta d\\varphi = 4 \\pi \\eta_\\text{rad}.\n$$"
"## Modelling of a Receiving Antenna\n\nAlthough the transmitting antenna radiates a spherical wave $\\mathbf{E}_\\text{T}(r,\\theta_\\text{T},\\varphi_\\text{T})$,\nwe assume that the receiving antenna observes a planar incoming wave $\\mathbf{E}_\\text{R}$ that arrives from the angles $\\theta_\\text{R}$ and $\\varphi_\\text{R}$\nwhich are defined in the local spherical coordinates of the receiving antenna. The Poynting vector of the incoming wave $\\mathbf{S}_\\text{R}$ is hence [(11)](https://nvlabs.github.io/sionna/em_primer.html#equation-s-spherical)\n\n$$\n\\mathbf{S}_\\text{R} = -\\frac{1}{2Z_0} \\lVert \\mathbf{E}_\\text{R} \\rVert^2 \\hat{\\mathbf{r}}(\\theta_\\text{R}, \\varphi_\\text{R})\n$$\n\nwhere $\\hat{\\mathbf{r}}(\\theta_\\text{R}, \\varphi_\\text{R})$ is the radial unit vector in the spherical coordinate system of the receiver.\n\nThe aperture or effective area $A_\\text{R}$ of an antenna with gain $G_\\text{R}$ is defined as the ratio of the available received power $P_\\text{R}$ at the output of the antenna and the absolute value of the Poynting vector, i.e., the power density:\n\n$$\nA_\\text{R} = \\frac{P_\\text{R}}{\\lVert \\mathbf{S}_\\text{R}\\rVert} = G_\\text{R}\\frac{\\lambda^2}{4\\pi}\n$$\n\nwhere $\\frac{\\lambda^2}{4\\pi}$ is the aperture of an isotropic antenna. In the definition above, it is assumed that the antenna is ideally directed towards and polarization matched to the incoming wave.\nFor an arbitrary orientation of the antenna (but still assuming polarization matching), we can define a direction dependent effective area\n\n$$\nA_\\text{R}(\\theta_\\text{R}, \\varphi_\\text{R}) = G_\\text{R}(\\theta_\\text{R}, \\varphi_\\text{R})\\frac{\\lambda^2}{4\\pi}.\n$$\n\nThe available received power at the output of the antenna can be expressed as\n\n$$\nP_\\text{R} = \\frac{|V_\\text{R}|^2}{8\\Re\\{Z_\\text{R}\\}}\n$$\n\nwhere $Z_\\text{R}$ is the impedance of the receiving antenna and $V_\\text{R}$ the open circuit voltage.\n\nWe can now combine [(20)](https://nvlabs.github.io/sionna/em_primer.html#equation-p-r), [(19)](https://nvlabs.github.io/sionna/em_primer.html#equation-a-dir), and [(18)](https://nvlabs.github.io/sionna/em_primer.html#equation-a-r) to obtain the following expression for the absolute value of the voltage $|V_\\text{R}|$\nassuming matched polarization:\n\n$$\n\\begin{split}\\begin{align}\n    |V_\\text{R}| &= \\sqrt{P_\\text{R} 8\\Re\\{Z_\\text{R}\\}}\\\\\n                 &= \\sqrt{\\frac{\\lambda^2}{4\\pi} G_\\text{R}(\\theta_\\text{R}, \\varphi_\\text{R}) \\frac{8\\Re\\{Z_\\text{R}\\}}{2 Z_0} \\lVert \\mathbf{E}_\\text{R} \\rVert^2}\\\\\n                 &= \\sqrt{\\frac{\\lambda^2}{4\\pi} G_\\text{R} \\frac{4\\Re\\{Z_\\text{R}\\}}{Z_0}} \\lVert \\mathbf{F}_\\text{R}(\\theta_\\text{R}, \\varphi_\\text{R})\\rVert\\lVert\\mathbf{E}_\\text{R}\\rVert.\n\\end{align}\\end{split}\n$$\n\nBy extension of the previous equation, we can obtain an expression for $V_\\text{R}$ which is valid for\narbitrary polarizations of the incoming wave and the receiving antenna:\n\n$$\nV_\\text{R} = \\sqrt{\\frac{\\lambda^2}{4\\pi} G_\\text{R} \\frac{4\\Re\\{Z_\\text{R}\\}}{Z_0}} \\mathbf{F}_\\text{R}(\\theta_\\text{R}, \\varphi_\\text{R})^{\\mathsf{H}}\\mathbf{E}_\\text{R}.\n$$\n\n**Example: Recovering Friis equation**\n\nIn the case of free space propagation, we have $\\mathbf{E}_\\text{R}=\\mathbf{E}_\\text{T}(r,\\theta_\\text{T},\\varphi_\\text{T})$.\nCombining [(21)](https://nvlabs.github.io/sionna/em_primer.html#equation-v-r), [(20)](https://nvlabs.github.io/sionna/em_primer.html#equation-p-r), and [(15)](https://nvlabs.github.io/sionna/em_primer.html#equation-e-t), we obtain the following expression for the received power:\n\n$$\nP_\\text{R} = \\left(\\frac{\\lambda}{4\\pi r}\\right)^2 G_\\text{R} G_\\text{T} P_\\text{T} \\left|\\mathbf{F}_\\text{R}(\\theta_\\text{R}, \\varphi_\\text{R})^{\\mathsf{H}} \\mathbf{F}_\\text{T}(\\theta_\\text{T}, \\varphi_\\text{T})\\right|^2.\n$$\n\nIt is important that $\\mathbf{F}_\\text{R}$ and $\\mathbf{F}_\\text{T}$ are expressed in the same coordinate system for the last equation to make sense.\nFor perfect orientation and polarization matching, we can recover the well-known Friis transmission equation:\n\n$$\n\\frac{P_\\text{R}}{P_\\text{T}} = \\left(\\frac{\\lambda}{4\\pi r}\\right)^2 G_\\text{R} G_\\text{T}.\n$$"
"## General Propagation Path\n\nA single propagation path consists of a cascade of multiple scattering processes, where a scattering process can be anything that prevents the wave from propagating as in free space. This includes reflection, refraction, diffraction, and diffuse scattering. For each scattering process, one needs to compute a relationship between the incoming field at the scatter center and the created far field at the next scatter center or the receiving antenna.\nWe can represent this cascade of scattering processes by a single matrix $\\widetilde{\\mathbf{T}}$\nthat describes the transformation that the radiated field $\\mathbf{E}_\\text{T}(r, \\theta_\\text{T}, \\varphi_\\text{T})$ undergoes until it reaches the receiving antenna:\n\n$$\n\\mathbf{E}_\\text{R} = \\sqrt{ \\frac{P_\\text{T} G_\\text{T} Z_0}{2\\pi}} \\widetilde{\\mathbf{T}} \\mathbf{F}_\\text{T}(\\theta_\\text{T}, \\varphi_\\text{T}).\n$$\n\nNote that we have obtained this expression by replacing the free space propagation term $\\frac{e^{-jk_0r}}{r}$ in [(15)](https://nvlabs.github.io/sionna/em_primer.html#equation-e-t) by the matrix $\\widetilde{\\mathbf{T}}$. This requires that all quantities are expressed in the same coordinate system which is also assumed in the following expressions. Further, it is assumed that the matrix $\\widetilde{\\mathbf{T}}$ includes the necessary coordinate transformations. In some cases, e.g., for diffuse scattering (see [(38)](https://nvlabs.github.io/sionna/em_primer.html#equation-scattered-field) in [Scattering](https://nvlabs.github.io/sionna/em_primer.html#scattering)), the matrix $\\widetilde{\\mathbf{T}}$ depends on the incoming field and is not a linear transformation.\n\nPlugging [(22)](https://nvlabs.github.io/sionna/em_primer.html#equation-e-r) into [(21)](https://nvlabs.github.io/sionna/em_primer.html#equation-v-r), we can obtain a general expression for the received voltage of a propagation path:\n\n$$\nV_\\text{R} = \\sqrt{\\left(\\frac{\\lambda}{4\\pi}\\right)^2 G_\\text{R}G_\\text{T}P_\\text{T} 8\\Re\\{Z_\\text{R}\\}} \\,\\mathbf{F}_\\text{R}(\\theta_\\text{R}, \\varphi_\\text{R})^{\\mathsf{H}}\\widetilde{\\mathbf{T}} \\mathbf{F}_\\text{T}(\\theta_\\text{T}, \\varphi_\\text{T}).\n$$\n\nIf the electromagnetic wave arrives at the receiving antenna over $N$ propagation paths, we can simply add the received voltages\nfrom all paths to obtain\n\n$$\n\\begin{split}\\begin{align}\nV_\\text{R} &= \\sqrt{\\left(\\frac{\\lambda}{4\\pi}\\right)^2 G_\\text{R}G_\\text{T}P_\\text{T} 8\\Re\\{Z_\\text{R}\\}} \\sum_{n=1}^N\\mathbf{F}_\\text{R}(\\theta_{\\text{R},i}, \\varphi_{\\text{R},i})^{\\mathsf{H}}\\widetilde{\\mathbf{T}}_i \\mathbf{F}_\\text{T}(\\theta_{\\text{T},i}, \\varphi_{\\text{T},i})\\\\\n&= \\sqrt{\\left(\\frac{\\lambda}{4\\pi}\\right)^2 P_\\text{T} 8\\Re\\{Z_\\text{R}\\}} \\sum_{n=1}^N\\mathbf{C}_\\text{R}(\\theta_{\\text{R},i}, \\varphi_{\\text{R},i})^{\\mathsf{H}}\\widetilde{\\mathbf{T}}_i \\mathbf{C}_\\text{T}(\\theta_{\\text{T},i}, \\varphi_{\\text{T},i})\n\\end{align}\\end{split}\n$$\n\nwhere all path-dependent quantities carry the subscript $i$. Note that the matrices $\\widetilde{\\mathbf{T}}_i$ also ensure appropriate scaling so that the total received power can never be larger than the transmit power."
"## Frequency & Impulse Response\n\nThe channel frequency response $H(f)$ at frequency $f=\\frac{c}{\\lambda}$ is defined as the ratio between the received voltage and the voltage at the input to the transmitting antenna:\n\n$$\nH(f) = \\frac{V_\\text{R}}{V_\\text{T}} = \\frac{V_\\text{R}}{|V_\\text{T}|}\n$$\n\nwhere it is assumed that the input voltage has zero phase.\n\nIt is useful to separate phase shifts due to wave propagation from the transfer matrices $\\widetilde{\\mathbf{T}}_i$. If we denote by $r_i$ the total length of path $i$ with average propagation speed $c_i$, the path delay is $\\tau_i=r_i/c_i$. We can now define the new transfer matrix\n\n$$\n\\mathbf{T}_i=\\widetilde{\\mathbf{T}}_ie^{j2\\pi f \\tau_i}.\n$$\n\nUsing [(16)](https://nvlabs.github.io/sionna/em_primer.html#equation-p-t) and [(25)](https://nvlabs.github.io/sionna/em_primer.html#equation-t-tilde) in [(23)](https://nvlabs.github.io/sionna/em_primer.html#equation-v-rmulti) while assuming equal real parts of both antenna impedances, i.e., $\\Re\\{Z_\\text{T}\\}=\\Re\\{Z_\\text{R}\\}$ (which is typically the case), we obtain the final expression for the channel frequency response:\n\n$$\n\\boxed{H(f) = \\sum_{i=1}^N \\underbrace{\\frac{\\lambda}{4\\pi} \\mathbf{C}_\\text{R}(\\theta_{\\text{R},i}, \\varphi_{\\text{R},i})^{\\mathsf{H}}\\mathbf{T}_i \\mathbf{C}_\\text{T}(\\theta_{\\text{T},i}, \\varphi_{\\text{T},i})}_{\\triangleq a_i} e^{-j2\\pi f\\tau_i}}\n$$\n\nTaking the inverse Fourier transform, we finally obtain the channel impulse response\n\n$$\n\\boxed{h(\\tau) = \\int_{-\\infty}^{\\infty} H(f) e^{j2\\pi f \\tau} df = \\sum_{i=1}^N a_i \\delta(\\tau-\\tau_i)}\n$$\n\nThe baseband equivalent channel impulse reponse is then defined as (Eq. 2.28) [[Tse]](https://nvlabs.github.io/sionna/em_primer.html#tse):\n\n$$\nh_\\text{b}(\\tau) = \\sum_{i=1}^N \\underbrace{a_i e^{-j2\\pi f \\tau_i}}_{\\triangleq a^\\text{b}_i} \\delta(\\tau-\\tau_i).\n$$"
"## Reflection and Refraction\n\nWhen a plane wave hits a plane interface which separates two materials, e.g., air and concrete, a part of the wave gets reflected and the other transmitted (or *refracted*), i.e., it propagates into the other material.  We assume in the following description that both materials are uniform non-magnetic dielectrics, i.e., $\\mu_r=1$, and follow the definitions as in [[ITURP20402]](https://nvlabs.github.io/sionna/em_primer.html#iturp20402). The incoming wave phasor $\\mathbf{E}_\\text{i}$ is expressed by two arbitrary orthogonal polarization components, i.e.,\n\n$$\n\\mathbf{E}_\\text{i} = E_{\\text{i},s} \\hat{\\mathbf{e}}_{\\text{i},s} + E_{\\text{i},p} \\hat{\\mathbf{e}}_{\\text{i},p}\n$$\n\nwhich are both orthogonal to the incident wave vector, i.e., $\\hat{\\mathbf{e}}_{\\text{i},s}^{\\mathsf{T}} \\hat{\\mathbf{e}}_{\\text{i},p}=\\hat{\\mathbf{e}}_{\\text{i},s}^{\\mathsf{T}} \\hat{\\mathbf{k}}_\\text{i}=\\hat{\\mathbf{e}}_{\\text{i},p}^{\\mathsf{T}} \\hat{\\mathbf{k}}_\\text{i} =0$.\n\n ig. 1 Reflection and refraction of a plane wave at a plane interface between two materials.\n\n[Fig. 1](https://nvlabs.github.io/sionna/em_primer.html#fig-reflection) shows reflection and refraction of the incoming wave at the plane interface between two materials with relative permittivities $\\eta_1$ and $\\eta_2$. The coordinate system is chosen such that the wave vectors of the incoming, reflected, and transmitted waves lie within the plane of incidence, which is chosen to be the x-z plane. The normal vector of the interface $\\hat{\\mathbf{n}}$ is pointing toward the negative z axis.\nThe incoming wave is must be represented in a different basis, i.e., in the form two different orthogonal polarization components $E_{\\text{i}, \\perp}$ and $E_{\\text{i}, \\parallel}$, i.e.,\n\n$$\n\\mathbf{E}_\\text{i} = E_{\\text{i},\\perp} \\hat{\\mathbf{e}}_{\\text{i},\\perp} + E_{\\text{i},\\parallel} \\hat{\\mathbf{e}}_{\\text{i},\\parallel}\n$$\n\nwhere the former is orthogonal to the plane of incidence and called transverse electric (TE) polarization (left), and the latter is parallel to the plane of incidence and called transverse magnetic (TM) polarization (right). We adopt in the following the convention that all transverse components are coming out of the figure (indicated by the $\\odot$ symbol). One can easily verify that the following relationships must hold:\n\n$$\n\\begin{split}\\begin{align}\n    \\hat{\\mathbf{e}}_{\\text{i},\\perp} &= \\frac{\\hat{\\mathbf{k}}_\\text{i} \\times \\hat{\\mathbf{n}}}{\\lVert \\hat{\\mathbf{k}}_\\text{i} \\times \\hat{\\mathbf{n}} \\rVert} \\\\\n    \\hat{\\mathbf{e}}_{\\text{i},\\parallel} &= \\hat{\\mathbf{e}}_{\\text{i},\\perp} \\times \\hat{\\mathbf{k}}_\\text{i}\n\\end{align}\\end{split}\n$$\n\n$$\n\\begin{split}\\begin{align}\n\\begin{bmatrix}E_{\\text{i},\\perp} \\\\ E_{\\text{i},\\parallel} \\end{bmatrix} &=\n    \\begin{bmatrix}\n        \\hat{\\mathbf{e}}_{\\text{i},\\perp}^\\mathsf{T}\\hat{\\mathbf{e}}_{\\text{i},s} & \\hat{\\mathbf{e}}_{\\text{i},\\perp}^\\mathsf{T}\\hat{\\mathbf{e}}_{\\text{i},p}\\\\\n        \\hat{\\mathbf{e}}_{\\text{i},\\parallel}^\\mathsf{T}\\hat{\\mathbf{e}}_{\\text{i},s} & \\hat{\\mathbf{e}}_{\\text{i},\\parallel}^\\mathsf{T}\\hat{\\mathbf{e}}_{\\text{i},p}\n    \\end{bmatrix}\n \\begin{bmatrix}E_{\\text{i},s} \\\\ E_{\\text{i},p}\\end{bmatrix} =\n \\mathbf{W}\\left(\\hat{\\mathbf{e}}_{\\text{i},\\perp}, \\hat{\\mathbf{e}}_{\\text{i},\\parallel}, \\hat{\\mathbf{e}}_{\\text{i},s}, \\hat{\\mathbf{e}}_{\\text{i},p}\\right)\n\\end{align}\\end{split}\n$$\n\nwhere we have defined the following matrix-valued function\n\n$$\n\\begin{split}\\begin{align}\n\\mathbf{W}\\left(\\hat{\\mathbf{a}}, \\hat{\\mathbf{b}}, \\hat{\\mathbf{q}}, \\hat{\\mathbf{r}} \\right) =\n    \\begin{bmatrix}\n        \\hat{\\mathbf{a}}^\\textsf{T} \\hat{\\mathbf{q}} & \\hat{\\mathbf{a}}^\\textsf{T} \\hat{\\mathbf{r}} \\\\\n        \\hat{\\mathbf{b}}^\\textsf{T} \\hat{\\mathbf{q}} & \\hat{\\mathbf{b}}^\\textsf{T} \\hat{\\mathbf{r}}\n    \\end{bmatrix}.\n\\end{align}\\end{split}\n$$\n\nWhile the angles of incidence and reflection are both equal to $\\theta_1$, the angle of the refracted wave $\\theta_2$ is given by Snells law:\n\n$$\n\\sin(\\theta_2) = \\sqrt{\\frac{\\eta_1}{\\eta_2}} \\sin(\\theta_1)\n$$\n\nor, equivalently,\n\n$$\n\\cos(\\theta_2) = \\sqrt{1 - \\frac{\\eta_1}{\\eta_2} \\sin^2(\\theta_1)}.\n$$\n\nThe reflected and transmitted wave phasors $\\mathbf{E}_\\text{r}$ and $\\mathbf{E}_\\text{t}$ are similarly represented as\n\n$$\n\\begin{split}\\begin{align}\n    \\mathbf{E}_\\text{r} &= E_{\\text{r},\\perp} \\hat{\\mathbf{e}}_{\\text{r},\\perp} + E_{\\text{r},\\parallel} \\hat{\\mathbf{e}}_{\\text{r},\\parallel}\\\\\n    \\mathbf{E}_\\text{t} &= E_{\\text{t},\\perp} \\hat{\\mathbf{e}}_{\\text{t},\\perp} + E_{\\text{t},\\parallel} \\hat{\\mathbf{e}}_{\\text{t},\\parallel}\n\\end{align}\\end{split}\n$$\n\nwhere\n\n$$\n\\begin{split}\\begin{align}\n    \\hat{\\mathbf{e}}_{\\text{r},\\perp} &= \\hat{\\mathbf{e}}_{\\text{i},\\perp}\\\\\n    \\hat{\\mathbf{e}}_{\\text{r},\\parallel} &= \\frac{\\hat{\\mathbf{e}}_{\\text{r},\\perp}\\times\\hat{\\mathbf{k}}_\\text{r}}{\\lVert \\hat{\\mathbf{e}}_{\\text{r},\\perp}\\times\\hat{\\mathbf{k}}_\\text{r} \\rVert}\\\\\n    \\hat{\\mathbf{e}}_{\\text{t},\\perp} &= \\hat{\\mathbf{e}}_{\\text{i},\\perp}\\\\\n    \\hat{\\mathbf{e}}_{\\text{t},\\parallel} &= \\frac{\\hat{\\mathbf{e}}_{\\text{t},\\perp}\\times\\hat{\\mathbf{k}}_\\text{t}}{ \\Vert \\hat{\\mathbf{e}}_{\\text{t},\\perp}\\times\\hat{\\mathbf{k}}_\\text{t} \\rVert}\n\\end{align}\\end{split}\n$$\n\nand\n\n$$\n\\begin{split}\\begin{align}\n    \\hat{\\mathbf{k}}_\\text{r} &= \\hat{\\mathbf{k}}_\\text{i} - 2\\left( \\hat{\\mathbf{k}}_\\text{i}^\\mathsf{T}\\hat{\\mathbf{n}} \\right)\\hat{\\mathbf{n}}\\\\\n    \\hat{\\mathbf{k}}_\\text{t} &= \\sqrt{\\frac{\\eta_1}{\\eta_2}} \\hat{\\mathbf{k}}_\\text{i} + \\left(\\sqrt{\\frac{\\eta_1}{\\eta_2}}\\cos(\\theta_1) - \\cos(\\theta_2) \\right)\\hat{\\mathbf{n}}.\n\\end{align}\\end{split}\n$$\n\nThe *Fresnel* equations provide relationships between the incident, reflected, and refracted field components for $\\sqrt{\\left| \\eta_1/\\eta_2 \\right|}\\sin(\\theta_1)<1$:\n\n$$\n\\begin{split}\\begin{align}\n    r_{\\perp}     &= \\frac{E_{\\text{r}, \\perp    }}{E_{\\text{i}, \\perp    }} = \\frac{ \\sqrt{\\eta_1}\\cos(\\theta_1) - \\sqrt{\\eta_2}\\cos(\\theta_2) }{ \\sqrt{\\eta_1}\\cos(\\theta_1) + \\sqrt{\\eta_2}\\cos(\\theta_2) } \\\\\n    r_{\\parallel} &= \\frac{E_{\\text{r}, \\parallel}}{E_{\\text{i}, \\parallel}} = \\frac{ \\sqrt{\\eta_2}\\cos(\\theta_1) - \\sqrt{\\eta_1}\\cos(\\theta_2) }{ \\sqrt{\\eta_2}\\cos(\\theta_1) + \\sqrt{\\eta_1}\\cos(\\theta_2) } \\\\\n    t_{\\perp}     &= \\frac{E_{\\text{t}, \\perp    }}{E_{\\text{t}, \\perp    }} = \\frac{ 2\\sqrt{\\eta_1}\\cos(\\theta_1) }{ \\sqrt{\\eta_1}\\cos(\\theta_1) + \\sqrt{\\eta_2}\\cos(\\theta_2) } \\\\\n    t_{\\parallel} &= \\frac{E_{\\text{t}, \\parallel}}{E_{\\text{t}, \\parallel}} = \\frac{ 2\\sqrt{\\eta_1}\\cos(\\theta_1) }{ \\sqrt{\\eta_2}\\cos(\\theta_1) + \\sqrt{\\eta_1}\\cos(\\theta_2) }.\n\\end{align}\\end{split}\n$$\n\nIf $\\sqrt{\\left| \\eta_1/\\eta_2 \\right|}\\sin(\\theta_1)\\ge 1$, we have $r_{\\perp}=r_{\\parallel}=1$ and $t_{\\perp}=t_{\\parallel}=0$, i.e., total reflection.\n\nFor the case of an incident wave in vacuum, i.e., $\\eta_1=1$, the Fresnel equations [(33)](https://nvlabs.github.io/sionna/em_primer.html#equation-fresnel) simplify to\n\n$$\n\\begin{split}\\begin{align}\n    r_{\\perp}     &= \\frac{\\cos(\\theta_1) -\\sqrt{\\eta_2 -\\sin^2(\\theta_1)}}{\\cos(\\theta_1) +\\sqrt{\\eta_2 -\\sin^2(\\theta_1)}} \\\\\n    r_{\\parallel} &= \\frac{\\eta_2\\cos(\\theta_1) -\\sqrt{\\eta_2 -\\sin^2(\\theta_1)}}{\\eta_2\\cos(\\theta_1) +\\sqrt{\\eta_2 -\\sin^2(\\theta_1)}} \\\\\n    t_{\\perp}     &= \\frac{2\\cos(\\theta_1)}{\\cos(\\theta_1) + \\sqrt{\\eta_2-\\sin^2(\\theta_1)}}\\\\\n    t_{\\parallel} &= \\frac{2\\sqrt{\\eta_2}\\cos(\\theta_1)}{\\eta_2 \\cos(\\theta_1) + \\sqrt{\\eta_2-\\sin^2(\\theta_1)}}.\n\\end{align}\\end{split}\n$$\n\nPutting everything together, we obtain the following relationships between incident, reflected, and transmitted waves:\n\n$$\n\\begin{split}\\begin{align}\n    \\begin{bmatrix}E_{\\text{r},\\perp} \\\\ E_{\\text{r},\\parallel} \\end{bmatrix} &=\n    \\begin{bmatrix}\n        r_{\\perp} & 0 \\\\\n        0         & r_{\\parallel}\n    \\end{bmatrix}\n    \\mathbf{W}\\left(\\hat{\\mathbf{e}}_{\\text{i},\\perp}, \\hat{\\mathbf{e}}_{\\text{i},\\parallel}, \\hat{\\mathbf{e}}_{\\text{i},s}, \\hat{\\mathbf{e}}_{\\text{i},p}\\right)\n \\begin{bmatrix}E_{\\text{i},s} \\\\ E_{\\text{i},p}\\end{bmatrix} \\\\\n \\begin{bmatrix}E_{\\text{t},\\perp} \\\\ E_{\\text{t},\\parallel} \\end{bmatrix} &=\n    \\begin{bmatrix}\n        t_{\\perp} & 0 \\\\\n        0         & t_{\\parallel}\n    \\end{bmatrix}\n    \\mathbf{W}\\left(\\hat{\\mathbf{e}}_{\\text{i},\\perp}, \\hat{\\mathbf{e}}_{\\text{i},\\parallel}, \\hat{\\mathbf{e}}_{\\text{i},s}, \\hat{\\mathbf{e}}_{\\text{i},p}\\right)\n \\begin{bmatrix}E_{\\text{i},s} \\\\ E_{\\text{i},p}\\end{bmatrix}.\n\\end{align}\\end{split}\n$$"
"## Diffraction\n\nWhile modern geometrical optics (GO) [[Kline]](https://nvlabs.github.io/sionna/em_primer.html#kline), [[Luneberg]](https://nvlabs.github.io/sionna/em_primer.html#luneberg) can accurately describe phase and polarization properties of electromagnetic fields undergoing reflection and refraction (transmission) as described above, they fail to account for the phenomenon of diffraction, e.g., bending of waves around corners. This leads to the undesired and physically incorrect effect that the field abruptly falls to zero at geometrical shadow boundaries (for incident and reflected fields).\n\nJoseph Keller presented in [[Keller62]](https://nvlabs.github.io/sionna/em_primer.html#keller62) a method which allowed the incorporation of diffraction into GO which is known as the geometrical theory of diffraction (GTD). He introduced the notion of diffracted rays that follow the law of edge diffraction, i.e., the diffracted and incident rays make the same angle with the edge at the point of diffraction and lie on opposite sides of the plane normal to the edge. The GTD suffers, however from several shortcomings, most importantly the fact that the diffracted field is infinite at shadow boundaries.\n\nThe uniform theory of diffraction (UTD) [[Kouyoumjian74]](https://nvlabs.github.io/sionna/em_primer.html#kouyoumjian74) alleviates this problem and provides solutions that are uniformly valid, even at shadow boundaries. For a great introduction to the UTD, we refer to [[McNamara90]](https://nvlabs.github.io/sionna/em_primer.html#mcnamara90). While [[Kouyoumjian74]](https://nvlabs.github.io/sionna/em_primer.html#kouyoumjian74) deals with diffraction at edges of perfectly conducting surfaces, it was heuristically extended to finitely conducting wedges in [[Luebbers84]](https://nvlabs.github.io/sionna/em_primer.html#luebbers84). This solution, which is also recomended by the ITU [[ITURP52615]](https://nvlabs.github.io/sionna/em_primer.html#iturp52615), is implemented in Sionna. However, both [[Luebbers84]](https://nvlabs.github.io/sionna/em_primer.html#luebbers84) and [[ITURP52615]](https://nvlabs.github.io/sionna/em_primer.html#iturp52615) only deal with two-dimensional scenes where source and observation lie in the same plane, orthogonal to the edge. We will provide below the three-dimensional version of [[Luebbers84]](https://nvlabs.github.io/sionna/em_primer.html#luebbers84), following the defintitions of (Ch. 6) [[McNamara90]](https://nvlabs.github.io/sionna/em_primer.html#mcnamara90). A similar result can be found, e.g., in (Eq. 6-296-39) [[METIS]](https://nvlabs.github.io/sionna/em_primer.html#metis).\n\n ig. 2 Incident and diffracted rays for an infinitely long wedge in an edge-fixed coordinate system.\n\nWe consider an infinitely long wedge with unit norm edge vector $\\hat{\\mathbf{e}}$, as shown in [Fig. 2](https://nvlabs.github.io/sionna/em_primer.html#fig-kellers-cone). An incident ray of a spherical wave with field phasor $\\mathbf{E}_i(S')$ at point $S'$ propagates in the direction $\\hat{\\mathbf{s}}'$ and is diffracted at point $Q_d$ on the edge. The diffracted ray of interest (there are infinitely many on Kellers cone) propagates\nin the direction $\\hat{\\mathbf{s}}$ towards the point of observation $S$. We denote by $s'=\\lVert S'-Q_d \\rVert$ and $s=\\lVert Q_d - S\\rVert$ the lengths of the incident and diffracted path segments, respectively. By the law of edge diffraction, the angles $\\beta_0'$ and $\\beta_0$ between the edge and the incident and diffracted rays, respectively, satisfy:\n\n$$\n\\begin{equation}\n    \\cos(\\beta_0') = |\\hat{\\mathbf{s}}'^\\textsf{T}\\hat{\\mathbf{e}}| = |\\hat{\\mathbf{s}}^\\textsf{T}\\hat{\\mathbf{e}}| = \\cos(\\beta_0).\n\\end{equation}\n$$\n\nTo be able to express the diffraction coefficients as a 2x2 matrixsimilar to what is done for reflection and refractionthe incident field must be resolved into two components $E_{i,\\phi'}$ and $E_{i,\\beta_0'}$, the former orthogonal and the latter parallel to the edge-fixed plane of incidence, i.e., the plane containing $\\hat{\\mathbf{e}}$ and $\\hat{\\mathbf{s}}'$. The diffracted field is then represented by two components $E_{d,\\phi}$ and $E_{d,\\beta_0}$ that are respectively orthogonal and parallel to the edge-fixed plane of diffraction, i.e., the plane containing $\\hat{\\mathbf{e}}$ and $\\hat{\\mathbf{s}}$.\nThe corresponding component unit vectors are defined as\n\n$$\n\\begin{split}\\begin{align}\n    \\hat{\\boldsymbol{\\phi}}' &= \\frac{\\hat{\\mathbf{s}}' \\times \\hat{\\mathbf{e}}}{\\lVert \\hat{\\mathbf{s}}' \\times \\hat{\\mathbf{e}} \\rVert }\\\\\n    \\hat{\\boldsymbol{\\beta}}_0' &=  \\hat{\\boldsymbol{\\phi}}' \\times \\hat{\\mathbf{s}}' \\\\\n    \\hat{\\boldsymbol{\\phi}} &= -\\frac{\\hat{\\mathbf{s}} \\times \\hat{\\mathbf{e}}}{\\lVert \\hat{\\mathbf{s}} \\times \\hat{\\mathbf{e}} \\rVert }\\\\\n    \\hat{\\boldsymbol{\\beta}}_0 &=  \\hat{\\boldsymbol{\\phi}} \\times \\hat{\\mathbf{s}}.\n\\end{align}\\end{split}\n$$\n\n[Fig. 3](https://nvlabs.github.io/sionna/em_primer.html#fig-diffraction) below shows the top view on the wedge that we need for some additional definitions.\n\n ig. 3 Top view on the wedge with edge vector pointing upwards.\n\nThe wedge has two faces called *0-face* and *n-face*, respectively, with surface normal vectors $\\hat{\\mathbf{n}}_0$ and $\\hat{\\mathbf{n}}_n$. The exterior wedge angle is $n\\pi$, with $1\\le n \\le 2$. Note that the surfaces are chosen such that $\\hat{\\mathbf{e}} = \\hat{\\mathbf{n}}_0 \\times \\hat{\\mathbf{n}}_n$. For $n=2$, the wedge reduces to a screen and the choice of the *0-face* and *n-face* is arbitrary as they point in opposite directions.\n\nThe incident and diffracted rays have angles $\\phi'$ and $\\phi$ measured with respect to the *0-face* in the plane perpendicular to the edge.\nThey can be computed as follows:\n\n$$\n\\begin{split}\\begin{align}\n    \\phi' & = \\pi - \\left[\\pi - \\cos^{-1}\\left( -\\hat{\\mathbf{s}}_t'^\\textsf{T} \\hat{\\mathbf{t}}_0\\right) \\right] \\mathop{\\text{sgn}}\\left(-\\hat{\\mathbf{s}}_t'^\\textsf{T} \\hat{\\mathbf{n}}_0\\right)\\\\\n    \\phi & = \\pi - \\left[\\pi - \\cos^{-1}\\left( \\hat{\\mathbf{s}}_t^\\textsf{T} \\hat{\\mathbf{t}}_0\\right) \\right] \\mathop{\\text{sgn}}\\left(\\hat{\\mathbf{s}}_t^\\textsf{T} \\hat{\\mathbf{n}}_0\\right)\n\\end{align}\\end{split}\n$$\n\nwhere\n\n$$\n\\begin{split}\\begin{align}\n    \\hat{\\mathbf{t}}_0 &= \\hat{\\mathbf{n}}_0 \\times \\hat{\\mathbf{e}}\\\\\n    \\hat{\\mathbf{s}}_t' &= \\frac{ \\hat{\\mathbf{s}}' - \\left( \\hat{\\mathbf{s}}'^\\textsf{T}\\hat{\\mathbf{e}} \\right)\\hat{\\mathbf{e}} }{\\lVert \\hat{\\mathbf{s}}' - \\left( \\hat{\\mathbf{s}}'^\\textsf{T}\\hat{\\mathbf{e}} \\right)\\hat{\\mathbf{e}}  \\rVert}\\\\\n    \\hat{\\mathbf{s}}_t  &= \\frac{ \\hat{\\mathbf{s}} - \\left( \\hat{\\mathbf{s}}^\\textsf{T}\\hat{\\mathbf{e}} \\right)\\hat{\\mathbf{e}} }{\\lVert \\hat{\\mathbf{s}} - \\left( \\hat{\\mathbf{s}}^\\textsf{T}\\hat{\\mathbf{e}} \\right)\\hat{\\mathbf{e}}  \\rVert}\n\\end{align}\\end{split}\n$$\n\nare the unit vector tangential to the *0-face*, as well as the unit vectors pointing in the directions of $\\hat{\\mathbf{s}}'$ and $\\hat{\\mathbf{s}}$, projected on the plane perpendicular to the edge, respectively. The function $\\mathop{\\text{sgn}}(x)$ is defined in this context as\n\n$$\n\\begin{split}\\mathop{\\text{sgn}}(x) = \\begin{cases}\n                         1  &, x \\ge 0\\\\\n                         -1 &, x< 0.\n                         \\end{cases}\\end{split}\n$$\n\nWith these definitions, the diffracted field at point $S$ can be computed from the incoming field at point $S'$ as follows:\n\n$$\n\\begin{split}\\begin{align}\n    \\begin{bmatrix}\n        E_{d,\\phi} \\\\\n        E_{d,\\beta_0}\n    \\end{bmatrix} (S) = - \\left( \\left(D_1 + D_2\\right)\\mathbf{I} - D_3 \\mathbf{R}_n - D_4\\mathbf{R}_0 \\right)\\begin{bmatrix}\n        E_{i,\\phi'} \\\\\n        E_{i,\\beta_0'}\n    \\end{bmatrix}(S') \\sqrt{\\frac{1}{s's(s'+s)}} e^{-jk(s'+s)}\n\\end{align}\\end{split}\n$$\n\nwhere $k=2\\pi/\\lambda$ is the wave number and the matrices $\\mathbf{R}_\\nu,\\, \\nu \\in [0,n]$, are given as\n\n$$\n\\begin{split}\\begin{align}\n    \\mathbf{R}_\\nu = \\mathbf{W}\\left(\\hat{\\boldsymbol{\\phi}}, \\hat{\\boldsymbol{\\beta}}_0, \\hat{\\mathbf{e}}_{r, \\perp, \\nu}, \\hat{\\mathbf{e}}_{r, \\parallel, \\nu}  \\right)\n                    \\begin{bmatrix}\n                        r_{\\perp}(\\theta_{r,\\nu}, \\eta_{\\nu}) & 0\\\\\n                        0 & r_{\\parallel}(\\theta_{r,\\nu}, \\eta_{nu})\n                    \\end{bmatrix}\n                     \\mathbf{W}\\left( \\hat{\\mathbf{e}}_{i, \\perp, \\nu}, \\hat{\\mathbf{e}}_{i, \\parallel, \\nu}, \\hat{\\boldsymbol{\\phi}}', \\hat{\\boldsymbol{\\beta}}_0' \\right)\n\\end{align}\\end{split}\n$$\n\nwith $\\mathbf{W}(\\cdot)$ as defined in [(30)](https://nvlabs.github.io/sionna/em_primer.html#equation-w), where $r_{\\perp}(\\theta_{r,\\nu}, \\eta_{\\nu})$ and $r_{\\parallel}(\\theta_{r,\\nu}, \\eta_{\\nu})$ are the Fresnel reflection coefficents from [(34)](https://nvlabs.github.io/sionna/em_primer.html#equation-fresnel-vac), evaluated for the complex relative permittivities $\\eta_{\\nu}$ and angles $\\theta_{r_,\\nu}$ with cosines\n\n$$\n\\begin{split}\\begin{align}\n    \\cos\\left(\\theta_{r,0}\\right) &= \\left|\\sin(\\phi') \\right|\\\\\n    \\cos\\left(\\theta_{r,n}\\right) &= \\left|\\sin(n\\pi -\\phi) \\right|.\n\\end{align}\\end{split}\n$$\n\nand where\n\n$$\n\\begin{split}\\begin{align}\n    \\hat{\\mathbf{e}}_{i,\\perp,\\nu} &= \\frac{ \\hat{\\mathbf{s}}' \\times \\hat{\\mathbf{n}}_{\\nu} }{\\lVert \\hat{\\mathbf{s}}' \\times \\hat{\\mathbf{n}}_{\\nu} \\rVert}\\\\\n    \\hat{\\mathbf{e}}_{i,\\parallel,\\nu} &=  \\hat{\\mathbf{e}}_{i,\\perp,\\nu} \\times \\hat{\\mathbf{s}}'\\\\\n    \\hat{\\mathbf{e}}_{r,\\perp,\\nu} &=  \\hat{\\mathbf{e}}_{i,\\perp,\\nu}\\\\\n    \\hat{\\mathbf{e}}_{r,\\parallel,\\nu} &=  \\hat{\\mathbf{e}}_{i,\\perp,\\nu} \\times \\hat{\\mathbf{s}}\n\\end{align}\\end{split}\n$$\n\nas already defined in [(29)](https://nvlabs.github.io/sionna/em_primer.html#equation-fresnel-in-vectors) and [(31)](https://nvlabs.github.io/sionna/em_primer.html#equation-fresnel-out-vectors), but made explicit here for the case of diffraction. The matrices $\\mathbf{R}_\\nu$ simply describe the reflected field from both surfaces in the basis used for the description of the diffraction process. Note that the absolute value is used in [(36)](https://nvlabs.github.io/sionna/em_primer.html#equation-diffraction-cos) to account for virtual reflections from shadowed surfaces, see the discussion in (p.185) [[McNamara90]](https://nvlabs.github.io/sionna/em_primer.html#mcnamara90).\nThe diffraction coefficients $D_1,\\dots,D_4$ are computed as\n\n$$\n\\begin{split}\\begin{align}\n    D_1 &= \\frac{-e^{-\\frac{j\\pi}{4}}}{2n\\sqrt{2\\pi k} \\sin(\\beta_0)} \\mathop{\\text{cot}}\\left( \\frac{\\pi+(\\phi-\\phi')}{2n}\\right) F\\left( k L a^+(\\phi-\\phi')\\right)\\\\\n    D_2 &= \\frac{-e^{-\\frac{j\\pi}{4}}}{2n\\sqrt{2\\pi k} \\sin(\\beta_0)} \\mathop{\\text{cot}}\\left( \\frac{\\pi-(\\phi-\\phi')}{2n}\\right) F\\left( k L a^-(\\phi-\\phi')\\right)\\\\\n    D_3 &= \\frac{-e^{-\\frac{j\\pi}{4}}}{2n\\sqrt{2\\pi k} \\sin(\\beta_0)} \\mathop{\\text{cot}}\\left( \\frac{\\pi+(\\phi+\\phi')}{2n}\\right) F\\left( k L a^+(\\phi+\\phi')\\right)\\\\\n    D_4 &= \\frac{-e^{-\\frac{j\\pi}{4}}}{2n\\sqrt{2\\pi k} \\sin(\\beta_0)} \\mathop{\\text{cot}}\\left( \\frac{\\pi-(\\phi+\\phi')}{2n}\\right) F\\left( k L a^-(\\phi+\\phi')\\right)\n\\end{align}\\end{split}\n$$\n\nwhere\n\n$$\n\\begin{split}\\begin{align}\n    L &= \\frac{ss'}{s+s'}\\sin^2(\\beta_0)\\\\\n    a^{\\pm}(\\beta) &= 2\\cos^2\\left(\\frac{2n\\pi N^{\\pm}-\\beta}{2}\\right)\\\\\n    N^{\\pm} &= \\mathop{\\text{round}}\\left(\\frac{\\beta\\pm\\pi}{2n\\pi}\\right)\\\\\n    F(x) &= 2j\\sqrt{x}e^{jx}\\int_{\\sqrt{x}}^\\infty e^{-jt^2}dt\n\\end{align}\\end{split}\n$$\n\nand $\\mathop{\\text{round}}()$ is the function that rounds to the closest integer. The function $F(x)$ can be expressed with the help of the standard Fresnel integrals [[Fresnel]](https://nvlabs.github.io/sionna/em_primer.html#fresnel)\n\n$$\n\\begin{split}\\begin{align}\n    S(x) &= \\int_0^x \\sin\\left( \\pi t^2/2 \\right)dt \\\\\n    C(x) &= \\int_0^x \\cos\\left( \\pi t^2/2 \\right)dt\n\\end{align}\\end{split}\n$$\n\nas\n\n$$\n\\begin{align}\n    F(x) = \\sqrt{\\frac{\\pi x}{2}} e^{jx} \\left[1+j-2\\left( S\\left(\\sqrt{2x/\\pi}\\right) +jC\\left(\\sqrt{2x/\\pi}\\right) \\right) \\right].\n\\end{align}\n$$"
"## Scattering\n\nWhen an electromagnetic wave impinges on a surface, one part of the energy gets reflected while the other part gets refracted, i.e., it propagates into the surface.\nWe distinguish between two types of reflection, specular and diffuse. The former type is discussed in [Reflection and Refraction](https://nvlabs.github.io/sionna/em_primer.html#reflection-and-refraction) and we will focus now on the latter type which is also called diffuse scattering. When a rays hits a diffuse reflection surface, it is not reflected into a single (specular) direction but rather scattered toward many different directions. Since most surfaces give both specular and diffuse reflections, we denote by $S^2$ the fraction of the reflected energy that is diffusely scattered, where $S\\in[0,1]$ is the so-called *scattering coefficient* [[Degli-Esposti07]](https://nvlabs.github.io/sionna/em_primer.html#degli-esposti07). Similarly, $R^2$ is the specularly reflected fraction of the reflected energy, where $R\\in[0,1]$ is the *reflection reduction factor*. The following relationship between $R$ and $S$ holds:\n\n$$\nR = \\sqrt{1-S^2}.\n$$\n\nWhenever a material has a scattering coefficient $S>0$, the Fresnel reflection coefficents in [(33)](https://nvlabs.github.io/sionna/em_primer.html#equation-fresnel) must be multiplied by $R$. These *reduced* coefficients must then be also used in the compuation of the diffraction coefficients [(35)](https://nvlabs.github.io/sionna/em_primer.html#equation-diff-mat).\n\n ig. 4 Diffuse and specular reflection of an incoming wave.\n\nLet us consider an incoming locally planar linearly polarized wave with field phasor $\\mathbf{E}_\\text{i}(\\mathbf{q})$ at the scattering point $\\mathbf{q}$ on the surface, as shown in [Fig. 4](https://nvlabs.github.io/sionna/em_primer.html#fig-scattering). We focus on the scattered field of and infinitesimally small surface element $dA$ in the direction $\\hat{\\mathbf{k}}_\\text{s}$. Note that the surface normal $\\hat{\\mathbf{n}}$ has an arbitrary orientation with respect to the global coordinate system, whose $(x,y,z)$ axes are shown in green dotted lines.\nThe incoming field phasor can be represented by two arbitrary orthogonal polarization components (both orthogonal to the incoming wave vector $\\hat{\\mathbf{k}}_i$):\n\n$$\n\\begin{split}\\begin{align}\n\\mathbf{E}_\\text{i} &= E_{\\text{i},s} \\hat{\\mathbf{e}}_{\\text{i},s} + E_{\\text{i},p} \\hat{\\mathbf{e}}_{\\text{i},p} \\\\\n                    &= E_{\\text{i},\\perp} \\hat{\\mathbf{e}}_{\\text{i},\\perp} + E_{\\text{i},\\parallel} \\hat{\\mathbf{e}}_{\\text{i},\\parallel} \\\\\n                    &= E_{\\text{i},\\text{pol}} \\hat{\\mathbf{e}}_{\\text{i},\\text{pol}} + E_{\\text{i},\\text{xpol}} \\hat{\\mathbf{e}}_{\\text{i},\\text{xpol}}\n\\end{align}\\end{split}\n$$\n\nwhere me have omitted the dependence of the field strength on the position $\\mathbf{q}$ for brevity.\nThe second representation via $(E_{\\text{i},\\perp}, E_{\\text{i},\\parallel})$ is used for the computation of the specularly reflected field as explained in [Reflection and refraction](https://nvlabs.github.io/sionna/em_primer.html#reflection-and-refraction). The third representation via $(E_{\\text{i},\\text{pol}}, E_{\\text{i},\\text{xpol}})$ will be used to express the scattered field, where\n\n$$\n\\begin{split}\\begin{align}\n\\hat{\\mathbf{e}}_{\\text{i},\\text{pol}} &= = \\frac{\\Re\\left\\{\\mathbf{E}_\\text{i}\\right\\}}{\\lVert \\Re\\left\\{\\mathbf{E}_\\text{i}\\right\\} \\rVert} =  \\frac{\\Re\\left\\{E_{\\text{i},s}\\right\\}}{ \\lVert\\Re\\left\\{\\mathbf{E}_\\text{i} \\right\\} \\rVert} \\hat{\\mathbf{e}}_{\\text{i},s} + \\frac{\\Re\\left\\{E_{\\text{i},p}\\right\\}}{\\lVert\\Re\\left\\{\\mathbf{E}_\\text{i} \\right\\} \\rVert} \\hat{\\mathbf{e}}_{\\text{i},p}\\\\\n\\hat{\\mathbf{e}}_{\\text{i},\\text{xpol}} &= \\hat{\\mathbf{e}}_\\text{pol} \\times \\hat{\\mathbf{k}}_\\text{i}\n\\end{align}\\end{split}\n$$\n\nsuch that $|E_{\\text{i},\\text{pol}}|=\\lVert \\mathbf{E}_\\text{i} \\rVert$ and $E_{\\text{i},\\text{xpol}}=0$. That means that $\\hat{\\mathbf{e}}_{\\text{i},\\text{pol}}$ points toward the polarization direction which carries all of the energy.\n\nAccording to (Eq. 9) [[Degli-Esposti11]](https://nvlabs.github.io/sionna/em_primer.html#degli-esposti11), the diffusely scattered field $\\mathbf{E}_\\text{s}(\\mathbf{r})$ at the observation point $\\mathbf{r}$ can be modeled as\n$\\mathbf{E}_\\text{s}(\\mathbf{r})=E_{\\text{s}, \\theta}\\hat{\\boldsymbol{\\theta}}(\\hat{\\mathbf{k}}_\\text{s}) + E_{\\text{s}, \\varphi}\\hat{\\boldsymbol{\\varphi}}(\\hat{\\mathbf{k}}_\\text{s})$, where\n$\\hat{\\boldsymbol{\\theta}}, \\hat{\\boldsymbol{\\varphi}}$ are defined in [(1)](https://nvlabs.github.io/sionna/em_primer.html#equation-spherical-vecs) and the orthogonal field components are computed as\n\n$$\n\\begin{split}\\begin{bmatrix}E_{\\text{s}, \\theta} \\\\ E_{\\text{s}, \\varphi} \\end{bmatrix}(\\mathbf{r}) &= \\frac{\\lVert \\mathbf{E}_\\text{s}(\\mathbf{q}) \\rVert}{\\lVert \\mathbf{r} - \\mathbf{q} \\rVert}\n\\mathbf{W}\\left( \\hat{\\boldsymbol{\\theta}}(-\\hat{\\mathbf{k}}_\\text{i}), \\hat{\\boldsymbol{\\varphi}}(-\\hat{\\mathbf{k}}_\\text{i}), \\hat{\\mathbf{e}}_{\\text{i},\\text{pol}}, \\hat{\\mathbf{e}}_{\\text{i},\\text{xpol}} \\right)\n \\begin{bmatrix} \\sqrt{1-K_x}e^{j\\chi_1} \\\\ \\sqrt{K_x}e^{j\\chi_2}  \\end{bmatrix}\\end{split}\n$$\n\nwhere $\\mathbf{W}(\\cdot)$ as defined in [(30)](https://nvlabs.github.io/sionna/em_primer.html#equation-w), $\\chi_1, \\chi_2 \\in [0,2\\pi]$ are independent random phase shifts, and the quantity $K_x\\in[0,1]$ is defined by the scattering cross-polarization discrimination\n\n$$\n\\text{XPD}_\\text{s} = 10\\log_{10}\\left(\\frac{|E_{\\text{s}, \\text{pol}}|^2}{|E_{\\text{s}, \\text{xpol}}|^2} \\right) = 10\\log_{10}\\left(\\frac{1-K_x}{K_x} \\right).\n$$\n\nThis quantity determines how much energy gets transfered from $\\hat{\\mathbf{e}}_{\\text{i},\\text{pol}}$ into the orthogonal polarization direction $\\hat{\\mathbf{e}}_{\\text{i},\\text{xpol}}$ through the scattering process. The matrix $\\mathbf{W}$ is used to represent the scattered electric field in the vertical ($\\hat{\\boldsymbol{\\theta}}$) and horizontal ($\\hat{\\boldsymbol{\\varphi}}$) polarization components according to the incoming ray direction $-\\hat{\\mathbf{k}}_\\text{i}$. It is then assumed that the same polarization is kept for the outgoing ray in the $\\hat{\\mathbf{k}}_\\text{s}$ direction.\n\nThe squared amplitude of the diffusely scattered field in [(38)](https://nvlabs.github.io/sionna/em_primer.html#equation-scattered-field) can be expressed as (Eq. 8) [[Degli-Esposti07]](https://nvlabs.github.io/sionna/em_primer.html#degli-esposti07):\n\n$$\n\\lVert \\mathbf{E}_\\text{s}(\\mathbf{q})) \\rVert^2 = \\underbrace{\\lVert \\mathbf{E}_\\text{i}(\\mathbf{q}) \\rVert^2 \\cos(\\theta_i) dA}_{\\sim \\text{incoming power} } \\cdot \\underbrace{\\left(S\\Gamma\\right)^2}_{\\text{fraction of diffusely reflected power}} \\cdot \\underbrace{f_\\text{s}\\left(\\hat{\\mathbf{k}}_\\text{i}, \\hat{\\mathbf{k}}_\\text{s}, \\hat{\\mathbf{n}}\\right)}_{\\text{scattering pattern}}\n$$\n\nwhere $\\Gamma^2$ is the percentage of the incoming power that is reflected (specularly and diffuse), which can be computed as\n\n$$\n\\Gamma = \\frac{\\sqrt{ |r_{\\perp} E_{\\text{i},\\perp} |^2 + |r_{\\parallel} E_{\\text{i},\\parallel} |^2}}\n          {\\lVert \\mathbf{E}_\\text{i}(\\mathbf{q}) \\rVert}\n$$\n\nwhere $r_{\\perp}, r_{\\parallel}$ are defined in [(33)](https://nvlabs.github.io/sionna/em_primer.html#equation-fresnel), $dA$ is the size of the small area element on the reflecting surface under consideration, and $f_\\text{s}\\left(\\hat{\\mathbf{k}}_i, \\hat{\\mathbf{k}}_s, \\hat{\\mathbf{n}}\\right)$ is the *scattering pattern*, which has similarities with the bidirectional reflectance distribution function (BRDF) in computer graphics (Ch. 5.6.1) [[Pharr]](https://nvlabs.github.io/sionna/em_primer.html#pharr).\nThe scattering pattern must be normalized to satisfy the condition\n\n$$\n\\int_{0}^{\\pi/2}\\int_0^{2\\pi} f_\\text{s}\\left(\\hat{\\mathbf{k}}_\\text{i}, \\hat{\\mathbf{k}}_\\text{s}, \\hat{\\mathbf{n}}\\right) \\sin(\\theta_s) d\\phi_s d\\theta_s = 1\n$$\n\nwhich ensures the power balance between the incoming, reflected, and refracted fields.\n\n**Example scattering patterns**\n\nThe authors of [[Degli-Esposti07]](https://nvlabs.github.io/sionna/em_primer.html#degli-esposti07) derived several simple scattering patterns that were shown to achieve good agreement with measurements when correctly parametrized.\n\n**Lambertian Model** ([`LambertianPattern`](api/rt.html#sionna.rt.LambertianPattern)):\nThis model describes a perfectly diffuse scattering surface whose *scattering radiation lobe* has its maximum in the direction of the surface normal:\n\n$$\nf^\\text{Lambert}_\\text{s}\\left(\\hat{\\mathbf{k}}_\\text{i}, \\hat{\\mathbf{k}}_\\text{s}, \\hat{\\mathbf{n}}\\right) = \\frac{\\hat{\\mathbf{n}}^\\mathsf{T} \\hat{\\mathbf{k}}_\\text{s} }{\\pi} = \\frac{\\cos(\\theta_s)}{\\pi}\n$$\n\n**Directive Model** ([`DirectivePattern`](api/rt.html#sionna.rt.DirectivePattern)):\nThis model assumes that the scattered field is concentrated around the direction of the specular reflection $\\hat{\\mathbf{k}}_\\text{r}$ (defined in [(32)](https://nvlabs.github.io/sionna/em_primer.html#equation-reflected-refracted-vectors)). The width of the scattering lobe\ncan be controlled via the integer parameter $\\alpha_\\text{R}=1,2,\\dots$:\n\n$$\nf^\\text{directive}_\\text{s}\\left(\\hat{\\mathbf{k}}_\\text{i}, \\hat{\\mathbf{k}}_\\text{s}, \\hat{\\mathbf{n}}\\right) = F_{\\alpha_\\text{R}}(\\theta_i)^{-1} \\left(\\frac{ 1 + \\hat{\\mathbf{k}}_\\text{r}^\\mathsf{T} \\hat{\\mathbf{k}}_\\text{s}}{2}\\right)^{\\alpha_\\text{R}}\n$$\n\n$$\nF_{\\alpha}(\\theta_i) = \\frac{1}{2^\\alpha} \\sum_{k=0}^\\alpha \\binom{\\alpha}{k} I_k,\\qquad \\theta_i =\\cos^{-1}(-\\hat{\\mathbf{k}}_\\text{i}^\\mathsf{T}\\hat{\\mathbf{n}})\n$$\n\n$$\n\\begin{split}I_k = \\frac{2\\pi}{k+1} \\begin{cases}\n        1 & ,\\quad k \\text{ even} \\\\\n        \\cos(\\theta_i) \\sum_{w=0}^{(k-1)/2} \\binom{2w}{w} \\frac{\\sin^{2w}(\\theta_i)}{2^{2w}}  &,\\quad k \\text{ odd}\n      \\end{cases}\\end{split}\n$$\n\n**Backscattering Lobe Model** ([`BackscatteringPattern`](api/rt.html#sionna.rt.BackscatteringPattern)):\nThis model adds a scattering lobe to the directive model described above which points toward the direction from which the incident wave arrives (i.e., $-\\hat{\\mathbf{k}}_\\text{i}$). The width of this lobe is controlled by the parameter $\\alpha_\\text{I}=1,2,\\dots$. The parameter $\\Lambda\\in[0,1]$ determines the distribution of energy between both lobes. For $\\Lambda=1$, this models reduces to the directive model.\n\n$$\nf^\\text{bs}_\\text{s}\\left(\\hat{\\mathbf{k}}_\\text{i}, \\hat{\\mathbf{k}}_\\text{s}, \\hat{\\mathbf{n}}\\right) = F_{\\alpha_\\text{R}, \\alpha_\\text{I}}(\\theta_i)^{-1} \\left[ \\Lambda \\left(\\frac{ 1 + \\hat{\\mathbf{k}}_\\text{r}^\\mathsf{T} \\hat{\\mathbf{k}}_\\text{s}}{2}\\right)^{\\alpha_\\text{R}} + (1-\\Lambda) \\left(\\frac{ 1 - \\hat{\\mathbf{k}}_\\text{i}^\\mathsf{T} \\hat{\\mathbf{k}}_\\text{s}}{2}\\right)^{\\alpha_\\text{I}}\\right]\n$$\n\n$$\nF_{\\alpha, \\beta}(\\theta_i)^{-1} = \\Lambda F_\\alpha(\\theta_i) + (1-\\Lambda)F_\\beta(\\theta_i)\n$$"
"## References:\n[atan2](https://nvlabs.github.io/sionna/em_primer.html#id2)\n\nWikipedia, [atan2](https://en.wikipedia.org/wiki/Atan2), accessed 8 Feb. 2023.\n\n[Balanis](https://nvlabs.github.io/sionna/em_primer.html#id5)\n<ol class=\"upperalpha simple\">\n- Balanis, Advanced Engineering Electromagnetics, John Wiley & Sons, 2012.\n</ol>\n\nDegli-Esposti07([1](https://nvlabs.github.io/sionna/em_primer.html#id24),[2](https://nvlabs.github.io/sionna/em_primer.html#id26),[3](https://nvlabs.github.io/sionna/em_primer.html#id28))\n\nVittorio Degli-Esposti et al., [Measurement and modelling of scattering from buildings](https://ieeexplore.ieee.org/abstract/document/4052607), IEEE Trans. Antennas Propag, vol. 55, no. 1,  pp.143-153, Jan. 2007.\n\n[Degli-Esposti11](https://nvlabs.github.io/sionna/em_primer.html#id25)\n\nVittorio Degli-Esposti et al., [Analysis and Modeling on co- and Cross-Polarized Urban Radio Propagation for Dual-Polarized MIMO Wireless Systems](https://ieeexplore.ieee.org/abstract/document/5979177), IEEE Trans. Antennas Propag, vol. 59, no. 11,  pp.4247-4256, Nov. 2011.\n\n[Fresnel](https://nvlabs.github.io/sionna/em_primer.html#id23)\n\nWikipedia, [Fresnel integral](https://en.wikipedia.org/wiki/Fresnel_integral), accessed 21 Apr. 2023.\n\n[ITURP20402](https://nvlabs.github.io/sionna/em_primer.html#id8)\n\nITU, [Recommendation ITU-R P.2040-2: Effects of building materials and structures on radiowave propagation above about 100 MHz](https://www.itu.int/rec/R-REC-P.2040/en). Sep. 2021.\n\nITURP52615([1](https://nvlabs.github.io/sionna/em_primer.html#id16),[2](https://nvlabs.github.io/sionna/em_primer.html#id18))\n\nITU, [Recommendation ITU-R P.526-15: Propagation by diffraction](https://www.itu.int/rec/R-REC-P.526/en), Oct. 2019.\n\n[Keller62](https://nvlabs.github.io/sionna/em_primer.html#id11)\n\nJ.B. Keller, [Geometrical Theory of Diffraction](https://opg.optica.org/josa/abstract.cfm?uri=josa-52-2-116), Journal of the Optical Society of America, vol. 52, no. 2, Feb. 1962.\n\n[Kline](https://nvlabs.github.io/sionna/em_primer.html#id9)\n<ol class=\"upperalpha simple\" start=\"13\">\n- Kline, An Asymptotic Solution of Maxwells Equations, Commun. Pure Appl. Math., vol. 4, 1951.\n</ol>\n\nKouyoumjian74([1](https://nvlabs.github.io/sionna/em_primer.html#id12),[2](https://nvlabs.github.io/sionna/em_primer.html#id14))\n\nR.G. Kouyoumjian, [A uniform geometrical theory of diffraction for an edge in a perfectly conducting surface](https://ieeexplore.ieee.org/abstract/document/1451581/authors#authors), Proc. of the IEEE, vol. 62, no. 11, Nov. 1974.\n\nLuebbers84([1](https://nvlabs.github.io/sionna/em_primer.html#id15),[2](https://nvlabs.github.io/sionna/em_primer.html#id17),[3](https://nvlabs.github.io/sionna/em_primer.html#id19))\n<ol class=\"upperalpha simple\" start=\"18\">\n- Luebbers, [Finite conductivity uniform GTD versus knife edge diffraction in prediction of propagation path loss](https://ieeexplore.ieee.org/abstract/document/1143189), IEEE Trans. Antennas and Propagation, vol. 32, no. 1, Jan. 1984.\n</ol>\n\n[Luneberg](https://nvlabs.github.io/sionna/em_primer.html#id10)\n\nR.M. Luneberg, Mathematical Theory of Optics, Brown University Press, 1944.\n\nMcNamara90([1](https://nvlabs.github.io/sionna/em_primer.html#id13),[2](https://nvlabs.github.io/sionna/em_primer.html#id20),[3](https://nvlabs.github.io/sionna/em_primer.html#id22))\n\nD.A. McNamara, C.W.I. Pistorius, J.A.G. Malherbe, [Introduction to the Uniform Geometrical Theory of Diffraction](https://us.artechhouse.com/Introduction-to-the-Uniform-Geometrical-Theory-of-Diffraction-P288.aspx), Artech House, 1990.\n\n[METIS](https://nvlabs.github.io/sionna/em_primer.html#id21)\n\nMETIS Deliverable D1.4, [METIS Channel Models](https://metis2020.com/wp-content/uploads/deliverables/METIS_D1.4_v1.0.pdf), Feb. 2015.\n\n[Tse](https://nvlabs.github.io/sionna/em_primer.html#id7)\n<ol class=\"upperalpha simple\" start=\"4\">\n- Tse, P. Viswanath, [Fundamentals of Wireless Communication](https://web.stanford.edu/~dntse/wireless_book.html), Cambridge University Press, 2005.\n</ol>\n\n[Wiesbeck](https://nvlabs.github.io/sionna/em_primer.html#id1)\n<ol class=\"upperalpha simple\" start=\"14\">\n- Geng and W. Wiesbeck, Planungsmethoden fr die Mobilkommunikation, Springer, 1998.\n</ol>\n\n[Wikipedia](https://nvlabs.github.io/sionna/em_primer.html#id6)\n\nWikipedia, [Maximum power transfer theorem](https://en.wikipedia.org/wiki/Maximum_power_transfer_theorem), accessed 7 Oct. 2022.\n\n[Wikipedia_Rodrigues](https://nvlabs.github.io/sionna/em_primer.html#id4)\n\nWikipedia, [Rodrigues rotation formula](https://en.wikipedia.org/wiki/Rodrigues%27_rotation_formula), accessed 16 Jun. 2023.\n\n[Pharr](https://nvlabs.github.io/sionna/em_primer.html#id27)\n<ol class=\"upperalpha simple\" start=\"13\">\n- Pharr, J. Wenzel, G. Humphreys, [Physically Based Rendering: From Theory to Implementation](https://www.pbr-book.org/3ed-2018/contents), MIT Press, 2023.\n</ol>"
"# Hello, world!\n\nImport Sionna:\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n# IPython \"magic function\" for inline plots\n%matplotlib inline\nimport matplotlib.pyplot as plt\n```\n\n\nLet us first create a [BinarySource](https://nvlabs.github.io/sionna/api/utils.html?highlight=binarysource#binarysource) to generate a random batch of bit vectors that we can map to constellation symbols:\n\n\n```python\nbatch_size = 1000 # Number of symbols we want to generate\nnum_bits_per_symbol = 4 # 16-QAM has four bits per symbol\nbinary_source = sionna.utils.BinarySource()\nb = binary_source([batch_size, num_bits_per_symbol])\nb\n```\n\n```python\n<tf.Tensor: shape=(1000, 4), dtype=float32, numpy=\narray([[1., 0., 1., 0.],\n       [0., 1., 1., 1.],\n       [0., 1., 0., 0.],\n       ...,\n       [1., 0., 1., 0.],\n       [1., 1., 0., 0.],\n       [0., 1., 0., 1.]], dtype=float32)>\n```\n\n\nNext, let us create a [Constellation](https://nvlabs.github.io/sionna/api/mapping.html#sionna.mapping.Constellation) and visualize it:\n\n\n```python\nconstellation = sionna.mapping.Constellation(\"qam\", num_bits_per_symbol)\nconstellation.show();\n```\n\n\nWe now need a [Mapper](https://nvlabs.github.io/sionna/api/mapping.html#mapper) that maps each row of b to the constellation symbols according to the bit labeling shown above.\n\n\n```python\nmapper = sionna.mapping.Mapper(constellation=constellation)\nx = mapper(b)\nx[:10]\n```\n\n```python\n<tf.Tensor: shape=(10, 1), dtype=complex64, numpy=\narray([[-0.9486833+0.3162278j],\n       [ 0.9486833-0.9486833j],\n       [ 0.3162278-0.3162278j],\n       [-0.3162278-0.3162278j],\n       [ 0.9486833-0.3162278j],\n       [-0.3162278+0.3162278j],\n       [ 0.3162278-0.3162278j],\n       [-0.9486833-0.9486833j],\n       [ 0.9486833+0.3162278j],\n       [ 0.9486833+0.9486833j]], dtype=complex64)>\n```"
"Let us now make things a bit more interesting a send our symbols over and [AWGN channel](https://nvlabs.github.io/sionna/api/channel.html#sionna.channel.AWGN):\n\n\n```python\nawgn = sionna.channel.AWGN()\nebno_db = 15 # Desired Eb/No in dB\nno = sionna.utils.ebnodb2no(ebno_db, num_bits_per_symbol, coderate=1)\ny = awgn([x, no])\n# Visualize the received signal\nimport matplotlib.pyplot as plt\nimport numpy as np\nfig = plt.figure(figsize=(7,7))\nax = fig.add_subplot(111)\nplt.scatter(np.real(y), np.imag(y));\nax.set_aspect(\"equal\", adjustable=\"box\")\nplt.xlabel(\"Real Part\")\nplt.ylabel(\"Imaginary Part\")\nplt.grid(True, which=\"both\", axis=\"both\")\nplt.title(\"Received Symbols\");\n```"
"# Installation\n\nSionna requires [Python](https://www.python.org/) and [Tensorflow](https://www.tensorflow.org/).\nIn order to run the tutorial notebooks on your machine, you also need [JupyterLab](https://jupyter.org/).\nYou can alternatively test them on [Google Colab](https://colab.research.google.com/github/nvlabs/sionna/blob/main/examples/Discover_Sionna.ipynb).\nAlthough not necessary, we recommend running Sionna in a [Docker container](https://www.docker.com).\n\n**Note**\n\nSionna requires [TensorFlow 2.10-2.15](https://www.tensorflow.org/install) and Python 3.8-3.11.\nWe recommend Ubuntu 22.04.\nEarlier versions of TensorFlow may still work but are not recommended because of known, unpatched CVEs.\n\nTo run the ray tracer on CPU, [LLVM](https://llvm.org) is required by DrJit. Please check the [installation instructions for the LLVM backend](https://drjit.readthedocs.io/en/latest/firststeps-py.html#llvm-backend).\nThe ray tracing preview requires a recent version of <cite>JupyterLab</cite>. You can upgrade to the latest version via `pip` `install` `--upgrade` `ipykernel` `jupyterlab` (requires restart of <cite>JupyterLab</cite>).\n\nWe refer to the [TensorFlow GPU support tutorial](https://www.tensorflow.org/install/gpu) for GPU support and the required driver setup."
"## Installation using pip\n\nWe recommend to do this within a [virtual environment](https://docs.python.org/3/tutorial/venv.html),\ne.g., using [conda](https://docs.conda.io). On macOS, you need to install [tensorflow-macos](https://github.com/apple/tensorflow_macos) first.\n\n1.) Install the package\n```python\npip install sionna\n```\n\n\n2.) Test the installation in Python\n```python\npython\n```\n\n```python\n>>> import sionna\n>>> print(sionna.__version__)\n0.16.2\n```\n\n\n3.) Once Sionna is installed, you can run the [Sionna Hello, World! example](https://nvlabs.github.io/sionna/examples/Hello_World.html), have a look at the [quick start guide](https://nvlabs.github.io/sionna/quickstart.html), or at the [tutorials](https://nvlabs.github.io/sionna/tutorials.html).\n\nFor a local installation, the [JupyterLab Desktop](https://github.com/jupyterlab/jupyterlab-desktop) application can be used. This directly includes the Python installation and configuration."
"## Docker-based Installation\n\n1.) Make sure that you have Docker [installed](https://docs.docker.com/engine/install/ubuntu/) on your system. On Ubuntu 22.04, you can run for example\n```python\nsudo apt install docker.io\n```\n\n\nEnsure that your user belongs to the <cite>docker</cite> group (see [Docker post-installation](https://docs.docker.com/engine/install/linux-postinstall/)).\n```python\nsudo usermod -aG docker $USER\n```\n\n\nLog out and re-login to load updated group memberships.\n\nFor GPU support on Linux, you need to install the [NVIDIA Container Toolkit](https://github.com/NVIDIA/nvidia-docker).\n\n2.) Build the Sionna Docker image. From within the Sionna directory, run:\n```python\nmake docker\n```\n\n\n3.) Run the Docker image with GPU support\n```python\nmake run-docker gpus=all\n```\n\n\nor without GPU:\n```python\nmake run-docker\n```\n\n\nThis will immediately launch a Docker image with Sionna installed, running JupyterLab on port 8888.\n\n4.) Browse through the example notebook by connecting to [http://127.0.0.1:8888](http://127.0.0.1:8888) in your browser."
"## Installation from source\n\nWe recommend to do this within a [virtual environment](https://docs.python.org/3/tutorial/venv.html),\ne.g., using [conda](https://docs.conda.io).\n\n1.) Clone this repository and execute from within its root folder:\n```python\nmake install\n```\n\n\n2.) Test the installation in Python\n```python\npython\n```\n\n```python\n>>> import sionna\n>>> print(sionna.__version__)\n0.16.2\n````````````"
"# Basic MIMO Simulations\n\nIn this notebook, you will learn how to setup simulations of MIMO transmissions over a flat-fading channel.\n\nHere is a schematic diagram of the system model with all required components:\n\n\nYou will learn how to:\n\n- Use the FastFadingChannel class\n- Apply spatial antenna correlation\n- Implement LMMSE detection with perfect channel knowledge\n- Run BER/SER simulations\n\n\nWe will first walk through the configuration of all components of the system model, before building a general Keras model which will allow you to run efficiently simulations with different parameter settings."
"## GPU Configuration and Imports\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n# For more details, see https://www.tensorflow.org/guide/gpu\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\n```\n\n```python\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport sys\nfrom sionna.utils import BinarySource, QAMSource, ebnodb2no, compute_ser, compute_ber, PlotBER\nfrom sionna.channel import FlatFadingChannel, KroneckerModel\nfrom sionna.channel.utils import exp_corr_mat\nfrom sionna.mimo import lmmse_equalizer\nfrom sionna.mapping import SymbolDemapper, Mapper, Demapper\nfrom sionna.fec.ldpc.encoding import LDPC5GEncoder\nfrom sionna.fec.ldpc.decoding import LDPC5GDecoder\n```"
"## Simple uncoded transmission\n\nWe will consider point-to-point transmissions from a transmitter with `num_tx_ant` antennas to a receiver with `num_rx_ant` antennas. The transmitter applies no precoding and sends independent data stream from each antenna.\n\nLet us now generate a batch of random transmit vectors of random 16QAM symbols:\n\n\n```python\nnum_tx_ant = 4\nnum_rx_ant = 16\nnum_bits_per_symbol = 4\nbatch_size = 1024\nqam_source = QAMSource(num_bits_per_symbol)\nx = qam_source([batch_size, num_tx_ant])\nprint(x.shape)\n```\n\n\n```python\n(1024, 4)\n```\n\n\nNext, we will create an instance of the `FlatFadingChannel` class to simulate transmissions over an i.i.d. Rayleigh fading channel. The channel will also add AWGN with variance `no`. As we will need knowledge of the channel realizations for detection, we activate the `return_channel` flag.\n\n\n```python\nchannel = FlatFadingChannel(num_tx_ant, num_rx_ant, add_awgn=True, return_channel=True)\nno = 0.2 # Noise variance of the channel\n# y and h are the channel output and channel realizations, respectively.\ny, h = channel([x, no])\nprint(y.shape)\nprint(h.shape)\n```\n\n\n```python\n(1024, 16)\n(1024, 16, 4)\n```\n\n\nUsing the perfect channel knowledge, we can now implement an LMMSE equalizer to compute soft-symbols. The noise covariance matrix in this example is just a scaled identity matrix which we need to provide to the `lmmse_equalizer`.\n\n\n```python\ns = tf.cast(no*tf.eye(num_rx_ant, num_rx_ant), y.dtype)\nx_hat, no_eff = lmmse_equalizer(y, h, s)\n```\n\n\nLet us know have a look at the transmitted and received constellations:\n\n\n```python\nplt.axes().set_aspect(1.0)\nplt.scatter(np.real(x_hat), np.imag(x_hat));\nplt.scatter(np.real(x), np.imag(x));\n```\n\n\nAs expected, the soft symbols `x_hat` are scattered around the 16QAM constellation points. The equalizer output `no_eff` provides an estimate of the effective noise variance for each soft-symbol.\n\n\n```python\nprint(no_eff.shape)\n```\n\n\n```python\n(1024, 4)\n```"
"One can confirm that this estimate is correct by comparing the MSE between the transmitted and equalized symbols against the average estimated effective noise variance:\n\n\n```python\nnoise_var_eff = np.var(x-x_hat)\nnoise_var_est = np.mean(no_eff)\nprint(noise_var_eff)\nprint(noise_var_est)\n```\n\n\n```python\n0.016722694\n0.016684469\n```\n\n\nThe last step is to make hard decisions on the symbols and compute the SER:\n\n\n```python\nsymbol_demapper = SymbolDemapper(\"qam\", num_bits_per_symbol, hard_out=True)\n# Get symbol indices for the transmitted symbols\nx_ind = symbol_demapper([x, no])\n# Get symbol indices for the received soft-symbols\nx_ind_hat = symbol_demapper([x_hat, no])\ncompute_ser(x_ind, x_ind_hat)\n```\n\n```python\n<tf.Tensor: shape=(), dtype=float64, numpy=0.002197265625>\n```"
"### Adding spatial correlation\n\nIt is very easy add spatial correlation to the `FlatFadingChannel` using the `SpatialCorrelation` class. We can, e.g., easily setup a Kronecker (`KroneckerModel`) (or two-sided) correlation model using exponetial correlation matrices (`exp_corr_mat`).\n\n\n```python\n# Create transmit and receive correlation matrices\nr_tx = exp_corr_mat(0.4, num_tx_ant)\nr_rx = exp_corr_mat(0.9, num_rx_ant)\n# Add the spatial correlation model to the channel\nchannel.spatial_corr = KroneckerModel(r_tx, r_rx)\n```\n\n\nNext, we can validate that the channel model applies the desired spatial correlation by creating a large batch of channel realizations from which we compute the empirical transmit and receiver covariance matrices:\n\n\n```python\nh = channel.generate(1000000)\n# Compute empirical covariance matrices\nr_tx_hat = tf.reduce_mean(tf.matmul(h, h, adjoint_a=True), 0)/num_rx_ant\nr_rx_hat = tf.reduce_mean(tf.matmul(h, h, adjoint_b=True), 0)/num_tx_ant\n# Test that the empirical results match the theory\nassert(np.allclose(r_tx, r_tx_hat, atol=1e-2))\nassert(np.allclose(r_rx, r_rx_hat, atol=1e-2))\n```\n\n\nNow, we can transmit the same symbols `x` over the channel with spatial correlation and compute the SER:\n\n\n```python\ny, h = channel([x, no])\nx_hat, no_eff = lmmse_equalizer(y, h, s)\nx_ind_hat = symbol_demapper([x_hat, no])\ncompute_ser(x_ind, x_ind_hat)\n```\n```python\n<tf.Tensor: shape=(), dtype=float64, numpy=0.115234375>\n```\n\n\nThe result cleary show the negative effect of spatial correlation in this setting. You can play around with the `a` parameter defining the exponential correlation matrices and see its impact on the SER."
"## Extension to channel coding\n\nSo far, we have simulated uncoded symbol transmissions. With a few lines of additional code, we can extend what we have done to coded BER simulations. We need the following additional components:\n\n\n```python\nn = 1024 # codeword length\nk = 512  # number of information bits per codeword\ncoderate = k/n # coderate\nbatch_size = 32\nbinary_source = BinarySource()\nencoder = LDPC5GEncoder(k, n)\ndecoder = LDPC5GDecoder(encoder, hard_out=True)\nmapper = Mapper(\"qam\", num_bits_per_symbol)\ndemapper = Demapper(\"app\", \"qam\", num_bits_per_symbol)\n```\n\n\nNext we need to generate random QAM symbols through mapping of coded bits. Reshaping is required to bring `x` into the needed shape.\n\n\n```python\nb = binary_source([batch_size, num_tx_ant, k])\nc = encoder(b)\nx = mapper(c)\nx_ind = symbol_demapper([x, no]) # Get symbol indices for SER computation later on\nshape = tf.shape(x)\nx = tf.reshape(x, [-1, num_tx_ant])\nprint(x.shape)\n```\n\n\n```python\n(8192, 4)\n```\n\n\nWe will now transmit the symbols over the channel:\n\n\n```python\ny, h = channel([x, no])\nx_hat, no_eff = lmmse_equalizer(y, h, s)\n```\n\n\nAnd then demap the symbols to LLRs prior to decoding them. Note that we need to bring `x_hat` and `no_eff` back to the desired shape for decoding.\n\n\n```python\nx_ind_hat.shape\n```\n\n```python\nTensorShape([1024, 4])\n```\n\n```python\nx_hat = tf.reshape(x_hat, shape)\nno_eff = tf.reshape(no_eff, shape)\nllr = demapper([x_hat, no_eff])\nb_hat = decoder(llr)\nx_ind_hat = symbol_demapper([x_hat, no])\nber = compute_ber(b, b_hat).numpy()\nprint(\"Uncoded SER : {}\".format(compute_ser(x_ind, x_ind_hat)))\nprint(\"Coded BER : {}\".format(compute_ber(b, b_hat)))\n```\n\n\n```python\nUncoded SER : 0.1219482421875\nCoded BER : 0.0\n```\n\n\nDespite the fairly high SER, the BER is very low, thanks to the channel code."
"### BER simulations using a Keras model\n\nNext, we will wrap everything that we have done so far in a Keras model for convenient BER simulations and comparison of model parameters. Note that we use the `@tf.function(jit_compile=True)` decorator which will speed-up the simulations tremendously. See [https://www.tensorflow.org/guide/function](https://www.tensorflow.org/guide/function) for further information. You need to enable the [sionna.config.xla_compat](https://nvlabs.github.io/sionna/api/config.html#sionna.Config.xla_compat) feature prior to executing the model.\n\n\n```python\nsionna.config.xla_compat=True\nclass Model(tf.keras.Model):\n    def __init__(self, spatial_corr=None):\n        super().__init__()\n        self.n = 1024\n        self.k = 512\n        self.coderate = self.k/self.n\n        self.num_bits_per_symbol = 4\n        self.num_tx_ant = 4\n        self.num_rx_ant = 16\n        self.binary_source = BinarySource()\n        self.encoder = LDPC5GEncoder(self.k, self.n)\n        self.mapper = Mapper(\"qam\", self.num_bits_per_symbol)\n        self.demapper = Demapper(\"app\", \"qam\", self.num_bits_per_symbol)\n        self.decoder = LDPC5GDecoder(self.encoder, hard_out=True)\n        self.channel = FlatFadingChannel(self.num_tx_ant,\n                                         self.num_rx_ant,\n                                         spatial_corr=spatial_corr,\n                                         add_awgn=True,\n                                         return_channel=True)\n    @tf.function(jit_compile=True)\n    def call(self, batch_size, ebno_db):\n        b = self.binary_source([batch_size, self.num_tx_ant, self.k])\n        c = self.encoder(b)\n        x = self.mapper(c)\n        shape = tf.shape(x)\n        x = tf.reshape(x, [-1, self.num_tx_ant])\n        no = ebnodb2no(ebno_db, self.num_bits_per_symbol, self.coderate)\n        no *= np.sqrt(self.num_rx_ant)\n        y, h = self.channel([x, no])\n        s = tf.complex(no*tf.eye(self.num_rx_ant, self.num_rx_ant), 0.0)\n        x_hat, no_eff = lmmse_equalizer(y, h, s)\n        x_hat = tf.reshape(x_hat, shape)\n        no_eff = tf.reshape(no_eff, shape)\n        llr = self.demapper([x_hat, no_eff])\n        b_hat = self.decoder(llr)\n        return b,  b_hat\n```"
"We can now instantiate different version of this model and use the `PlotBer` class for easy Monte-Carlo simulations.\n\n\n```python\nber_plot = PlotBER()\n```\n\n```python\nmodel1 = Model()\nber_plot.simulate(model1,\n        np.arange(-2.5, 0.25, 0.25),\n        batch_size=4096,\n        max_mc_iter=1000,\n        num_target_block_errors=100,\n        legend=\"Uncorrelated\",\n        show_fig=False);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -2.5 | 1.1113e-01 | 9.1742e-01 |      932264 |     8388608 |        15031 |       16384 |         6.7 |reached target block errors\n    -2.25 | 7.9952e-02 | 7.8546e-01 |      670690 |     8388608 |        12869 |       16384 |         0.2 |reached target block errors\n     -2.0 | 5.0242e-02 | 5.9320e-01 |      421458 |     8388608 |         9719 |       16384 |         0.2 |reached target block errors\n    -1.75 | 2.6710e-02 | 3.7158e-01 |      224061 |     8388608 |         6088 |       16384 |         0.2 |reached target block errors\n     -1.5 | 1.1970e-02 | 1.9104e-01 |      100415 |     8388608 |         3130 |       16384 |         0.2 |reached target block errors\n    -1.25 | 4.6068e-03 | 7.8186e-02 |       38645 |     8388608 |         1281 |       16384 |         0.2 |reached target block errors\n     -1.0 | 1.2861e-03 | 2.5818e-02 |       10789 |     8388608 |          423 |       16384 |         0.2 |reached target block errors\n    -0.75 | 2.7883e-04 | 7.8735e-03 |        2339 |     8388608 |          129 |       16384 |         0.2 |reached target block errors\n     -0.5 | 8.5314e-05 | 2.2990e-03 |        2147 |    25165824 |          113 |       49152 |         0.7 |reached target block errors\n    -0.25 | 1.2082e-05 | 3.1738e-04 |        2027 |   167772160 |          104 |      327680 |         4.4 |reached target block errors\n      0.0 | 1.9351e-06 | 7.1681e-05 |        1396 |   721420288 |          101 |     1409024 |        19.0 |reached target block errors\n```"
"```python\nr_tx = exp_corr_mat(0.4, num_tx_ant)\nr_rx = exp_corr_mat(0.7, num_rx_ant)\nmodel2 = Model(KroneckerModel(r_tx, r_rx))\nber_plot.simulate(model2,\n        np.arange(0,2.6,0.25),\n        batch_size=4096,\n        max_mc_iter=1000,\n        num_target_block_errors=200,\n        legend=\"Kronecker model\");\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 7.2249e-02 | 7.1844e-01 |      606070 |     8388608 |        11771 |       16384 |         4.9 |reached target block errors\n     0.25 | 4.7019e-02 | 5.4126e-01 |      394421 |     8388608 |         8868 |       16384 |         0.2 |reached target block errors\n      0.5 | 2.7080e-02 | 3.5498e-01 |      227161 |     8388608 |         5816 |       16384 |         0.2 |reached target block errors\n     0.75 | 1.3981e-02 | 2.0380e-01 |      117280 |     8388608 |         3339 |       16384 |         0.2 |reached target block errors\n      1.0 | 6.1550e-03 | 9.6802e-02 |       51632 |     8388608 |         1586 |       16384 |         0.2 |reached target block errors\n     1.25 | 2.2970e-03 | 4.0100e-02 |       19269 |     8388608 |          657 |       16384 |         0.2 |reached target block errors\n      1.5 | 7.9966e-04 | 1.4282e-02 |        6708 |     8388608 |          234 |       16384 |         0.2 |reached target block errors\n     1.75 | 2.4907e-04 | 4.5166e-03 |        6268 |    25165824 |          222 |       49152 |         0.7 |reached target block errors\n      2.0 | 7.0466e-05 | 1.3767e-03 |        5320 |    75497472 |          203 |      147456 |         2.0 |reached target block errors\n     2.25 | 1.4114e-05 | 3.0670e-04 |        4736 |   335544320 |          201 |      655360 |         9.0 |reached target block errors\n      2.5 | 2.8881e-06 | 7.0971e-05 |        4167 |  1442840576 |          200 |     2818048 |        38.7 |reached target block errors\n```"
"# Optical Channel with Lumped Amplification\n\nIn this notebook, you will learn how to simulate the transmission of a single Gaussian impulse over a lumped amplification channel model consisting of multiple fiber spans and optical amplifiers, so-called Erbium Doped Fiber Amplifiers (EDFA), as shown in the Figure below. We assume a *standard single mode fiber* (S-SMF) and denote the fiber length between two amplifiers by $\\ell_\\text{span}$.\n\n\nLet $G$ denote the amplifier gain and $F$ the noise figure of each EDFA.\n\nAs we focus on the optical channel and not the corresponding signal processing, the transmitter directly generates the optical signal. Hence, all components that, in practice, are required to generate the optical signal given an electrical control voltage (e.g., the Mach-Zehnder-Modulator (MZM)) are assumed to be ideal or are neglected. The same holds on the receiver side, where the photodiode that would add shot noise is neglected.\n\nTo provide a better understanding of the implemented channel impairments (attenuation, noise, dispersion, nonlinearity) introduced during propagation, those are successively enabled, starting with attenuation."
"## Setup\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\nfrom sionna.channel import utils\n```\n\n```python\nimport tensorflow as tf\n# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n# For more details, see https://www.tensorflow.org/guide/gpu\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\n```\n\n```python\nimport numpy as np\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom sionna.channel import utils\n```"
"## Impulse Generation\n\nBefore diving into the first channel model, the simulation shall be parametrized and the initial Gaussian impulse\n\n$$\ng(t)=\\sqrt{P_0\\cdot 2^{\\left(-\\left(\\frac{2t}{T_0}\\right)^2\\right)}}\n$$\n\nis generated. The impulse shall have peak power $P_0$ and a pulse duration of $T_0$. Note that the Gaussian filter is infinitely long, such that $T_0$ is the full width at half-maximum (FWHM) pulse duration.\n\nFurther, the simulation window is set to $T_\\mathrm{sim}=1000\\,\\mathrm{ps}$ and the sample duration is set to $\\Delta_t=1\\,\\mathrm{ps}$.\n\n\n```python\n# Simulation parameters\ndtype = tf.complex128  # Simulation accuracy (double)\nt_sim = int(1e4)  # (ps) Simulation time window\nn_sim = int(1e4)  # Number of simulation samples\n# Channel parameters\nn_span = 3\n# Impulse parameters\np_0 = 3e-2  # (W) Peak power of the Gaussian pulse\nt_0 = 50  # (ps) Norm. temporal scaling of the Gaussian pulse\n# Support\ndt = t_sim / n_sim  # (s) sample duration\nt, f = utils.time_frequency_vector(\n    n_sim, dt, dtype=dtype.real_dtype)  # (ps), (THz) Time and frequency vector\n# Generate Gaussian impulse\ng_0 = np.sqrt(p_0 * 2**(-((2.0*t / t_0) ** 2.0)))\ng_0 = tf.cast(g_0, dtype=dtype)\nG_0 = tf.signal.fftshift(\n        tf.abs(\n            tf.cast(dt, dtype) *\n            tf.signal.fft(g_0) /\n            tf.cast(tf.math.sqrt(2 * np.pi), dtype)\n        ) ** 2\n)\n```\n\n```python\nfig, (ax1, ax2) = plt.subplots(2, 1)\nax1.plot(t.numpy().flatten(), np.abs(g_0.numpy().flatten())**2, '-')\nax1.set_xlim(-150, 150)\nax1.set_xlabel(r\"$t$ in (ps)\")\nax1.set_ylabel(r\"$|g(t)|^2$ in (W)\")\nax1.grid()\nax2.plot(\n    f.numpy().flatten(),\n    (G_0.numpy().flatten())/np.max(G_0.numpy().flatten()),\n    '-')\nax2.set_xlim(-0.015, 0.015)\nax2.set_xlabel(r\"$f-f_c$ in (THz)\")\nax2.set_ylabel(r\"$\\frac{|G(f-f_c)|^2}{|G_\\mathrm{max}|^2}$\")\nax2.grid()\nax1.legend(['transmitted'])\nplt.tight_layout()\nplt.show()\n```"
"## Attenuation\n\nAttenuation is present in all media including optical fibers. A typical value of $\\alpha=0.046\\,\\mathrm{km}^{-1}$ is used in this notebook. To compensate for this, Erbium doped fiber amplifiers (EDFAs) are required, as shown in the figure at the beginning of this notebook."
"## Amplified Spontaneous Emission Noise\n\nAn optical channel model contains several sources of noise, e.g., amplified spontaneous emission (ASE) and Rayleigh scattering. However, for this experiment, only ASE noise is implemented. It was shown in [1] that this is the most dominant source of noise.\n\nAs we assume a discrete lumped amplification, ASE noise is introduced only due to the amplification by the EDFAs. The noise power is given as\n\n$$\nP_\\mathrm{ASE}=\\rho_\\mathrm{ASE}\\cdot f_\\text{sim}=\\frac{1}{2}G F h f_\\text{c}\\cdot f_\\mathrm{sim}\n$$\n\nand, hence, depends on the gain $G$, the (linear) noise figure $F$, the carrier frequency $f_\\text{c}$, and the simulation bandwidth $f_\\mathrm{sim}$. The intermediate quantitiy $\\rho_\\mathrm{ASE}$ denotes the noise spectral density of the EDFAs and $h$ is Plancks constant. Usually, not the simulation bandwidth but the captured bandwidth $W$ of the receiver is used. Here, for demonstration purpose, our receiver has an infinite bandwidth that is only\nlimited by the simulation $W=f_\\mathrm{sim}$.\n\n**Note** that Sionna also provides ideally distributed Raman amplification, where the noise is introduced in a fiber span. This can be enabled by setting `with_amplification` to `True` when instantiating the `SSFM` layer."
"### Channel Configuration\n\nThe fiber (i.e., *SSFM*) is implemented using normalized units for distance and time. Hence, it is required that the units of the same kind (time, distance, power) for all parameters ($\\alpha$, $\\beta_2$, ) have to be given with the same unit prefix, e.g., for time use always $\\mathrm{ps}$. This does not only simplify the usage of the SSFM but also prevents from dealing with different orders of magnitude within the SSFM.\n\nFor our first experiment only ASE noise is considered and, thus, nonlinearity and chromatic dispersion (CD) are disabled. Attenuation is kept enabled such that the amplifiers are required and introduce the noise. The gain is chosen such that the link becomes transparent (input power equals output power).\n\n\n```python\n# Normalization\nt_norm = 1e-12  # (s) -> (ps) Time normalization\nz_norm = 1e3  # (m) -> (km) Distance normalization\n# Fiber parameters\nf_c = 193.55e12  # (Hz) Abs. Carrier frequency\nlength_sp = 80.0  # (km) Norm. fiber span length\nalpha = 0.046  # (1/km) Norm. fiber attenuation\n# EDFA parameters\ng_edfa = tf.exp(alpha * length_sp)\nf_edfa = 10**(5/10)  # (1) Noise figure\n```\n\n```python\nspan = sionna.channel.optical.SSFM(\n            alpha=alpha,\n            f_c=f_c,\n            length=length_sp,\n            sample_duration=dt,\n            with_amplification=False,\n            with_attenuation=True,\n            with_dispersion=False,\n            with_nonlinearity=False,\n            dtype=dtype,\n            t_norm=t_norm)\namplifier = sionna.channel.optical.EDFA(\n            g=g_edfa,\n            f=f_edfa,\n            f_c=f_c,\n            dt=dt * t_norm,  # t_norm is in absolute (not normalized) units\n            dtype=dtype)\ndef lumped_amplification_channel(inputs):\n    (u_0) = inputs\n    u = u_0\n    for _ in range(n_span):\n        u = span(u)\n        u = amplifier(u)\n    return u\n```"
"### Transmission\n\nNext, the impulse is transmitted over the channel and the output is visualized.\n\n\n```python\nx = g_0\ny = lumped_amplification_channel(x)\nX = tf.signal.fftshift(\n    tf.abs(\n        tf.cast(dt, dtype) *\n        tf.signal.fft(x) /\n        tf.cast(tf.math.sqrt(2 * np.pi), dtype)\n    ) ** 2\n)\nY = tf.signal.fftshift(\n    tf.abs(\n        tf.cast(dt, dtype) *\n        tf.signal.fft(y) /\n        tf.cast(tf.math.sqrt(2 * np.pi), dtype)\n    ) ** 2\n)\n```\n\n```python\nfig, (ax1, ax2) = plt.subplots(2, 1)\nax1.plot(t.numpy().flatten(), np.abs(x.numpy().flatten())**2, '-')\nax1.plot(t.numpy().flatten(), np.abs(y.numpy().flatten())**2, '--')\nax1.set_xlim(-150, 150)\nax1.set_xlabel(r\"$t$ in (ps)\")\nax1.set_ylabel(r\"$|g(t)|^2$ in (W)\")\nax1.grid()\nax2.plot(\n    f.numpy().flatten(),\n    (X.numpy().flatten())/np.max(X.numpy().flatten()),\n    '-')\nax2.plot(\n    f.numpy().flatten(),\n    (Y.numpy().flatten())/np.max(Y.numpy().flatten()),\n    '--')\nax2.set_xlim(-0.015, 0.015)\nax2.set_xlabel(r\"$f-f_c$ in (THz)\")\nax2.set_ylabel(r\"$\\frac{|G(f-f_c)|^2}{|G_\\mathrm{max}|^2}$\")\nax2.grid()\nax1.legend(['transmitted', 'received'])\nplt.tight_layout()\nplt.show()\n```\n\n\nAs can be seen, attenuation is completely compensated by the EDFAs. However, they introduce significant noise."
"## Chromatic Dispersion\n\nAfter having seen how the noise distorts the original Gaussian impulse, we can now enable the next linear effect, which is chromatic dispersion (CD). Regarding the nonlinear Schrdinger equation that describes the propagation of an optical signal, the impact of CD is parametrized by the group velocity dispersion (GVD) parameter $\\beta_2$, where $\\beta_2=-21.67\\,\\mathrm{ps}^2\\mathrm{km}^{-1}$ is a typical choice."
"### Channel Configuration\n\nBesides the present parameters we now set $\\beta_2$. For a better understanding of CD we disable the noise (`EDFA.f` `=` `0`) from the previous section.\n\n\n```python\nbeta_2 = -21.67  # (ps^2/km) Norm. group velocity dispersion\n```\n\n```python\nspan_cd = sionna.channel.optical.SSFM(\n            alpha=alpha,\n            beta_2=beta_2,\n            f_c=f_c,\n            length=length_sp,\n            sample_duration=dt,\n            with_amplification=False,\n            with_attenuation=True,\n            with_dispersion=True,\n            with_nonlinearity=False,\n            dtype=dtype,\n            t_norm=t_norm)\namplifier_cd = sionna.channel.optical.EDFA(\n            g=g_edfa,\n            f=0,\n            f_c=f_c,\n            dt=dt * t_norm,\n            dtype=dtype)\n\ndef lumped_amplification_channel_cd(inputs):\n    (u_0) = inputs\n    u = u_0\n    for _ in range(n_span):\n        u = span_cd(u)\n        u = amplifier_cd(u)\n    return u\n```"
"### Transmission\n\nWe now transmit the previously generated Gaussian impulse over the optical fiber and compare the received signal with the transmitted impulse.\n\n\n```python\nx = g_0  # previously generated Gaussian impulse\ny = lumped_amplification_channel_cd(x)\nX = tf.signal.fftshift(\n    tf.abs(\n        tf.cast(dt, dtype) *\n        tf.signal.fft(x) /\n        tf.cast(tf.math.sqrt(2 * np.pi), dtype)\n    ) ** 2\n)\nY = tf.signal.fftshift(\n    tf.abs(\n        tf.cast(dt, dtype) *\n        tf.signal.fft(y) /\n        tf.cast(tf.math.sqrt(2 * np.pi), dtype)\n    ) ** 2\n)\nX_angle = tf.math.angle(tf.signal.fftshift(tf.signal.fft(x)))\nY_angle = tf.math.angle(tf.signal.fftshift(tf.signal.fft(y)))\n```\n\n```python\nfig, (ax1, ax2) = plt.subplots(2, 1)\nax1.plot(t.numpy().flatten(), np.abs(x.numpy().flatten())**2, '-')\nax1.plot(t.numpy().flatten(), np.abs(y.numpy().flatten())**2, '--')\nax1.set_xlim(-250, 250)\nax1.set_xlabel(r\"$t$ in (ps)\")\nax1.set_ylabel(r\"$|g(t)|^2$ in (W)\")\nax1.grid()\nax2.plot(\n    f.numpy().flatten(),\n    (X.numpy().flatten())/np.max(X.numpy().flatten()),\n    '-')\nax2.plot(\n    f.numpy().flatten(),\n    (Y.numpy().flatten())/np.max(Y.numpy().flatten()),\n    '--')\nax2.set_xlim(-0.015, 0.015)\nax2.set_xlabel(r\"$f-f_c$ in (THz)\")\nax2.set_ylabel(r\"$\\frac{|G(f-f_c)|^2}{|G_\\mathrm{max}|^2}$\")\nax2.grid()\nax1.legend(['transmitted', 'received'])\nplt.tight_layout()\nplt.show()\n```\n\n\nCompared to the transmit impulse the received one has significantly broadened in time. The absolute value of the spectrum, nevertheless, stayed the same. By plotting the phase of the received signal one can see the typical parabolic shift.\n\n\n```python\nfig, (ax1) = plt.subplots(1, 1, tight_layout=True)\nax1.plot(t.numpy().flatten(), np.angle(x.numpy().flatten()), '-')\nax1.plot(t.numpy().flatten(), np.angle(y.numpy().flatten()), '--')\nax1.set_xlim(-750, 750)\nax1.set_xlabel(r\"$t$ in (ps)\")\nax1.set_ylabel(\"$\\u2220 x(t), \\u2220 y(t)$\")\nax1.grid()\nax1.legend(['transmitted', 'received'])\nplt.tight_layout()\nplt.show()\n```"
"## Kerr Nonlinearity\n\nLast, we depict the Kerr nonlinearity and, for a better understanding, disable all previous impairments. This nonlinear effect applies a phase shift to the transmitted signal depending on its instantaneous power. Hence, we should see a phase that, in contrast to the phase of the original signal which is zero, follows the (inverse) absolute value of the impulse.\n\n**Note:** Only the interaction between Kerr nonlinearity and CD requires an SSFM for fiber simulation. Otherwise (as done so far), the transfer function of the individual effect is just a single multiplication (in time- or Fourier-domain, respectively)."
"### Channel configuration\n\nSimilarly to the definition of CD, we specify a typical value for $\\gamma=1.27\\,\\mathrm{\\frac{1}{km W}}$.\n\n\n```python\ngamma = 1.27  # (1/W/km) Nonlinearity coefficient\n```\n\n```python\nspan_nl = sionna.channel.optical.SSFM(\n            alpha=alpha,\n            beta_2=beta_2,\n            f_c=f_c,\n            length=length_sp,\n            sample_duration=dt,\n            with_amplification=False,\n            with_attenuation=True,\n            with_dispersion=False,\n            with_nonlinearity=True,\n            dtype=dtype, t_norm=t_norm)\namplifier_nl = sionna.channel.optical.EDFA(\n            g=g_edfa,\n            f=0,\n            f_c=f_c,\n            dt=dt * t_norm,\n            dtype=dtype)\n\ndef lumped_amplification_channel_nl(inputs):\n    (u_0) = inputs\n    u = u_0\n    for _ in range(n_span):\n        u = span_nl(u)\n        u = amplifier_nl(u)\n    return u\n```"
"### Transmission\n\nWe now transmit the same Gaussian impulse again over the optical fiber where only Kerr nonlinearity is activated.\n\n\n```python\nx = g_0\ny = lumped_amplification_channel_nl(x)\nX = tf.signal.fftshift(\n    tf.abs(\n        tf.cast(dt, dtype) *\n        tf.signal.fft(x) /\n        tf.cast(tf.math.sqrt(2 * np.pi), dtype)\n    ) ** 2\n)\nY = tf.signal.fftshift(\n    tf.abs(\n        tf.cast(dt, dtype) *\n        tf.signal.fft(y) /\n        tf.cast(tf.math.sqrt(2 * np.pi), dtype)\n    ) ** 2\n)\nX_angle = tf.math.angle(tf.signal.fftshift(tf.signal.fft(x)))\nY_angle = tf.math.angle(tf.signal.fftshift(tf.signal.fft(y)))\n```\n\n```python\nfig, (ax1, ax2) = plt.subplots(2, 1)\nax1.plot(t.numpy().flatten(), np.abs(x.numpy().flatten())**2, '-')\nax1.plot(t.numpy().flatten(), np.abs(y.numpy().flatten())**2, '--')\nax1.set_xlim(-150, 150)\nax1.set_xlabel(r\"$t$ in (ps)\")\nax1.set_ylabel(\"$\\u2220 x(t), \\u2220 y(t)$\")\nax1.grid()\nax2.plot(\n    f.numpy().flatten(),\n    (X.numpy().flatten())/np.max(X.numpy().flatten()),\n    '-')\nax2.plot(\n    f.numpy().flatten(),\n    (Y.numpy().flatten())/np.max(Y.numpy().flatten()),\n    '--')\nax2.set_xlim(-0.015, 0.015)\nax2.set_xlabel(r\"$f-f_c$ in (THz)\")\nax2.set_ylabel(r\"$\\frac{|G(f-f_c)|^2}{|G_\\mathrm{max}|^2}$\")\nax2.grid()\nax1.legend(['transmitted', 'received'])\nplt.tight_layout()\n\nplt.show()\n```\n\n\nAs shown in the previous plot the (isolated) Kerr nonlinearity does not affect the absolute value of the signals amplitude but only shifts the phase (see below).\n\nFurther, the bandwidth of the transmit signal was slightly increased.\n\n**Hint**: Increasing the peak power $p_0$ of the transmitted impuls increases the impact of the Kerr nonlinearity.\n\n\n```python\nfig, (ax1) = plt.subplots(1, 1, tight_layout=True)\nax1.plot(t.numpy().flatten(), np.angle(x.numpy().flatten()), '-')\nax1.plot(t.numpy().flatten(), np.angle(y.numpy().flatten()), '--')\nax1.set_xlim(-750, 750)\nax1.set_xlabel(\"$t$ in (ps)\")\nax1.set_ylabel(\"$\\u2220 x(t), \\u2220 y(t)$\")\nax1.grid()\nax1.legend(['transmitted', 'received'])\nplt.tight_layout()\nplt.show()\n```"
"## Split-Step Fourier Method\n\nLast, we perform the true SSFM to simulate the impairments (ASE noise, CD, and Kerr nonlinearity) jointly. As this is computationally complex, we compile the channel model before its execution by adding the `tf.function` decorator."
"### Channel Configuration\n\nKeeping the former configuration, we only have to increase the number of SSFM simulation steps.\n\n\n```python\nn_ssfm = 160  # number of SSFM simulation steps\n```\n\n```python\nspan_ssfm = sionna.channel.optical.SSFM(\n            alpha=alpha,\n            beta_2=beta_2,\n            gamma=gamma,\n            f_c=f_c,\n            length=length_sp,\n            sample_duration=dt,\n            n_ssfm=n_ssfm,\n            with_amplification=False,\n            with_attenuation=True,\n            with_dispersion=True,\n            with_nonlinearity=True,\n            dtype=dtype,\n            t_norm=t_norm)\namplifier_ssfm = sionna.channel.optical.EDFA(\n            g=g_edfa,\n            f=0,\n            f_c=f_c,\n            dt=dt * t_norm,\n            dtype=dtype)\n@tf.function\ndef lumped_amplification_channel_ssfm(inputs):\n    (u_0) = inputs\n    u = u_0\n    for _ in range(1):\n        u = span_ssfm(u)\n        u = amplifier_ssfm(u)\n    return u\n```"
"### Transmission\n\nWe transmit the Gaussian impulse over the optical fiber. However, we have now enabled ASE noise, CD, and Kerr nonlinearity.\n\n\n```python\nx = g_0\ny = lumped_amplification_channel_ssfm(x)\nX = tf.signal.fftshift(\n    tf.abs(\n        tf.cast(dt, dtype) *\n        tf.signal.fft(x) /\n        tf.cast(tf.math.sqrt(2 * np.pi), dtype)\n    ) ** 2\n)\nY = tf.signal.fftshift(\n    tf.abs(\n        tf.cast(dt, dtype) *\n        tf.signal.fft(y) /\n        tf.cast(tf.math.sqrt(2 * np.pi), dtype)\n    ) ** 2\n)\nX_angle = tf.math.angle(tf.signal.fftshift(tf.signal.fft(x)))\nY_angle = tf.math.angle(tf.signal.fftshift(tf.signal.fft(y)))\n```\n\n```python\nfig, (ax1, ax2) = plt.subplots(2, 1)\nax1.plot(t.numpy().flatten(), np.abs(x.numpy().flatten())**2, '-')\nax1.plot(t.numpy().flatten(), np.abs(y.numpy().flatten())**2, '--')\nax1.set_xlim(-150, 150)\nax1.set_xlabel(r\"$t$ in (ps)\")\nax1.set_ylabel(r\"$|g(t)|^2$ in (W)\")\nax1.grid()\nax2.plot(\n    f.numpy().flatten(),\n    (X.numpy().flatten()/np.max(X.numpy().flatten())),\n    '-')\nax2.plot(\n    f.numpy().flatten(),\n    (Y.numpy().flatten()/np.max(Y.numpy().flatten())),\n    '--')\nax2.set_xlim(-0.015, 0.015)\nax2.set_xlabel(r\"$f-f_c$ in (THz)\")\nax2.set_ylabel(r\"$\\frac{|G(f-f_c)|^2}{|G_\\mathrm{max}|^2}$\")\nax2.grid()\nax1.legend(['transmitted', 'received'])\nplt.tight_layout()\nplt.show()\n```\n\n\n```python\nfig, (ax1) = plt.subplots(1, 1, tight_layout=True)\nax1.plot(t.numpy().flatten(), np.angle(x.numpy().flatten()), '-')\nax1.plot(t.numpy().flatten(), np.angle(y.numpy().flatten()), '--')\nax1.set_xlim(-500, 500)\nax1.set_xlabel(\"$t$ in (ps)\")\nax1.set_ylabel(\"$\\u2220 x(t), \\u2220 y(t)$\")\nax1.grid()\nax1.legend(['transmitted', 'received'])\nplt.tight_layout()\nplt.show()\n```"
"The most interesting observation that one can make here is that the spectrum of the received signal is compressed. This is in contrast to the expected Kerr nonlinearity-induced spectral broadening, and shows that joint application of the fiber effects may result in completely different observations compared to the isolated investigation.\n\nWhat we can see here, however, is that the Gaussian input impulse is transformed to a higher-order Soliton during propagation. Those require a joint CD and Kerr nonlinearity to exist."
"## References\n\n[1] Ren-Jean Essiambre, Gerhard Kramer, Peter J. Winzer, Gerard J. Foschini, and Bernhard Goebel. Capacity Limits of Optical Fiber Networks. Journal of Lightwave Technology 28, Nr. 4, pp 662701, February 2010.[1] Ren-Jean Essiambre, Gerhard Kramer, Peter J. Winzer, Gerard J. Foschini, and Bernhard Goebel. Capacity Limits of Optical Fiber Networks. Journal of Lightwave Technology 28, Nr. 4, pp 662701, February 2010.[1] Ren-Jean Essiambre, Gerhard Kramer, Peter J. Winzer, Gerard J. Foschini, and Bernhard Goebel. Capacity Limits of Optical Fiber Networks. Journal of Lightwave Technology 28, Nr. 4, pp 662701, February 2010.[1] Ren-Jean Essiambre, Gerhard Kramer, Peter J. Winzer, Gerard J. Foschini, and Bernhard Goebel. Capacity Limits of Optical Fiber Networks. Journal of Lightwave Technology 28, Nr. 4, pp 662701, February 2010."
"# Part 1: Getting Started with Sionna\n\nThis tutorial will guide you through Sionna, from its basic principles to the implementation of a point-to-point link with a 5G NR compliant code and a 3GPP channel model. You will also learn how to write custom trainable layers by implementing a state of the art neural receiver, and how to train and evaluate end-to-end communication systems.\n\nThe tutorial is structured in four notebooks:\n\n- **Part I: Getting started with Sionna**\n- Part II: Differentiable Communication Systems\n- Part III: Advanced Link-level Simulations\n- Part IV: Toward Learned Receivers\n\n\nThe [official documentation](https://nvlabs.github.io/sionna) provides key material on how to use Sionna and how its components are implemented."
"## Imports & Basics\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna as sn\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna as sn\n# Import TensorFlow and NumPy\nimport tensorflow as tf\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\nimport numpy as np\n# For plotting\n%matplotlib inline\n# also try %matplotlib widget\nimport matplotlib.pyplot as plt\n# for performance measurements\nimport time\n# For the implementation of the Keras models\nfrom tensorflow.keras import Model\n```\n\n\nWe can now access Sionna functions within the `sn` namespace.\n\n**Hint**: In Jupyter notebooks, you can run bash commands with `!`.\n\n\n```python\n!nvidia-smi\n```\n\n\n```python\nTue Mar 15 14:47:45 2022\n+-----------------------------------------------------------------------------+\n| NVIDIA-SMI 470.103.01   Driver Version: 470.103.01   CUDA Version: 11.4     |\n|-------------------------------+----------------------+----------------------+\n| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n|                               |                      |               MIG M. |\n|===============================+======================+======================|\n|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n| 30%   51C    P8    23W / 350W |     53MiB / 24265MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n|   1  NVIDIA GeForce ...  Off  | 00000000:4C:00.0 Off |                  N/A |\n|  0%   33C    P8    24W / 350W |      8MiB / 24268MiB |      0%      Default |\n|                               |                      |                  N/A |\n+-------------------------------+----------------------+----------------------+\n+-----------------------------------------------------------------------------+\n| Processes:                                                                  |\n|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n|        ID   ID                                                   Usage      |\n|=============================================================================|\n+-----------------------------------------------------------------------------+\n```"
"## Sionna Data-flow and Design Paradigms\n\nSionna inherently parallelizes simulations via *batching*, i.e., each element in the batch dimension is simulated independently.\n\nThis means the first tensor dimension is always used for *inter-frame* parallelization similar to an outer *for-loop* in Matlab/NumPy simulations, but operations can be operated in parallel.\n\nTo keep the dataflow efficient, Sionna follows a few simple design principles:\n\n- Signal-processing components are implemented as an individual [Keras layer](https://keras.io/api/layers/).\n- `tf.float32` is used as preferred datatype and `tf.complex64` for complex-valued datatypes, respectively.\nThis allows simpler re-use of components (e.g., the same scrambling layer can be used for binary inputs and LLR-values).\n- `tf.float64`/`tf.complex128` are available when high precision is needed.\n- Models can be developed in *eager mode* allowing simple (and fast) modification of system parameters.\n- Number crunching simulations can be executed in the faster *graph mode* or even *XLA* acceleration (experimental) is available for most components.\n- Whenever possible, components are automatically differentiable via [auto-grad](https://www.tensorflow.org/guide/autodiff) to simplify the deep learning design-flow.\n- Code is structured into sub-packages for different tasks such as channel coding, mapping, (see [API documentation](http://nvlabs.github.io/sionna/api/sionna.html) for details).\n\n\nThese paradigms simplify the re-useability and reliability of our components for a wide range of communications related applications."
"## Hello, Sionna!\n\nLets start with a very simple simulation: Transmitting QAM symbols over an AWGN channel. We will implement the system shown in the figure below.\n\n\nWe will use upper case for naming simulation parameters that are used throughout this notebook\n\nEvery layer needs to be initialized once before it can be used.\n\n**Tip**: Use the [API documentation](http://nvlabs.github.io/sionna/api/sionna.html) to find an overview of all existing components. You can directly access the signature and the docstring within jupyter via `Shift+TAB`.\n\n*Remark*: Most layers are defined to be complex-valued.\n\nWe first need to create a QAM constellation.\n\n\n```python\nNUM_BITS_PER_SYMBOL = 2 # QPSK\nconstellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\nconstellation.show();\n```\n\n\n**Task:** Try to change the modulation order, e.g., to 16-QAM.\n\nWe then need to setup a mapper to map bits into constellation points. The mapper takes as parameter the constellation.\n\nWe also need to setup a corresponding demapper to compute log-likelihood ratios (LLRs) from received noisy samples.\n\n\n```python\nmapper = sn.mapping.Mapper(constellation=constellation)\n# The demapper uses the same constellation object as the mapper\ndemapper = sn.mapping.Demapper(\"app\", constellation=constellation)\n```\n\n\n**Tip**: You can access the signature+docstring via `?` command and print the complete class definition via `??` operator.\n\nObviously, you can also access the source code via [https://github.com/nvlabs/sionna/](https://github.com/nvlabs/sionna/).\n\n\n```python\n# print class definition of the Constellation class\nsn.mapping.Mapper??\n```\n\n\n```python\nInit signature: sn.mapping.Mapper(*args, **kwargs)\nSource:\nclass Mapper(Layer):\n    # pylint: disable=line-too-long\n    r&#34;&#34;&#34;\n    Mapper(constellation_type=None, num_bits_per_symbol=None, constellation=None, dtype=tf.complex64, **kwargs)\n    Maps binary tensors to points of a constellation.\n    This class defines a layer that maps a tensor of binary values\n    to a tensor of points from a provided constellation.\n    Parameters\n    ----------\n    constellation_type : One of [&#34;qam&#34;, &#34;pam&#34;, &#34;custom&#34;], str\n        For &#34;custom&#34;, an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [&#34;qam&#34;, &#34;pam&#34;].\n    constellation :  Constellation\n        An instance of :class:`~sionna.mapping.Constellation` or\n        `None`. In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n    dtype : One of [tf.complex64, tf.complex128], tf.DType\n        The output dtype. Defaults to tf.complex64.\n    Input\n    -----\n    : [..., n], tf.float or tf.int\n        Tensor with with binary entries.\n    Output\n    ------\n    : [...,n/Constellation.num_bits_per_symbol], tf.complex\n        The mapped constellation symbols.\n    Note\n    ----\n    The last input dimension must be an integer multiple of the\n    number of bits per constellation symbol.\n    &#34;&#34;&#34;\n    def __init__(self,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 dtype=tf.complex64,\n                 **kwargs\n                ):\n        super().__init__(dtype=dtype, **kwargs)\n        assert dtype in [tf.complex64, tf.complex128],\\\n            &#34;dtype must be tf.complex64 or tf.complex128&#34;\n        #self._dtype = dtype\n        #print(dtype, self._dtype)\n        if constellation is not None:\n            assert constellation_type in [None, &#34;custom&#34;], \\\n                &#34;&#34;&#34;`constellation_type` must be &#34;custom&#34;.&#34;&#34;&#34;\n            assert num_bits_per_symbol in \\\n                     [None, constellation.num_bits_per_symbol], \\\n                &#34;&#34;&#34;`Wrong value of `num_bits_per_symbol.`&#34;&#34;&#34;\n            self._constellation = constellation\n        else:\n            assert constellation_type in [&#34;qam&#34;, &#34;pam&#34;], \\\n                &#34;Wrong constellation type.&#34;\n            assert num_bits_per_symbol is not None, \\\n                &#34;`num_bits_per_symbol` must be provided.&#34;\n            self._constellation = Constellation(constellation_type,\n                                                num_bits_per_symbol,\n                                                dtype=self._dtype)\n        self._binary_base = 2**tf.constant(\n                        range(self.constellation.num_bits_per_symbol-1,-1,-1))\n    @property\n    def constellation(self):\n        &#34;&#34;&#34;The Constellation used by the Mapper.&#34;&#34;&#34;\n        return self._constellation\n    def call(self, inputs):\n        tf.debugging.assert_greater_equal(tf.rank(inputs), 2,\n            message=&#34;The input must have at least rank 2&#34;)\n        # Reshape inputs to the desired format\n        new_shape = [-1] + inputs.shape[1:-1].as_list() + \\\n           [int(inputs.shape[-1] / self.constellation.num_bits_per_symbol),\n            self.constellation.num_bits_per_symbol]\n        inputs_reshaped = tf.cast(tf.reshape(inputs, new_shape), tf.int32)\n        # Convert the last dimension to an integer\n        int_rep = tf.reduce_sum(inputs_reshaped * self._binary_base, axis=-1)\n        # Map integers to constellation symbols\n        x = tf.gather(self.constellation.points, int_rep, axis=0)\n        return x\nFile:           ~/.local/lib/python3.8/site-packages/sionna/mapping.py\nType:           type\nSubclasses:\n```"
"As can be seen, the `Mapper` class inherits from `Layer`, i.e., implements a Keras layer.\n\nThis allows to simply built complex systems by using the [Keras functional API](https://keras.io/guides/functional_api/) to stack layers.\n\nSionna provides as utility a binary source to sample uniform i.i.d. bits.\n\n\n```python\nbinary_source = sn.utils.BinarySource()\n```\n\n\nFinally, we need the AWGN channel.\n\n\n```python\nawgn_channel = sn.channel.AWGN()\n```\n\n\nSionna provides a utility function to compute the noise power spectral density ratio $N_0$ from the energy per bit to noise power spectral density ratio $E_b/N_0$ in dB and a variety of parameters such as the coderate and the nunber of bits per symbol.\n\n\n```python\nno = sn.utils.ebnodb2no(ebno_db=10.0,\n                        num_bits_per_symbol=NUM_BITS_PER_SYMBOL,\n                        coderate=1.0) # Coderate set to 1 as we do uncoded transmission here\n```\n\n\nWe now have all the components we need to transmit QAM symbols over an AWGN channel.\n\nSionna natively supports multi-dimensional tensors.\n\nMost layers operate at the last dimension and can have arbitrary input shapes (preserved at output).\n\n\n```python\nBATCH_SIZE = 64 # How many examples are processed by Sionna in parallel\nbits = binary_source([BATCH_SIZE,\n                      1024]) # Blocklength\nprint(\"Shape of bits: \", bits.shape)\nx = mapper(bits)\nprint(\"Shape of x: \", x.shape)\ny = awgn_channel([x, no])\nprint(\"Shape of y: \", y.shape)\nllr = demapper([y, no])\nprint(\"Shape of llr: \", llr.shape)\n```\n\n\n```python\nShape of bits:  (64, 1024)\nShape of x:  (64, 512)\nShape of y:  (64, 512)\nShape of llr:  (64, 1024)\n```\n\n\nIn *Eager* mode, we can directly access the values of each tensor. This simplify debugging.\n\n\n```python\nnum_samples = 8 # how many samples shall be printed\nnum_symbols = int(num_samples/NUM_BITS_PER_SYMBOL)\nprint(f\"First {num_samples} transmitted bits: {bits[0,:num_samples]}\")\nprint(f\"First {num_symbols} transmitted symbols: {np.round(x[0,:num_symbols], 2)}\")\nprint(f\"First {num_symbols} received symbols: {np.round(y[0,:num_symbols], 2)}\")\nprint(f\"First {num_samples} demapped llrs: {np.round(llr[0,:num_samples], 2)}\")\n```"
"```python\nFirst 8 transmitted bits: [0. 1. 1. 1. 1. 0. 1. 0.]\nFirst 4 transmitted symbols: [ 0.71-0.71j -0.71-0.71j -0.71+0.71j -0.71+0.71j]\nFirst 4 received symbols: [ 0.65-0.61j -0.62-0.69j -0.6 +0.72j -0.86+0.63j]\nFirst 8 demapped llrs: [-36.65  34.36  35.04  38.83  33.96 -40.5   48.47 -35.65]\n```\n\n\nLets visualize the received noisy samples.\n\n\n```python\nplt.figure(figsize=(8,8))\nplt.axes().set_aspect(1)\nplt.grid(True)\nplt.title('Channel output')\nplt.xlabel('Real Part')\nplt.ylabel('Imaginary Part')\nplt.scatter(tf.math.real(y), tf.math.imag(y))\nplt.tight_layout()\n```\n\n\n**Task:** One can play with the SNR to visualize the impact on the received samples.\n\n**Advanced Task:** Compare the LLR distribution for app demapping with maxlog demapping. The [Bit-Interleaved Coded Modulation](https://nvlabs.github.io/sionna/examples/Bit_Interleaved_Coded_Modulation.html) example notebook can be helpful for this task."
"## Communication Systems as Keras Models\n\nIt is typically more convenient to wrap a Sionna-based communication system into a [Keras models](https://keras.io/api/models/model/).\n\nThese models can be simply built by using the [Keras functional API](https://keras.io/guides/functional_api/) to stack layers.\n\nThe following cell implements the previous system as a Keras model.\n\nThe key functions that need to be defined are `__init__()`, which instantiates the required components, and `__call()__`, which performs forward pass through the end-to-end system.\n\n\n```python\nclass UncodedSystemAWGN(Model): # Inherits from Keras Model\n    def __init__(self, num_bits_per_symbol, block_length):\n        \"\"\"\n        A keras model of an uncoded transmission over the AWGN channel.\n        Parameters\n        ----------\n        num_bits_per_symbol: int\n            The number of bits per constellation symbol, e.g., 4 for QAM16.\n        block_length: int\n            The number of bits per transmitted message block (will be the codeword length later).\n        Input\n        -----\n        batch_size: int\n            The batch_size of the Monte-Carlo simulation.\n        ebno_db: float\n            The `Eb/No` value (=rate-adjusted SNR) in dB.\n        Output\n        ------\n        (bits, llr):\n            Tuple:\n        bits: tf.float32\n            A tensor of shape `[batch_size, block_length] of 0s and 1s\n            containing the transmitted information bits.\n        llr: tf.float32\n            A tensor of shape `[batch_size, block_length] containing the\n            received log-likelihood-ratio (LLR) values.\n        \"\"\"\n        super().__init__() # Must call the Keras model initializer\n        self.num_bits_per_symbol = num_bits_per_symbol\n        self.block_length = block_length\n        self.constellation = sn.mapping.Constellation(\"qam\", self.num_bits_per_symbol)\n        self.mapper = sn.mapping.Mapper(constellation=self.constellation)\n        self.demapper = sn.mapping.Demapper(\"app\", constellation=self.constellation)\n        self.binary_source = sn.utils.BinarySource()\n        self.awgn_channel = sn.channel.AWGN()\n    # @tf.function # Enable graph execution to speed things up\n    def __call__(self, batch_size, ebno_db):\n        # no channel coding used; we set coderate=1.0\n        no = sn.utils.ebnodb2no(ebno_db,\n                                num_bits_per_symbol=self.num_bits_per_symbol,\n                                coderate=1.0)\n        bits = self.binary_source([batch_size, self.block_length]) # Blocklength set to 1024 bits\n        x = self.mapper(bits)\n        y = self.awgn_channel([x, no])\n        llr = self.demapper([y,no])\n        return bits, llr\n```"
"We need first to instantiate the model.\n\n\n```python\nmodel_uncoded_awgn = UncodedSystemAWGN(num_bits_per_symbol=NUM_BITS_PER_SYMBOL, block_length=1024)\n```\n\n\nSionna provides a utility to easily compute and plot the bit error rate (BER).\n\n\n```python\nEBN0_DB_MIN = -3.0 # Minimum value of Eb/N0 [dB] for simulations\nEBN0_DB_MAX = 5.0 # Maximum value of Eb/N0 [dB] for simulations\nBATCH_SIZE = 2000 # How many examples are processed by Sionna in parallel\nber_plots = sn.utils.PlotBER(\"AWGN\")\nber_plots.simulate(model_uncoded_awgn,\n                  ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 20),\n                  batch_size=BATCH_SIZE,\n                  num_target_block_errors=100, # simulate until 100 block errors occured\n                  legend=\"Uncoded\",\n                  soft_estimates=True,\n                  max_mc_iter=100, # run 100 Monte-Carlo simulations (each with batch_size samples)\n                  show_fig=True);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -3.0 | 1.5825e-01 | 1.0000e+00 |      324099 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n   -2.579 | 1.4687e-01 | 1.0000e+00 |      300799 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n   -2.158 | 1.3528e-01 | 1.0000e+00 |      277061 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n   -1.737 | 1.2323e-01 | 1.0000e+00 |      252373 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n   -1.316 | 1.1246e-01 | 1.0000e+00 |      230320 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n   -0.895 | 1.0107e-01 | 1.0000e+00 |      206992 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n   -0.474 | 9.0021e-02 | 1.0000e+00 |      184362 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n   -0.053 | 8.0165e-02 | 1.0000e+00 |      164177 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n    0.368 | 6.9933e-02 | 1.0000e+00 |      143222 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n    0.789 | 6.0897e-02 | 1.0000e+00 |      124717 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n    1.211 | 5.2020e-02 | 1.0000e+00 |      106537 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n    1.632 | 4.3859e-02 | 1.0000e+00 |       89823 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n    2.053 | 3.6686e-02 | 1.0000e+00 |       75132 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n    2.474 | 3.0071e-02 | 1.0000e+00 |       61586 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n    2.895 | 2.4304e-02 | 1.0000e+00 |       49775 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n    3.316 | 1.9330e-02 | 1.0000e+00 |       39588 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n    3.737 | 1.4924e-02 | 1.0000e+00 |       30565 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n    4.158 | 1.1227e-02 | 1.0000e+00 |       22992 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n    4.579 | 8.2632e-03 | 1.0000e+00 |       16923 |     2048000 |         2000 |        2000 |         0.0 |reached target block errors\n      5.0 | 5.9722e-03 | 9.9850e-01 |       12231 |     2048000 |         1997 |        2000 |         0.0 |reached target block errors\n```"
"The `sn.utils.PlotBER` object stores the results and allows to add additional simulations to the previous curves.\n\n*Remark*: In Sionna, a block error is defined to happen if for two tensors at least one position in the last dimension differs (i.e., at least one bit wrongly received per codeword). The bit error rate the total number of erroneous positions divided by the total number of transmitted bits."
"## Forward Error Correction (FEC)\n\nWe now add channel coding to our transceiver to make it more robust against transmission errors. For this, we will use [5G compliant low-density parity-check (LDPC) codes and Polar codes](https://portal.3gpp.org/desktopmodules/Specifications/SpecificationDetails.aspx?specificationId=3214). You can find more detailed information in the notebooks [Bit-Interleaved Coded Modulation (BICM)](https://nvlabs.github.io/sionna/examples/Bit_Interleaved_Coded_Modulation.html) and <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/examples/5G_Channel_Coding_Polar_vs_LDPC_Codes.html\">5G Channel Coding\nand Rate-Matching: Polar vs.LDPC Codes</a>.\n\n\n```python\nk = 12\nn = 20\nencoder = sn.fec.ldpc.LDPC5GEncoder(k, n)\ndecoder = sn.fec.ldpc.LDPC5GDecoder(encoder, hard_out=True)\n```\n\n\nLet us encode some random input bits.\n\n\n```python\nBATCH_SIZE = 1 # one codeword in parallel\nu = binary_source([BATCH_SIZE, k])\nprint(\"Input bits are: \\n\", u.numpy())\nc = encoder(u)\nprint(\"Encoded bits are: \\n\", c.numpy())\n```\n\n\n```python\nInput bits are:\n [[1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 1.]]\nEncoded bits are:\n [[1. 1. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 1. 1.]]\n```\n\n\nOne of the fundamental paradigms of Sionna is batch-processing. Thus, the example above could be executed with for arbitrary batch-sizes to simulate `batch_size` codewords in parallel.\n\nHowever, Sionna can do more - it supports *N*-dimensional input tensors and, thereby, allows the processing of multiple samples of multiple users and several antennas in a single command line. Lets say we want to encoded `batch_size` codewords of length `n` for each of the `num_users` connected to each of the `num_basestations`. This means in total we transmit `batch_size` * `n` * `num_users` * `num_basestations` bits."
"```python\nBATCH_SIZE = 10 # samples per scenario\nnum_basestations = 4\nnum_users = 5 # users per basestation\nn = 1000 # codeword length per transmitted codeword\ncoderate = 0.5 # coderate\nk = int(coderate * n) # number of info bits per codeword\n# instantiate a new encoder for codewords of length n\nencoder = sn.fec.ldpc.LDPC5GEncoder(k, n)\n# the decoder must be linked to the encoder (to know the exact code parameters used for encoding)\ndecoder = sn.fec.ldpc.LDPC5GDecoder(encoder,\n                                    hard_out=True, # binary output or provide soft-estimates\n                                    return_infobits=True, # or also return (decoded) parity bits\n                                    num_iter=20, # number of decoding iterations\n                                    cn_type=\"boxplus-phi\") # also try \"minsum\" decoding\n# draw random bits to encode\nu = binary_source([BATCH_SIZE, num_basestations, num_users, k])\nprint(\"Shape of u: \", u.shape)\n# We can immediately encode u for all users, basetation and samples\n# This all happens with a single line of code\nc = encoder(u)\nprint(\"Shape of c: \", c.shape)\nprint(\"Total number of processed bits: \", np.prod(c.shape))\n```\n\n\n```python\nShape of u:  (10, 4, 5, 500)\nShape of c:  (10, 4, 5, 1000)\nTotal number of processed bits:  200000\n```\n\n\nThis works for arbitrary dimensions and allows a simple extension of the designed system to multi-user or multi-antenna scenarios.\n\nLet us now replace the LDPC code by a Polar code. The API remains similar.\n\n\n```python\nk = 64\nn = 128\nencoder = sn.fec.polar.Polar5GEncoder(k, n)\ndecoder = sn.fec.polar.Polar5GDecoder(encoder,\n                                      dec_type=\"SCL\") # you can also use \"SCL\"\n```\n\n\n*Advanced Remark:* The 5G Polar encoder/decoder class directly applies rate-matching and the additional CRC concatenation. This is all done internally and transparent to the user.\n\nIn case you want to access low-level features of the Polar codes, please use `sionna.fec.polar.PolarEncoder` and the desired decoder (`sionna.fec.polar.PolarSCDecoder`, `sionna.fec.polar.PolarSCLDecoder` or `sionna.fec.polar.PolarBPDecoder`).\n\nFurther details can be found in the tutorial notebook on [5G Channel Coding and Rate-Matching: Polar vs.LDPC Codes](https://nvlabs.github.io/sionna/examples/5G_Channel_Coding_Polar_vs_LDPC_Codes.html)."
"```python\nclass CodedSystemAWGN(Model): # Inherits from Keras Model\n    def __init__(self, num_bits_per_symbol, n, coderate):\n        super().__init__() # Must call the Keras model initializer\n        self.num_bits_per_symbol = num_bits_per_symbol\n        self.n = n\n        self.k = int(n*coderate)\n        self.coderate = coderate\n        self.constellation = sn.mapping.Constellation(\"qam\", self.num_bits_per_symbol)\n        self.mapper = sn.mapping.Mapper(constellation=self.constellation)\n        self.demapper = sn.mapping.Demapper(\"app\", constellation=self.constellation)\n        self.binary_source = sn.utils.BinarySource()\n        self.awgn_channel = sn.channel.AWGN()\n        self.encoder = sn.fec.ldpc.LDPC5GEncoder(self.k, self.n)\n        self.decoder = sn.fec.ldpc.LDPC5GDecoder(self.encoder, hard_out=True)\n    #@tf.function # activate graph execution to speed things up\n    def __call__(self, batch_size, ebno_db):\n        no = sn.utils.ebnodb2no(ebno_db, num_bits_per_symbol=self.num_bits_per_symbol, coderate=self.coderate)\n        bits = self.binary_source([batch_size, self.k])\n        codewords = self.encoder(bits)\n        x = self.mapper(codewords)\n        y = self.awgn_channel([x, no])\n        llr = self.demapper([y,no])\n        bits_hat = self.decoder(llr)\n        return bits, bits_hat\n```\n\n```python\nCODERATE = 0.5\nBATCH_SIZE = 2000\nmodel_coded_awgn = CodedSystemAWGN(num_bits_per_symbol=NUM_BITS_PER_SYMBOL,\n                                   n=2048,\n                                   coderate=CODERATE)\nber_plots.simulate(model_coded_awgn,\n                   ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 15),\n                   batch_size=BATCH_SIZE,\n                   num_target_block_errors=500,\n                   legend=\"Coded\",\n                   soft_estimates=False,\n                   max_mc_iter=15,\n                   show_fig=True,\n                   forward_keyboard_interrupt=False);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -3.0 | 2.7896e-01 | 1.0000e+00 |      571312 |     2048000 |         2000 |        2000 |         1.8 |reached target block errors\n   -2.429 | 2.6327e-01 | 1.0000e+00 |      539174 |     2048000 |         2000 |        2000 |         1.7 |reached target block errors\n   -1.857 | 2.4783e-01 | 1.0000e+00 |      507546 |     2048000 |         2000 |        2000 |         1.7 |reached target block errors\n   -1.286 | 2.2687e-01 | 1.0000e+00 |      464636 |     2048000 |         2000 |        2000 |         1.7 |reached target block errors\n   -0.714 | 2.0312e-01 | 1.0000e+00 |      415988 |     2048000 |         2000 |        2000 |         1.7 |reached target block errors\n   -0.143 | 1.7154e-01 | 1.0000e+00 |      351316 |     2048000 |         2000 |        2000 |         1.7 |reached target block errors\n    0.429 | 1.1296e-01 | 9.9050e-01 |      231337 |     2048000 |         1981 |        2000 |         1.7 |reached target block errors\n      1.0 | 2.0114e-02 | 4.7150e-01 |       41193 |     2048000 |          943 |        2000 |         1.7 |reached target block errors\n    1.571 | 1.7617e-04 | 1.1633e-02 |        5412 |    30720000 |          349 |       30000 |        25.2 |reached max iter\n    2.143 | 0.0000e+00 | 0.0000e+00 |           0 |    30720000 |            0 |       30000 |        25.3 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 2.1 dB.\n\n```"
"As can be seen, the `BerPlot` class uses multiple stopping conditions and stops the simulation after no error occured at a specifc SNR point.\n\n**Task**: Replace the coding scheme by a Polar encoder/decoder or a convolutional code with Viterbi decoding."
"## Eager vs Graph Mode\n\nSo far, we have executed the example in *eager* mode. This allows to run TensorFlow ops as if it was written NumPy and simplifies development and debugging.\n\nHowever, to unleash Sionnas full performance, we need to activate *graph* mode which can be enabled with the function decorator *@tf.function()*.\n\nWe refer to [TensorFlow Functions](https://www.tensorflow.org/guide/function) for further details.\n\n\n```python\n@tf.function() # enables graph-mode of the following function\ndef run_graph(batch_size, ebno_db):\n    # all code inside this function will be executed in graph mode, also calls of other functions\n    print(f\"Tracing run_graph for values batch_size={batch_size} and ebno_db={ebno_db}.\") # print whenever this function is traced\n    return model_coded_awgn(batch_size, ebno_db)\n```\n\n```python\nbatch_size = 10 # try also different batch sizes\nebno_db = 1.5\n# run twice - how does the output change?\nrun_graph(batch_size, ebno_db)\n```\n\n\n```python\nTracing run_graph for values batch_size=10 and ebno_db=1.5.\n```\n\n```python\n(<tf.Tensor: shape=(10, 1024), dtype=float32, numpy=\n array([[1., 1., 0., ..., 0., 1., 0.],\n        [1., 1., 1., ..., 0., 1., 1.],\n        [1., 1., 0., ..., 0., 1., 1.],\n        ...,\n        [0., 1., 0., ..., 0., 0., 0.],\n        [0., 1., 0., ..., 0., 1., 0.],\n        [0., 1., 1., ..., 0., 1., 1.]], dtype=float32)>,\n <tf.Tensor: shape=(10, 1024), dtype=float32, numpy=\n array([[1., 1., 0., ..., 0., 1., 0.],\n        [1., 1., 1., ..., 0., 1., 1.],\n        [1., 1., 0., ..., 0., 1., 1.],\n        ...,\n        [0., 1., 0., ..., 0., 0., 0.],\n        [0., 1., 0., ..., 0., 1., 0.],\n        [0., 1., 1., ..., 0., 1., 1.]], dtype=float32)>)\n```"
"In graph mode, Python code (i.e., *non-TensorFlow code*) is only executed whenever the function is *traced*. This happens whenever the input signature changes.\n\nAs can be seen above, the print statement was executed, i.e., the graph was traced again.\n\nTo avoid this re-tracing for different inputs, we now input tensors. You can see that the function is now traced once for input tensors of same dtype.\n\nSee [TensorFlow Rules of Tracing](https://www.tensorflow.org/guide/function#rules_of_tracing) for details.\n\n**Task:** change the code above such that tensors are used as input and execute the code with different input values. Understand when re-tracing happens.\n\n*Remark*: if the input to a function is a tensor its signature must change and not *just* its value. For example the input could have a different size or datatype. For efficient code execution, we usually want to avoid re-tracing of the code if not required.\n\n\n```python\n# You can print the cached signatures with\nprint(run_graph.pretty_printed_concrete_signatures())\n```\n\n\n```python\nrun_graph(batch_size=10, ebno_db=1.5)\n  Returns:\n    (<1>, <2>)\n      <1>: float32 Tensor, shape=(10, 1024)\n      <2>: float32 Tensor, shape=(10, 1024)\n```\n\n\nWe now compare the throughput of the different modes.\n\n\n```python\nrepetitions = 4 # average over multiple runs\nbatch_size = BATCH_SIZE # try also different batch sizes\nebno_db = 1.5\n# --- eager mode ---\nt_start = time.perf_counter()\nfor _ in range(repetitions):\n    bits, bits_hat = model_coded_awgn(tf.constant(batch_size, tf.int32),\n                                tf.constant(ebno_db, tf. float32))\nt_stop = time.perf_counter()\n# throughput in bit/s\nthroughput_eager = np.size(bits.numpy())*repetitions / (t_stop - t_start) / 1e6\nprint(f\"Throughput in Eager mode: {throughput_eager :.3f} Mbit/s\")\n# --- graph mode ---\n# run once to trace graph (ignored for throughput)\nrun_graph(tf.constant(batch_size, tf.int32),\n          tf.constant(ebno_db, tf. float32))\nt_start = time.perf_counter()\nfor _ in range(repetitions):\n    bits, bits_hat = run_graph(tf.constant(batch_size, tf.int32),\n                                tf.constant(ebno_db, tf. float32))\nt_stop = time.perf_counter()\n# throughput in bit/s\nthroughput_graph = np.size(bits.numpy())*repetitions / (t_stop - t_start) / 1e6\nprint(f\"Throughput in graph mode: {throughput_graph :.3f} Mbit/s\")\n\n```"
"```python\nThroughput in Eager mode: 1.212 Mbit/s\nTracing run_graph for values batch_size=Tensor(&#34;batch_size:0&#34;, shape=(), dtype=int32) and ebno_db=Tensor(&#34;ebno_db:0&#34;, shape=(), dtype=float32).\nThroughput in graph mode: 8.623 Mbit/s\n```\n\n\nLets run the same simulation as above in graph mode.\n\n\n```python\nber_plots.simulate(run_graph,\n                   ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 12),\n                   batch_size=BATCH_SIZE,\n                   num_target_block_errors=500,\n                   legend=\"Coded (Graph mode)\",\n                   soft_estimates=True,\n                   max_mc_iter=100,\n                   show_fig=True,\n                   forward_keyboard_interrupt=False);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -3.0 | 2.7922e-01 | 1.0000e+00 |      571845 |     2048000 |         2000 |        2000 |         0.2 |reached target block errors\n   -2.273 | 2.5948e-01 | 1.0000e+00 |      531422 |     2048000 |         2000 |        2000 |         0.2 |reached target block errors\n   -1.545 | 2.3550e-01 | 1.0000e+00 |      482301 |     2048000 |         2000 |        2000 |         0.2 |reached target block errors\n   -0.818 | 2.0768e-01 | 1.0000e+00 |      425335 |     2048000 |         2000 |        2000 |         0.2 |reached target block errors\n   -0.091 | 1.6918e-01 | 1.0000e+00 |      346477 |     2048000 |         2000 |        2000 |         0.2 |reached target block errors\n    0.636 | 7.6115e-02 | 9.1650e-01 |      155883 |     2048000 |         1833 |        2000 |         0.2 |reached target block errors\n    1.364 | 1.7544e-03 | 7.2125e-02 |       14372 |     8192000 |          577 |        8000 |         1.0 |reached target block errors\n    2.091 | 7.8125e-08 | 2.0000e-05 |          16 |   204800000 |            4 |      200000 |        24.3 |reached max iter\n    2.818 | 0.0000e+00 | 0.0000e+00 |           0 |   204800000 |            0 |      200000 |        24.4 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 2.8 dB.\n\n```"
"**Task:** TensorFlow allows to *compile* graphs with [XLA](https://www.tensorflow.org/xla). Try to further accelerate the code with XLA (`@tf.function(jit_compile=True)`).\n\n*Remark*: XLA is still an experimental feature and not all TensorFlow (and, thus, Sionna) functions support XLA.\n\n**Task 2:** Check the GPU load with `!nvidia-smi`. Find the best tradeoff between batch-size and throughput for your specific GPU architecture."
"## Exercise\n\nSimulate the coded bit error rate (BER) for a Polar coded and 64-QAM modulation. Assume a codeword length of n = 200 and coderate = 0.5.\n\n**Hint**: For Polar codes, successive cancellation list decoding (SCL) gives the best BER performance. However, successive cancellation (SC) decoding (without a list) is less complex.\n\n\n```python\nn = 200\ncoderate = 0.5\n# *You can implement your code here*\n\n```"
"# Part 2: Differentiable Communication Systems\n\nThis tutorial will guide you through Sionna, from its basic principles to the implementation of a point-to-point link with a 5G NR compliant code and a 3GPP channel model. You will also learn how to write custom trainable layers by implementing a state of the art neural receiver, and how to train and evaluate end-to-end communication systems.\n\nThe tutorial is structured in four notebooks:\n\n- Part I: Getting started with Sionna\n- **Part II: Differentiable Communication Systems**\n- Part III: Advanced Link-level Simulations\n- Part IV: Toward Learned Receivers\n\n\nThe [official documentation](https://nvlabs.github.io/sionna) provides key material on how to use Sionna and how its components are implemented."
"## Imports\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna as sn\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna as sn\n# Import TensorFlow and NumPy\nimport tensorflow as tf\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\nimport numpy as np\n# For plotting\n%matplotlib inline\nimport matplotlib.pyplot as plt\n# For saving complex Python data structures efficiently\nimport pickle\n# For the implementation of the neural receiver\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Dense, Layer\n```"
"## Gradient Computation Through End-to-end Systems\n\nLets start by setting up a simple communication system that transmit bits modulated as QAM symbols over an AWGN channel.\n\nHowever, compared to what we have previously done, we now make the constellation *trainable*. With Sionna, achieving this requires only setting a boolean parameter to `True` when instantiating the `Constellation` object.\n\n\n```python\n# Binary source to generate uniform i.i.d. bits\nbinary_source = sn.utils.BinarySource()\n# 256-QAM constellation\nNUM_BITS_PER_SYMBOL = 6\nconstellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL, trainable=True) # The constellation is set to be trainable\n# Mapper and demapper\nmapper = sn.mapping.Mapper(constellation=constellation)\ndemapper = sn.mapping.Demapper(\"app\", constellation=constellation)\n# AWGN channel\nawgn_channel = sn.channel.AWGN()\n```\n\n\nAs we have already seen, we can now easily simulate forward passes through the system we have just setup\n\n\n```python\nBATCH_SIZE = 128 # How many examples are processed by Sionna in parallel\nEBN0_DB = 17.0 # Eb/N0 in dB\nno = sn.utils.ebnodb2no(ebno_db=EBN0_DB,\n                        num_bits_per_symbol=NUM_BITS_PER_SYMBOL,\n                        coderate=1.0) # Coderate set to 1 as we do uncoded transmission here\nbits = binary_source([BATCH_SIZE,\n                        1200]) # Blocklength\nx = mapper(bits)\ny = awgn_channel([x, no])\nllr = demapper([y,no])\n```\n\n\nJust for fun, lets visualize the channel inputs and outputs\n\n\n```python\nplt.figure(figsize=(8,8))\nplt.axes().set_aspect(1.0)\nplt.grid(True)\nplt.scatter(tf.math.real(y), tf.math.imag(y), label='Output')\nplt.scatter(tf.math.real(x), tf.math.imag(x), label='Input')\nplt.legend(fontsize=20);\n```\n\n\nLets now *optimize* the constellation through *stochastic gradient descent* (SGD). As we will see, this is made very easy by Sionna.\n\nWe need to define a *loss function* that we will aim to minimize.\n\nWe can see the task of the receiver as jointly solving, for each received symbol, `NUM_BITS_PER_SYMBOL` binary classification problems in order to reconstruct the transmitted bits. Therefore, a natural choice for the loss function is the *binary cross-entropy* (BCE) applied to each bit and to each received symbol.\n\n*Remark:* The LLRs computed by the demapper are *logits* on the transmitted bits, and can therefore be used as-is to compute the BCE without any additional processing. *Remark 2:* The BCE is closely related to an achieveable information rate for bit-interleaved coded modulation systems [1,2]\n\n[1] Georg Bcherer, Principles of Coded Modulation, [available online](http://www.georg-boecherer.de/bocherer2018principles.pdf)\n\n[2] F. Ait Aoudia and J. Hoydis, End-to-End Learning for OFDM: From Neural Receivers to Pilotless Communication, in IEEE Transactions on Wireless Communications, vol.21, no. 2, pp.1049-1063, Feb.2022, doi: 10.1109/TWC.2021.3101364."
"```python\nbce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\nprint(f\"BCE: {bce(bits, llr)}\")\n```\n\n\n```python\nBCE: 0.0001015052548609674\n```\n\n\nOne iteration of SGD consists in three steps: 1. Perform a forward pass through the end-to-end system and compute the loss function 2. Compute the gradient of the loss function with respect to the trainable weights 3. Apply the gradient to the weights\n\nTo enable gradient computation, we need to perform the forward pass (step 1) within a `GradientTape`\n\n\n```python\nwith tf.GradientTape() as tape:\n    bits = binary_source([BATCH_SIZE,\n                            1200]) # Blocklength\n    x = mapper(bits)\n    y = awgn_channel([x, no])\n    llr = demapper([y,no])\n    loss = bce(bits, llr)\n```\n\n\nUsing the `GradientTape`, computing the gradient is done as follows\n\n\n```python\ngradient = tape.gradient(loss, tape.watched_variables())\n```\n\n\n`gradient` is a list of tensor, each tensor corresponding to a trainable variable of our model.\n\nFor this model, we only have a single trainable tensor: The constellation of shape [`2`, `2^NUM_BITS_PER_SYMBOL`], the first dimension corresponding to the real and imaginary components of the constellation points.\n\n*Remark:* It is important to notice that the gradient computation was performed *through the demapper and channel*, which are conventional non-trainable algorithms implemented as *differentiable* Keras layers. This key feature of Sionna enables the training of end-to-end communication systems that combine both trainable and conventional and/or non-trainable signal processing algorithms.\n\n\n```python\nfor g in gradient:\n    print(g.shape)\n```\n\n\n```python\n(2, 64)\n```\n\n\nApplying the gradient (third step) is performed using an *optimizer*. [Many optimizers are available as part of TensorFlow](https://www.tensorflow.org/api_docs/python/tf/keras/optimizers), and we use in this notebook `Adam`.\n\n\n```python\noptimizer = tf.keras.optimizers.Adam(1e-2)\n```\n\n\nUsing the optimizer, the gradients can be applied to the trainable weights to update them\n\n\n```python\noptimizer.apply_gradients(zip(gradient, tape.watched_variables()));\n```\n\n\nLet compare the constellation before and after the gradient application"
"```python\nfig = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL).show()\nfig.axes[0].scatter(tf.math.real(constellation.points), tf.math.imag(constellation.points), label='After SGD')\nfig.axes[0].legend();\n```\n\n\nThe SGD step has led to slight change in the position of the constellation points. Training of a communication system using SGD consists in looping over such SGD steps until a stop criterion is met."
"## Creating Custom Layers\n\nCustom trainable (or not trainable) algorithms should be implemented as [Keras layers](https://keras.io/api/layers/). All Sionna components, such as the mapper, demapper, channel are implemented as Keras layers.\n\nTo illustrate how this can be done, the next cell implements a simple neural network-based demapper which consists of three dense layers.\n\n\n```python\nclass NeuralDemapper(Layer): # Inherits from Keras Layer\n    def __init__(self):\n        super().__init__()\n        # The three dense layers that form the custom trainable neural network-based demapper\n        self.dense_1 = Dense(64, 'relu')\n        self.dense_2 = Dense(64, 'relu')\n        self.dense_3 = Dense(NUM_BITS_PER_SYMBOL, None) # The last layer has no activation and therefore outputs logits, i.e., LLRs\n    def call(self, y):\n        # y : complex-valued with shape [batch size, block length]\n        # y is first mapped to a real-valued tensor with shape\n        #  [batch size, block length, 2]\n        # where the last dimension consists of the real and imaginary components\n        # The dense layers operate on the last dimension, and treat the inner dimensions as batch dimensions, i.e.,\n        # all the received symbols are independently processed.\n        nn_input = tf.stack([tf.math.real(y), tf.math.imag(y)], axis=-1)\n        z = self.dense_1(nn_input)\n        z = self.dense_2(z)\n        z = self.dense_3(z) # [batch size, number of symbols per block, number of bits per symbol]\n        llr = tf.reshape(z, [tf.shape(y)[0], -1]) # [batch size, number of bits per block]\n        return llr\n```\n\n\nA custom Keras layer is used as any other Sionna layer, and therefore integration to a Sionna-based communication is straightforward.\n\nThe following model uses the neural demapper instead of the conventional demapper. It takes at initialization a parameter that indicates if the model is intantiated to be trained or evaluated. When instantiated to be trained, the loss function is returned. Otherwise, the transmitted bits and LLRs are returned.\n\n\n```python\nclass End2EndSystem(Model): # Inherits from Keras Model\n    def __init__(self, training):\n        super().__init__() # Must call the Keras model initializer\n        self.constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL, trainable=True) # Constellation is trainable\n        self.mapper = sn.mapping.Mapper(constellation=self.constellation)\n        self.demapper = NeuralDemapper() # Intantiate the NeuralDemapper custom layer as any other\n        self.binary_source = sn.utils.BinarySource()\n        self.awgn_channel = sn.channel.AWGN()\n        self.bce = tf.keras.losses.BinaryCrossentropy(from_logits=True) # Loss function\n        self.training = training\n    @tf.function(jit_compile=True) # Enable graph execution to speed things up\n    def __call__(self, batch_size, ebno_db):\n        # no channel coding used; we set coderate=1.0\n        no = sn.utils.ebnodb2no(ebno_db,\n                                num_bits_per_symbol=NUM_BITS_PER_SYMBOL,\n                                coderate=1.0)\n        bits = self.binary_source([batch_size, 1200]) # Blocklength set to 1200 bits\n        x = self.mapper(bits)\n        y = self.awgn_channel([x, no])\n        llr = self.demapper(y)  # Call the NeuralDemapper custom layer as any other\n        if self.training:\n            loss = self.bce(bits, llr)\n            return loss\n        else:\n            return bits, llr\n```"
"When a model that includes a neural network is created, the neural network weights are randomly initialized typically leading to very poor performance.\n\nTo see this, the following cell benchmarks the previously defined untrained model against a conventional baseline.\n\n\n```python\nEBN0_DB_MIN = 10.0\nEBN0_DB_MAX = 20.0\n\n###############################\n# Baseline\n###############################\nclass Baseline(Model): # Inherits from Keras Model\n    def __init__(self):\n        super().__init__() # Must call the Keras model initializer\n        self.constellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL)\n        self.mapper = sn.mapping.Mapper(constellation=self.constellation)\n        self.demapper = sn.mapping.Demapper(\"app\", constellation=self.constellation)\n        self.binary_source = sn.utils.BinarySource()\n        self.awgn_channel = sn.channel.AWGN()\n    @tf.function # Enable graph execution to speed things up\n    def __call__(self, batch_size, ebno_db):\n        # no channel coding used; we set coderate=1.0\n        no = sn.utils.ebnodb2no(ebno_db,\n                                num_bits_per_symbol=NUM_BITS_PER_SYMBOL,\n                                coderate=1.0)\n        bits = self.binary_source([batch_size, 1200]) # Blocklength set to 1200 bits\n        x = self.mapper(bits)\n        y = self.awgn_channel([x, no])\n        llr = self.demapper([y,no])\n        return bits, llr\n###############################\n# Benchmarking\n###############################\nbaseline = Baseline()\nmodel = End2EndSystem(False)\nber_plots = sn.utils.PlotBER(\"Neural Demapper\")\nber_plots.simulate(baseline,\n                  ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 20),\n                  batch_size=BATCH_SIZE,\n                  num_target_block_errors=100, # simulate until 100 block errors occured\n                  legend=\"Baseline\",\n                  soft_estimates=True,\n                  max_mc_iter=100, # run 100 Monte-Carlo simulations (each with batch_size samples)\n                  show_fig=False);\nber_plots.simulate(model,\n                  ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 20),\n                  batch_size=BATCH_SIZE,\n                  num_target_block_errors=100, # simulate until 100 block errors occured\n                  legend=\"Untrained model\",\n                  soft_estimates=True,\n                  max_mc_iter=100, # run 100 Monte-Carlo simulations (each with batch_size samples)\n                  show_fig=True);\n```"
"```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     10.0 | 2.6927e-02 | 1.0000e+00 |        4136 |      153600 |          128 |         128 |         0.7 |reached target block errors\n   10.526 | 2.1426e-02 | 1.0000e+00 |        3291 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   11.053 | 1.6100e-02 | 1.0000e+00 |        2473 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   11.579 | 1.2051e-02 | 1.0000e+00 |        1851 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   12.105 | 9.1927e-03 | 1.0000e+00 |        1412 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   12.632 | 6.5234e-03 | 1.0000e+00 |        1002 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   13.158 | 4.4792e-03 | 9.8438e-01 |         688 |      153600 |          126 |         128 |         0.0 |reached target block errors\n   13.684 | 2.7474e-03 | 9.6875e-01 |         422 |      153600 |          124 |         128 |         0.0 |reached target block errors\n   14.211 | 1.6146e-03 | 8.8281e-01 |         248 |      153600 |          113 |         128 |         0.0 |reached target block errors\n   14.737 | 9.9609e-04 | 7.0312e-01 |         306 |      307200 |          180 |         256 |         0.0 |reached target block errors\n   15.263 | 5.2083e-04 | 4.7266e-01 |         160 |      307200 |          121 |         256 |         0.0 |reached target block errors\n   15.789 | 3.4071e-04 | 3.3333e-01 |         157 |      460800 |          128 |         384 |         0.0 |reached target block errors\n   16.316 | 1.4193e-04 | 1.5781e-01 |         109 |      768000 |          101 |         640 |         0.0 |reached target block errors\n   16.842 | 6.0961e-05 | 7.1023e-02 |         103 |     1689600 |          100 |        1408 |         0.1 |reached target block errors\n   17.368 | 2.4113e-05 | 2.8935e-02 |         100 |     4147200 |          100 |        3456 |         0.2 |reached target block errors\n   17.895 | 7.6593e-06 | 9.1912e-03 |         100 |    13056000 |          100 |       10880 |         0.5 |reached target block errors\n   18.421 | 2.7995e-06 | 3.3594e-03 |          43 |    15360000 |           43 |       12800 |         0.6 |reached max iter\n   18.947 | 6.5104e-07 | 7.8125e-04 |          10 |    15360000 |           10 |       12800 |         0.6 |reached max iter\n   19.474 | 6.5104e-08 | 7.8125e-05 |           1 |    15360000 |            1 |       12800 |         0.5 |reached max iter\n     20.0 | 0.0000e+00 | 0.0000e+00 |           0 |    15360000 |            0 |       12800 |         0.5 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 20.0 dB.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     10.0 | 4.7460e-01 | 1.0000e+00 |       72899 |      153600 |          128 |         128 |         1.3 |reached target block errors\n   10.526 | 4.7907e-01 | 1.0000e+00 |       73585 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   11.053 | 4.7525e-01 | 1.0000e+00 |       72999 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   11.579 | 4.7865e-01 | 1.0000e+00 |       73521 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   12.105 | 4.7684e-01 | 1.0000e+00 |       73242 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   12.632 | 4.7469e-01 | 1.0000e+00 |       72913 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   13.158 | 4.7614e-01 | 1.0000e+00 |       73135 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   13.684 | 4.7701e-01 | 1.0000e+00 |       73268 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   14.211 | 4.7544e-01 | 1.0000e+00 |       73027 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   14.737 | 4.7319e-01 | 1.0000e+00 |       72682 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   15.263 | 4.7740e-01 | 1.0000e+00 |       73329 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   15.789 | 4.7385e-01 | 1.0000e+00 |       72783 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   16.316 | 4.7344e-01 | 1.0000e+00 |       72721 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   16.842 | 4.7303e-01 | 1.0000e+00 |       72658 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   17.368 | 4.7378e-01 | 1.0000e+00 |       72773 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   17.895 | 4.7257e-01 | 1.0000e+00 |       72586 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   18.421 | 4.7377e-01 | 1.0000e+00 |       72771 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   18.947 | 4.7315e-01 | 1.0000e+00 |       72676 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   19.474 | 4.7217e-01 | 1.0000e+00 |       72525 |      153600 |          128 |         128 |         0.0 |reached target block errors\n     20.0 | 4.7120e-01 | 1.0000e+00 |       72376 |      153600 |          128 |         128 |         0.0 |reached target block errors\n```"
"## Setting up Training Loops\n\nTraining of end-to-end communication systems consists in iterating over SGD steps.\n\nThe next cell implements a training loop of `NUM_TRAINING_ITERATIONS` iterations. The training SNR is set to $E_b/N_0 = 15$ dB.\n\nAt each iteration: - A forward pass through the end-to-end system is performed within a gradient tape - The gradients are computed using the gradient tape, and applied using the Adam optimizer - The estimated loss is periodically printed to follow the progress of training\n\n\n```python\n# Number of iterations used for training\nNUM_TRAINING_ITERATIONS = 30000\n# Set a seed for reproducibility\ntf.random.set_seed(1)\n# Instantiating the end-to-end model for training\nmodel_train = End2EndSystem(training=True)\n# Adam optimizer (SGD variant)\noptimizer = tf.keras.optimizers.Adam()\n# Training loop\nfor i in range(NUM_TRAINING_ITERATIONS):\n    # Forward pass\n    with tf.GradientTape() as tape:\n        loss = model_train(BATCH_SIZE, 15.0) # The model is assumed to return the BMD rate\n    # Computing and applying gradients\n    grads = tape.gradient(loss, model_train.trainable_weights)\n    optimizer.apply_gradients(zip(grads, model_train.trainable_weights))\n    # Print progress\n    if i % 100 == 0:\n        print(f\"{i}/{NUM_TRAINING_ITERATIONS}  Loss: {loss:.2E}\", end=\"\\r\")\n```\n\n\n```python\n29900/30000  Loss: 2.02E-03\n```\n\n\nThe weights of the trained model are saved using [pickle](https://docs.python.org/3/library/pickle.html).\n\n\n```python\n# Save the weightsin a file\nweights = model_train.get_weights()\nwith open('weights-neural-demapper', 'wb') as f:\n    pickle.dump(weights, f)\n```\n\n\nFinally, we evaluate the trained model and benchmark it against the previously introduced baseline.\n\nWe first instantiate the model for evaluation and load the saved weights.\n\n\n```python\n# Instantiating the end-to-end model for evaluation\nmodel = End2EndSystem(training=False)\n# Run one inference to build the layers and loading the weights\nmodel(tf.constant(1, tf.int32), tf.constant(10.0, tf.float32))\nwith open('weights-neural-demapper', 'rb') as f:\n    weights = pickle.load(f)\n    model.set_weights(weights)\n```"
"The trained model is then evaluated.\n\n\n```python\n# Computing and plotting BER\nber_plots.simulate(model,\n                  ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 20),\n                  batch_size=BATCH_SIZE,\n                  num_target_block_errors=100,\n                  legend=\"Trained model\",\n                  soft_estimates=True,\n                  max_mc_iter=100,\n                  show_fig=True);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     10.0 | 2.6094e-02 | 1.0000e+00 |        4008 |      153600 |          128 |         128 |         0.4 |reached target block errors\n   10.526 | 2.0768e-02 | 1.0000e+00 |        3190 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   11.053 | 1.5729e-02 | 1.0000e+00 |        2416 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   11.579 | 1.1667e-02 | 1.0000e+00 |        1792 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   12.105 | 8.3789e-03 | 1.0000e+00 |        1287 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   12.632 | 6.1458e-03 | 1.0000e+00 |         944 |      153600 |          128 |         128 |         0.0 |reached target block errors\n   13.158 | 3.8411e-03 | 9.7656e-01 |         590 |      153600 |          125 |         128 |         0.0 |reached target block errors\n   13.684 | 2.8971e-03 | 9.7656e-01 |         445 |      153600 |          125 |         128 |         0.0 |reached target block errors\n   14.211 | 1.6602e-03 | 8.4375e-01 |         255 |      153600 |          108 |         128 |         0.0 |reached target block errors\n   14.737 | 9.8958e-04 | 6.7578e-01 |         304 |      307200 |          173 |         256 |         0.0 |reached target block errors\n   15.263 | 5.0130e-04 | 4.7656e-01 |         154 |      307200 |          122 |         256 |         0.0 |reached target block errors\n   15.789 | 2.5228e-04 | 2.6367e-01 |         155 |      614400 |          135 |         512 |         0.0 |reached target block errors\n   16.316 | 1.4453e-04 | 1.6250e-01 |         111 |      768000 |          104 |         640 |         0.0 |reached target block errors\n   16.842 | 5.2548e-05 | 5.8594e-02 |         113 |     2150400 |          105 |        1792 |         0.1 |reached target block errors\n   17.368 | 2.7083e-05 | 3.1875e-02 |         104 |     3840000 |          102 |        3200 |         0.1 |reached target block errors\n   17.895 | 8.6520e-06 | 1.0382e-02 |         101 |    11673600 |          101 |        9728 |         0.3 |reached target block errors\n   18.421 | 2.7344e-06 | 3.2812e-03 |          42 |    15360000 |           42 |       12800 |         0.4 |reached max iter\n   18.947 | 8.4635e-07 | 1.0156e-03 |          13 |    15360000 |           13 |       12800 |         0.4 |reached max iter\n   19.474 | 1.3021e-07 | 1.5625e-04 |           2 |    15360000 |            2 |       12800 |         0.4 |reached max iter\n     20.0 | 0.0000e+00 | 0.0000e+00 |           0 |    15360000 |            0 |       12800 |         0.4 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 20.0 dB.\n\n```"
"# Part 3: Advanced Link-level Simulations\n\nThis tutorial will guide you through Sionna, from its basic principles to the implementation of a point-to-point link with a 5G NR compliant code and a 3GPP channel model. You will also learn how to write custom trainable layers by implementing a state of the art neural receiver, and how to train and evaluate end-to-end communication systems.\n\nThe tutorial is structured in four notebooks:\n\n- Part I: Getting started with Sionna\n- Part II: Differentiable Communication Systems\n- **Part III: Advanced Link-level Simulations**\n- Part IV: Toward Learned Receivers\n\n\nThe [official documentation](https://nvlabs.github.io/sionna) provides key material on how to use Sionna and how its components are implemented."
"## Imports\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna as sn\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna as sn\n# Import TensorFlow and NumPy\nimport tensorflow as tf\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\nimport numpy as np\n# For plotting\n%matplotlib inline\nimport matplotlib.pyplot as plt\n# For the implementation of the Keras models\nfrom tensorflow.keras import Model\n```"
"## OFDM Resource Grid and Stream Management\n\nWe will setup a realistic SIMO point-to-point link between a mobile user terminal (UT) and a base station (BS). The system we will setup is shown in the figure below."
"### Stream Management\n\nFor any type of MIMO simulations, it is required to setup a `StreamManagement` object. It determines which transmitters and receivers communicate data streams with each other. In our scenario, we will configure a single UT equipped with a single antenna and a single BS equipped with multiple antennas. Whether the UT or BS is considered as a transmitter depends on the link direction, which can be either uplink or downlink. The `StreamManagement` has many properties that are used by other\ncomponents, such as precoding and equalization.\n\nWe will configure the system here such that the number of streams per transmitter is equal to the number of UT antennas.\n\n\n```python\n# Define the number of UT and BS antennas\nNUM_UT = 1\nNUM_BS = 1\nNUM_UT_ANT = 1\nNUM_BS_ANT = 4\n# The number of transmitted streams is equal to the number of UT antennas\n# in both uplink and downlink\nNUM_STREAMS_PER_TX = NUM_UT_ANT\n# Create an RX-TX association matrix.\n# RX_TX_ASSOCIATION[i,j]=1 means that receiver i gets at least one stream\n# from transmitter j. Depending on the transmission direction (uplink or downlink),\n# the role of UT and BS can change.\n# For example, considering a system with 2 RX and 4 TX, the RX-TX\n# association matrix could be\n# [ [1 , 1, 0, 0],\n#   [0 , 0, 1, 1] ]\n# which indicates that the RX 0 receives from TX 0 and 1, and RX 1 receives from\n# TX 2 and 3.\n#\n# In this notebook, as we have only a single transmitter and receiver,\n# the RX-TX association matrix is simply:\nRX_TX_ASSOCIATION = np.array([[1]])\n# Instantiate a StreamManagement object\n# This determines which data streams are determined for which receiver.\n# In this simple setup, this is fairly easy. However, it can get more involved\n# for simulations with many transmitters and receivers.\nSTREAM_MANAGEMENT = sn.mimo.StreamManagement(RX_TX_ASSOCIATION, NUM_STREAMS_PER_TX)\n```"
"### OFDM Resource Grid\n\nNext, we configure an OFDM `ResourceGrid` spanning multiple OFDM symbols. The resource grid contains data symbols and pilots and is equivalent to a *slot* in 4G/5G terminology. Although it is not relevant for our simulation, we null the DC subcarrier and a few guard carriers to the left and right of the spectrum. Also a cyclic prefix is added.\n\nDuring the creation of the `ResourceGrid`, a `PilotPattern` is automatically generated. We could have alternatively created a `PilotPattern` first and then provided it as initialization parameter. When multiple streams are considered, the corresponding pilot patterns must be orthogonal. By default, orthogonal pilots are setup when considering such systems.\n\n\n```python\nRESOURCE_GRID = sn.ofdm.ResourceGrid( num_ofdm_symbols=14,\n                                      fft_size=76,\n                                      subcarrier_spacing=30e3,\n                                      num_tx=NUM_UT,\n                                      num_streams_per_tx=NUM_STREAMS_PER_TX,\n                                      cyclic_prefix_length=6,\n                                      pilot_pattern=\"kronecker\",\n                                      pilot_ofdm_symbol_indices=[2,11])\nRESOURCE_GRID.show();\n```\n\n\n```python\nRESOURCE_GRID.pilot_pattern.show();\n```\n\n\n**Task:** You can try different pilot patterns, FFT size, number of OFDM symbols, and visualize how it affects the resource grid.\n\nSee the notebook [MIMO_OFDM_Transmissions_over_CDL](https://nvlabs.github.io/sionna/examples/MIMO_OFDM_Transmissions_over_CDL.html) for more advanced examples."
"## Antenna Arrays\n\nWe need to configure the antenna arrays used by the UT and BS. This can be ignored for simple channel models, such as `AWGN`, `RayleighBlockFading`, or `TDL` which do not account for antenna array geometries and antenna radiation patterns. However, other models, such as `CDL`, `UMi`, `UMa`, and `RMa` from the 3GPP 38.901 specification, require it.\n\nWe will assume here that UT is equipped with one vertically single-polarized antenna and the BS antenna array is composed of dual cross-polarized antenna elements with an antenna pattern defined in the [3GPP 38.901 specification](https://portal.3gpp.org/desktopmodules/Specifications/SpecificationDetails.aspx?specificationId=3173). By default, the antenna elements are spaced half of a wavelength apart in both vertical and horizontal directions. You can define your own antenna geometries an\nradiation patterns if needed.\n\nAn `AntennaArray` is always defined in the y-z plane. Its final orientation will be determined by the orientation of the UT or BS. This parameter can be configured in the `ChannelModel` that we will create later.\n\n\n```python\nCARRIER_FREQUENCY = 2.6e9 # Carrier frequency in Hz.\n                          # This is needed here to define the antenna element spacing.\nUT_ARRAY = sn.channel.tr38901.Antenna(  polarization=\"single\",\n                                        polarization_type=\"V\",\n                                        antenna_pattern=\"38.901\",\n                                        carrier_frequency=CARRIER_FREQUENCY)\nUT_ARRAY.show();\nBS_ARRAY = sn.channel.tr38901.AntennaArray( num_rows=1,\n                                            num_cols=int(NUM_BS_ANT/2),\n                                            polarization=\"dual\",\n                                            polarization_type=\"cross\",\n                                            antenna_pattern=\"38.901\", # Try 'omni'\n                                            carrier_frequency=CARRIER_FREQUENCY)\nBS_ARRAY.show();\n```\n\n\n```python\nBS_ARRAY.show_element_radiation_pattern();\n```\n\n\n**Task:** You can try different antenna pattern (omni), polarization, and array geometries."
"## Channel Model\n\nSionna implements the CDL, TDL, UMi, UMa, and RMa models from [3GPP TR 38.901](https://portal.3gpp.org/desktopmodules/Specifications/SpecificationDetails.aspx?specificationId=3173), as well as Rayleigh block fading.\n\nNote that: * TDL only supports SISO * CDL only supports single-user, possibly with multiple antenna * UMi, UMa, and RMa support single- and multi-user\n\n*Remark:* The TDL and CDL models correspond to fixed power delay profiles and fixed angles.\n\n\nWe consider the 3GPP CDL model family in this notebook.\n\n\n```python\nDELAY_SPREAD = 100e-9 # Nominal delay spread in [s]. Please see the CDL documentation\n                      # about how to choose this value.\nDIRECTION = \"uplink\"  # The `direction` determines if the UT or BS is transmitting.\n                      # In the `uplink`, the UT is transmitting.\nCDL_MODEL = \"C\"       # Suitable values are [\"A\", \"B\", \"C\", \"D\", \"E\"]\nSPEED = 10.0          # UT speed [m/s]. BSs are always assumed to be fixed.\n                     # The direction of travel will chosen randomly within the x-y plane.\n# Configure a channel impulse reponse (CIR) generator for the CDL model.\nCDL = sn.channel.tr38901.CDL(CDL_MODEL,\n                             DELAY_SPREAD,\n                             CARRIER_FREQUENCY,\n                             UT_ARRAY,\n                             BS_ARRAY,\n                             DIRECTION,\n                             min_speed=SPEED)\n```\n\n\nThe instance `CDL` of the CDL model can be used to generate batches of random realizations of continuous-time channel impulse responses, consisting of complex gains `a` and delays `tau` for each path. To account for time-varying channels, a channel impulse responses is sampled at the `sampling_frequency` for `num_time_samples` samples. For more details on this, please have a look at the API documentation of the channel models.\n\nIn order to model the channel in the frequency domain, we need `num_ofdm_symbols` samples that are taken once per `ofdm_symbol_duration`, which corresponds to the length of an OFDM symbol plus the cyclic prefix.\n\n\n```python\nBATCH_SIZE = 128 # How many examples are processed by Sionna in parallel\na, tau = CDL(batch_size=BATCH_SIZE,\n             num_time_steps=RESOURCE_GRID.num_ofdm_symbols,\n             sampling_frequency=1/RESOURCE_GRID.ofdm_symbol_duration)\n```"
"The path gains `a` have shape\n`[batch` `size,` `num_rx,` `num_rx_ant,` `num_tx,` `num_tx_ant,` `num_paths,` `num_time_steps]`\nand the delays `tau` have shape\n`[batch_size,` `num_rx,` `num_tx,` `num_paths]`.\n\n\n```python\nprint(\"Shape of the path gains: \", a.shape)\nprint(\"Shape of the delays:\", tau.shape)\n```\n\n\n```python\nShape of the path gains:  (128, 1, 4, 1, 1, 24, 14)\nShape of the delays: (128, 1, 1, 24)\n```\n\n\nThe delays are assumed to be static within the time-window of interest. Only the complex path gains change over time. The following two figures depict the channel impulse response at a particular time instant and the time-evolution of the gain of one path, respectively.\n\n\n```python\nplt.figure()\nplt.title(\"Channel impulse response realization\")\nplt.stem(tau[0,0,0,:]/1e-9, np.abs(a)[0,0,0,0,0,:,0])\nplt.xlabel(r\"$\\tau$ [ns]\")\nplt.ylabel(r\"$|a|$\")\n\nplt.figure()\nplt.title(\"Time evolution of path gain\")\nplt.plot(np.arange(RESOURCE_GRID.num_ofdm_symbols)*RESOURCE_GRID.ofdm_symbol_duration/1e-6, np.real(a)[0,0,0,0,0,0,:])\nplt.plot(np.arange(RESOURCE_GRID.num_ofdm_symbols)*RESOURCE_GRID.ofdm_symbol_duration/1e-6, np.imag(a)[0,0,0,0,0,0,:])\nplt.legend([\"Real part\", \"Imaginary part\"])\nplt.xlabel(r\"$t$ [us]\")\nplt.ylabel(r\"$a$\");\n```\n\n\nSee the notebook [Realistic_Multiuser_MIMO_Simulations](https://nvlabs.github.io/sionna/examples/Realistic_Multiuser_MIMO_Simulations.html) for more advanced examples."
"## Uplink Transmission in the Frequency Domain\n\nWe are now ready to simulate a transmission.\n\nIn the following, the channel is simulated in the frequency domain. Therefore, the channel is assumed to be constant over the duration of an OFDM symbol, which leads to not simulating the intercarrier interference (ICI) that could occur due to channel aging over the duration of OFDM symbols.\n\nThe `OFDMChannel` layer is used to simulate the channel in the frequency domain and takes care of sampling channel impulse responses, computing the frequency responses, and applying the channel transfer function to the channel inputs (including AWGN).\n\nNote that it is also possible to simulate the channel in time domain using the `TimeChannel` layer, which enables simulation of ICI. For more information, please have a look at the API documentation.\n\n\n```python\nNUM_BITS_PER_SYMBOL = 2 # QPSK\nCODERATE = 0.5\n# Number of coded bits in a resource grid\nn = int(RESOURCE_GRID.num_data_symbols*NUM_BITS_PER_SYMBOL)\n# Number of information bits in a resource groud\nk = int(n*CODERATE)\n# The binary source will create batches of information bits\nbinary_source = sn.utils.BinarySource()\n# The encoder maps information bits to coded bits\nencoder = sn.fec.ldpc.LDPC5GEncoder(k, n)\n# The mapper maps blocks of information bits to constellation symbols\nmapper = sn.mapping.Mapper(\"qam\", NUM_BITS_PER_SYMBOL)\n# The resource grid mapper maps symbols onto an OFDM resource grid\nrg_mapper = sn.ofdm.ResourceGridMapper(RESOURCE_GRID)\n# Frequency domain channel\nchannel = sn.channel.OFDMChannel(CDL, RESOURCE_GRID, add_awgn=True, normalize_channel=True, return_channel=True)\n# The LS channel estimator will provide channel estimates and error variances\nls_est = sn.ofdm.LSChannelEstimator(RESOURCE_GRID, interpolation_type=\"nn\")\n# The LMMSE equalizer will provide soft symbols together with noise variance estimates\nlmmse_equ = sn.ofdm.LMMSEEqualizer(RESOURCE_GRID, STREAM_MANAGEMENT)\n# The demapper produces LLR for all coded bits\ndemapper = sn.mapping.Demapper(\"app\", \"qam\", NUM_BITS_PER_SYMBOL)\n# The decoder provides hard-decisions on the information bits\ndecoder = sn.fec.ldpc.LDPC5GDecoder(encoder, hard_out=True)\n```"
"Lets now simulate the transmission, and look at the shape of the layers outputs at each stage.\n\nThe utility function `ebnodb2no` takes as additional input the resource grid to account for the pilots when computing the noise power spectral density ratio $N_0$ from the energy per bit to noise power spectral density ratio $E_b/N_0$ (in dB).\n\n\n```python\nno = sn.utils.ebnodb2no(ebno_db=10.0,\n                        num_bits_per_symbol=NUM_BITS_PER_SYMBOL,\n                        coderate=CODERATE,\n                        resource_grid=RESOURCE_GRID)\n# Transmitter\nbits = binary_source([BATCH_SIZE, NUM_UT, RESOURCE_GRID.num_streams_per_tx, k])\nprint(\"Shape of bits: \", bits.shape)\ncodewords = encoder(bits)\nprint(\"Shape of codewords: \", codewords.shape)\nx = mapper(codewords)\nprint(\"Shape of x: \", x.shape)\nx_rg = rg_mapper(x)\nprint(\"Shape of x_rg: \", x_rg.shape)\n# Channel\ny, h_freq = channel([x_rg, no])\nprint(\"Shape of y_rg: \", y.shape)\nprint(\"Shape of h_freq: \", h_freq.shape)\n# Receiver\nh_hat, err_var = ls_est ([y, no])\nprint(\"Shape of h_hat: \", h_hat.shape)\nprint(\"Shape of err_var: \", err_var.shape)\nx_hat, no_eff = lmmse_equ([y, h_hat, err_var, no])\nprint(\"Shape of x_hat: \", x_hat.shape)\nprint(\"Shape of no_eff: \", no_eff.shape)\nllr = demapper([x_hat, no_eff])\nprint(\"Shape of llr: \", llr.shape)\nbits_hat = decoder(llr)\nprint(\"Shape of bits_hat: \", bits_hat.shape)\n```\n\n\n```python\nShape of bits:  (128, 1, 1, 912)\nShape of codewords:  (128, 1, 1, 1824)\nShape of x:  (128, 1, 1, 912)\nShape of x_rg:  (128, 1, 1, 14, 76)\nShape of y_rg:  (128, 1, 4, 14, 76)\nShape of h_freq:  (128, 1, 4, 1, 1, 14, 76)\nShape of h_hat:  (128, 1, 4, 1, 1, 14, 76)\nShape of err_var:  (1, 1, 1, 1, 1, 14, 76)\nShape of x_hat:  (128, 1, 1, 912)\nShape of no_eff:  (128, 1, 1, 912)\nShape of llr:  (128, 1, 1, 1824)\nShape of bits_hat:  (128, 1, 1, 912)\n```"
"The next cell implements the previous system as a Keras model.\n\nMoreover, a boolean given as parameter to the initializer enables using either LS estimation or perfect CSI, as shown in the figure below.\n\n\n```python\nclass OFDMSystem(Model): # Inherits from Keras Model\n    def __init__(self, perfect_csi):\n        super().__init__() # Must call the Keras model initializer\n        self.perfect_csi = perfect_csi\n        n = int(RESOURCE_GRID.num_data_symbols*NUM_BITS_PER_SYMBOL) # Number of coded bits\n        k = int(n*CODERATE) # Number of information bits\n        self.k = k\n        # The binary source will create batches of information bits\n        self.binary_source = sn.utils.BinarySource()\n        # The encoder maps information bits to coded bits\n        self.encoder = sn.fec.ldpc.LDPC5GEncoder(k, n)\n        # The mapper maps blocks of information bits to constellation symbols\n        self.mapper = sn.mapping.Mapper(\"qam\", NUM_BITS_PER_SYMBOL)\n        # The resource grid mapper maps symbols onto an OFDM resource grid\n        self.rg_mapper = sn.ofdm.ResourceGridMapper(RESOURCE_GRID)\n        # Frequency domain channel\n        self.channel = sn.channel.OFDMChannel(CDL, RESOURCE_GRID, add_awgn=True, normalize_channel=True, return_channel=True)\n        # The LS channel estimator will provide channel estimates and error variances\n        self.ls_est = sn.ofdm.LSChannelEstimator(RESOURCE_GRID, interpolation_type=\"nn\")\n        # The LMMSE equalizer will provide soft symbols together with noise variance estimates\n        self.lmmse_equ = sn.ofdm.LMMSEEqualizer(RESOURCE_GRID, STREAM_MANAGEMENT)\n        # The demapper produces LLR for all coded bits\n        self.demapper = sn.mapping.Demapper(\"app\", \"qam\", NUM_BITS_PER_SYMBOL)\n        # The decoder provides hard-decisions on the information bits\n        self.decoder = sn.fec.ldpc.LDPC5GDecoder(self.encoder, hard_out=True)\n    @tf.function # Graph execution to speed things up\n    def __call__(self, batch_size, ebno_db):\n        no = sn.utils.ebnodb2no(ebno_db, num_bits_per_symbol=NUM_BITS_PER_SYMBOL, coderate=CODERATE, resource_grid=RESOURCE_GRID)\n        # Transmitter\n        bits = self.binary_source([batch_size, NUM_UT, RESOURCE_GRID.num_streams_per_tx, self.k])\n        codewords = self.encoder(bits)\n        x = self.mapper(codewords)\n        x_rg = self.rg_mapper(x)\n        # Channel\n        y, h_freq = self.channel([x_rg, no])\n        # Receiver\n        if self.perfect_csi:\n            h_hat, err_var = h_freq, 0.\n        else:\n            h_hat, err_var = self.ls_est ([y, no])\n        x_hat, no_eff = self.lmmse_equ([y, h_hat, err_var, no])\n        llr = self.demapper([x_hat, no_eff])\n        bits_hat = self.decoder(llr)\n        return bits, bits_hat\n```"
"```python\nEBN0_DB_MIN = -8.0 # Minimum value of Eb/N0 [dB] for simulations\nEBN0_DB_MAX = 3.0 # Maximum value of Eb/N0 [dB] for simulations\nber_plots = sn.utils.PlotBER(\"OFDM over 3GPP CDL\")\nmodel_ls = OFDMSystem(False)\nber_plots.simulate(model_ls,\n                  ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 20),\n                  batch_size=BATCH_SIZE,\n                  num_target_block_errors=100, # simulate until 100 block errors occured\n                  legend=\"LS Estimation\",\n                  soft_estimates=True,\n                  max_mc_iter=100, # run 100 Monte-Carlo simulations (each with batch_size samples)\n                  show_fig=False);\nmodel_pcsi = OFDMSystem(True)\nber_plots.simulate(model_pcsi,\n                  ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 20),\n                  batch_size=BATCH_SIZE,\n                  num_target_block_errors=100, # simulate until 100 block errors occured\n                  legend=\"Perfect CSI\",\n                  soft_estimates=True,\n                  max_mc_iter=100, # run 100 Monte-Carlo simulations (each with batch_size samples)\n                  show_fig=False);\nber_plots();\n```\n\n\n```python\nWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\nInstructions for updating:\nThe `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -8.0 | 4.2978e-01 | 1.0000e+00 |       50171 |      116736 |          128 |         128 |         7.0 |reached target block errors\n   -7.421 | 4.1871e-01 | 1.0000e+00 |       48878 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -6.842 | 4.1140e-01 | 1.0000e+00 |       48025 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -6.263 | 4.0080e-01 | 1.0000e+00 |       46788 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -5.684 | 3.8840e-01 | 1.0000e+00 |       45340 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -5.105 | 3.7817e-01 | 1.0000e+00 |       44146 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -4.526 | 3.6195e-01 | 1.0000e+00 |       42253 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -3.947 | 3.4381e-01 | 1.0000e+00 |       40135 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -3.368 | 3.2687e-01 | 1.0000e+00 |       38158 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -2.789 | 3.0678e-01 | 1.0000e+00 |       35812 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -2.211 | 2.8767e-01 | 1.0000e+00 |       33582 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -1.632 | 2.6431e-01 | 1.0000e+00 |       30855 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -1.053 | 2.4057e-01 | 1.0000e+00 |       28083 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -0.474 | 2.1041e-01 | 1.0000e+00 |       24563 |      116736 |          128 |         128 |         0.2 |reached target block errors\n    0.105 | 1.5792e-01 | 9.8438e-01 |       18435 |      116736 |          126 |         128 |         0.2 |reached target block errors\n    0.684 | 3.1259e-02 | 4.3750e-01 |        7298 |      233472 |          112 |         256 |         0.3 |reached target block errors\n    1.263 | 4.5551e-04 | 1.2525e-02 |        3350 |     7354368 |          101 |        8064 |         9.9 |reached target block errors\n    1.842 | 0.0000e+00 | 0.0000e+00 |           0 |    11673600 |            0 |       12800 |        15.8 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 1.8 dB.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -8.0 | 2.8242e-01 | 1.0000e+00 |       32969 |      116736 |          128 |         128 |         3.4 |reached target block errors\n   -7.421 | 2.6455e-01 | 1.0000e+00 |       30883 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -6.842 | 2.4662e-01 | 1.0000e+00 |       28790 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -6.263 | 2.2697e-01 | 1.0000e+00 |       26495 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -5.684 | 2.0201e-01 | 1.0000e+00 |       23582 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -5.105 | 1.7199e-01 | 1.0000e+00 |       20078 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -4.526 | 1.0359e-01 | 9.6094e-01 |       12093 |      116736 |          123 |         128 |         0.2 |reached target block errors\n   -3.947 | 1.7351e-02 | 4.1016e-01 |        4051 |      233472 |          105 |         256 |         0.3 |reached target block errors\n   -3.368 | 1.4470e-04 | 8.4918e-03 |        1554 |    10739712 |          100 |       11776 |        14.8 |reached target block errors\n   -2.789 | 0.0000e+00 | 0.0000e+00 |           0 |    11673600 |            0 |       12800 |        16.1 |reached max iter\nSimulation stopped as no error occurred @ EbNo = -2.8 dB.\n\n```"
"# Part 4: Toward Learned Receivers\n\nThis tutorial will guide you through Sionna, from its basic principles to the implementation of a point-to-point link with a 5G NR compliant code and a 3GPP channel model. You will also learn how to write custom trainable layers by implementing a state of the art neural receiver, and how to train and evaluate end-to-end communication systems.\n\nThe tutorial is structured in four notebooks:\n\n- Part I: Getting started with Sionna\n- Part II: Differentiable Communication Systems\n- Part III: Advanced Link-level Simulations\n- **Part IV: Toward Learned Receivers**\n\n\nThe [official documentation](https://nvlabs.github.io/sionna) provides key material on how to use Sionna and how its components are implemented."
"## Imports\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna as sn\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna as sn\n# Import TensorFlow and NumPy\nimport tensorflow as tf\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\nimport numpy as np\n# For saving complex Python data structures efficiently\nimport pickle\n# For plotting\n%matplotlib inline\nimport matplotlib.pyplot as plt\n# For the implementation of the neural receiver\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Layer, Conv2D, LayerNormalization\nfrom tensorflow.nn import relu\n```"
"## Simulation Parameters\n\n\n```python\n# Bit per channel use\nNUM_BITS_PER_SYMBOL = 2 # QPSK\n# Minimum value of Eb/N0 [dB] for simulations\nEBN0_DB_MIN = -3.0\n# Maximum value of Eb/N0 [dB] for simulations\nEBN0_DB_MAX = 5.0\n# How many examples are processed by Sionna in parallel\nBATCH_SIZE = 128\n# Coding rate\nCODERATE = 0.5\n# Define the number of UT and BS antennas\nNUM_UT = 1\nNUM_BS = 1\nNUM_UT_ANT = 1\nNUM_BS_ANT = 2\n# The number of transmitted streams is equal to the number of UT antennas\n# in both uplink and downlink\nNUM_STREAMS_PER_TX = NUM_UT_ANT\n# Create an RX-TX association matrix.\n# RX_TX_ASSOCIATION[i,j]=1 means that receiver i gets at least one stream\n# from transmitter j. Depending on the transmission direction (uplink or downlink),\n# the role of UT and BS can change.\n# For example, considering a system with 2 RX and 4 TX, the RX-TX\n# association matrix could be\n# [ [1 , 1, 0, 0],\n#   [0 , 0, 1, 1] ]\n# which indicates that the RX 0 receives from TX 0 and 1, and RX 1 receives from\n# TX 2 and 3.\n#\n# In this notebook, as we have only a single transmitter and receiver,\n# the RX-TX association matrix is simply:\nRX_TX_ASSOCIATION = np.array([[1]])\n# Instantiate a StreamManagement object\n# This determines which data streams are determined for which receiver.\n# In this simple setup, this is fairly easy. However, it can get more involved\n# for simulations with many transmitters and receivers.\nSTREAM_MANAGEMENT = sn.mimo.StreamManagement(RX_TX_ASSOCIATION, NUM_STREAMS_PER_TX)\nRESOURCE_GRID = sn.ofdm.ResourceGrid( num_ofdm_symbols=14,\n                                      fft_size=76,\n                                      subcarrier_spacing=30e3,\n                                      num_tx=NUM_UT,\n                                      num_streams_per_tx=NUM_STREAMS_PER_TX,\n                                      cyclic_prefix_length=6,\n                                      pilot_pattern=\"kronecker\",\n                                      pilot_ofdm_symbol_indices=[2,11])\n# Carrier frequency in Hz.\nCARRIER_FREQUENCY = 2.6e9\n# Antenna setting\nUT_ARRAY = sn.channel.tr38901.Antenna(  polarization=\"single\",\n                                        polarization_type=\"V\",\n                                        antenna_pattern=\"38.901\",\n                                        carrier_frequency=CARRIER_FREQUENCY)\nBS_ARRAY = sn.channel.tr38901.AntennaArray( num_rows=1,\n                                            num_cols=int(NUM_BS_ANT/2),\n                                            polarization=\"dual\",\n                                            polarization_type=\"cross\",\n                                            antenna_pattern=\"38.901\", # Try 'omni'\n                                            carrier_frequency=CARRIER_FREQUENCY)\n# Nominal delay spread in [s]. Please see the CDL documentation\n# about how to choose this value.\nDELAY_SPREAD = 100e-9\n# The `direction` determines if the UT or BS is transmitting.\n# In the `uplink`, the UT is transmitting.\nDIRECTION = \"uplink\"\n# Suitable values are [\"A\", \"B\", \"C\", \"D\", \"E\"]\nCDL_MODEL = \"C\"\n# UT speed [m/s]. BSs are always assumed to be fixed.\n# The direction of travel will chosen randomly within the x-y plane.\nSPEED = 10.0\n# Configure a channel impulse reponse (CIR) generator for the CDL model.\nCDL = sn.channel.tr38901.CDL(CDL_MODEL,\n                             DELAY_SPREAD,\n                             CARRIER_FREQUENCY,\n                             UT_ARRAY,\n                             BS_ARRAY,\n                             DIRECTION,\n                             min_speed=SPEED)\n```"
"## Implemention of an Advanced Neural Receiver\n\nWe will implement a state-of-the-art neural receiver that operates over the entire resource grid of received symbols.\n\nThe neural receiver computes LLRs on the coded bits from the received resource grid of frequency-domain baseband symbols.\n\n\nAs shown in the following figure, the neural receiver substitutes to the channel estimator, equalizer, and demapper.\n\n\nAs in [1] and [2], a neural receiver using residual convolutional layers is implemented.\n\nConvolutional layers are leveraged to efficienly process the 2D resource grid that is fed as an input to the neural receiver.\n\nResidual (skip) connections are used to avoid gradient vanishing [3].\n\nFor convenience, a Keras layer that implements a *residual block* is first defined. The Keras layer that implements the neural receiver is built by stacking such blocks. The following figure shows the architecture of the neural receiver.\n\n\n```python\nclass ResidualBlock(Layer):\n    def __init__(self):\n        super().__init__()\n        # Layer normalization is done over the last three dimensions: time, frequency, conv 'channels'\n        self._layer_norm_1 = LayerNormalization(axis=(-1, -2, -3))\n        self._conv_1 = Conv2D(filters=128,\n                              kernel_size=[3,3],\n                              padding='same',\n                              activation=None)\n        # Layer normalization is done over the last three dimensions: time, frequency, conv 'channels'\n        self._layer_norm_2 = LayerNormalization(axis=(-1, -2, -3))\n        self._conv_2 = Conv2D(filters=128,\n                              kernel_size=[3,3],\n                              padding='same',\n                              activation=None)\n    def call(self, inputs):\n        z = self._layer_norm_1(inputs)\n        z = relu(z)\n        z = self._conv_1(z)\n        z = self._layer_norm_2(z)\n        z = relu(z)\n        z = self._conv_2(z) # [batch size, num time samples, num subcarriers, num_channels]\n        # Skip connection\n        z = z + inputs\n        return z\nclass NeuralReceiver(Layer):\n    def __init__(self):\n        super().__init__()\n        # Input convolution\n        self._input_conv = Conv2D(filters=128,\n                                  kernel_size=[3,3],\n                                  padding='same',\n                                  activation=None)\n        # Residual blocks\n        self._res_block_1 = ResidualBlock()\n        self._res_block_2 = ResidualBlock()\n        self._res_block_3 = ResidualBlock()\n        self._res_block_4 = ResidualBlock()\n        # Output conv\n        self._output_conv = Conv2D(filters=NUM_BITS_PER_SYMBOL,\n                                   kernel_size=[3,3],\n                                   padding='same',\n                                   activation=None)\n    def call(self, inputs):\n        y, no = inputs\n        # Assuming a single receiver, remove the num_rx dimension\n        y = tf.squeeze(y, axis=1)\n        # Feeding the noise power in log10 scale helps with the performance\n        no = sn.utils.log10(no)\n        # Stacking the real and imaginary components of the different antennas along the 'channel' dimension\n        y = tf.transpose(y, [0, 2, 3, 1]) # Putting antenna dimension last\n        no = sn.utils.insert_dims(no, 3, 1)\n        no = tf.tile(no, [1, y.shape[1], y.shape[2], 1])\n        # z : [batch size, num ofdm symbols, num subcarriers, 2*num rx antenna + 1]\n        z = tf.concat([tf.math.real(y),\n                       tf.math.imag(y),\n                       no], axis=-1)\n        # Input conv\n        z = self._input_conv(z)\n        # Residual blocks\n        z = self._res_block_1(z)\n        z = self._res_block_2(z)\n        z = self._res_block_3(z)\n        z = self._res_block_4(z)\n        # Output conv\n        z = self._output_conv(z)\n        # Reshape the input to fit what the resource grid demapper is expected\n        z = sn.utils.insert_dims(z, 2, 1)\n        return z\n```"
"The task of the receiver is to jointly solve, for each resource element, `NUM_BITS_PER_SYMBOL` binary classification problems in order to reconstruct the transmitted bits. Therefore, a natural choice for the loss function is the *binary cross-entropy* (BCE) applied to each bit and to each received symbol.\n\n*Remark:* The LLRs computed by the demapper are *logits* on the transmitted bits, and can therefore be used as-is to compute the BCE without any additional processing. *Remark 2:* The BCE is closely related to an achieveable information rate for bit-interleaved coded modulation systems [4,5]\n\nThe next cell defines an end-to-end communication system using the neural receiver layer.\n\nAt initialization, the paramater `training` indicates if the system is instantiated to be trained (`True`) or evaluated (`False`).\n\nIf the system is instantiated to be trained, the outer encoder and decoder are not used as they are not required for training. Moreover, the estimated BCE is returned. This significantly reduces the computational complexity of training.\n\nIf the system is instantiated to be evaluated, the outer encoder and decoder are used, and the transmited information and corresponding LLRs are returned.\n\n\n```python\nclass OFDMSystemNeuralReceiver(Model): # Inherits from Keras Model\n    def __init__(self, training):\n        super().__init__() # Must call the Keras model initializer\n        self.training = training\n        n = int(RESOURCE_GRID.num_data_symbols*NUM_BITS_PER_SYMBOL) # Number of coded bits\n        k = int(n*CODERATE) # Number of information bits\n        self.k = k\n        self.n = n\n        # The binary source will create batches of information bits\n        self.binary_source = sn.utils.BinarySource()\n        # The encoder maps information bits to coded bits\n        self.encoder = sn.fec.ldpc.LDPC5GEncoder(k, n)\n        # The mapper maps blocks of information bits to constellation symbols\n        self.mapper = sn.mapping.Mapper(\"qam\", NUM_BITS_PER_SYMBOL)\n        # The resource grid mapper maps symbols onto an OFDM resource grid\n        self.rg_mapper = sn.ofdm.ResourceGridMapper(RESOURCE_GRID)\n        # Frequency domain channel\n        self.channel = sn.channel.OFDMChannel(CDL, RESOURCE_GRID, add_awgn=True, normalize_channel=True, return_channel=False)\n        # Neural receiver\n        self.neural_receiver = NeuralReceiver()\n        # Used to extract data-carrying resource elements\n        self.rg_demapper = sn.ofdm.ResourceGridDemapper(RESOURCE_GRID, STREAM_MANAGEMENT)\n        # The decoder provides hard-decisions on the information bits\n        self.decoder = sn.fec.ldpc.LDPC5GDecoder(self.encoder, hard_out=True)\n        # Loss function\n        self.bce = tf.keras.losses.BinaryCrossentropy(from_logits=True) # Loss function\n    @tf.function # Graph execution to speed things up\n    def __call__(self, batch_size, ebno_db):\n        no = sn.utils.ebnodb2no(ebno_db, num_bits_per_symbol=NUM_BITS_PER_SYMBOL, coderate=CODERATE, resource_grid=RESOURCE_GRID)\n        # The neural receiver is expected no to have shape [batch_size].\n        if len(no.shape) == 0:\n            no = tf.fill([batch_size], no)\n        # Transmitter\n        # Outer coding is only performed if not training\n        if self.training:\n            codewords = self.binary_source([batch_size, NUM_UT, NUM_UT_ANT, self.n])\n        else:\n            bits = self.binary_source([batch_size, NUM_UT, NUM_UT_ANT, self.k])\n            codewords = self.encoder(bits)\n        x = self.mapper(codewords)\n        x_rg = self.rg_mapper(x)\n        # Channel\n        y = self.channel([x_rg, no])\n        # Receiver\n        llr = self.neural_receiver([y, no])\n        llr = self.rg_demapper(llr) # Extract data-carrying resource elements. The other LLrs are discarded\n        llr = tf.reshape(llr, [batch_size, NUM_UT, NUM_UT_ANT, self.n]) # Reshape the LLRs to fit what the outer decoder is expected\n        if self.training:\n            loss = self.bce(codewords, llr)\n            return loss\n        else:\n            bits_hat = self.decoder(llr)\n            return bits, bits_hat\n```"
"## Training the Neural Receiver\n\nThe next cell implements a training loop of `NUM_TRAINING_ITERATIONS` iterations.\n\nAt each iteration: - A batch of SNRs $E_b/N_0$ is sampled - A forward pass through the end-to-end system is performed within a gradient tape - The gradients are computed using the gradient tape, and applied using the Adam optimizer - A progress bar is periodically updated to follow the progress of training\n\nAfter training, the weights of the models are saved in a file using [pickle](https://docs.python.org/3/library/pickle.html).\n\n```python\n[ ]:\n```\n\n```python\n# Set a seed for reproducibility\ntf.random.set_seed(1)\n# Number of iterations used for training\nNUM_TRAINING_ITERATIONS = 100000\n# Instantiating the end-to-end model for training\nmodel = OFDMSystemNeuralReceiver(training=True)\n# Adam optimizer (SGD variant)\noptimizer = tf.keras.optimizers.Adam()\n# Training loop\nfor i in range(NUM_TRAINING_ITERATIONS):\n    # Sample a batch of SNRs.\n    ebno_db = tf.random.uniform(shape=[BATCH_SIZE], minval=EBN0_DB_MIN, maxval=EBN0_DB_MAX)\n    # Forward pass\n    with tf.GradientTape() as tape:\n        loss = model(BATCH_SIZE, ebno_db)\n    # Computing and applying gradients\n    weights = model.trainable_weights\n    grads = tape.gradient(loss, weights)\n    optimizer.apply_gradients(zip(grads, weights))\n    # Print progress\n    if i % 100 == 0:\n        print(f\"{i}/{NUM_TRAINING_ITERATIONS}  Loss: {loss:.2E}\", end=\"\\r\")\n# Save the weightsin a file\nweights = model.get_weights()\nwith open('weights-ofdm-neuralrx', 'wb') as f:\n    pickle.dump(weights, f)\n```"
"## Benchmarking the Neural Receiver\n\nWe evaluate the trained model and benchmark it against the previously introduced baselines.\n\nWe first define and evaluate the baselines.\n\n\n```python\nclass OFDMSystem(Model): # Inherits from Keras Model\n    def __init__(self, perfect_csi):\n        super().__init__() # Must call the Keras model initializer\n        self.perfect_csi = perfect_csi\n        n = int(RESOURCE_GRID.num_data_symbols*NUM_BITS_PER_SYMBOL) # Number of coded bits\n        k = int(n*CODERATE) # Number of information bits\n        self.k = k\n        # The binary source will create batches of information bits\n        self.binary_source = sn.utils.BinarySource()\n        # The encoder maps information bits to coded bits\n        self.encoder = sn.fec.ldpc.LDPC5GEncoder(k, n)\n        # The mapper maps blocks of information bits to constellation symbols\n        self.mapper = sn.mapping.Mapper(\"qam\", NUM_BITS_PER_SYMBOL)\n        # The resource grid mapper maps symbols onto an OFDM resource grid\n        self.rg_mapper = sn.ofdm.ResourceGridMapper(RESOURCE_GRID)\n        # Frequency domain channel\n        self.channel = sn.channel.OFDMChannel(CDL, RESOURCE_GRID, add_awgn=True, normalize_channel=True, return_channel=True)\n        # The LS channel estimator will provide channel estimates and error variances\n        self.ls_est = sn.ofdm.LSChannelEstimator(RESOURCE_GRID, interpolation_type=\"nn\")\n        # The LMMSE equalizer will provide soft symbols together with noise variance estimates\n        self.lmmse_equ = sn.ofdm.LMMSEEqualizer(RESOURCE_GRID, STREAM_MANAGEMENT)\n        # The demapper produces LLR for all coded bits\n        self.demapper = sn.mapping.Demapper(\"app\", \"qam\", NUM_BITS_PER_SYMBOL)\n        # The decoder provides hard-decisions on the information bits\n        self.decoder = sn.fec.ldpc.LDPC5GDecoder(self.encoder, hard_out=True)\n    @tf.function # Graph execution to speed things up\n    def __call__(self, batch_size, ebno_db):\n        no = sn.utils.ebnodb2no(ebno_db, num_bits_per_symbol=NUM_BITS_PER_SYMBOL, coderate=CODERATE, resource_grid=RESOURCE_GRID)\n        # Transmitter\n        bits = self.binary_source([batch_size, NUM_UT, RESOURCE_GRID.num_streams_per_tx, self.k])\n        codewords = self.encoder(bits)\n        x = self.mapper(codewords)\n        x_rg = self.rg_mapper(x)\n        # Channel\n        y, h_freq = self.channel([x_rg, no])\n        # Receiver\n        if self.perfect_csi:\n            h_hat, err_var = h_freq, 0.\n        else:\n            h_hat, err_var = self.ls_est ([y, no])\n        x_hat, no_eff = self.lmmse_equ([y, h_hat, err_var, no])\n        llr = self.demapper([x_hat, no_eff])\n        bits_hat = self.decoder(llr)\n        return bits, bits_hat\n```"
"```python\nber_plots = sn.utils.PlotBER(\"Advanced neural receiver\")\nbaseline_ls = OFDMSystem(False)\nber_plots.simulate(baseline_ls,\n                  ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 20),\n                  batch_size=BATCH_SIZE,\n                  num_target_block_errors=100, # simulate until 100 block errors occured\n                  legend=\"Baseline: LS Estimation\",\n                  soft_estimates=True,\n                  max_mc_iter=100, # run 100 Monte-Carlo simulations (each with batch_size samples)\n                  show_fig=False);\nbaseline_pcsi = OFDMSystem(True)\nber_plots.simulate(baseline_pcsi,\n                  ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 20),\n                  batch_size=BATCH_SIZE,\n                  num_target_block_errors=100, # simulate until 100 block errors occured\n                  legend=\"Baseline: Perfect CSI\",\n                  soft_estimates=True,\n                  max_mc_iter=100, # run 100 Monte-Carlo simulations (each with batch_size samples)\n                  show_fig=False);\n```\n\n\n```python\nWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\nInstructions for updating:\nThe `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -3.0 | 3.6894e-01 | 1.0000e+00 |       43069 |      116736 |          128 |         128 |         7.7 |reached target block errors\n   -2.579 | 3.5806e-01 | 1.0000e+00 |       41799 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -2.158 | 3.4527e-01 | 1.0000e+00 |       40305 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -1.737 | 3.3213e-01 | 1.0000e+00 |       38771 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -1.316 | 3.2260e-01 | 1.0000e+00 |       37659 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -0.895 | 3.0787e-01 | 1.0000e+00 |       35940 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -0.474 | 2.9344e-01 | 1.0000e+00 |       34255 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -0.053 | 2.7841e-01 | 1.0000e+00 |       32501 |      116736 |          128 |         128 |         0.2 |reached target block errors\n    0.368 | 2.6109e-01 | 1.0000e+00 |       30479 |      116736 |          128 |         128 |         0.2 |reached target block errors\n    0.789 | 2.4077e-01 | 1.0000e+00 |       28107 |      116736 |          128 |         128 |         0.2 |reached target block errors\n    1.211 | 2.2460e-01 | 1.0000e+00 |       26219 |      116736 |          128 |         128 |         0.2 |reached target block errors\n    1.632 | 1.9116e-01 | 1.0000e+00 |       22315 |      116736 |          128 |         128 |         0.2 |reached target block errors\n    2.053 | 1.5909e-01 | 1.0000e+00 |       18572 |      116736 |          128 |         128 |         0.2 |reached target block errors\n    2.474 | 9.3930e-02 | 8.6719e-01 |       10965 |      116736 |          111 |         128 |         0.2 |reached target block errors\n    2.895 | 2.1987e-02 | 3.8281e-01 |        7700 |      350208 |          147 |         384 |         0.5 |reached target block errors\n    3.316 | 1.5316e-03 | 4.2352e-02 |        3397 |     2217984 |          103 |        2432 |         2.9 |reached target block errors\n    3.737 | 1.1607e-04 | 1.6406e-03 |        1355 |    11673600 |           21 |       12800 |        15.5 |reached max iter\n    4.158 | 0.0000e+00 | 0.0000e+00 |           0 |    11673600 |            0 |       12800 |        15.5 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 4.2 dB.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -3.0 | 2.1695e-01 | 1.0000e+00 |       25326 |      116736 |          128 |         128 |         3.4 |reached target block errors\n   -2.579 | 1.9826e-01 | 1.0000e+00 |       23144 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -2.158 | 1.7926e-01 | 1.0000e+00 |       20926 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -1.737 | 1.3810e-01 | 1.0000e+00 |       16121 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -1.316 | 7.1966e-02 | 8.7500e-01 |        8401 |      116736 |          112 |         128 |         0.2 |reached target block errors\n   -0.895 | 1.6267e-02 | 3.6719e-01 |        5697 |      350208 |          141 |         384 |         0.5 |reached target block errors\n   -0.474 | 6.2963e-04 | 2.8181e-02 |        2058 |     3268608 |          101 |        3584 |         4.3 |reached target block errors\n   -0.053 | 4.5916e-05 | 8.5938e-04 |         536 |    11673600 |           11 |       12800 |        15.4 |reached max iter\n    0.368 | 2.9126e-05 | 1.5625e-04 |         340 |    11673600 |            2 |       12800 |        15.4 |reached max iter\n    0.789 | 1.5676e-05 | 7.8125e-05 |         183 |    11673600 |            1 |       12800 |        15.4 |reached max iter\n    1.211 | 0.0000e+00 | 0.0000e+00 |           0 |    11673600 |            0 |       12800 |        15.5 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 1.2 dB.\n\n```"
"We then instantiate and evaluate the end-to-end system equipped with the neural receiver.\n\n\n```python\n# Instantiating the end-to-end model for evaluation\nmodel_neuralrx = OFDMSystemNeuralReceiver(training=False)\n# Run one inference to build the layers and loading the weights\nmodel_neuralrx(tf.constant(1, tf.int32), tf.constant(10.0, tf.float32))\nwith open('weights-ofdm-neuralrx', 'rb') as f:\n    weights = pickle.load(f)\n    model_neuralrx.set_weights(weights)\n```\n\n```python\n# Computing and plotting BER\nber_plots.simulate(model_neuralrx,\n                  ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 20),\n                  batch_size=BATCH_SIZE,\n                  num_target_block_errors=100,\n                  legend=\"Neural Receiver\",\n                  soft_estimates=True,\n                  max_mc_iter=100,\n                  show_fig=True);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -3.0 | 2.2083e-01 | 1.0000e+00 |       25779 |      116736 |          128 |         128 |         0.3 |reached target block errors\n   -2.579 | 2.0480e-01 | 1.0000e+00 |       23907 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -2.158 | 1.8219e-01 | 1.0000e+00 |       21268 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -1.737 | 1.4852e-01 | 1.0000e+00 |       17338 |      116736 |          128 |         128 |         0.2 |reached target block errors\n   -1.316 | 9.0503e-02 | 9.4531e-01 |       10565 |      116736 |          121 |         128 |         0.2 |reached target block errors\n   -0.895 | 2.2251e-02 | 4.4922e-01 |        5195 |      233472 |          115 |         256 |         0.3 |reached target block errors\n   -0.474 | 1.7106e-03 | 6.4303e-02 |        2596 |     1517568 |          107 |        1664 |         2.2 |reached target block errors\n   -0.053 | 1.4828e-04 | 3.2812e-03 |        1731 |    11673600 |           42 |       12800 |        16.6 |reached max iter\n    0.368 | 6.3305e-05 | 6.2500e-04 |         739 |    11673600 |            8 |       12800 |        16.5 |reached max iter\n    0.789 | 8.6520e-06 | 1.5625e-04 |         101 |    11673600 |            2 |       12800 |        16.5 |reached max iter\n    1.211 | 4.2832e-07 | 7.8125e-05 |           5 |    11673600 |            1 |       12800 |        16.6 |reached max iter\n    1.632 | 0.0000e+00 | 0.0000e+00 |           0 |    11673600 |            0 |       12800 |        16.5 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 1.6 dB.\n\n```"
"## Conclusion\n\nWe hope you are excited about Sionna - there is much more to be discovered:\n\n- TensorBoard debugging available\n- Scaling to multi-GPU simulation is simple\n- See the [available tutorials](https://nvlabs.github.io/sionna/tutorials.html) for more examples\n\n\nAnd if something is still missing - the project is open-source: you can modify, add, and extend any component at any time.\n\nTo get started you can use the `pip` installer:\n\n```python\n[ ]:\n```\n\n```python\n!pip install sionna\n```"
"## References\n\n[1] [M. Honkala, D. Korpi and J. M. J. Huttunen, DeepRx: Fully Convolutional Deep Learning Receiver, in IEEE Transactions on Wireless Communications, vol.20, no. 6, pp.3925-3940, June 2021, doi: 10.1109/TWC.2021.3054520](https://ieeexplore.ieee.org/abstract/document/9345504).\n\n[2] [F. Ait Aoudia and J. Hoydis, End-to-end Learning for OFDM: From Neural Receivers to Pilotless Communication, in IEEE Transactions on Wireless Communications, doi: 10.1109/TWC.2021.3101364](https://ieeexplore.ieee.org/abstract/document/9508784).\n\n[3] [Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Deep Residual Learning for Image Recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp.770-778](https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html)\n[3] [Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Deep Residual Learning for Image Recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp.770-778](https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html)\n[3] [Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Deep Residual Learning for Image Recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp.770-778](https://openaccess.thecvf.com/content_cvpr_2016/html/He_Deep_Residual_Learning_CVPR_2016_paper.html)"
"# Pulse-shaping Basics\n\nIn this tutorial notebook, you will learn about various components of Sionnas signal module, such as pulse-shaping filters, windowing functions, as well as layers for up- and down-sampling.\n\nBelow is a schematic diagram of the used components and how they connect. For simplicity, we have not added any channel between the pulse-shaping filter and the matched filter.\n\n\nYou will learn how to:\n\n- Use filters for pulse-shaping and matched filtering\n- Visualize impulse and magnitude responses\n- Compute the empirical power spectral density (PSD) and adjacent channel leakage power ratio (ACLR)\n- Apply the Upsampling and Downsampling layers\n- Add windowing to filters for improved spectral characteristics"
"## GPU Configuration and Imports\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n# For more details, see https://www.tensorflow.org/guide/gpu\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\n```\n\n```python\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sionna.utils import QAMSource\nfrom sionna.signal import Upsampling, Downsampling, RootRaisedCosineFilter, empirical_psd, empirical_aclr\n```"
"## Pulse-shaping of a sequence of QAM symbols\n\nWe start by creating a root-raised-cosine filter with a roll-off factor of 0.22, spanning 32 symbols, with an oversampling factor of four.\n\n\n```python\nbeta = 0.22 # Roll-off factor\nspan_in_symbols = 32 # Filter span in symbold\nsamples_per_symbol = 4 # Number of samples per symbol, i.e., the oversampling factor\nrrcf = RootRaisedCosineFilter(span_in_symbols, samples_per_symbol, beta)\n```\n\n\nAll filters have a function to visualize their impulse response $h(t)$ and magnitude response $H(f)$, i.e., the absolute value of the Fourier transform of $h(t)$. The symbol duration is denoted $T$ and the bandwidth $W$. The *normalized time* and *normalized frequency* are then defined as $t/T$ and $f/W$, respectively.\n\n\n```python\nrrcf.show(\"impulse\")\nrrcf.show(\"magnitude\", \"db\") # Logarithmic scale\nrrcf.show(\"magnitude\", \"lin\") # Linear scale\n```\n\n\nIn Sionna, filters have always an odd number of samples. This is despite the fact that the product *span_in_symbols* $\\times$ *samples_per_symbol* can be even. Let us verify the length property of our root-raised-cosine filter:\n\n\n```python\nprint(\"Filter length:\", rrcf.length)\n```\n\n\n```python\nFilter length: 129\n```\n\n\nNext, we will use this filter to pulse shape a sequence of QAM symbols. This requires upsampling of the sequence to the desired sampling rate. The sampling rate is defined as the number of samples per symbol $k$, and upsampling simply means that $k-1$ zeros are inserted after every QAM symbol.\n\n\n```python\n# Configure QAM source\nnum_bits_per_symbol = 4 # The modulation order of the QAM constellation, i.e., 16QAM\nqam = QAMSource(num_bits_per_symbol) # Layer to generate batches of QAM symbols\n# Generate batch of QAM symbol sequences\nbatch_size = 128\nnum_symbols = 1000\nx = qam([batch_size, num_symbols])\nprint(\"Shape of x\", x.shape)\n# Create instance of the Upsampling layer\nus = Upsampling(samples_per_symbol)\n# Upsample the QAM symbol sequence\nx_us = us(x)\nprint(\"Shape of x_us\", x_us.shape)\n# Inspect the first few elements of one row of x_us\nplt.stem(np.abs(x_us)[0,:20]);\nplt.xlabel(r\"Sample index $i$\")\nplt.ylabel(r\"|$x_{us}[i]$|\");\n```"
"```python\nShape of x (128, 1000)\nShape of x_us (128, 4000)\n```\n\n\nAfter upsampling, we can apply the filter:\n\n\n```python\n# Filter the upsampled sequence\nx_rrcf = rrcf(x_us)\n```"
"## Recovering the QAM symbols through matched filtering and downsampling\n\nIn order to recover the QAM symbols from this waveform, we need to apply a matched filter, i.e., the same filter in our case, and downsample the result, starting from the correct index. This index can be obtained as follows. The transmit filter has its peak value after $(L-1)/2$ samples, where $L$ is the filter length. If we apply the same filter for reception, the peak will be delayed by a total of $L-1$ samples. The code in the following cell creates a Downsampling layer that\nallows us to recover the transmitted symbol sequence.\n\n\n```python\n# Apply the matched filter\nx_mf = rrcf(x_rrcf)\n# Instantiate a downsampling layer\nds = Downsampling(samples_per_symbol, rrcf.length-1, num_symbols)\n# Recover the transmitted symbol sequence\nx_hat = ds(x_mf)\n# Visualize the different signals\nplt.figure(figsize=(12, 8))\nplt.plot(np.real(x_us[0]), \"x\")\nplt.plot(np.real(x_rrcf[0, rrcf.length//2:]))\nplt.plot(np.real(x_mf[0, rrcf.length-1:]));\nplt.xlim(0,100)\nplt.legend([r\"Oversampled sequence of QAM symbols $x_{us}$\",\n            r\"Transmitted sequence after pulse shaping $x_{rrcf}$\",\n            r\"Received sequence after matched filtering $x_{mf}$\"]);\n```\n\n\nWe can see nicely from the above figure that the signal after matched filtering overlaps almost perfectly with the oversampled sequence of QAM symbols at the symbol times. As further verification, we will next show a scatter plot of the transmitted and recovered symbols and compute the mean-squared error (MSE) between them. As one can see, the MSE is not zero, which is due to truncation of the filter to finite length. The MSE can be reduced by making the filter longer or by increasing the\nroll-off factor.\n\nGive it a try and change *span_in_symbols* above to a larger number, e.g., 100. This will reduce the MSE by around 26dB.\n\n\n```python\nplt.figure()\nplt.scatter(np.real(x_hat), np.imag(x_hat));\nplt.scatter(np.real(x), np.imag(x));\nplt.legend([\"Transmitted\", \"Received\"]);\nplt.title(\"Scatter plot of the transmitted and received QAM symbols\")\nprint(\"MSE between x and x_hat (dB)\", 10*np.log10(np.var(x-x_hat)))\n```"
"## Investigating the ACLR\n\nAn important metric of waveforms is the so-called adjacent channel leakage power ratio, or short ACLR. It is defined as the ratio of the out-of-band power and the in-band power. One can get a first idea of the ACLR by looking at the power spectral density (PSD) of a transmitted signal.\n\n\n```python\nempirical_psd(x_rrcf, oversampling=samples_per_symbol, ylim=[-100, 3]);\n```\n\n\nThe in-band is defined by the interval from [-0.5, 0.5] in normalized frequency. Due to the non-zero roll-of factor, a significant amount of energy is located out of this band. The resulting ACLR can be computed with the following convenience function:\n\n\n```python\naclr_db = 10*np.log10(empirical_aclr(x_rrcf, oversampling=samples_per_symbol))\nprint(\"Empirical ACLR (db):\", aclr_db)\n```\n\n\n```python\nEmpirical ACLR (db): -13.801279067993164\n```\n\n\nWe can now verify that this empirical ACLR is well aligned with the theoretical ACLR that can be computed based on the magnitude response of the pulse-shaping filter. Every filter provides this value as the property *Filter.aclr*.\n\n\n```python\nprint(\"Filter ACLR (dB)\", 10*np.log10(rrcf.aclr))\n```\n\n\n```python\nFilter ACLR (dB) -13.805673122406006\n```\n\n\nWe can improve the ACLR by decreasing the roll-off factor $\\beta$ from 0.22 to 0.1:\n\n\n```python\nprint(\"Filter ACLR (dB)\", 10*np.log10(RootRaisedCosineFilter(span_in_symbols, samples_per_symbol, 0.1).aclr))\n```\n\n\n```python\nFilter ACLR (dB) -17.342106103897095\n```"
"## Windowing\n\nWindowing can be used to improve the spectral properties of a truncated filter. For a filter of length $L$, a window is a real-valued vector of the same length that is multiplied element-wise with the filter coefficients. This is equivalent to a convolution of the filter and the window in the frequency domain.\n\nLet us now create a slightly shorter root-raised-cosine filter and compare its properties with and without windowing. One can see that windowing leads to a much reduced out-of-band attenuation. However, the passband of the filter is also broadened which leads to an even slightly increased ACLR.\n\n\n```python\nspan_in_symbols = 8 # Filter span in symbols\nsamples_per_symbol = 8 # Number of samples per symbol, i.e., the oversampling factor\nrrcf_short = RootRaisedCosineFilter(span_in_symbols, samples_per_symbol, beta)\nrrcf_short_blackman = RootRaisedCosineFilter(span_in_symbols, samples_per_symbol, beta, window=\"blackman\")\nrrcf_short_blackman.window.show(samples_per_symbol)\nrrcf_short_blackman.window.show(samples_per_symbol, domain=\"frequency\", scale=\"db\")\nrrcf_short.show()\nplt.title(\"Impulse response without windowing\")\nrrcf_short_blackman.show()\nplt.title(\"Impulse response with windowing\")\nrrcf_short.show(\"magnitude\", \"db\")\nplt.title(\"Magnitude response without windowing\")\nrrcf_short_blackman.show(\"magnitude\", \"db\")\nplt.title(\"Magnitude response with windowing\")\nprint(\"ACLR (db) without window\", 10*np.log10(rrcf_short.aclr))\nprint(\"ACLR (db) with window\", 10*np.log10(rrcf_short_blackman.aclr))\n```\n\n\n```python\nACLR (db) without window -13.982985019683838\nACLR (db) with window -12.624131441116333\n```"
"# 5G Channel Coding and Rate-Matching: Polar vs.LDPC Codes\n\n*For block lengths of about 500, an IBM 7090 computer requires about 0.1 seconds per iteration to decode a block by probabilistic decoding scheme. Consequently, many hours of computation time are necessary to evaluate even a* $P(e)$ *in the order of* ${10^{-4}}$ *.* Robert G. Gallager, 1963 [7]\n\nIn this notebook, you will learn about the different coding schemes in 5G NR and how rate-matching works (cf.3GPP TS 38.212 [3]). The coding schemes are compared under different length/rate settings and for different decoders.\n\nYou will learn about the following components:\n\n- 5G low-density parity-checks (LDPC) codes [7]. These codes support - without further segmentation - up to *k=8448* information bits per codeword [3] for a wide range of coderates.\n- Polar codes [1] including CRC concatenation and rate-matching for 5G compliant en-/decoding is implemented for the Polar uplink control channel (UCI) [3]. Besides Polar codes, Reed-Muller (RM) codes and several decoders are available:\n\n- Successive cancellation (SC) decoding [1]\n- Successive cancellation list (SCL) decoding [2]\n- Hybrid SC / SCL decoding for enhanced throughput\n- Iterative belief propagation (BP) decoding [6]\n\n\nFurther, we will demonstrate the basic functionality of the Sionna forward error correction (FEC) module which also includes support for:\n\n- Convolutional codes with non-recursive encoding and Viterbi/BCJR decoding\n- Turbo codes and iterative BCJR decoding\n- Ordered statistics decoding (OSD) for any binary, linear code\n- Interleaving and scrambling\n\n\nFor additional technical background we refer the interested reader to [4,5,8].\n\nPlease note that block segmentation is not implemented as it only concatenates multiple code blocks without increasing the effective codewords length (from decoders perspective).\n\nSome simulations in this notebook require severe simulation time, in particular if parameter sweeps are involved (e.g., different length comparisons). Please keep in mind that each cell in this notebook already contains the pre-computed outputs and no new execution is required to understand the examples."
"## GPU Configuration and Imports\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n# Load the required Sionna components\nfrom sionna.mapping import Constellation, Mapper, Demapper\nfrom sionna.fec.polar import PolarEncoder, Polar5GEncoder, PolarSCLDecoder, Polar5GDecoder, PolarSCDecoder\nfrom sionna.fec.ldpc import LDPC5GEncoder, LDPC5GDecoder\nfrom sionna.fec.polar.utils import generate_5g_ranking, generate_rm_code\nfrom sionna.fec.conv import ConvEncoder, ViterbiDecoder, BCJRDecoder\nfrom sionna.fec.turbo import TurboEncoder, TurboDecoder\nfrom sionna.fec.linear import OSDecoder\nfrom sionna.utils import BinarySource, ebnodb2no\nfrom sionna.utils.metrics import  count_block_errors\nfrom sionna.channel import AWGN\nfrom sionna.utils.plotting import PlotBER\n```\n\n```python\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time # for throughput measurements\n```\n\n```python\nimport tensorflow as tf\n# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n# For more details, see https://www.tensorflow.org/guide/gpu\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\n```"
"## BER Performance of 5G Coding Schemes\n\nLet us first focus on short length coding, e.g., for internet of things (IoT) and ultra-reliable low-latency communications (URLLC). We aim to reproduce similar results as in [9] for the coding schemes supported by Sionna.\n\nFor a detailed explanation of the `PlotBER` class, we refer to the example notebook on [Bit-Interleaved Coded Modulation](https://nvlabs.github.io/sionna/examples/Bit_Interleaved_Coded_Modulation.html).\n\nThe Sionna API allows to pass an encoder object/layer to the decoder initialization for the 5G decoders. This means that the decoder is directly *associated* to a specific encoder and *knows* all relevant code parameters. Please note that - of course - no data or information bits are exchanged between these two associated components. It just simplifies handling of the code parameters, in particular, if rate-matching is used.\n\nLet us define the system model first. We use encoder and decoder as input parameter such that the model remains flexible w.r.t. the coding scheme.\n\n\n```python\nclass System_Model(tf.keras.Model):\n    \"\"\"System model for channel coding BER simulations.\n    This model allows to simulate BERs over an AWGN channel with\n    QAM modulation. Arbitrary FEC encoder/decoder layers can be used to\n    initialize the model.\n    Parameters\n    ----------\n        k: int\n            number of information bits per codeword.\n        n: int\n            codeword length.\n        num_bits_per_symbol: int\n            number of bits per QAM symbol.\n        encoder: Keras layer\n            A Keras layer that encodes information bit tensors.\n        decoder: Keras layer\n            A Keras layer that decodes llr tensors.\n        demapping_method: str\n            A string denoting the demapping method. Can be either \"app\" or \"maxlog\".\n        sim_esno: bool\n            A boolean defaults to False. If true, no rate-adjustment is done for the SNR calculation.\n         cw_estiamtes: bool\n            A boolean defaults to False. If true, codewords instead of information estimates are returned.\n    Input\n    -----\n        batch_size: int or tf.int\n            The batch_size used for the simulation.\n        ebno_db: float or tf.float\n            A float defining the simulation SNR.\n    Output\n    ------\n        (u, u_hat):\n            Tuple:\n        u: tf.float32\n            A tensor of shape `[batch_size, k] of 0s and 1s containing the transmitted information bits.\n        u_hat: tf.float32\n            A tensor of shape `[batch_size, k] of 0s and 1s containing the estimated information bits.\n    \"\"\"\n    def __init__(self,\n                 k,\n                 n,\n                 num_bits_per_symbol,\n                 encoder,\n                 decoder,\n                 demapping_method=\"app\",\n                 sim_esno=False,\n                 cw_estimates=False):\n        super().__init__()\n        # store values internally\n        self.k = k\n        self.n = n\n        self.sim_esno = sim_esno # disable rate-adjustment for SNR calc\n        self.cw_estimates=cw_estimates # if true codewords instead of info bits are returned\n        # number of bit per QAM symbol\n        self.num_bits_per_symbol = num_bits_per_symbol\n        # init components\n        self.source = BinarySource()\n        # initialize mapper and demapper for constellation object\n        self.constellation = Constellation(\"qam\",\n                                num_bits_per_symbol=self.num_bits_per_symbol)\n        self.mapper = Mapper(constellation=self.constellation)\n        self.demapper = Demapper(demapping_method,\n                                 constellation=self.constellation)\n        # the channel can be replaced by more sophisticated models\n        self.channel = AWGN()\n        # FEC encoder / decoder\n        self.encoder = encoder\n        self.decoder = decoder\n    @tf.function() # enable graph mode for increased throughputs\n    def call(self, batch_size, ebno_db):\n        # calculate noise variance\n        if self.sim_esno:\n                no = ebnodb2no(ebno_db,\n                       num_bits_per_symbol=1,\n                       coderate=1)\n        else:\n            no = ebnodb2no(ebno_db,\n                           num_bits_per_symbol=self.num_bits_per_symbol,\n                           coderate=self.k/self.n)\n        u = self.source([batch_size, self.k]) # generate random data\n        c = self.encoder(u) # explicitly encode\n        x = self.mapper(c) # map c to symbols x\n        y = self.channel([x, no]) # transmit over AWGN channel\n        llr_ch = self.demapper([y, no]) # demap y to LLRs\n        u_hat = self.decoder(llr_ch) # run FEC decoder (incl. rate-recovery)\n        if self.cw_estimates:\n            return c, u_hat\n        return u, u_hat\n```"
"And let us define the codes to be simulated.\n\n\n```python\n# code parameters\nk = 64 # number of information bits per codeword\nn = 128 # desired codeword length\n# Create list of encoder/decoder pairs to be analyzed.\n# This allows automated evaluation of the whole list later.\ncodes_under_test = []\n# 5G instruction_answer codes with 20 BP iterations\nenc = LDPC5GEncoder(k=k, n=n)\ndec = LDPC5GDecoder(enc, num_iter=20)\nname = \"5G instruction_answer BP-20\"\ncodes_under_test.append([enc, dec, name])\n# Polar Codes (SC decoding)\nenc = Polar5GEncoder(k=k, n=n)\ndec = Polar5GDecoder(enc, dec_type=\"SC\")\nname = \"5G Polar+CRC SC\"\ncodes_under_test.append([enc, dec, name])\n# Polar Codes (SCL decoding) with list size 8.\n# The CRC is automatically added by the layer.\nenc = Polar5GEncoder(k=k, n=n)\ndec = Polar5GDecoder(enc, dec_type=\"SCL\", list_size=8)\nname = \"5G Polar+CRC SCL-8\"\ncodes_under_test.append([enc, dec, name])\n### non-5G coding schemes\n# RM codes with SCL decoding\nf,_,_,_,_ = generate_rm_code(3,7) # equals k=64 and n=128 code\nenc = PolarEncoder(f, n)\ndec = PolarSCLDecoder(f, n, list_size=8)\nname = \"Reed Muller (RM) SCL-8\"\ncodes_under_test.append([enc, dec, name])\n# Conv. code with Viterbi decoding\nenc = ConvEncoder(rate=1/2, constraint_length=8)\ndec = ViterbiDecoder(gen_poly=enc.gen_poly, method=\"soft_llr\")\nname = \"Conv. Code Viterbi (constraint length 8)\"\ncodes_under_test.append([enc, dec, name])\n# Turbo. codes\nenc = TurboEncoder(rate=1/2, constraint_length=4, terminate=False) # no termination used due to the rate loss\ndec = TurboDecoder(enc, num_iter=8)\nname = \"Turbo Code (constraint length 4)\"\ncodes_under_test.append([enc, dec, name])\n```\n\n\n```python\nWarning: 5G Polar codes use an integrated CRC that cannot be materialized with SC decoding and, thus, causes a degraded performance. Please consider SCL decoding instead.\n```"
"*Remark*: some of the coding schemes are not 5G relevant, but are included in this comparison for the sake of completeness.\n\nGenerate a new BER plot figure to save and plot simulation results efficiently.\n\n\n```python\nber_plot128 = PlotBER(f\"Performance of Short Length Codes (k={k}, n={n})\")\n```\n\n\nAnd run the BER simulation for each code.\n\n\n```python\nnum_bits_per_symbol = 2 # QPSK\nebno_db = np.arange(0, 5, 0.5) # sim SNR range\n# run ber simulations for each code we have added to the list\nfor code in codes_under_test:\n    print(\"\\nRunning: \" + code[2])\n    # generate a new model with the given encoder/decoder\n    model = System_Model(k=k,\n                         n=n,\n                         num_bits_per_symbol=num_bits_per_symbol,\n                         encoder=code[0],\n                         decoder=code[1])\n    # the first argument must be a callable (function) that yields u and u_hat for batch_size and ebno\n    ber_plot128.simulate(model, # the function have defined previously\n                         ebno_dbs=ebno_db, # SNR to simulate\n                         legend=code[2], # legend string for plotting\n                         max_mc_iter=100, # run 100 Monte Carlo runs per SNR point\n                         num_target_block_errors=1000, # continue with next SNR point after 1000 bit errors\n                         batch_size=10000, # batch-size per Monte Carlo run\n                         soft_estimates=False, # the model returns hard-estimates\n                         early_stop=True, # stop simulation if no error has been detected at current SNR point\n                         show_fig=False, # we show the figure after all results are simulated\n                         add_bler=True, # in case BLER is also interesting\n                         forward_keyboard_interrupt=True); # should be True in a loop\n# and show the figure\nber_plot128(ylim=(1e-5, 1), show_bler=False) # we set the ylim to 1e-5 as otherwise more extensive simulations would be required for accurate curves.\n\n```\n\n\n```python\n\nRunning: 5G LDPC BP-20\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 1.6724e-01 | 8.5960e-01 |      107031 |      640000 |         8596 |       10000 |         2.5 |reached target block errors\n      0.5 | 1.2503e-01 | 6.9560e-01 |       80018 |      640000 |         6956 |       10000 |         0.1 |reached target block errors\n      1.0 | 8.8070e-02 | 5.1250e-01 |       56365 |      640000 |         5125 |       10000 |         0.1 |reached target block errors\n      1.5 | 5.2178e-02 | 3.1040e-01 |       33394 |      640000 |         3104 |       10000 |         0.1 |reached target block errors\n      2.0 | 2.5391e-02 | 1.5390e-01 |       16250 |      640000 |         1539 |       10000 |         0.1 |reached target block errors\n      2.5 | 1.0280e-02 | 6.4150e-02 |       13159 |     1280000 |         1283 |       20000 |         0.2 |reached target block errors\n      3.0 | 3.3266e-03 | 2.0760e-02 |       10645 |     3200000 |         1038 |       50000 |         0.5 |reached target block errors\n      3.5 | 9.5947e-04 | 6.0882e-03 |       10439 |    10880000 |         1035 |      170000 |         1.6 |reached target block errors\n      4.0 | 2.0158e-04 | 1.3400e-03 |        9676 |    48000000 |         1005 |      750000 |         7.1 |reached target block errors\n      4.5 | 4.0484e-05 | 2.5700e-04 |        2591 |    64000000 |          257 |     1000000 |         9.5 |reached max iter\nRunning: 5G Polar+CRC SC\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 4.0980e-01 | 9.5260e-01 |      262275 |      640000 |         9526 |       10000 |         4.8 |reached target block errors\n      0.5 | 3.6786e-01 | 8.9330e-01 |      235431 |      640000 |         8933 |       10000 |         0.0 |reached target block errors\n      1.0 | 3.0912e-01 | 7.9180e-01 |      197837 |      640000 |         7918 |       10000 |         0.0 |reached target block errors\n      1.5 | 2.4575e-01 | 6.5500e-01 |      157277 |      640000 |         6550 |       10000 |         0.0 |reached target block errors\n      2.0 | 1.7330e-01 | 4.7950e-01 |      110914 |      640000 |         4795 |       10000 |         0.0 |reached target block errors\n      2.5 | 1.0759e-01 | 3.1080e-01 |       68859 |      640000 |         3108 |       10000 |         0.0 |reached target block errors\n      3.0 | 6.0220e-02 | 1.7530e-01 |       38541 |      640000 |         1753 |       10000 |         0.0 |reached target block errors\n      3.5 | 2.8487e-02 | 8.3300e-02 |       36463 |     1280000 |         1666 |       20000 |         0.1 |reached target block errors\n      4.0 | 1.0125e-02 | 3.1375e-02 |       25920 |     2560000 |         1255 |       40000 |         0.1 |reached target block errors\n      4.5 | 3.1420e-03 | 9.7091e-03 |       22120 |     7040000 |         1068 |      110000 |         0.4 |reached target block errors\nRunning: 5G Polar+CRC SCL-8\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 3.3954e-01 | 7.9370e-01 |      217305 |      640000 |         7937 |       10000 |        16.3 |reached target block errors\n      0.5 | 2.5614e-01 | 6.2320e-01 |      163931 |      640000 |         6232 |       10000 |         2.3 |reached target block errors\n      1.0 | 1.7195e-01 | 4.2970e-01 |      110045 |      640000 |         4297 |       10000 |         2.3 |reached target block errors\n      1.5 | 9.5338e-02 | 2.4580e-01 |       61016 |      640000 |         2458 |       10000 |         2.3 |reached target block errors\n      2.0 | 3.8995e-02 | 1.0390e-01 |       24957 |      640000 |         1039 |       10000 |         2.3 |reached target block errors\n      2.5 | 1.2763e-02 | 3.4967e-02 |       24505 |     1920000 |         1049 |       30000 |         6.9 |reached target block errors\n      3.0 | 2.6419e-03 | 7.5214e-03 |       23671 |     8960000 |         1053 |      140000 |        32.1 |reached target block errors\n      3.5 | 4.2701e-04 | 1.2613e-03 |       21863 |    51200000 |         1009 |      800000 |       183.4 |reached target block errors\n      4.0 | 5.9375e-05 | 1.7100e-04 |        3800 |    64000000 |          171 |     1000000 |       229.1 |reached max iter\n      4.5 | 3.3125e-06 | 9.0000e-06 |         212 |    64000000 |            9 |     1000000 |       229.2 |reached max iter\nRunning: Reed Muller (RM) SCL-8\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 2.7000e-01 | 6.4760e-01 |      172801 |      640000 |         6476 |       10000 |        12.8 |reached target block errors\n      0.5 | 1.9087e-01 | 4.7100e-01 |      122160 |      640000 |         4710 |       10000 |         2.0 |reached target block errors\n      1.0 | 1.1507e-01 | 2.9300e-01 |       73643 |      640000 |         2930 |       10000 |         2.0 |reached target block errors\n      1.5 | 5.9103e-02 | 1.5370e-01 |       37826 |      640000 |         1537 |       10000 |         2.0 |reached target block errors\n      2.0 | 2.3795e-02 | 6.3450e-02 |       30458 |     1280000 |         1269 |       20000 |         4.0 |reached target block errors\n      2.5 | 7.2339e-03 | 1.9750e-02 |       27778 |     3840000 |         1185 |       60000 |        12.0 |reached target block errors\n      3.0 | 1.6989e-03 | 4.7667e-03 |       22833 |    13440000 |         1001 |      210000 |        41.9 |reached target block errors\n      3.5 | 2.5781e-04 | 7.3300e-04 |       16500 |    64000000 |          733 |     1000000 |       199.6 |reached max iter\n      4.0 | 3.1578e-05 | 8.3000e-05 |        2021 |    64000000 |           83 |     1000000 |       199.6 |reached max iter\n      4.5 | 2.3437e-06 | 6.0000e-06 |         150 |    64000000 |            6 |     1000000 |       199.6 |reached max iter\nRunning: Conv. Code Viterbi (constraint length 8)\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 1.6208e-01 | 6.8980e-01 |      103733 |      640000 |         6898 |       10000 |         1.8 |reached target block errors\n      0.5 | 1.0615e-01 | 5.4740e-01 |       67936 |      640000 |         5474 |       10000 |         0.5 |reached target block errors\n      1.0 | 6.0327e-02 | 4.0450e-01 |       38609 |      640000 |         4045 |       10000 |         0.5 |reached target block errors\n      1.5 | 3.2498e-02 | 2.7790e-01 |       20799 |      640000 |         2779 |       10000 |         0.5 |reached target block errors\n      2.0 | 1.6691e-02 | 1.8970e-01 |       10682 |      640000 |         1897 |       10000 |         0.5 |reached target block errors\n      2.5 | 7.9234e-03 | 1.1960e-01 |        5071 |      640000 |         1196 |       10000 |         0.5 |reached target block errors\n      3.0 | 4.0820e-03 | 8.0250e-02 |        5225 |     1280000 |         1605 |       20000 |         1.0 |reached target block errors\n      3.5 | 1.9516e-03 | 4.7400e-02 |        3747 |     1920000 |         1422 |       30000 |         1.5 |reached target block errors\n      4.0 | 1.1066e-03 | 3.1350e-02 |        2833 |     2560000 |         1254 |       40000 |         1.9 |reached target block errors\n      4.5 | 6.0313e-04 | 1.9083e-02 |        2316 |     3840000 |         1145 |       60000 |         2.9 |reached target block errors\nRunning: Turbo Code (constraint length 4)\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 1.0916e-01 | 7.8380e-01 |       69865 |      640000 |         7838 |       10000 |         3.8 |reached target block errors\n      0.5 | 7.6463e-02 | 6.0200e-01 |       48936 |      640000 |         6020 |       10000 |         1.3 |reached target block errors\n      1.0 | 4.6916e-02 | 4.0020e-01 |       30026 |      640000 |         4002 |       10000 |         1.2 |reached target block errors\n      1.5 | 2.4842e-02 | 2.2510e-01 |       15899 |      640000 |         2251 |       10000 |         1.2 |reached target block errors\n      2.0 | 9.7844e-03 | 9.2300e-02 |       12524 |     1280000 |         1846 |       20000 |         2.5 |reached target block errors\n      2.5 | 2.9223e-03 | 3.0625e-02 |        7481 |     2560000 |         1225 |       40000 |         5.1 |reached target block errors\n      3.0 | 8.1080e-04 | 9.6545e-03 |        5708 |     7040000 |         1062 |      110000 |        13.9 |reached target block errors\n      3.5 | 1.7529e-04 | 2.6605e-03 |        4263 |    24320000 |         1011 |      380000 |        47.7 |reached target block errors\n      4.0 | 3.2750e-05 | 6.6900e-04 |        2096 |    64000000 |          669 |     1000000 |       125.4 |reached max iter\n      4.5 | 8.3281e-06 | 2.3100e-04 |         533 |    64000000 |          231 |     1000000 |       125.3 |reached max iter\n```"
"And lets also look at the block-error-rate.\n\n\n```python\nber_plot128(ylim=(1e-5, 1), show_ber=False)\n```\n\n\nPlease keep in mind that the decoding complexity differs significantly and should be also included in a fair comparison as shown in Section [Throughput and Decoding Complexity](https://nvlabs.github.io/sionna/examples/5G_Channel_Coding_Polar_vs_LDPC_Codes.html#Throughput-and-Decoding-Complexity)."
"### Performance under Optimal Decoding\n\nThe achievable error-rate performance of a coding scheme depends on the strength of the code construction and the performance of the actual decoding algorithm. We now approximate the maximum-likelihood performance of all previous coding schemes by using the ordered statistics decoder (OSD) [12].\n\n\n```python\n# overwrite existing legend entries for OSD simulations\nlegends = [\"5G instruction_answer\", \"5G Polar+CRC\", \"5G Polar+CRC\", \"RM\", \"Conv. Code\", \"Turbo Code\"]\n# run ber simulations for each code we have added to the list\nfor idx, code in enumerate(codes_under_test):\n    if idx==2: # skip second polar code (same code only different decoder)\n        continue\n    print(\"\\nRunning: \" + code[2])\n    # initialize encoder\n    encoder = code[0]\n    # encode dummy bits to init conv encoders (otherwise k is not defined)\n    encoder(tf.zeros((1, k)))\n    # OSD can be directly associated to an encoder\n    decoder = OSDecoder(encoder=encoder, t=4)\n    # generate a new model with the given encoder/decoder\n    model = System_Model(k=k,\n                         n=n,\n                         num_bits_per_symbol=num_bits_per_symbol,\n                         encoder=encoder,\n                         decoder=decoder,\n                         cw_estimates=True) # OSD returns codeword estimates and not info bit estimates\n    # the first argument must be a callable (function) that yields u and u_hat for batch_size and ebno\n    ber_plot128.simulate(tf.function(model, jit_compile=True),\n                         ebno_dbs=ebno_db, # SNR to simulate\n                         legend=legends[idx]+f\" OSD-{decoder.t} \", # legend string for plotting\n                         max_mc_iter=1000, # run 100 Monte Carlo runs per SNR point\n                         num_target_block_errors=1000, # continue with next SNR point after 1000 bit errors\n                         batch_size=1000, # batch-size per Monte Carlo run\n                         soft_estimates=False, # the model returns hard-estimates\n                         early_stop=True, # stop simulation if no error has been detected at current SNR point\n                         show_fig=False, # we show the figure after all results are simulated\n                         add_bler=True, # in case BLER is also interesting\n                         forward_keyboard_interrupt=True); # should be True in a loop\n\n```"
"```python\n\nRunning: 5G LDPC BP-20\nNote: Required memory complexity is large for the given code parameters and t=4. Please consider small batch-sizes to keep the inference complexity small and activate XLA mode if possible.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 1.0525e-01 | 4.6233e-01 |       40416 |      384000 |         1387 |        3000 |         4.2 |reached target block errors\n      0.5 | 5.5930e-02 | 2.5625e-01 |       28636 |      512000 |         1025 |        4000 |         2.0 |reached target block errors\n      1.0 | 2.4980e-02 | 1.1889e-01 |       28777 |     1152000 |         1070 |        9000 |         4.6 |reached target block errors\n      1.5 | 8.3019e-03 | 4.1040e-02 |       26566 |     3200000 |         1026 |       25000 |        12.7 |reached target block errors\n      2.0 | 2.1109e-03 | 1.1055e-02 |       24588 |    11648000 |         1006 |       91000 |        46.7 |reached target block errors\n      2.5 | 3.8392e-04 | 2.1874e-03 |       22556 |    58752000 |         1004 |      459000 |       236.2 |reached target block errors\n      3.0 | 4.9438e-05 | 3.2400e-04 |        6328 |   128000000 |          324 |     1000000 |       512.5 |reached max iter\n      3.5 | 5.0078e-06 | 3.9000e-05 |         641 |   128000000 |           39 |     1000000 |       511.6 |reached max iter\n      4.0 | 3.6719e-07 | 4.0000e-06 |          47 |   128000000 |            4 |     1000000 |       512.2 |reached max iter\n      4.5 | 0.0000e+00 | 0.0000e+00 |           0 |   128000000 |            0 |     1000000 |       512.5 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 4.5 dB.\n\nRunning: 5G Polar+CRC SC\nNote: Required memory complexity is large for the given code parameters and t=4. Please consider small batch-sizes to keep the inference complexity small and activate XLA mode if possible.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 1.0706e-01 | 4.4833e-01 |       41110 |      384000 |         1345 |        3000 |         4.4 |reached target block errors\n      0.5 | 5.7684e-02 | 2.4560e-01 |       36918 |      640000 |         1228 |        5000 |         2.5 |reached target block errors\n      1.0 | 2.5269e-02 | 1.0990e-01 |       32344 |     1280000 |         1099 |       10000 |         5.1 |reached target block errors\n      1.5 | 7.8858e-03 | 3.5276e-02 |       29272 |     3712000 |         1023 |       29000 |        14.8 |reached target block errors\n      2.0 | 1.7343e-03 | 7.8976e-03 |       28192 |    16256000 |         1003 |      127000 |        64.9 |reached target block errors\n      2.5 | 2.6134e-04 | 1.2516e-03 |       26728 |   102272000 |         1000 |      799000 |       408.2 |reached target block errors\n      3.0 | 2.6187e-05 | 1.3300e-04 |        3352 |   128000000 |          133 |     1000000 |       510.5 |reached max iter\n      3.5 | 1.7031e-06 | 8.0000e-06 |         218 |   128000000 |            8 |     1000000 |       510.0 |reached max iter\n      4.0 | 0.0000e+00 | 0.0000e+00 |           0 |   128000000 |            0 |     1000000 |       510.5 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 4.0 dB.\n\nRunning: Reed Muller (RM) SCL-8\nNote: Required memory complexity is large for the given code parameters and t=4. Please consider small batch-sizes to keep the inference complexity small and activate XLA mode if possible.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 9.9979e-02 | 4.8533e-01 |       38392 |      384000 |         1456 |        3000 |         4.3 |reached target block errors\n      0.5 | 5.8141e-02 | 3.0425e-01 |       29768 |      512000 |         1217 |        4000 |         2.0 |reached target block errors\n      1.0 | 2.5547e-02 | 1.4088e-01 |       26160 |     1024000 |         1127 |        8000 |         4.1 |reached target block errors\n      1.5 | 9.7431e-03 | 5.8222e-02 |       22448 |     2304000 |         1048 |       18000 |         9.2 |reached target block errors\n      2.0 | 2.8170e-03 | 1.8182e-02 |       19832 |     7040000 |         1000 |       55000 |        28.1 |reached target block errors\n      2.5 | 5.9362e-04 | 4.0732e-03 |       18692 |    31488000 |         1002 |      246000 |       125.7 |reached target block errors\n      3.0 | 1.0056e-04 | 7.4500e-04 |       12872 |   128000000 |          745 |     1000000 |       510.3 |reached max iter\n      3.5 | 1.3063e-05 | 9.8000e-05 |        1672 |   128000000 |           98 |     1000000 |       510.3 |reached max iter\n      4.0 | 6.2500e-07 | 5.0000e-06 |          80 |   128000000 |            5 |     1000000 |       510.2 |reached max iter\n      4.5 | 1.2500e-07 | 1.0000e-06 |          16 |   128000000 |            1 |     1000000 |       510.1 |reached max iter\nRunning: Conv. Code Viterbi (constraint length 8)\nNote: Required memory complexity is large for the given code parameters and t=4. Please consider small batch-sizes to keep the inference complexity small and activate XLA mode if possible.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 9.7660e-02 | 7.0150e-01 |       25001 |      256000 |         1403 |        2000 |         2.9 |reached target block errors\n      0.5 | 6.5164e-02 | 5.5900e-01 |       16682 |      256000 |         1118 |        2000 |         1.0 |reached target block errors\n      1.0 | 3.6641e-02 | 4.1567e-01 |       14070 |      384000 |         1247 |        3000 |         1.5 |reached target block errors\n      1.5 | 1.9215e-02 | 2.7100e-01 |        9838 |      512000 |         1084 |        4000 |         2.0 |reached target block errors\n      2.0 | 1.0513e-02 | 1.8833e-01 |        8074 |      768000 |         1130 |        6000 |         3.1 |reached target block errors\n      2.5 | 5.0686e-03 | 1.1822e-01 |        5839 |     1152000 |         1064 |        9000 |         4.6 |reached target block errors\n      3.0 | 2.7242e-03 | 7.8538e-02 |        4533 |     1664000 |         1021 |       13000 |         6.6 |reached target block errors\n      3.5 | 1.4941e-03 | 5.1800e-02 |        3825 |     2560000 |         1036 |       20000 |        10.2 |reached target block errors\n      4.0 | 7.7959e-04 | 3.0545e-02 |        3293 |     4224000 |         1008 |       33000 |        16.8 |reached target block errors\n      4.5 | 4.3529e-04 | 1.8887e-02 |        2953 |     6784000 |         1001 |       53000 |        27.1 |reached target block errors\nRunning: Turbo Code (constraint length 4)\nNote: Required memory complexity is large for the given code parameters and t=4. Please consider small batch-sizes to keep the inference complexity small and activate XLA mode if possible.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 1.0087e-01 | 5.0400e-01 |       25823 |      256000 |         1008 |        2000 |         3.1 |reached target block errors\n      0.5 | 6.4128e-02 | 3.4400e-01 |       24625 |      384000 |         1032 |        3000 |         1.5 |reached target block errors\n      1.0 | 3.0613e-02 | 1.7683e-01 |       23511 |      768000 |         1061 |        6000 |         3.1 |reached target block errors\n      1.5 | 1.2736e-02 | 8.1692e-02 |       21193 |     1664000 |         1062 |       13000 |         6.7 |reached target block errors\n      2.0 | 3.9779e-03 | 2.9500e-02 |       17312 |     4352000 |         1003 |       34000 |        17.4 |reached target block errors\n      2.5 | 1.0436e-03 | 1.0192e-02 |       13225 |    12672000 |         1009 |       99000 |        50.7 |reached target block errors\n      3.0 | 2.3167e-04 | 3.0895e-03 |        9608 |    41472000 |         1001 |      324000 |       165.9 |reached target block errors\n      3.5 | 7.3588e-05 | 1.2706e-03 |        7413 |   100736000 |         1000 |      787000 |       402.9 |reached target block errors\n      4.0 | 2.3914e-05 | 4.7400e-04 |        3061 |   128000000 |          474 |     1000000 |       511.9 |reached max iter\n      4.5 | 7.0391e-06 | 1.5300e-04 |         901 |   128000000 |          153 |     1000000 |       512.1 |reached max iter\n```"
"And lets plot the results.\n\n*Remark*: we define a custom plotting function to enable a nicer visualization of OSD vs.non-OSD results.\n\n\n```python\n# for simplicity, we only plot a subset of the simulated curves\n# focus on BLER\nplots_to_show = ['5G instruction_answer BP-20 (BLER)', '5G instruction_answer OSD-4  (BLER)', '5G Polar+CRC SCL-8 (BLER)', '5G Polar+CRC OSD-4  (BLER)', 'Reed Muller (RM) SCL-8 (BLER)', 'RM OSD-4  (BLER)', 'Conv. Code Viterbi (constraint length 8) (BLER)', 'Conv. Code OSD-4  (BLER)', 'Turbo Code (constraint length 4) (BLER)', 'Turbo Code OSD-4  (BLER)']\n# find indices of relevant curves\nidx = []\nfor p in plots_to_show:\n    for i,l in enumerate(ber_plot128._legends):\n        if p==l:\n            idx.append(i)\n# generate new figure\nfig, ax = plt.subplots(figsize=(16,12))\nplt.xticks(fontsize=18)\nplt.yticks(fontsize=18)\nplt.title(f\"Performance under Ordered Statistic Decoding (k={k},n={n})\", fontsize=25)\nplt.grid(which=\"both\")\nplt.xlabel(r\"$E_b/N_0$ (dB)\", fontsize=25)\nplt.ylabel(r\"BLER\", fontsize=25)\n# plot pairs of BLER curves (non-osd vs. osd)\nfor i in range(int(len(idx)/2)):\n    # non-OSD\n    plt.semilogy(ebno_db,\n                 ber_plot128._bers[idx[2*i]],\n                 c='C%d'%(i),\n                 label=ber_plot128._legends[idx[2*i]].replace(\" (BLER)\", \"\"), #remove \"(BLER)\" from label\n                 linewidth=2)\n    # OSD\n    plt.semilogy(ebno_db,\n                 ber_plot128._bers[idx[2*i+1]],\n                 c='C%d'%(i),\n                 label= ber_plot128._legends[idx[2*i+1]].replace(\" (BLER)\", \"\"), #remove \"(BLER)\" from label\n                 linestyle = \"--\",\n                 linewidth=2)\nplt.legend(fontsize=20)\nplt.xlim([0, 4.5])\nplt.ylim([1e-4, 1]);\n\n```"
"As can be seen, the performance of Polar and Convolutional codes is in practice close to their ML performance. For other codes such as LDPC codes, there is a practical performance gap under BP decoding which tends to be smaller for longer codes."
"### Performance of Longer LDPC Codes\n\nNow, let us have a look at the performance gains due to longer codewords. For this, we scale the length of the LDPC code and compare the results (same rate, same decoder, same channel).\n\n\n```python\n# init new figure\nber_plot_ldpc = PlotBER(f\"BER/BLER Performance of instruction_answer Codes @ Fixed Rate=0.5\")\n```\n\n```python\n# code parameters to simulate\nns = [128, 256, 512, 1000, 2000, 4000, 8000, 16000]  # number of codeword bits per codeword\nrate = 0.5 # fixed coderate\n# create list of encoder/decoder pairs to be analyzed\ncodes_under_test = []\n# 5G instruction_answer codes\nfor n in ns:\n    k = int(rate*n) # calculate k for given n and rate\n    enc = LDPC5GEncoder(k=k, n=n)\n    dec = LDPC5GDecoder(enc, num_iter=20)\n    name = f\"5G instruction_answer BP-20 (n={n})\"\n    codes_under_test.append([enc, dec, name, k, n])\n\n```\n\n```python\n# and simulate the results\nnum_bits_per_symbol = 2 # QPSK\nebno_db = np.arange(0, 5, 0.25) # sim SNR range\n# note that the waterfall for long codes can be steep and requires a fine\n# SNR quantization\n# run ber simulations for each case\nfor code in codes_under_test:\n    print(\"Running: \" + code[2])\n    model = System_Model(k=code[3],\n                         n=code[4],\n                         num_bits_per_symbol=num_bits_per_symbol,\n                         encoder=code[0],\n                         decoder=code[1])\n    # the first argument must be a callable (function) that yields u and u_hat\n    # for given batch_size and ebno\n    # we fix the target number of BLOCK errors instead of the BER to\n    # ensure that same accurate results for each block lengths is simulated\n    ber_plot_ldpc.simulate(model, # the function have defined previously\n                           ebno_dbs=ebno_db,\n                           legend=code[2],\n                           max_mc_iter=100,\n                           num_target_block_errors=500, # we fix the target block errors\n                           batch_size=1000,\n                           soft_estimates=False,\n                           early_stop=True,\n                           show_fig=False,\n                           forward_keyboard_interrupt=True); # should be True in a loop\n# and show figure\nber_plot_ldpc(ylim=(1e-5, 1))\n```"
"```python\nRunning: 5G LDPC BP-20 (n=128)\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 1.6914e-01 | 8.6600e-01 |       10825 |       64000 |          866 |        1000 |         1.0 |reached target block errors\n     0.25 | 1.4652e-01 | 7.8400e-01 |        9377 |       64000 |          784 |        1000 |         0.1 |reached target block errors\n      0.5 | 1.2748e-01 | 7.2800e-01 |        8159 |       64000 |          728 |        1000 |         0.1 |reached target block errors\n     0.75 | 1.0242e-01 | 6.0000e-01 |        6555 |       64000 |          600 |        1000 |         0.1 |reached target block errors\n      1.0 | 8.1711e-02 | 4.8800e-01 |       10459 |      128000 |          976 |        2000 |         0.1 |reached target block errors\n     1.25 | 6.5227e-02 | 3.8400e-01 |        8349 |      128000 |          768 |        2000 |         0.1 |reached target block errors\n      1.5 | 5.1398e-02 | 3.0700e-01 |        6579 |      128000 |          614 |        2000 |         0.1 |reached target block errors\n     1.75 | 3.6177e-02 | 2.1933e-01 |        6946 |      192000 |          658 |        3000 |         0.2 |reached target block errors\n      2.0 | 2.5227e-02 | 1.4900e-01 |        6458 |      256000 |          596 |        4000 |         0.2 |reached target block errors\n     2.25 | 1.6531e-02 | 1.0200e-01 |        5290 |      320000 |          510 |        5000 |         0.3 |reached target block errors\n      2.5 | 1.0494e-02 | 6.6250e-02 |        5373 |      512000 |          530 |        8000 |         0.4 |reached target block errors\n     2.75 | 6.5373e-03 | 4.0385e-02 |        5439 |      832000 |          525 |       13000 |         0.7 |reached target block errors\n      3.0 | 3.5675e-03 | 2.2773e-02 |        5023 |     1408000 |          501 |       22000 |         1.2 |reached target block errors\n     3.25 | 1.8422e-03 | 1.2195e-02 |        4834 |     2624000 |          500 |       41000 |         2.3 |reached target block errors\n      3.5 | 9.0968e-04 | 6.1341e-03 |        4774 |     5248000 |          503 |       82000 |         4.8 |reached target block errors\n     3.75 | 4.7891e-04 | 2.9900e-03 |        3065 |     6400000 |          299 |      100000 |         5.6 |reached max iter\n      4.0 | 1.8422e-04 | 1.1300e-03 |        1179 |     6400000 |          113 |      100000 |         5.6 |reached max iter\n     4.25 | 1.1438e-04 | 7.4000e-04 |         732 |     6400000 |           74 |      100000 |         5.6 |reached max iter\n      4.5 | 5.5313e-05 | 3.5000e-04 |         354 |     6400000 |           35 |      100000 |         5.7 |reached max iter\n     4.75 | 1.1094e-05 | 9.0000e-05 |          71 |     6400000 |            9 |      100000 |         5.6 |reached max iter\nRunning: 5G LDPC BP-20 (n=256)\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 1.6655e-01 | 9.4200e-01 |       21318 |      128000 |          942 |        1000 |         1.0 |reached target block errors\n     0.25 | 1.4567e-01 | 8.8100e-01 |       18646 |      128000 |          881 |        1000 |         0.1 |reached target block errors\n      0.5 | 1.2033e-01 | 7.7200e-01 |       15402 |      128000 |          772 |        1000 |         0.1 |reached target block errors\n     0.75 | 9.4398e-02 | 6.3800e-01 |       12083 |      128000 |          638 |        1000 |         0.1 |reached target block errors\n      1.0 | 6.7824e-02 | 4.9150e-01 |       17363 |      256000 |          983 |        2000 |         0.1 |reached target block errors\n     1.25 | 4.6043e-02 | 3.5300e-01 |       11787 |      256000 |          706 |        2000 |         0.1 |reached target block errors\n      1.5 | 3.1776e-02 | 2.4000e-01 |       12202 |      384000 |          720 |        3000 |         0.2 |reached target block errors\n     1.75 | 1.8992e-02 | 1.5250e-01 |        9724 |      512000 |          610 |        4000 |         0.2 |reached target block errors\n      2.0 | 9.2221e-03 | 8.0857e-02 |        8263 |      896000 |          566 |        7000 |         0.4 |reached target block errors\n     2.25 | 4.7396e-03 | 4.2083e-02 |        7280 |     1536000 |          505 |       12000 |         0.7 |reached target block errors\n      2.5 | 2.2689e-03 | 1.9808e-02 |        7551 |     3328000 |          515 |       26000 |         1.5 |reached target block errors\n     2.75 | 9.2346e-04 | 8.5424e-03 |        6974 |     7552000 |          504 |       59000 |         3.5 |reached target block errors\n      3.0 | 3.2531e-04 | 3.0000e-03 |        4164 |    12800000 |          300 |      100000 |         5.8 |reached max iter\n     3.25 | 1.2242e-04 | 1.1500e-03 |        1567 |    12800000 |          115 |      100000 |         5.9 |reached max iter\n      3.5 | 3.8672e-05 | 4.0000e-04 |         495 |    12800000 |           40 |      100000 |         5.9 |reached max iter\n     3.75 | 8.5938e-06 | 1.2000e-04 |         110 |    12800000 |           12 |      100000 |         5.8 |reached max iter\n      4.0 | 1.5625e-06 | 2.0000e-05 |          20 |    12800000 |            2 |      100000 |         5.8 |reached max iter\n     4.25 | 3.1250e-07 | 1.0000e-05 |           4 |    12800000 |            1 |      100000 |         5.9 |reached max iter\n      4.5 | 0.0000e+00 | 0.0000e+00 |           0 |    12800000 |            0 |      100000 |         5.9 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 4.5 dB.\nRunning: 5G LDPC BP-20 (n=512)\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 1.6162e-01 | 9.7100e-01 |       41376 |      256000 |          971 |        1000 |         1.0 |reached target block errors\n     0.25 | 1.3645e-01 | 9.3300e-01 |       34931 |      256000 |          933 |        1000 |         0.1 |reached target block errors\n      0.5 | 1.1016e-01 | 8.3000e-01 |       28202 |      256000 |          830 |        1000 |         0.1 |reached target block errors\n     0.75 | 7.9887e-02 | 6.6900e-01 |       20451 |      256000 |          669 |        1000 |         0.1 |reached target block errors\n      1.0 | 5.1861e-02 | 4.6150e-01 |       26553 |      512000 |          923 |        2000 |         0.1 |reached target block errors\n     1.25 | 2.9461e-02 | 2.8550e-01 |       15084 |      512000 |          571 |        2000 |         0.1 |reached target block errors\n      1.5 | 1.4026e-02 | 1.4900e-01 |       14363 |     1024000 |          596 |        4000 |         0.3 |reached target block errors\n     1.75 | 5.2413e-03 | 5.8667e-02 |       12076 |     2304000 |          528 |        9000 |         0.6 |reached target block errors\n      2.0 | 1.9423e-03 | 2.3810e-02 |       10442 |     5376000 |          500 |       21000 |         1.3 |reached target block errors\n     2.25 | 6.3080e-04 | 7.9063e-03 |       10335 |    16384000 |          506 |       64000 |         4.1 |reached target block errors\n      2.5 | 1.5441e-04 | 2.0400e-03 |        3953 |    25600000 |          204 |      100000 |         6.4 |reached max iter\n     2.75 | 3.3320e-05 | 5.1000e-04 |         853 |    25600000 |           51 |      100000 |         6.3 |reached max iter\n      3.0 | 4.7266e-06 | 1.3000e-04 |         121 |    25600000 |           13 |      100000 |         6.4 |reached max iter\n     3.25 | 2.3438e-07 | 2.0000e-05 |           6 |    25600000 |            2 |      100000 |         6.4 |reached max iter\n      3.5 | 0.0000e+00 | 0.0000e+00 |           0 |    25600000 |            0 |      100000 |         6.4 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 3.5 dB.\nRunning: 5G LDPC BP-20 (n=1000)\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 1.6359e-01 | 9.9800e-01 |       81793 |      500000 |          998 |        1000 |         1.0 |reached target block errors\n     0.25 | 1.3874e-01 | 9.8100e-01 |       69368 |      500000 |          981 |        1000 |         0.1 |reached target block errors\n      0.5 | 9.9932e-02 | 9.0700e-01 |       49966 |      500000 |          907 |        1000 |         0.1 |reached target block errors\n     0.75 | 6.5646e-02 | 7.0900e-01 |       32823 |      500000 |          709 |        1000 |         0.1 |reached target block errors\n      1.0 | 3.3873e-02 | 4.6600e-01 |       33873 |     1000000 |          932 |        2000 |         0.2 |reached target block errors\n     1.25 | 1.3356e-02 | 2.2533e-01 |       20034 |     1500000 |          676 |        3000 |         0.2 |reached target block errors\n      1.5 | 4.1151e-03 | 7.8000e-02 |       14403 |     3500000 |          546 |        7000 |         0.6 |reached target block errors\n     1.75 | 7.8215e-04 | 1.9308e-02 |       10168 |    13000000 |          502 |       26000 |         2.1 |reached target block errors\n      2.0 | 1.1394e-04 | 3.3300e-03 |        5697 |    50000000 |          333 |      100000 |         7.9 |reached max iter\n     2.25 | 1.1760e-05 | 4.9000e-04 |         588 |    50000000 |           49 |      100000 |         7.9 |reached max iter\n      2.5 | 1.1600e-06 | 5.0000e-05 |          58 |    50000000 |            5 |      100000 |         7.9 |reached max iter\n     2.75 | 8.2000e-07 | 2.0000e-05 |          41 |    50000000 |            2 |      100000 |         7.9 |reached max iter\n      3.0 | 0.0000e+00 | 0.0000e+00 |           0 |    50000000 |            0 |      100000 |         7.9 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 3.0 dB.\nRunning: 5G LDPC BP-20 (n=2000)\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 1.5922e-01 | 1.0000e+00 |      159218 |     1000000 |         1000 |        1000 |         1.3 |reached target block errors\n     0.25 | 1.3586e-01 | 1.0000e+00 |      135862 |     1000000 |         1000 |        1000 |         0.1 |reached target block errors\n      0.5 | 9.8168e-02 | 9.7100e-01 |       98168 |     1000000 |          971 |        1000 |         0.1 |reached target block errors\n     0.75 | 5.4171e-02 | 8.0800e-01 |       54171 |     1000000 |          808 |        1000 |         0.1 |reached target block errors\n      1.0 | 1.9121e-02 | 4.5550e-01 |       38243 |     2000000 |          911 |        2000 |         0.2 |reached target block errors\n     1.25 | 4.1725e-03 | 1.5675e-01 |       16690 |     4000000 |          627 |        4000 |         0.4 |reached target block errors\n      1.5 | 4.1236e-04 | 2.3000e-02 |        9072 |    22000000 |          506 |       22000 |         2.4 |reached target block errors\n     1.75 | 2.9270e-05 | 2.3000e-03 |        2927 |   100000000 |          230 |      100000 |        11.0 |reached max iter\n      2.0 | 8.2000e-07 | 1.7000e-04 |          82 |   100000000 |           17 |      100000 |        11.0 |reached max iter\n     2.25 | 1.0000e-08 | 1.0000e-05 |           1 |   100000000 |            1 |      100000 |        10.9 |reached max iter\n      2.5 | 0.0000e+00 | 0.0000e+00 |           0 |   100000000 |            0 |      100000 |        10.9 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 2.5 dB.\nRunning: 5G LDPC BP-20 (n=4000)\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 1.6200e-01 | 1.0000e+00 |      323995 |     2000000 |         1000 |        1000 |         1.3 |reached target block errors\n     0.25 | 1.3757e-01 | 1.0000e+00 |      275132 |     2000000 |         1000 |        1000 |         0.2 |reached target block errors\n      0.5 | 9.8322e-02 | 9.9800e-01 |      196644 |     2000000 |          998 |        1000 |         0.2 |reached target block errors\n     0.75 | 4.9637e-02 | 9.1400e-01 |       99274 |     2000000 |          914 |        1000 |         0.2 |reached target block errors\n      1.0 | 1.0812e-02 | 5.2700e-01 |       21624 |     2000000 |          527 |        1000 |         0.2 |reached target block errors\n     1.25 | 9.5500e-04 | 1.0020e-01 |        9550 |    10000000 |          501 |        5000 |         0.9 |reached target block errors\n      1.5 | 2.3473e-05 | 5.5385e-03 |        4272 |   182000000 |          504 |       91000 |        16.1 |reached target block errors\n     1.75 | 2.3500e-07 | 7.0000e-05 |          47 |   200000000 |            7 |      100000 |        17.6 |reached max iter\n      2.0 | 0.0000e+00 | 0.0000e+00 |           0 |   200000000 |            0 |      100000 |        17.6 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 2.0 dB.\nRunning: 5G LDPC BP-20 (n=8000)\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 1.3612e-01 | 1.0000e+00 |      544473 |     4000000 |         1000 |        1000 |         1.8 |reached target block errors\n     0.25 | 1.1098e-01 | 1.0000e+00 |      443911 |     4000000 |         1000 |        1000 |         0.4 |reached target block errors\n      0.5 | 7.1998e-02 | 1.0000e+00 |      287993 |     4000000 |         1000 |        1000 |         0.4 |reached target block errors\n     0.75 | 2.5447e-02 | 9.4400e-01 |      101788 |     4000000 |          944 |        1000 |         0.4 |reached target block errors\n      1.0 | 2.5708e-03 | 4.1150e-01 |       20566 |     8000000 |          823 |        2000 |         0.8 |reached target block errors\n     1.25 | 4.0510e-05 | 1.9346e-02 |        4213 |   104000000 |          503 |       26000 |        10.0 |reached target block errors\n      1.5 | 9.7500e-08 | 1.4000e-04 |          39 |   400000000 |           14 |      100000 |        38.6 |reached max iter\n     1.75 | 1.0000e-08 | 1.0000e-05 |           4 |   400000000 |            1 |      100000 |        38.6 |reached max iter\n      2.0 | 0.0000e+00 | 0.0000e+00 |           0 |   400000000 |            0 |      100000 |        38.6 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 2.0 dB.\nRunning: 5G LDPC BP-20 (n=16000)\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 1.3777e-01 | 1.0000e+00 |     1102186 |     8000000 |         1000 |        1000 |         2.8 |reached target block errors\n     0.25 | 1.1079e-01 | 1.0000e+00 |      886359 |     8000000 |         1000 |        1000 |         0.8 |reached target block errors\n      0.5 | 7.1611e-02 | 1.0000e+00 |      572892 |     8000000 |         1000 |        1000 |         0.8 |reached target block errors\n     0.75 | 2.4264e-02 | 9.9300e-01 |      194114 |     8000000 |          993 |        1000 |         0.8 |reached target block errors\n      1.0 | 1.1114e-03 | 4.4550e-01 |       17783 |    16000000 |          891 |        2000 |         1.6 |reached target block errors\n     1.25 | 1.4387e-06 | 3.6800e-03 |        1151 |   800000000 |          368 |      100000 |        79.6 |reached max iter\n      1.5 | 0.0000e+00 | 0.0000e+00 |           0 |   800000000 |            0 |      100000 |        79.6 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 1.5 dB.\n\n```"
"## A Deeper Look into the Polar Code Module\n\nA Polar code can be defined by a set of `frozen` `bit` and `information` `bit` positions [1]. The package `sionna.fec.polar.utils` supports 5G-compliant Polar code design, but also Reed-Muller (RM) codes are available and can be used within the same encoder/decoder layer. If required, rate-matching and CRC concatenation are handled by the class `sionna.fec.polar.Polar5GEncoder` and `sionna.fec.polar.Polar5GDecoder`, respectively.\n\nFurther, the following decoders are available:\n\n- Successive cancellation (SC) decoding [1]\n\n- Fast and low-complexity\n- Sub-optimal error-rate performance\n\n\n- Successive cancellation list (SCL) decoding [2]\n\n- Excellent error-rate performance\n- High-complexity\n- CRC-aided decoding possible\n\n\n- Hybrid SCL decoder (combined SC and SCL decoder)\n\n- Pre-decode with SC and only apply SCL iff CRC fails\n- Excellent error-rate performance\n- Needs outer CRC (e.g., as done in 5G)\n- CPU-based implementation and, thus, no XLA support (+ increased decoding latency)\n\n\n- Iterative belief propagation (BP) decoding [6]\n\n- Produces soft-output estimates\n- Sub-optimal error-rate performance\n\n\nLet us now generate a new Polar code.\n\n\n```python\ncode_type = \"5G\" # try also \"RM\"\n# Load the 5G compliant polar code\nif code_type==\"5G\":\n    k = 32\n    n = 64\n    # load 5G compliant channel ranking [3]\n    frozen_pos, info_pos = generate_5g_ranking(k,n)\n    print(\"Generated Polar code of length n = {} and k = {}\".format(n, k))\n    print(\"Frozen codeword positions: \", frozen_pos)\n# Alternatively Reed-Muller code design is also available\nelif code_type==\"RM\":\n    r = 3\n    m = 7\n    frozen_pos, info_pos, n, k, d_min = generate_rm_code(r, m)\n    print(\"Generated ({},{}) Reed-Muller code of length n = {} and k = {} with minimum distance d_min = {}\".format(r, m, n, k, d_min))\n    print(\"Frozen codeword positions: \", frozen_pos)\nelse:\n    print(\"Code not found\")\n```"
"```python\nGenerated Polar code of length n = 64 and k = 32\nFrozen codeword positions:  [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 16 17 18 19 20 21 24 25 26\n 32 33 34 35 36 37 40 48]\n```\n\n\nNow, we can initialize the encoder and a `BinarySource` to generate random Polar codewords.\n\n\n```python\n# init polar encoder\nencoder_polar = PolarEncoder(frozen_pos, n)\n# init binary source to generate information bits\nsource = BinarySource()\n# define a batch_size\nbatch_size = 1\n# generate random info bits\nu = source([batch_size, k])\n# and encode\nc = encoder_polar(u)\nprint(\"Information bits: \", u.numpy())\nprint(\"Polar encoded bits: \", c.numpy())\n```\n\n\n```python\nInformation bits:  [[1. 0. 1. 1. 1. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 1. 0. 1. 1. 1. 1. 0. 1. 1.\n  0. 0. 0. 0. 0. 0. 0. 1.]]\nPolar encoded bits:  [[0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 0.\n  1. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 1. 1. 1. 1. 0. 0. 1. 0. 0. 1.\n  1. 0. 1. 1. 0. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]]\n```"
"As can be seen, the length of the resulting code must be a power of 2. This brings us to the problem of rate-matching and we will now have a closer look how we can adapt the length of the code."
"## Rate-Matching and Rate-Recovery\n\nThe general task of rate-matching is to enable flexibility of the code w.r.t. the codeword length $n$ and information bit input size $k$ and, thereby, the rate $r = \\frac{k}{n}$. In modern communication standards such as 5G NR, these parameters can be adjusted on a bit-level granularity without - in a wider sense - redefining the (mother) code itself. This is enabled by a powerful rate-matching and the corresponding rate-recovery block which will be explained in the following.\n\nThe principle idea is to select a mother code as close as possible to the desired properties from a set of possible mother codes. For example for Polar codes, the codeword length must be a power of 2, i.e., $n = 32, 64, ..., 512, 1024$. For LDPC codes the codeword length is more flexible (due to the different *lifting* factors), however, does not allow bit-wise granularity neither. Afterwards, the bit-level granularity is provided by shortening, puncturing and repetitions.\n\nTo summarize, the rate-matching procedure consists of:\n<ol class=\"arabic simple\">\n- ) 5G NR defines multiple *mother* codes with similar properties (e.g., via base-graph lifting of LDPC code or sub-codes for Polar codes)\n- ) Puncturing, shortening and repetitions of bits to allow bit-level rate adjustments\n</ol>\n\nThe following figure summarizes the principle for the 5G NR Polar code uplink control channel (UCI). The Fig. is inspired by Fig. 6 in [9].\n\n\nFor bit-wise length adjustments, the following techniques are commonly used:\n<ol class=\"arabic simple\">\n- ) *Puncturing:* A ($k,n$) mother code is punctured by *not* transmitting $p$ punctured codeword bits. Thus, the rate increases to $r_{\\text{pun}} = \\frac{k}{n-p} > \\frac{k}{n} \\quad \\forall p > 0$. At the decoder these codeword bits are treated as erasure ($\\ell_{\\text{ch}} = 0$).\n- ) *Shortening:* A ($k,n$) mother code is shortened by setting $s$ information bits to a fixed (=known) value. Assuming systematic encoding, these $s$ positions are not transmitted leading to a new code of rate $r_{\\text{short}} = \\frac{k-s}{n-s}<\\frac{k}{n}$. At the decoder these codeword bits are treated as known values ($\\ell_{\\text{ch}} = \\infty$).\n- ) *Repetitions* can be used to lower the effective rate. For details we refer the interested reader to [11].\n</ol>\n\nWe will now simulate the performance of rate-matched 5G Polar codes for different lengths and rates. For this, we are interested in the required SNR to achieve a target BLER at $10^{-3}$. Please note that this is a reproduction of the results from [Fig.13a, 4].\n\n**Note**: This needs a bisection search as we usually simulate the BLER at fixed SNR and, thus, this is simulation takes some time. Please only execute the cell below if you have enough simulation capabilities."
"```python\n# find the EsNo in dB to achieve target_bler\ndef find_threshold(model, # model to be tested\n                   batch_size=1000,\n                   max_batch_iter=10, # simulate cws up to batch_size * max_batch_iter\n                   max_block_errors=100,  # number of errors before stop\n                   target_bler=1e-3): # target error rate to simulate (same as in[4])\n        \"\"\"Bisection search to find required SNR to reach target SNR.\"\"\"\n        # bisection parameters\n        esno_db_min = -15 # smallest possible search SNR\n        esno_db_max = 15 # largest possible search SNR\n        esno_interval = (esno_db_max-esno_db_min)/4 # initial search interval size\n        esno_db = 2*esno_interval + esno_db_min # current test SNR\n        max_iters = 12 # number of iterations for bisection search\n        # run bisection\n        for i in range(max_iters):\n            num_block_error = 0\n            num_cws = 0\n            for j in range(max_batch_iter):\n                # run model and evaluate BLER\n                u, u_hat = model(tf.constant(batch_size, tf.int32),\n                                 tf.constant(esno_db, tf.float32))\n                num_block_error += count_block_errors(u, u_hat)\n                num_cws += batch_size\n                # early stop if target number of block errors is reached\n                if num_block_error>max_block_errors:\n                    break\n            bler = num_block_error/num_cws\n            # increase SNR if BLER was great than target\n            # (larger SNR leads to decreases BLER)\n            if bler>target_bler:\n                esno_db += esno_interval\n            else: # and decrease SNR otherwise\n                esno_db -= esno_interval\n            esno_interval = esno_interval/2\n        # return final SNR after max_iters\n        return esno_db\n\n```\n\n```python\n[ ]:\n```\n\n```python\n# run simulations for multiple code parameters\nnum_bits_per_symbol = 2 # QPSK\n# we sweep over multiple values for k and n\nks = np.array([12, 16, 32, 64, 128, 140, 210, 220, 256, 300, 400, 450, 460, 512, 800, 880, 940])\nns = np.array([160, 240, 480, 960])\n# we use EsNo instead of EbNo to have the same results as in [4]\nesno = np.zeros([len(ns), len(ks)])\nfor j,n in enumerate(ns):\n    for i,k in enumerate(ks):\n        if k<n: # only simulate if code parameters are feasible (i.e., r < 1)\n            print(f\"Finding threshold of k = {k}, n = {n}\")\n            # initialize new encoder / decoder pair\n            enc = Polar5GEncoder(k=k, n=n)\n            dec = Polar5GDecoder(enc, dec_type=\"SCL\", list_size=8)\n            #build model\n            model = System_Model(k=k,\n                                 n=n,\n                                 num_bits_per_symbol=num_bits_per_symbol,\n                                 encoder=enc,\n                                 decoder=dec,\n                                 sim_esno=True) # no rate adjustment\n            # and find threshold via bisection search\n            esno[j, i] = find_threshold(model)\n            print(\"Found threshold at: \", esno[j, i])\n```"
"```python\n[ ]:\n```\n\n```python\n# plot the results\nleg_str = []\nfor j,n in enumerate(ns):\n    plt.plot(np.log2(ks[ks<n]), esno[j, ks<n])\n    leg_str.append(\"n = {}\".format(n))\n\n# define labels manually\nx_tick_labels = np.power(2, np.arange(3,11))\nplt.xticks(ticks=np.arange(3,11),labels=x_tick_labels, fontsize=18)\n# adjusted layout of figure\nplt.grid(\"both\")\nplt.ylim([-10, 15])\nplt.xlabel(\"Number of information bits $k$\", fontsize=20)\nplt.yticks(fontsize=18)\nplt.ylabel(\"$E_s/N_0^*$ (dB)\", fontsize=20)\nplt.legend(leg_str, fontsize=18);\nfig = plt.gcf() # get handle to current figure\nfig.set_size_inches(15,10)\n```\n\n\nThis figure equals [Fig. 13a, 4] with a few small exception for extreme low-rate codes. This can be explained by the fact that the 3 explicit parity-bits bits are not implemented, however, these bits are only relevant for for $12\\leq k \\leq20$. It also explains the degraded performance of the n=960, k=16 code."
"## Throughput and Decoding Complexity\n\nIn the last part of this notebook, you will compare the different computational complexity of the different codes and decoders. In theory the complexity is given as:\n\n- Successive cancellation list (SCL) decoding of Polar codes scales with $\\mathcal{O}(L \\cdot n \\cdot \\operatorname{log} n)$ (with $L=1$ for SC decoding)\n- Iterative belief propagation (BP) decoding of LDPC codes scales with $\\mathcal{O}(n)$. However, in particular for short codes a complexity comparison should be supported by empirical results.\n\n\nWe want to emphasize that the results strongly depend on the exact implementation and may differ for different implementations/optimizations. Implementing the SCL decoder in Tensorflow is a delicate task and requires several design trade-offs to enable a graph implementation which can lead to degraded throughput mainly caused by the missing *lazy copy-mechanism*. However, - inspired by [10] - the SCL decoder layer supports `hybrid` `SC` decoding meaning that SC decoding is done first and a\nsecond stage SCL decoder operates as afterburner iff the outer CRC check fails. Please note that this modus uses *tf.py_function* (due to the control flow and the dynamic shape of the decoding graph) and, thus, does not support XLA compilation.\n\n```python\n[ ]:\n```\n\n```python\ndef get_throughput(batch_size, ebno_dbs, model, repetitions=1):\n    \"\"\" Simulate throughput in bit/s per ebno_dbs point.\n    The results are average over `repetition` trials.\n    Input\n    -----\n    batch_size: tf.int32\n        Batch-size for evaluation.\n    ebno_dbs: tf.float32\n        A tensor containing SNR points to be evaluated.\n    model:\n        Function or model that yields the transmitted bits `u` and the\n        receiver's estimate `u_hat` for a given ``batch_size`` and\n        ``ebno_db``.\n    repetitions: int\n        An integer defining how many trails of the throughput\n        simulation are averaged.\n    \"\"\"\n    throughput = np.zeros_like(ebno_dbs)\n    # call model once to be sure it is compile properly\n    # otherwise time to build graph is measured as well.\n    u, u_hat = model(tf.constant(batch_size, tf.int32),\n                     tf.constant(0., tf.float32))\n    for idx, ebno_db in enumerate(ebno_dbs):\n        t_start = time.perf_counter()\n        # average over multiple runs\n        for _ in range(repetitions):\n            u, u_hat = model(tf.constant(batch_size, tf.int32),\n                             tf.constant(ebno_db, tf. float32))\n        t_stop = time.perf_counter()\n        # throughput in bit/s\n        throughput[idx] = np.size(u.numpy())*repetitions / (t_stop - t_start)\n    return throughput\n\n```"
"```python\n[ ]:\n```\n\n```python\n# plot throughput and ber together for ldpc codes\n# and simulate the results\nnum_bits_per_symbol = 2 # QPSK\nebno_db = [5] # SNR to simulate\nnum_bits_per_batch = 5e6 # must be reduced in case of out-of-memory errors\nnum_repetitions = 20 # average throughput over multiple runs\n# run throughput simulations for each code\nthroughput = np.zeros(len(codes_under_test))\ncode_length = np.zeros(len(codes_under_test))\nfor idx, code in enumerate(codes_under_test):\n    print(\"Running: \" + code[2])\n    # save codeword length for plotting\n    code_length[idx] = code[4]\n    # init new model for given encoder/decoder\n    model = System_Model(k=code[3],\n                         n=code[4],\n                         num_bits_per_symbol=num_bits_per_symbol,\n                         encoder=code[0],\n                         decoder=code[1])\n    # scale batch_size such that same number of bits is simulated for all codes\n    batch_size = int(num_bits_per_batch / code[4])\n    # and measure throughput of the model\n    throughput[idx] = get_throughput(batch_size,\n                                     ebno_db,\n                                     model,\n                                     repetitions=num_repetitions)\n```\n\n\n```python\nRunning: 5G LDPC BP-20 (n=128)\nRunning: 5G LDPC BP-20 (n=256)\nRunning: 5G LDPC BP-20 (n=512)\nRunning: 5G LDPC BP-20 (n=1000)\nRunning: 5G LDPC BP-20 (n=2000)\nRunning: 5G LDPC BP-20 (n=4000)\nRunning: 5G LDPC BP-20 (n=8000)\nRunning: 5G LDPC BP-20 (n=16000)\n```\n\n```python\n[ ]:\n```\n\n```python\n# plot results\nplt.figure(figsize=(16,10))\nplt.xticks(fontsize=18)\nplt.yticks(fontsize=18)\nplt.title(\"Throughput instruction_answer BP Decoding @ rate=0.5\", fontsize=25)\nplt.xlabel(\"Codeword length\", fontsize=25)\nplt.ylabel(\"Throughput (Mbit/s)\", fontsize=25)\nplt.grid(which=\"both\")\n# and plot results (logarithmic scale in x-dim)\nx_tick_labels = code_length.astype(int)\nplt.xticks(ticks=np.log2(code_length),labels=x_tick_labels, fontsize=18)\nplt.plot(np.log2(code_length), throughput/1e6)\n\n```"
"```python\n[<matplotlib.lines.Line2D at 0x7fee100c3e20>]\n```\n\n\nAs expected the throughput of BP decoding is (relatively) constant as the complexity scales linearly with $\\mathcal{O}(n)$ and, thus, the complexity *per* decoded bit remains constant. It is instructive to realize that the above plot is in the log-domain for the x-axis.\n\nLet us have a look at what happens for different SNR values.\n\n```python\n[ ]:\n```\n\n```python\n# --- instruction_answer ---\nn = 1000\nk = 500\nencoder = LDPC5GEncoder(k, n)\ndecoder = LDPC5GDecoder(encoder)\n# init a new model\nmodel = System_Model(k=k,\n                     n=n,\n                     num_bits_per_symbol=num_bits_per_symbol,\n                     encoder=encoder,\n                     decoder=decoder)\n# run throughput tests at 2 dB and 5 dB\nebno_db = [2, 5]\nbatch_size = 10000\nthroughput = get_throughput(batch_size,\n                            ebno_db, # snr point\n                            model,\n                            repetitions=num_repetitions)\n# and print the results\nfor idx, snr_db in enumerate(ebno_db):\n    print(f\"Throughput @ {snr_db:.1f} dB: {throughput[idx]/1e6:.2f} Mbit/s\")\n```\n\n\n```python\nThroughput @ 2.0 dB: 10.91 Mbit/s\nThroughput @ 5.0 dB: 10.90 Mbit/s\n```\n\n\nFor most Sionna decoders the throughput is not SNR dependent as early stopping of individual samples within a batch is difficult to realize.\n\nHowever, the `hybrid` `SCL` decoder uses an internal NumPy SCL decoder only if the SC decoder failed similar to [10]. We will now benchmark this decoder for different SNR values.\n\n```python\n[ ]:\n```\n\n```python\n# --- Polar ---\nn = 256\nk = 128\nencoder = Polar5GEncoder(k, n)\ndecoder = Polar5GDecoder(encoder, \"hybSCL\")\n# init a new model\nmodel = System_Model(k=k,\n                     n=n,\n                     num_bits_per_symbol=num_bits_per_symbol,\n                     encoder=encoder,\n                     decoder=decoder)\nebno_db = np.arange(0, 5, 0.5) # EbNo to evaluate\nbatch_size = 1000\nthroughput = get_throughput(batch_size,\n                            ebno_db, # snr point\n                            model,\n                            repetitions=num_repetitions)\n# and print the results\nfor idx, snr_db in enumerate(ebno_db):\n    print(f\"Throughput @ {snr_db:.1f} dB: {throughput[idx]/1e6:.3f} Mbit/s\")\n```"
"```python\nThroughput @ 0.0 dB: 0.016 Mbit/s\nThroughput @ 0.5 dB: 0.017 Mbit/s\nThroughput @ 1.0 dB: 0.020 Mbit/s\nThroughput @ 1.5 dB: 0.029 Mbit/s\nThroughput @ 2.0 dB: 0.047 Mbit/s\nThroughput @ 2.5 dB: 0.100 Mbit/s\nThroughput @ 3.0 dB: 0.236 Mbit/s\nThroughput @ 3.5 dB: 0.893 Mbit/s\nThroughput @ 4.0 dB: 1.294 Mbit/s\nThroughput @ 4.5 dB: 1.469 Mbit/s\n```\n\n\nWe can overlay the throughput with the BLER of the SC decoder. This can be intuitively explained by the fact that he `hybrid` `SCL` decoder consists of two decoding stages:\n\n- SC decoding for all received codewords.\n- SCL decoding *iff* the CRC does not hold, i.e., SC decoding did not yield the correct codeword.\n\n\nThus, the throughput directly depends on the BLER of the internal SC decoder.\n\n```python\n[ ]:\n```\n\n```python\nber_plot_polar = PlotBER(\"Polar SC/SCL Decoding\")\nber_plot_polar.simulate(model, # the function have defined previously\n                        ebno_dbs=ebno_db,\n                        legend=\"hybrid SCL decoding\",\n                        max_mc_iter=100,\n                        num_target_block_errors=100, # we fix the target bler\n                        batch_size=1000,\n                        soft_estimates=False,\n                        early_stop=True,\n                        add_ber=False,\n                        add_bler=True,\n                        show_fig=False,\n                        forward_keyboard_interrupt=False);\n# and add SC decoding\ndecoder2 = Polar5GDecoder(encoder, \"SC\")\nmodel = System_Model(k=k,\n                     n=n,\n                     num_bits_per_symbol=num_bits_per_symbol,\n                     encoder=encoder,\n                     decoder=decoder2)\nber_plot_polar.simulate(model, # the function have defined previously\n                        ebno_dbs=ebno_db,\n                        legend=\"SC decoding\",\n                        max_mc_iter=100,\n                        num_target_block_errors=100, # we fix the target bler\n                        batch_size=1000,\n                        soft_estimates=False,\n                        early_stop=True,\n                        add_ber=False, # we only focus on BLER\n                        add_bler=True,\n                        show_fig=False,\n                        forward_keyboard_interrupt=False);\n```"
"```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 3.3807e-01 | 8.3300e-01 |       43273 |      128000 |          833 |        1000 |         7.8 |reached target block errors\n      0.5 | 2.2667e-01 | 6.0800e-01 |       29014 |      128000 |          608 |        1000 |         7.4 |reached target block errors\n      1.0 | 1.1982e-01 | 3.4100e-01 |       15337 |      128000 |          341 |        1000 |         6.3 |reached target block errors\n      1.5 | 4.4477e-02 | 1.3400e-01 |        5693 |      128000 |          134 |        1000 |         4.6 |reached target block errors\n      2.0 | 9.6211e-03 | 3.2000e-02 |        4926 |      512000 |          128 |        4000 |        10.4 |reached target block errors\n      2.5 | 1.2563e-03 | 4.7619e-03 |        3377 |     2688000 |          100 |       21000 |        27.1 |reached target block errors\n      3.0 | 1.2359e-04 | 5.0000e-04 |        1582 |    12800000 |           50 |      100000 |        53.0 |reached max iter\n      3.5 | 1.6406e-06 | 1.0000e-05 |          21 |    12800000 |            1 |      100000 |        15.8 |reached max iter\n      4.0 | 0.0000e+00 | 0.0000e+00 |           0 |    12800000 |            0 |      100000 |        10.4 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 4.0 dB.\nWarning: 5G Polar codes use an integrated CRC that cannot be materialized with SC decoding and, thus, causes a degraded performance. Please consider SCL decoding instead.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 4.2356e-01 | 9.7900e-01 |       54216 |      128000 |          979 |        1000 |         7.9 |reached target block errors\n      0.5 | 3.5630e-01 | 8.9800e-01 |       45607 |      128000 |          898 |        1000 |         0.0 |reached target block errors\n      1.0 | 2.8463e-01 | 7.7300e-01 |       36433 |      128000 |          773 |        1000 |         0.1 |reached target block errors\n      1.5 | 1.9066e-01 | 5.4700e-01 |       24405 |      128000 |          547 |        1000 |         0.0 |reached target block errors\n      2.0 | 1.0170e-01 | 3.2100e-01 |       13017 |      128000 |          321 |        1000 |         0.0 |reached target block errors\n      2.5 | 4.2672e-02 | 1.5200e-01 |        5462 |      128000 |          152 |        1000 |         0.0 |reached target block errors\n      3.0 | 1.5059e-02 | 5.3000e-02 |        3855 |      256000 |          106 |        2000 |         0.1 |reached target block errors\n      3.5 | 4.9531e-03 | 1.8667e-02 |        3804 |      768000 |          112 |        6000 |         0.3 |reached target block errors\n      4.0 | 6.6205e-04 | 3.2258e-03 |        2627 |     3968000 |          100 |       31000 |         1.5 |reached target block errors\n      4.5 | 1.0281e-04 | 6.0000e-04 |        1316 |    12800000 |           60 |      100000 |         4.6 |reached max iter\n```"
"Let us visualize the results.\n\n```python\n[ ]:\n```\n\n```python\nber_plot_polar()\nax2 = plt.gca().twinx()  # new axis\nax2.plot(ebno_db, throughput, 'g', label=\"Throughput hybSCL-8\")\nax2.legend(fontsize=20)\nax2.set_ylabel(\"Throughput (bit/s)\", fontsize=25);\nax2.tick_params(labelsize=25)\n```\n\n\nYou can also try:\n\n- Analyze different rates\n- What happens for different batch-sizes? Can you explain what happens?\n- What happens for higher order modulation. Why is the complexity increased?"
"## References\n\n[1] E. Arikan, Channel polarization: A method for constructing capacity-achieving codes for symmetric binary-input memoryless channels, IEEE Transactions on Information Theory, 2009.\n\n[2] Ido Tal and Alexander Vardy, List Decoding of Polar Codes. IEEE Transactions on Information Theory, 2015.\n\n[3] ETSI 3GPP TS 38.212 5G NR Multiplexing and channel coding, v.16.5.0, 2021-03.\n\n[4] V. Bioglio, C. Condo, I. Land, Design of Polar Codes in 5G New Radio. IEEE Communications Surveys & Tutorials, 2020.\n\n[5] D. Hui, S. Sandberg, Y. Blankenship, M. Andersson, L. Grosjean Channel coding in 5G new radio: A Tutorial Overview and Performance Comparison with 4G LTE. IEEE Vehicular Technology Magazine, 2018.\n\n[6] E. Arikan, A Performance Comparison of Polar Codes and Reed-Muller Codes, IEEE Commun. Lett., vol.12, no. 6, pp.447449, Jun.2008.\n\n[7] R. G. Gallager, Low-Density Parity-Check Codes, M.I.T. Press Classic Series, Cambridge MA, 1963.\n\n[8] T. Richardson and S. Kudekar. Design of low-density parity check codes for 5G new radio, IEEE Communications Magazine 56.3, 2018.\n\n[9] G. Liva, L. Gaudio, T. Ninacs, T. Jerkovits, Code design for short blocks: A survey, arXiv preprint arXiv:1610.00873, 2016.\n\n[10] S. Cammerer, B. Leible, M. Stahl, J. Hoydis, and S ten Brink, Combining Belief Propagation and Successive Cancellation List Decoding of Polar Codes on a GPU Platform, IEEE ICASSP, 2017.\n\n[11] V. Bioglio, F. Gabry, I. Land, Low-complexity puncturing and shortening of polar codes, IEEE Wireless Communications and Networking Conference Workshops (WCNCW), 2017.\n\n[12] M. Fossorier, S. Lin, Soft-Decision Decoding of Linear Block Codes Based on Ordered Statistics, IEEE Transactions on Information Theory, vol.41, no. 5, 1995.[12] M. Fossorier, S. Lin, Soft-Decision Decoding of Linear Block Codes Based on Ordered Statistics, IEEE Transactions on Information Theory, vol.41, no. 5, 1995.\n[12] M. Fossorier, S. Lin, Soft-Decision Decoding of Linear Block Codes Based on Ordered Statistics, IEEE Transactions on Information Theory, vol.41, no. 5, 1995.[12] M. Fossorier, S. Lin, Soft-Decision Decoding of Linear Block Codes Based on Ordered Statistics, IEEE Transactions on Information Theory, vol.41, no. 5, 1995."
"# 5G NR PUSCH Tutorial\n\nThis notebook provides an introduction to Sionnas [5G New Radio (NR) module](https://nvlabs.github.io/sionna/api/nr.html) and, in particular, the [physical uplink shared channel (PUSCH)](https://nvlabs.github.io/sionna/api/nr.html#pusch). This module provides implementations of a small subset of the physical layer functionalities as described in the 3GPP specifications [38.211](https://portal.3gpp.org/desktopmodules/Specifications/SpecificationDetails.aspx?specificationId=3213),\n[38.212](https://portal.3gpp.org/desktopmodules/Specifications/SpecificationDetails.aspx?specificationId=3214) and [38.214](https://portal.3gpp.org/desktopmodules/Specifications/SpecificationDetails.aspx?specificationId=3216).\n\nYou will\n\n- Get an understanding of the different components of a PUSCH configuration, such as the carrier, DMRS, and transport block,\n- Learn how to rapidly simulate PUSCH transmissions for multiple transmitters,\n- Modify the PUSCHReceiver to use a custom MIMO Detector."
"## GPU Configuration and Imports\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n# Load the required Sionna components\nfrom sionna.nr import PUSCHConfig, PUSCHTransmitter, PUSCHReceiver\nfrom sionna.channel import AWGN, RayleighBlockFading, OFDMChannel, TimeChannel, time_lag_discrete_time_channel\nfrom sionna.channel.tr38901 import AntennaArray, UMi, UMa, RMa\nfrom sionna.channel import gen_single_sector_topology as gen_topology\nfrom sionna.utils import compute_ber, ebnodb2no, sim_ber\nfrom sionna.ofdm import KBestDetector, LinearDetector\nfrom sionna.mimo import StreamManagement\n```\n\n```python\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\n```\n\n```python\nimport tensorflow as tf\n# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n# For more details, see https://www.tensorflow.org/guide/gpu\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\n```"
"## A Hello World Example\n\nLet us start with a simple Hello, World! example in which we will simulate PUSCH transmissions from a single transmitter to a single receiver over an AWGN channel.\n\n\n```python\n# Create a PUSCH configuration with default settings\npusch_config = PUSCHConfig()\n# Instantiate a PUSCHTransmitter from the PUSCHConfig\npusch_transmitter = PUSCHTransmitter(pusch_config)\n# Create a PUSCHReceiver using the PUSCHTransmitter\npusch_receiver = PUSCHReceiver(pusch_transmitter)\n# AWGN channel\nchannel = AWGN()\n# Simulate transmissions over the AWGN channel\nbatch_size = 16\nno = 0.1 # Noise variance\nx, b = pusch_transmitter(batch_size) # Generate transmit signal and info bits\ny = channel([x, no]) # Simulate channel output\nb_hat = pusch_receiver([x, no]) # Recover the info bits\n# Compute BER\nprint(\"BER:\", compute_ber(b, b_hat).numpy())\n```\n\n\n```python\nBER: 0.0\n```\n\n\nAlthough the above code snippet seems rather simple, you have actually carried out standard-compliant simulations of the NR PUSCH!\n\nTo better understand what is actually going on under the hood, we can inspect the OFDM resource grid that is generated by the transmitter with the following command:\n\n\n```python\npusch_transmitter.resource_grid.show();\n```\n\n\nThe above figure tells us that we are simulating a slot of 14 OFDM symbols spanning 48 subcarriers, which correspond to four physical resource blocks (PRBs) in 5G terminology. The third OFDM symbol is reserved for pilot transmissions, so-called demodulation reference signals (DMRS), and the rest is used for data."
"## Carrier Configuration\n\nWhen you create a PUSCHConfig instance, it automatically creates a CarrierConfig instance with default settings. You can inspect this configuration with the following command:\n\n\n```python\npusch_config.carrier.show()\n```\n\n\n```python\nCarrier Configuration\n=====================\ncyclic_prefix : normal\ncyclic_prefix_length : 5.208333333333334e-06\nframe_duration : 0.01\nframe_number : 0\nkappa : 64.0\nmu : 0\nn_cell_id : 1\nn_size_grid : 4\nn_start_grid : 0\nnum_slots_per_frame : 10\nnum_slots_per_subframe : 1\nnum_symbols_per_slot : 14\nslot_number : 0\nsub_frame_duration : 0.001\nsubcarrier_spacing : 15\nt_c : 5.086263020833334e-10\nt_s : 3.2552083333333335e-08\n\n```\n\n\nMost of these parameters cannot be controlled as they are simply derived from others. For example, the cyclic prefix length depends on the subcarrier spacing. Let us see what happens, when we choose larger subcarrier spacing:\n\n\n```python\npusch_config.carrier.subcarrier_spacing = 60\npusch_config.carrier.show()\n```\n\n\n```python\nCarrier Configuration\n=====================\ncyclic_prefix : normal\ncyclic_prefix_length : 1.6927083333333335e-06\nframe_duration : 0.01\nframe_number : 0\nkappa : 64.0\nmu : 2\nn_cell_id : 1\nn_size_grid : 4\nn_start_grid : 0\nnum_slots_per_frame : 40\nnum_slots_per_subframe : 4\nnum_symbols_per_slot : 14\nslot_number : 0\nsub_frame_duration : 0.001\nsubcarrier_spacing : 60\nt_c : 5.086263020833334e-10\nt_s : 3.2552083333333335e-08\n\n```\n\n\nThe cyclic prefix has shrunk from $5.2 \\mu s$ to $1.69 \\mu s$ and the number of slots per frame has increased from $10$ to $40$.\n\nIf we change to the extended cyclic prefix, the number of OFDM symbols per slot will decrease from 14 to 12."
"```python\npusch_config_ext = pusch_config.clone()\npusch_config_ext.carrier.cyclic_prefix = \"extended\"\npusch_config_ext.carrier.show()\n```\n\n\n```python\nCarrier Configuration\n=====================\ncyclic_prefix : extended\ncyclic_prefix_length : 4.166666666666667e-06\nframe_duration : 0.01\nframe_number : 0\nkappa : 64.0\nmu : 2\nn_cell_id : 1\nn_size_grid : 4\nn_start_grid : 0\nnum_slots_per_frame : 40\nnum_slots_per_subframe : 4\nnum_symbols_per_slot : 12\nslot_number : 0\nsub_frame_duration : 0.001\nsubcarrier_spacing : 60\nt_c : 5.086263020833334e-10\nt_s : 3.2552083333333335e-08\n\n```\n\n\nPlease have a look at the API documentation of [PUSCHCarrierConfig](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.CarrierConfig) for more detail."
"## Understanding the DMRS Configuration\n\nWe can learn more about the structure of the resoure grid by having a look at the pilot pattern in the next section.\n\n\n```python\npusch_transmitter.pilot_pattern.show();\n```\n\n\nFrom the figure above, we can see that there is a single transmitter sending a single stream (or so-called layer). DMRS are only sent on even subcarriers while odd subcarriers are masked, i.e., blocked for data transmission. This corresponds to the DMRS Configuration Type 1 with the parameter `NumCDMGroupsWithoutData` set to 2. We will explain what that means later.\n\nIn 5G NR, one can configure many different pilot patterns to adapt to different channel conditions and to allow for spatial multiplexing of up to twelve layers. Each transmitted layer is identified by a DMRS port, i.e., a distinct pilot pattern. In our running example, the transmitter uses the DMRS port 0.\n\nWith the current PUSCH configuration, four different DMRS ports 0,1,2,3 are available. This can be verified with the following command:\n\n\n```python\npusch_config.dmrs.allowed_dmrs_ports\n```\n\n```python\n[0, 1, 2, 3]\n```\n\n\nNext, we configure three other transmitters using each one of the remaing ports. Then, we create a new PUSCHTransmitter instance from the list of PUSCH configurations which is able to generate transmit signals for all four transmitters in parallel.\n\n\n```python\n# Clone the original PUSCHConfig and change the DMRS port set\npusch_config_1 = pusch_config.clone()\npusch_config_1.dmrs.dmrs_port_set = [1]\npusch_config_2 = pusch_config.clone()\npusch_config_2.dmrs.dmrs_port_set = [2]\npusch_config_3 = pusch_config.clone()\npusch_config_3.dmrs.dmrs_port_set = [3]\n# Create a PUSCHTransmitter from the list of PUSCHConfigs\npusch_transmitter_multi = PUSCHTransmitter([pusch_config, pusch_config_1, pusch_config_2, pusch_config_3])\n# Generate a batch of random transmit signals\nx, b  = pusch_transmitter_multi(batch_size)\n# x has shape [batch_size, num_tx, num_tx_ant, num_ofdm_symbols, fft_size]\nprint(\"Shape of x:\", x.shape)\n```"
"```python\nShape of x: (16, 4, 1, 14, 48)\n```\n\n\nInspecting the shape of x reveals that we have indeed four single-antenna transmitters. Let us now have a look at the resuling pilot pattern for each of them:\n\n\n```python\npusch_transmitter_multi.pilot_pattern.show();\n```\n\n\nAs before, all transmitters send pilots only on the third OFDM symbol. Transmitter 0 and 1 (using DMRS port 0 and 1, respectively) send pilots on all even subcarriers, while Transmitter 2 and 3 (using DMRS port 2 and 3, respectively), send pilots on the odd subcarriers. This means that the pilots signals of DMRS port 0 and 1 (as well as 2 and 3) interfere with each other as they occupy the same resource elements. So how can we estimate the channel coefficients for both transmitters individually\nwithout pilot contamination?\n\nThe solution to this problem are the so-called code division multiplexing (CDM) groups in 5G NR. DMRS ports 0,1 belong to CDM group 0, while DMRS ports 2,3 belong to CDM group 1.\n\nThe pilot signals belonging to the same CDM group are multiplied by orthogonal cover codes which allow separating them during channel estimation. The way this works is as follows. Denote by $\\mathbf{p_0} = [s_1, s_2]^\\textsf{T}$ a pair of two adjacent pilot symbols, e.g., those on subcarrier 0 and 2, of DMRS port 0. DMRS port 1 will simply send $\\mathbf{p_1} = [s_1, -s_2]^\\textsf{T}$. If we assume that the channel is constant over both subcarriers, we get the following received pilot\nsignal at the receiver (we look only at a single antenna here):\n\n\\begin{align}\n\\mathbf{y} = h_0\\mathbf{p}_0 + h_1\\mathbf{p}_1 + \\mathbf{n}\n\\end{align}\n\nwhere $\\mathbf{y}\\in\\mathbb{C}^2$ is the received signal on both subcarriers, $h_0, h_1$ are the channel coefficients for both users, and $\\mathbf{n}\\in\\mathbb{C}^2$ is a noise vector.\n\nWe can now obtain channel estimates for both transmitters by projecting $\\mathbf{y}$ onto their respective pilot sequences:\n\n\\begin{align}\n\\hat{h}_0 &= \\frac{\\mathbf{p}_0^\\mathsf{H}}{\\lVert \\mathbf{p}_0 \\rVert|^2} \\mathbf{y} = h_0 + \\frac{|s_1|^2-|s_2|^2}{\\lVert \\mathbf{p}_0 \\rVert|^2} h_1 + \\frac{\\mathbf{p}_0^\\mathsf{H}}{\\lVert \\mathbf{p}_0 \\rVert|^2} \\mathbf{n} = h_0 + n_0 \\\\\n\\hat{h}_1 &= \\frac{\\mathbf{p}_1^\\mathsf{H}}{\\lVert \\mathbf{p}_1 \\rVert|^2} \\mathbf{y} = \\frac{|s_1|^2-|s_2|^2}{\\lVert \\mathbf{p}_1 \\rVert|^2} h_0 + h_1 +\\frac{\\mathbf{p}_1^\\mathsf{H}}{\\lVert \\mathbf{p}_1 \\rVert|^2} \\mathbf{n} = h_1 + n_1.\n\\end{align}\n\nSince the pilot symbols have the same amplitude, we have $|s_1|^2-|s_2|^2=0$, i.e., the interference between both pilot sequence is zero. Moreover, due to an implict averaging of the channel estimates for both subcarriers, the effective noise variance is reduced by a factor of 3dB since\n\n\\begin{align}\n\\mathbb{E}\\left[ |n_0|^2 \\right] = \\mathbb{E}\\left[ |n_1|^2 \\right] = \\frac{\\sigma^2}{\\lVert \\mathbf{p}_1 \\rVert|^2} = \\frac{\\sigma^2}{2 |s_0|^2}.\n\\end{align}\n\nWe can access the actual pilot sequences that are transmitted as follows:"
"```python\n# pilots has shape [num_tx, num_layers, num_pilots]\npilots = pusch_transmitter_multi.pilot_pattern.pilots\nprint(\"Shape of pilots:\", pilots.shape)\n# Select only the non-zero subcarriers for all sequence\np_0 = pilots[0,0,::2] # Pilot sequence of TX 0 on even subcarriers\np_1 = pilots[1,0,::2] # Pilot sequence of TX 1 on even subcarriers\np_2 = pilots[2,0,1::2] # Pilot sequence of TX 2 on odd subcarriers\np_3 = pilots[3,0,1::2] # Pilot sequence of TX 3 on odd subcarriers\n```\n\n\n```python\nShape of pilots: (4, 1, 48)\n```\n\n\nEach pilot pattern consists of 48 symbols that are transmitted on the third OFDM symbol with 4PRBs, i.e., 48 subcarriers. Let us now verify that pairs of two adjacent pilot symbols in `p_0` and `p_1` as well as in `p_2` and `p_3` are orthogonal.\n\n\n```python\nprint(np.sum(np.reshape(p_0, [-1,2]) * np.reshape(np.conj(p_1), [-1,2]), axis=1))\nprint(np.sum(np.reshape(p_2, [-1,2]) * np.reshape(np.conj(p_3), [-1,2]), axis=1))\n```\n\n\n```python\n[0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n 0.+0.j 0.+0.j]\n[0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j 0.+0.j\n 0.+0.j 0.+0.j]\n```\n\n\nLet us now come back to the masked resource elements in each pilot pattern. The parameter `NumCDMGroupsWithoutData` mentioned earlier determines which resource elements in a DMRS-carrying OFDM symbol are masked for data transmissions. This is to avoid inference with pilots from other DMRS groups.\n\nIn our example, `NumCDMGroupsWithoutData` is set to two. This means that no data can be transmitted on any of the resource elements occupied by both DMRS groups. However, if we would have set `NumCDMGroupsWithoutData` equal to one, data and pilots would be frequency multiplexed. This can be useful, if we only schedule transmissions from DMRS ports in the same CDM group.\n\nHere is an example of such a configuration:"
"```python\npusch_config = PUSCHConfig()\npusch_config.dmrs.num_cdm_groups_without_data = 1\npusch_config.dmrs.dmrs_port_set = [0]\npusch_config_1 = pusch_config.clone()\npusch_config_1.dmrs.dmrs_port_set = [1]\nPUSCHTransmitter([pusch_config, pusch_config_1]).pilot_pattern.show();\n```\n\n\nThe DRMS ports 0 and 1 belong both to CDM group 0 so that the resource elements of CDM group 1 do not need to be masked and can be used for data transmission. One can see in the above figure that data and pilots are now indeed multiplexed in the frequency domain."
"### Configuring Multiple Layers\n\nIn 5G NR, a transmitter can be equipped with 1,2, or 4 antenna ports, i.e., physical antennas that are fed with an individual transmit signal. It can transmit 1,2,3 or 4 layers, i.e., spatial streams, as long as the number of layers does not exceed the number of antenna ports. Using codebook-based precoding, a number of layers can be mapped onto a larger number of antenna ports, e.g., 2 layers using 4 antenna ports. If no precoding is used, each layer is simply mapped to one of the antenna\nports.\n\nIt is important to understand that each layer is transmitted using a different DMRS port. That means that the number of DMRS ports is independent of the number of antenna ports.\n\nIn the next cell, we will configure a single transmitter with four antenna ports, sending two layers on DMRS ports 0 and 1. We can then choose among different precoding matrices with the help of the transmit transmit precoding matrix identifier (TPMI).\n\n\n```python\npusch_config = PUSCHConfig()\npusch_config.num_antenna_ports = 4\npusch_config.num_layers = 2\npusch_config.dmrs.dmrs_port_set = [0,1]\npusch_config.precoding = \"codebook\"\npusch_config.tpmi = 7\n# Show the precoding matrix\npusch_config.precoding_matrix\n```\n```python\narray([[0.5+0.j , 0. +0.j ],\n       [0. +0.j , 0.5+0.j ],\n       [0.5+0.j , 0. +0.j ],\n       [0. +0.j , 0. +0.5j]])\n```\n\n```python\nPUSCHTransmitter(pusch_config).pilot_pattern.show();\n```\n\n\nWe can see from the pilot patterns above, that we have now a single transmitter sending two streams. Both streams will be precoded and transmit over four antenna ports. From a channel estimation perspective at the receiver, however, this scenario is identical to the previous one with two single-antenna transmitters. The receiver will simply estimate the effective channel (including precoding) for every configured DMRS port."
"### Controlling the Number of DMRS Symbols in a Slot\n\nHow can we add additional DMRS symbols to the resource grid to enable channel estimation for high-speed scenarios?\n\nThis can be controlled with the parameter `DMRS.additional_position`. In the next cell, we configure one additional DMRS symbol to the pattern and visualize it. You can try setting it to different values and see the impact.\n\n\n```python\npusch_config.dmrs.additional_position = 1\n# In order to reduce the number of figures, we only limit us here\n# to the pilot pattern of the first stream\nPUSCHTransmitter(pusch_config).pilot_pattern.show(stream_ind = 0);\n```"
"### How to control the number of available DMRS ports?\n\nThere are two factors that determine the available number of DMRS ports, i.e., layers, that can be transmitted. The first is the DMRS Configuration and the second the length of a DMRS symbol. Both parameters can take to values so that there are four options in total. In the previous example, the DMRS Configuration Type 1 was used. In this case, there are two CDM groups and each groups uses either odd or even subcarriers. This leads to four available DMRS ports. With DMRS Configuration Type 2,\nthere are three CDM groups and each group uses two pairs of adjacent subcarriers per PRB, i.e., four pilot-carrying subcarriers. That means that there are six available DMRS ports.\n\n\n```python\npusch_config.dmrs.config_type = 2\nPUSCHTransmitter(pusch_config).pilot_pattern.show(stream_ind = 0);\nprint(\"Available DMRS ports:\", pusch_config.dmrs.allowed_dmrs_ports)\n```\n\n\n```python\nAvailable DMRS ports: [0, 1, 2, 3]\n```\n\n\nIn the above figure, you can see that the pilot pattern has become sparser in the frequency domain. However, there are still only four available DMRS ports. This is because we now need to mask also the resource elements that are used by the third CDM group. This can be done by setting the parameter `NumCDMGroupsWithoutData` equal to three.\n\n\n```python\npusch_config.dmrs.num_cdm_groups_without_data = 3\nPUSCHTransmitter(pusch_config).pilot_pattern.show(stream_ind = 0);\nprint(\"Available antenna ports:\", pusch_config.dmrs.allowed_dmrs_ports)\n```\n\n\n```python\nAvailable antenna ports: [0, 1, 2, 3, 4, 5]\n```\n\n\nThe second parameter that controls the number of available DMRS ports is the `length`, which can be equal to either one or two. Lets see what happens when we change it to two.\n\n\n```python\npusch_config.n_size_bwp = 1 # We reduce the bandwidth to one PRB for better visualization\npusch_config.dmrs.length = 2\nPUSCHTransmitter(pusch_config).pilot_pattern.show(stream_ind = 0);\nprint(\"Available DMRS ports:\", pusch_config.dmrs.allowed_dmrs_ports)\n```"
"```python\nAvailable DMRS ports: [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n```\n\n\nThe pilot pattern is now composed of four 2x2 blocks within a PRB. These blocks are used by the four DMRS ports within the same CDM group. This means that we can now support up to twelve layers!\n\nLets create a setup with three transmitters, each sending four layers using four antenna ports. We choose the DMRS ports for each transmitters such that they belong to the CDM group. This is not necessary and you are free to choose any desired allocation. It is however important to understand, thet for channel estimation to work, the channel is supposed to be static over 2x2 blocks of resource elements. This is in general the case for low mobility scenarios and channels with not too large delay\nspread. You can see from the results below that the pilot sequences of the DMRS ports in the same CDM group are indeed orthogonal over the 2x2 blocks.\n\n\n```python\npusch_config = PUSCHConfig()\npusch_config.n_size_bwp = 1\npusch_config.dmrs.config_type = 2\npusch_config.dmrs.length = 2\npusch_config.dmrs.additional_position = 1\npusch_config.dmrs.num_cdm_groups_without_data = 3\npusch_config.num_antenna_ports = 4\npusch_config.num_layers = 4\npusch_config.dmrs.dmrs_port_set = [0,1,6,7]\npusch_config.precoding = \"codebook\"\npusch_config.tpmi = 4\npusch_config_1 = pusch_config.clone()\npusch_config_1.dmrs.dmrs_port_set = [2,3,8,9]\npusch_config_2 = pusch_config.clone()\npusch_config_2.dmrs.dmrs_port_set = [4,5,10,11]\npusch_transmitter_multi = PUSCHTransmitter([pusch_config, pusch_config_1, pusch_config_2])\n```\n\n```python\n# Extract the first 2x2 block of pilot symbols for all DMRS ports of the first transmitter\np = pusch_transmitter_multi.pilot_pattern.pilots[0].numpy()\np = np.matrix(p[:, [0,1,12,13]])\n# Test that these pilot sequences are mutually orthogonal\n# The result should be a boolean identity matrix\nnp.abs(p*p.getH())>1e-6\n```"
"```python\nmatrix([[ True, False, False, False],\n        [False,  True, False, False],\n        [False, False,  True, False],\n        [False, False, False,  True]])\n```\n\n\nThere are several other parameters that impact the pilot patterns. The full DMRS configuration can be displayed with the following command. We refer to the [API documentation of the PUSCHDMRSConfig class](https://nvlabs.github.io/sionna/api/nr.html#puschdmrsconfig) for further details.\n\n\n```python\npusch_config.dmrs.show()\n```\n\n\n```python\nPUSCH DMRS Configuration\n========================\nadditional_position : 1\nallowed_dmrs_ports : [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\nbeta : 1.7320508075688772\ncdm_groups : [0, 0, 0, 0]\nconfig_type : 2\ndeltas : [0, 0, 0, 0]\ndmrs_port_set : [0, 1, 6, 7]\nlength : 2\nn_id : None\nn_scid : 0\nnum_cdm_groups_without_data : 3\ntype_a_position : 2\nw_f : [[ 1  1  1  1]\n [ 1 -1  1 -1]]\nw_t : [[ 1  1  1  1]\n [ 1  1 -1 -1]]\n\n```"
"## Transport Blocks and MCS\n\nThe modulation and coding scheme (MCS) is set in 5G NR via the MCS index and MCS table which are properties of transport block configuration [TBConfig](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.TBConfig). When you create an instance of `PUSCHConfig`, a default instance of `TBConfig` is created. It can be accessed via the following command:\n\n\n```python\npusch_config = PUSCHConfig()\npusch_config.tb.show()\n```\n\n\n```python\nTransport Block Configuration\n=============================\nchannel_type : PUSCH\nmcs_index : 14\nmcs_table : 1\nn_id : None\nnum_bits_per_symbol : 4\ntarget_coderate : 0.5400390625\ntb_scaling : 1.0\n\n```\n\n\nYou can see that the current MCS Table is 1 and the MCS index is 14. Looking at the corresponding table in the API documentation of [TBConfig](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.TBConfig), you can see that we should have a 16QAM modulation (i.e., 4 bits per symbol) and a target coderate of 553/1024=0.54 which matches the values above. The data scrambling ID $n_\\text{ID}$ is set to `None` which implies that the physical layer cell id $N^\\text{cell}_\\text{ID}$\nwill be used instead.\n\nWe can change the MCS index and table as follows:\n\n\n```python\npusch_config.tb.mcs_index = 26\npusch_config.tb.mcs_table = 2\npusch_config.tb.show()\n```\n\n\n```python\nTransport Block Configuration\n=============================\nchannel_type : PUSCH\nmcs_index : 26\nmcs_table : 2\nn_id : None\nnum_bits_per_symbol : 8\ntarget_coderate : 0.89501953125\ntb_scaling : 1.0\n\n```\n\n\nThe transport block segmentation allows the PUSCH transmitter to fill resource grids of almost arbitrary size and with any of the possible DMRS configurations. The number of information bits transmitted in a single slot is given by the property `tb_size` of the `PUSCHConfig`.\n\n\n```python\n# Adding more PRBs will increase the TB size\npusch_config.carrier.n_size_grid = 273\npusch_config.tb_size\n```"
"```python\n303240\n```\n\n```python\n# Adding more layers will increase the TB size\npusch_config.num_antenna_ports = 4\npusch_config.num_layers = 4\npusch_config.tb_size\n```\n\n```python\n1213032\n```\n\n\nFor more details about how the transportblock encoding/decoding works, we refer to the API documentation of the [TBEncoder](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.TBEncoder)."
"## Looking into the PUSCHTransmitter\n\nWe have used the `PUSCHTransmitter` class already multiple times without speaking about what it actually does. In short, it generates for every configured transmitter a batch of random information bits of length `pusch_config.tb_size` and outputs either a frequency fo time-domain representation of the transmitted OFDM waveform from each of the antenna ports of each transmitter.\n\nHowever, under the hood it implements the sequence of layers shown in the following figure:\n\n\nInformation bits are either randomly generated or provided as input and then encoded into a transport block by the [TBEncoder](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.TBEncoder). The encoded bits are then mapped to QAM constellation symbols by the [Mapper](https://nvlabs.github.io/sionna/api/mapping.html#sionna.mapping.Mapper). The [LayerMapper](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.LayerMapper) splits the modulated symbols into different layers which are\nthen mapped onto OFDM resource grids by the [ResourceGridMapper](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGridMapper). If precoding is enabled in the [PUSCHConfig](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHConfig), the resource grids are further precoded by the [PUSCHPrecoder](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHPrecoder) so that there is one for each transmitter and antenna port. If `output_domain` equals freq, these\nare the ouputs x . If `output_domain` is chosen to be time, the resource grids are transformed into time-domain signals by the [OFDMModulator](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.OFDMModulator).\n\nLet us configure a `PUSCHTransmitter` from a list of two `PUSCHConfig` and inspect the output shapes:\n\n\n```python\npusch_config = PUSCHConfig()\npusch_config.num_antenna_ports = 4\npusch_config.num_layers = 2\npusch_config.dmrs.dmrs_port_set = [0,1]\npusch_config.precoding = \"codebook\"\npusch_config.tpmi = 7\npusch_config_1 = pusch_config.clone()\npusch_config.dmrs.dmrs_port_set = [2,3]\npusch_transmitter = PUSCHTransmitter([pusch_config, pusch_config_1])\nbatch_size = 32\nx, b = pusch_transmitter(batch_size)\n# b has shape [batch_size, num_tx, tb_size]\nprint(\"Shape of b:\", b.shape)\n# x has shape [batch_size, num_tx, num_tx_ant, num_ofdm_symbols, num_subcarriers]\nprint(\"Shape of x:\", x.shape)\n```"
"```python\nShape of b: (32, 2, 2728)\nShape of x: (32, 2, 4, 14, 48)\n```\n\n\nIf you want to transmit a custom payload, you simply need to deactive the `return_bits` flag when creating the transmitter:\n\n\n```python\npusch_transmitter = PUSCHTransmitter([pusch_config, pusch_config_1], return_bits=False)\nx_2 = pusch_transmitter(b)\nassert np.array_equal(x, x_2) # Check that we get the same output for the payload b generated above\n```\n\n\nBy default, the `PUSCHTransmitter` generates frequency-domain outputs. If you want to make time-domain simulations, you need to configure the `output_domain` during the initialization:\n\n\n```python\npusch_transmitter = PUSCHTransmitter([pusch_config, pusch_config_1], output_domain=\"time\", return_bits=False)\nx_time = pusch_transmitter(b)\n# x has shape [batch_size, num_tx, num_tx_ant, num_time_samples]\nprint(\"Shape of x:\", x_time.shape)\n```\n\n\n```python\nShape of x: (32, 2, 4, 728)\n```\n\n\nThe last dimension of the output signal correspond to the total number of time-domain samples which can be computed in the following way:\n\n\n```python\n(pusch_transmitter.resource_grid.cyclic_prefix_length  \\\n + pusch_transmitter.resource_grid.fft_size) \\\n* pusch_transmitter.resource_grid.num_ofdm_symbols\n```\n\n```python\n728\n```"
"## Components of the PUSCHReceiver\n\nThe [PUSCHReceiver](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHReceiver) is the counter-part to the [PUSCHTransmitter](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHTransmitter) as it *simply* recovers the transmitted information bits from received waveform. It combines multiple processing blocks in a single layer as shown in the following figure:\n\n\nIf the `input_domain` equals time, the inputs $\\mathbf{y}$ are first transformed to resource grids with the [OFDMDemodulator](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.OFDMModulator). Then channel estimation is performed, e.g., with the help of the [PUSCHLSChannelEstimator](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHLSChannelEstimator). If `channel_estimator` is chosen to be perfect, this step is skipped and the input $\\mathbf{h}$ is used\ninstead. Next, MIMO detection is carried out with an arbitrary [OFDMDetector](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.OFDMDetector). The resulting LLRs for each layer are then combined to transport blocks with the help of the [LayerDemapper](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.LayerDemapper). Finally, the transport blocks are decoded with the [TBDecoder](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.TBDecoder).\n\nIf we instantiate a `PUSCHReceiver` as done in the next cell, default implementations of all blocks as described in the [API documentation](https://nvlabs.github.io/sionna/api/nr.html#sionna.nr.PUSCHReceiver) are used.\n\n\n```python\npusch_receiver = PUSCHReceiver(pusch_transmitter)\npusch_receiver._mimo_detector\n```\n\n```python\n<sionna.ofdm.detection.LinearDetector at 0x7f86f28c72b0>\n```\n\n\nWe can also provide custom implementations for each block by providing them as keyword arguments during initialization. In the folllwing code snippet, we first create an instance of the [KBestDetector](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.KBestDetector), which is then used as MIMO detector in the `PUSCHReceiver`."
"```python\n# Create a new PUSCHTransmitter\npusch_transmitter = PUSCHTransmitter([pusch_config, pusch_config_1])\n# Create a StreamManagement instance\nrx_tx_association = np.ones([1, pusch_transmitter.resource_grid.num_tx], bool)\nstream_management = StreamManagement(rx_tx_association,\n                                     pusch_config.num_layers)\n# Get relevant parameters for the detector\nnum_streams = pusch_transmitter.resource_grid.num_tx \\\n              * pusch_transmitter.resource_grid.num_streams_per_tx\nk = 32 # Number of canditates for K-Best detection\nk_best = KBestDetector(\"bit\", num_streams, k,\n                       pusch_transmitter.resource_grid,\n                       stream_management,\n                       \"qam\", pusch_config.tb.num_bits_per_symbol)\n# Create a PUSCHReceiver using the KBest detector\npusch_receiver = PUSCHReceiver(pusch_transmitter, mimo_detector=k_best)\n```\n\n\nNext, we test if this receiver works over a simple Rayleigh block fading channel:\n\n\n```python\nnum_rx_ant = 16\nrayleigh = RayleighBlockFading(num_rx=1,\n                               num_rx_ant=num_rx_ant,\n                               num_tx=pusch_transmitter.resource_grid.num_tx,\n                               num_tx_ant=pusch_config.num_antenna_ports)\nchannel = OFDMChannel(rayleigh,\n                      pusch_transmitter.resource_grid,\n                      add_awgn=True,\n                      normalize_channel=True)\nx, b = pusch_transmitter(32)\nno = 0.1\ny = channel([x, no])\nb_hat = pusch_receiver([y, no])\nprint(\"BER:\", compute_ber(b, b_hat).numpy())\n```\n\n\n```python\nBER: 0.0\n```"
"## End-to-end PUSCH Simulations\n\nWe will now implement a end-to-end Keras model that is capable of running PUSCH simulations for many different configurations. You can use it as a boilerplate template for your own experiments.\n\n\n```python\n# We need to enable sionna.config.xla_compat before we can use\n# tf.function with jit_compile=True.\n# See https://nvlabs.github.io/sionna/api/config.html#sionna.Config.xla_compat\nsionna.config.xla_compat=True\nclass Model(tf.keras.Model):\n    \"\"\"Simulate PUSCH transmissions over a 3GPP 38.901 model.\n    This model runs BER simulations for a multiuser MIMO uplink channel\n    compliant with the 5G NR PUSCH specifications.\n    You can pick different scenarios, i.e., channel models, perfect or\n    estimated CSI, as well as different MIMO detectors (LMMSE or KBest).\n    You can chosse to run simulations in either time (\"time\") or frequency (\"freq\")\n    domains and configure different user speeds.\n    Parameters\n    ----------\n    scenario : str, one of [\"umi\", \"uma\", \"rma\"]\n        3GPP 38.901 channel model to be used\n    perfect_csi : bool\n        Determines if perfect CSI is assumed or if the CSI is estimated\n    domain :  str, one of [\"freq\", \"time\"]\n        Domain in which the simulations are carried out.\n        Time domain modelling is typically more complex but allows modelling\n        of realistic effects such as inter-symbol interference of subcarrier\n        interference due to very high speeds.\n    detector : str, one of [\"lmmse\", \"kbest\"]\n        MIMO detector to be used. Note that each detector has additional\n        parameters that can be configured in the source code of the _init_ call.\n    speed: float\n        User speed (m/s)\n    Input\n    -----\n    batch_size : int\n        Number of simultaneously simulated slots\n    ebno_db : float\n        Signal-to-noise-ratio\n    Output\n    ------\n    b : [batch_size, num_tx, tb_size], tf.float\n        Transmitted information bits\n    b_hat : [batch_size, num_tx, tb_size], tf.float\n        Decoded information bits\n    \"\"\"\n    def __init__(self,\n                 scenario,    # \"umi\", \"uma\", \"rma\"\n                 perfect_csi, # bool\n                 domain,      # \"freq\", \"time\"\n                 detector,    # \"lmmse\", \"kbest\"\n                 speed        # float\n                ):\n        super().__init__()\n        self._scenario = scenario\n        self._perfect_csi = perfect_csi\n        self._domain = domain\n        self._speed = speed\n        self._carrier_frequency = 3.5e9\n        self._subcarrier_spacing = 30e3\n        self._num_tx = 4\n        self._num_tx_ant = 4\n        self._num_layers = 2\n        self._num_rx_ant = 16\n        self._mcs_index = 14\n        self._mcs_table = 1\n        self._num_prb = 16\n        # Create PUSCHConfigs\n        # PUSCHConfig for the first transmitter\n        pusch_config = PUSCHConfig()\n        pusch_config.carrier.subcarrier_spacing = self._subcarrier_spacing/1000\n        pusch_config.carrier.n_size_grid = self._num_prb\n        pusch_config.num_antenna_ports = self._num_tx_ant\n        pusch_config.num_layers = self._num_layers\n        pusch_config.precoding = \"codebook\"\n        pusch_config.tpmi = 1\n        pusch_config.dmrs.dmrs_port_set = list(range(self._num_layers))\n        pusch_config.dmrs.config_type = 2\n        pusch_config.dmrs.length = 2\n        pusch_config.dmrs.additional_position = 1\n        pusch_config.dmrs.num_cdm_groups_without_data = 3\n        pusch_config.tb.mcs_index = self._mcs_index\n        pusch_config.tb.mcs_table = self._mcs_table\n        # Create PUSCHConfigs for the other transmitters by cloning of the first PUSCHConfig\n        # and modifying the used DMRS ports.\n        pusch_configs = [pusch_config]\n        for i in range(1, self._num_tx):\n            pc = pusch_config.clone()\n            pc.dmrs.dmrs_port_set = list(range(i*self._num_layers, (i+1)*self._num_layers))\n            pusch_configs.append(pc)\n        # Create PUSCHTransmitter\n        self._pusch_transmitter = PUSCHTransmitter(pusch_configs, output_domain=self._domain)\n        # Create PUSCHReceiver\n        self._l_min, self._l_max = time_lag_discrete_time_channel(self._pusch_transmitter.resource_grid.bandwidth)\n\n        rx_tx_association = np.ones([1, self._num_tx], bool)\n        stream_management = StreamManagement(rx_tx_association,\n                                             self._num_layers)\n        assert detector in[\"lmmse\", \"kbest\"], \"Unsupported MIMO detector\"\n        if detector==\"lmmse\":\n            detector = LinearDetector(equalizer=\"lmmse\",\n                                      output=\"bit\",\n                                      demapping_method=\"maxlog\",\n                                      resource_grid=self._pusch_transmitter.resource_grid,\n                                      stream_management=stream_management,\n                                      constellation_type=\"qam\",\n                                      num_bits_per_symbol=pusch_config.tb.num_bits_per_symbol)\n        elif detector==\"kbest\":\n            detector = KBestDetector(output=\"bit\",\n                                     num_streams=self._num_tx*self._num_layers,\n                                     k=64,\n                                     resource_grid=self._pusch_transmitter.resource_grid,\n                                     stream_management=stream_management,\n                                     constellation_type=\"qam\",\n                                     num_bits_per_symbol=pusch_config.tb.num_bits_per_symbol)\n        if self._perfect_csi:\n            self._pusch_receiver = PUSCHReceiver(self._pusch_transmitter,\n                                                 mimo_detector=detector,\n                                                 input_domain=self._domain,\n                                                 channel_estimator=\"perfect\",\n                                                 l_min = self._l_min)\n        else:\n            self._pusch_receiver = PUSCHReceiver(self._pusch_transmitter,\n                                                 mimo_detector=detector,\n                                                 input_domain=self._domain,\n                                                 l_min = self._l_min)\n        # Configure antenna arrays\n        self._ut_array = AntennaArray(\n                                 num_rows=1,\n                                 num_cols=int(self._num_tx_ant/2),\n                                 polarization=\"dual\",\n                                 polarization_type=\"cross\",\n                                 antenna_pattern=\"omni\",\n                                 carrier_frequency=self._carrier_frequency)\n        self._bs_array = AntennaArray(num_rows=1,\n                                      num_cols=int(self._num_rx_ant/2),\n                                      polarization=\"dual\",\n                                      polarization_type=\"cross\",\n                                      antenna_pattern=\"38.901\",\n                                      carrier_frequency=self._carrier_frequency)\n        # Configure the channel model\n        if self._scenario == \"umi\":\n            self._channel_model = UMi(carrier_frequency=self._carrier_frequency,\n                                      o2i_model=\"low\",\n                                      ut_array=self._ut_array,\n                                      bs_array=self._bs_array,\n                                      direction=\"uplink\",\n                                      enable_pathloss=False,\n                                      enable_shadow_fading=False)\n        elif self._scenario == \"uma\":\n            self._channel_model = UMa(carrier_frequency=self._carrier_frequency,\n                                      o2i_model=\"low\",\n                                      ut_array=self._ut_array,\n                                      bs_array=self._bs_array,\n                                      direction=\"uplink\",\n                                      enable_pathloss=False,\n                                      enable_shadow_fading=False)\n        elif self._scenario == \"rma\":\n            self._channel_model = RMa(carrier_frequency=self._carrier_frequency,\n                                      ut_array=self._ut_array,\n                                      bs_array=self._bs_array,\n                                      direction=\"uplink\",\n                                      enable_pathloss=False,\n                                      enable_shadow_fading=False)\n        # Configure the actual channel\n        if domain==\"freq\":\n            self._channel = OFDMChannel(\n                                self._channel_model,\n                                self._pusch_transmitter.resource_grid,\n                                normalize_channel=True,\n                                return_channel=True)\n        else:\n            self._channel = TimeChannel(\n                                self._channel_model,\n                                self._pusch_transmitter.resource_grid.bandwidth,\n                                self._pusch_transmitter.resource_grid.num_time_samples,\n                                l_min=self._l_min,\n                                l_max=self._l_max,\n                                normalize_channel=True,\n                                return_channel=True)\n    def new_topology(self, batch_size):\n        \"\"\"Set new topology\"\"\"\n        topology = gen_topology(batch_size,\n                                self._num_tx,\n                                self._scenario,\n                                min_ut_velocity=self._speed,\n                                max_ut_velocity=self._speed)\n        self._channel_model.set_topology(*topology)\n    @tf.function(jit_compile=True)\n    def call(self, batch_size, ebno_db):\n        self.new_topology(batch_size)\n        x, b = self._pusch_transmitter(batch_size)\n        no = ebnodb2no(ebno_db,\n                       self._pusch_transmitter._num_bits_per_symbol,\n                       self._pusch_transmitter._target_coderate,\n                       self._pusch_transmitter.resource_grid)\n        y, h = self._channel([x, no])\n        if self._perfect_csi:\n            b_hat = self._pusch_receiver([y, h, no])\n        else:\n            b_hat = self._pusch_receiver([y, no])\n        return b, b_hat\n```"
"We will now compare the PUSCH BLER performance over the 3GPP 38.901 UMi channel model with different detectors and either perfect or imperfect CSI. Note that these simulations might take some time depending or you available hardware. You can reduce the `batch_size` if the model does not fit into the memory of your GPU. Running the simulations in the time domain will significantly increase the complexity and you might need to decrease the `batch_size` further. The code will also run on CPU if\nnot GPU is available.\n\nNote that the XLA compilation step can take several minutes (but the simulations will be much quicker compared to eager or graph mode.\n\nIf you do not want to run the simulation yourself, you can skip the next cell and visualize the results in the next cell.\n\n\n```python\nPUSCH_SIMS = {\n    \"scenario\" : [\"umi\"],\n    \"domain\" : [\"freq\"],\n    \"perfect_csi\" : [True, False],\n    \"detector\" : [\"kbest\", \"lmmse\"],\n    \"ebno_db\" : list(range(-2,11)),\n    \"speed\" : 3.0,\n    \"batch_size_freq\" : 128,\n    \"batch_size_time\" : 28, # Reduced batch size from time-domain modeling\n    \"bler\" : [],\n    \"ber\" : []\n    }\nstart = time.time()\nfor scenario in PUSCH_SIMS[\"scenario\"]:\n    for domain in PUSCH_SIMS[\"domain\"]:\n        for perfect_csi in PUSCH_SIMS[\"perfect_csi\"]:\n            batch_size = PUSCH_SIMS[\"batch_size_freq\"] if domain==\"freq\" else PUSCH_SIMS[\"batch_size_time\"]\n            for detector in PUSCH_SIMS[\"detector\"]:\n                model = Model(scenario, perfect_csi, domain, detector, PUSCH_SIMS[\"speed\"])\n                ber, bler = sim_ber(model,\n                            PUSCH_SIMS[\"ebno_db\"],\n                            batch_size=batch_size,\n                            max_mc_iter=1000,\n                            num_target_block_errors=200)\n                PUSCH_SIMS[\"ber\"].append(list(ber.numpy()))\n                PUSCH_SIMS[\"bler\"].append(list(bler.numpy()))\nPUSCH_SIMS[\"duration\"] = time.time() - start\n```\n\n\n```python\nWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\nInstructions for updating:\nLambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -2.0 | 8.4141e-02 | 8.6523e-01 |      352915 |     4194304 |          443 |         512 |       174.7 |reached target block errors\n     -1.0 | 3.8089e-02 | 5.2539e-01 |      159757 |     4194304 |          269 |         512 |         0.6 |reached target block errors\n      0.0 | 1.3623e-02 | 2.3633e-01 |      114277 |     8388608 |          242 |        1024 |         1.2 |reached target block errors\n      1.0 | 5.1620e-03 | 7.0312e-02 |      129906 |    25165824 |          216 |        3072 |         3.5 |reached target block errors\n      2.0 | 1.8941e-03 | 2.2895e-02 |      142999 |    75497472 |          211 |        9216 |        10.6 |reached target block errors\n      3.0 | 6.8813e-04 | 8.1787e-03 |      138539 |   201326592 |          201 |       24576 |        28.4 |reached target block errors\n      4.0 | 2.8596e-04 | 3.1917e-03 |      147528 |   515899392 |          201 |       62976 |        73.4 |reached target block errors\n      5.0 | 1.2890e-04 | 1.1800e-03 |      181657 |  1409286144 |          203 |      172032 |       201.4 |reached target block errors\n      6.0 | 9.3746e-05 | 7.2742e-04 |      211149 |  2252341248 |          200 |      274944 |       321.9 |reached target block errors\n      7.0 | 3.3643e-05 | 2.9883e-04 |      141111 |  4194304000 |          153 |      512000 |       599.8 |reached max iter\n      8.0 | 2.6884e-05 | 1.8945e-04 |      112758 |  4194304000 |           97 |      512000 |       599.8 |reached max iter\n      9.0 | 1.2900e-05 | 1.0742e-04 |       54107 |  4194304000 |           55 |      512000 |       599.8 |reached max iter\n     10.0 | 6.6764e-06 | 4.6875e-05 |       28003 |  4194304000 |           24 |      512000 |       599.8 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -2.0 | 3.2366e-02 | 5.0195e-01 |      135754 |     4194304 |          257 |         512 |       171.7 |reached target block errors\n     -1.0 | 1.5961e-02 | 2.4121e-01 |      133888 |     8388608 |          247 |        1024 |         1.0 |reached target block errors\n      0.0 | 9.8741e-03 | 1.3411e-01 |      124245 |    12582912 |          206 |        1536 |         1.4 |reached target block errors\n      1.0 | 4.3543e-03 | 6.5569e-02 |      127843 |    29360128 |          235 |        3584 |         3.4 |reached target block errors\n      2.0 | 2.7020e-03 | 3.7109e-02 |      124664 |    46137344 |          209 |        5632 |         5.2 |reached target block errors\n      3.0 | 1.5692e-03 | 2.1073e-02 |      125056 |    79691776 |          205 |        9728 |         9.3 |reached target block errors\n      4.0 | 8.9329e-04 | 1.2251e-02 |      123642 |   138412032 |          207 |       16896 |        16.1 |reached target block errors\n      5.0 | 5.4429e-04 | 7.2443e-03 |      125561 |   230686720 |          204 |       28160 |        26.8 |reached target block errors\n      6.0 | 2.9038e-04 | 3.8869e-03 |      123013 |   423624704 |          201 |       51712 |        48.7 |reached target block errors\n      7.0 | 2.1879e-04 | 2.7646e-03 |      130307 |   595591168 |          201 |       72704 |        69.2 |reached target block errors\n      8.0 | 1.3987e-04 | 1.5751e-03 |      145486 |  1040187392 |          200 |      126976 |       121.0 |reached target block errors\n      9.0 | 7.8782e-05 | 9.8387e-04 |      132505 |  1681915904 |          202 |      205312 |       195.2 |reached target block errors\n     10.0 | 6.4391e-05 | 7.2391e-04 |      147192 |  2285895680 |          202 |      279040 |       266.3 |reached target block errors\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -2.0 | 1.5518e-01 | 9.9414e-01 |      650858 |     4194304 |          509 |         512 |        43.2 |reached target block errors\n     -1.0 | 1.2702e-01 | 9.7266e-01 |      532773 |     4194304 |          498 |         512 |         0.6 |reached target block errors\n      0.0 | 8.9072e-02 | 8.4961e-01 |      373596 |     4194304 |          435 |         512 |         0.6 |reached target block errors\n      1.0 | 3.6323e-02 | 5.1367e-01 |      152349 |     4194304 |          263 |         512 |         0.6 |reached target block errors\n      2.0 | 1.5565e-02 | 2.3438e-01 |      130566 |     8388608 |          240 |        1024 |         1.2 |reached target block errors\n      3.0 | 8.8474e-03 | 1.1523e-01 |      148435 |    16777216 |          236 |        2048 |         2.3 |reached target block errors\n      4.0 | 5.3303e-03 | 5.1270e-02 |      178854 |    33554432 |          210 |        4096 |         4.7 |reached target block errors\n      5.0 | 3.5277e-03 | 2.8878e-02 |      207146 |    58720256 |          207 |        7168 |         8.2 |reached target block errors\n      6.0 | 2.9088e-03 | 2.3093e-02 |      207410 |    71303168 |          201 |        8704 |        10.0 |reached target block errors\n      7.0 | 2.5939e-03 | 1.8694e-02 |      228468 |    88080384 |          201 |       10752 |        12.4 |reached target block errors\n      8.0 | 2.0388e-03 | 1.3672e-02 |      247983 |   121634816 |          203 |       14848 |        17.2 |reached target block errors\n      9.0 | 1.7823e-03 | 1.2451e-02 |      239211 |   134217728 |          204 |       16384 |        19.0 |reached target block errors\n     10.0 | 1.9271e-03 | 1.3739e-02 |      234399 |   121634816 |          204 |       14848 |        17.2 |reached target block errors\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -2.0 | 1.0344e-01 | 9.1992e-01 |      433850 |     4194304 |          471 |         512 |        43.9 |reached target block errors\n     -1.0 | 6.6115e-02 | 7.2461e-01 |      277305 |     4194304 |          371 |         512 |         0.5 |reached target block errors\n      0.0 | 4.3680e-02 | 5.3320e-01 |      183209 |     4194304 |          273 |         512 |         0.5 |reached target block errors\n      1.0 | 2.1767e-02 | 2.8027e-01 |      182593 |     8388608 |          287 |        1024 |         1.0 |reached target block errors\n      2.0 | 1.3199e-02 | 1.6536e-01 |      166083 |    12582912 |          254 |        1536 |         1.4 |reached target block errors\n      3.0 | 7.3069e-03 | 8.9844e-02 |      153236 |    20971520 |          230 |        2560 |         2.4 |reached target block errors\n      4.0 | 5.2081e-03 | 5.6920e-02 |      152911 |    29360128 |          204 |        3584 |         3.4 |reached target block errors\n      5.0 | 4.0943e-03 | 4.3620e-02 |      154555 |    37748736 |          201 |        4608 |         4.3 |reached target block errors\n      6.0 | 3.9949e-03 | 3.5006e-02 |      217828 |    54525952 |          233 |        6656 |         6.2 |reached target block errors\n      7.0 | 2.3833e-03 | 2.0559e-02 |      189928 |    79691776 |          200 |        9728 |         9.1 |reached target block errors\n      8.0 | 2.3061e-03 | 1.7578e-02 |      222467 |    96468992 |          207 |       11776 |        11.1 |reached target block errors\n      9.0 | 2.3562e-03 | 1.8466e-02 |      217420 |    92274688 |          208 |       11264 |        10.6 |reached target block errors\n     10.0 | 2.1590e-03 | 1.5325e-02 |      235439 |   109051904 |          204 |       13312 |        12.6 |reached target block errors\n```"
"```python\n# Load results (un-comment to show saved results from the cell above)\nPUSCH_SIMS = eval(\"{'scenario': ['umi'], 'domain': ['freq'], 'perfect_csi': [True, False], 'detector': ['kbest', 'lmmse'], 'ebno_db': [-2, -1, 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'speed': 3.0, 'batch_size_freq': 128, 'batch_size_time': 28, 'bler': [[0.865234375, 0.525390625, 0.236328125, 0.0703125, 0.022894965277777776, 0.0081787109375, 0.0031916920731707315, 0.0011800130208333333, 0.0007274208566108007, 0.000298828125, 0.000189453125, 0.000107421875, 4.6875e-05], [0.501953125, 0.2412109375, 0.13411458333333334, 0.06556919642857142, 0.037109375, 0.021073190789473683, 0.012251420454545454, 0.007244318181818182, 0.0038869121287128713, 0.0027646346830985913, 0.0015751008064516128, 0.0009838684538653367, 0.0007239105504587156], [0.994140625, 0.97265625, 0.849609375, 0.513671875, 0.234375, 0.115234375, 0.05126953125, 0.028878348214285716, 0.023092830882352942, 0.018694196428571428, 0.013671875, 0.012451171875, 0.013739224137931034], [0.919921875, 0.724609375, 0.533203125, 0.2802734375, 0.16536458333333334, 0.08984375, 0.056919642857142856, 0.043619791666666664, 0.035006009615384616, 0.02055921052631579, 0.017578125, 0.018465909090909092, 0.01532451923076923]], 'ber': [[0.08414149284362793, 0.03808903694152832, 0.013622879981994629, 0.00516200065612793, 0.0018940899107191297, 0.0006881306568781534, 0.0002859627328267912, 0.00012890001138051352, 9.374645169220823e-05, 3.3643484115600584e-05, 2.6883602142333983e-05, 1.2900114059448242e-05, 6.676435470581055e-06], [0.032366275787353516, 0.015960693359375, 0.009874105453491211, 0.004354306629725865, 0.00270201943137429, 0.0015692459909539473, 0.0008932893926447088, 0.0005442922765558416, 0.0002903820264457476, 0.00021878598441540356, 0.00013986518306116904, 7.878217911185171e-05, 6.43913898992976e-05], [0.15517663955688477, 0.12702298164367676, 0.08907222747802734, 0.036322832107543945, 0.015564680099487305, 0.008847415447235107, 0.005330264568328857, 0.003527675356183733, 0.0029088469112620633, 0.0025938579014369418, 0.002038750155218716, 0.0017822608351707458, 0.001927071604235419], [0.10343790054321289, 0.06611466407775879, 0.043680429458618164, 0.0217667818069458, 0.013199090957641602, 0.007306861877441406, 0.005208117621285575, 0.004094309277004666, 0.003994941711425781, 0.002383282310084293, 0.0023060985233472743, 0.002356225794011896, 0.002158962763272799]], 'duration': 4399.180883407593}\")\nprint(\"Simulation duration: {:1.2f} [h]\".format(PUSCH_SIMS[\"duration\"]/3600))\nplt.figure()\nplt.title(\"5G NR PUSCH over UMi Channel Model (8x16)\")\nplt.xlabel(\"SNR (dB)\")\nplt.ylabel(\"BLER\")\nplt.grid(which=\"both\")\nplt.xlim([PUSCH_SIMS[\"ebno_db\"][0], PUSCH_SIMS[\"ebno_db\"][-1]])\nplt.ylim([1e-5, 1.0])\ni = 0\nlegend = []\nfor scenario in PUSCH_SIMS[\"scenario\"]:\n    for domain in PUSCH_SIMS[\"domain\"]:\n        for perfect_csi in PUSCH_SIMS[\"perfect_csi\"]:\n            for detector in PUSCH_SIMS[\"detector\"]:\n                plt.semilogy(PUSCH_SIMS[\"ebno_db\"], PUSCH_SIMS[\"bler\"][i])\n                i += 1\n                csi = \"Perf. CSI\" if perfect_csi else \"Imperf. CSI\"\n                det = \"K-Best\" if detector==\"kbest\" else \"LMMSE\"\n                legend.append(det + \" \" + csi)\nplt.legend(legend);\n```"
"```python\nSimulation duration: 1.22 [h]\n```\n\n\nHopefully you have enjoyed this tutorial on Sionnas 5G NR PUSCH module!\n\nPlease have a look at the [API documentation](https://nvlabs.github.io/sionna/api/sionna.html) of the various components or the other available [tutorials](https://nvlabs.github.io/sionna/tutorials.html) to learn more.Please have a look at the [API documentation](https://nvlabs.github.io/sionna/api/sionna.html) of the various components or the other available [tutorials](https://nvlabs.github.io/sionna/tutorials.html) to learn more.\nPlease have a look at the [API documentation](https://nvlabs.github.io/sionna/api/sionna.html) of the various components or the other available [tutorials](https://nvlabs.github.io/sionna/tutorials.html) to learn more.Please have a look at the [API documentation](https://nvlabs.github.io/sionna/api/sionna.html) of the various components or the other available [tutorials](https://nvlabs.github.io/sionna/tutorials.html) to learn more."
"# Bit-Interleaved Coded Modulation (BICM)\n\nIn this notebook you will learn about the principles of bit interleaved coded modulation (BICM) and focus on the interface between LDPC decoding and demapping for higher order modulation. Further, we will discuss the idea of *all-zero codeword* simulations that enable bit-error rate simulations without having an explicit LDPC encoder available. In the last part, we analyze what happens for mismatched demapping, e.g., if the SNR is unknown and show how min-sum decoding can have practical\nadvantages in such cases.\n\n*From the coding viewpoint, the modulator, waveform channel, and demodulator together constitute a discrete channel with* $q$ *input letters and* $q'$ *output letters. [] the real goal of the modulation system is to create the best discrete memoryless channel (DMC) as seen by the coding system.* James L. Massey, 1974 [4, cf.preface in 5].\n\nThe fact that we usually separate modulation and coding into two individual tasks is strongly connected to the concept of bit-interleaved coded modulation (BICM) [1,2,5]. However, the joint optimization of coding and modulation has a long history, for example by Gottfried Ungerbcks *Trellis coded modulation* (TCM) [3] and we refer the interested reader to [1,2,5,6] for these *principles of coded modulation* [5]. Nonetheless, BICM has become the *de facto* standard in virtually any modern\ncommunication system due to its engineering simplicity.\n\nIn this notebook, you will use the following components:\n\n- Mapper / demapper and the constellation class\n- LDPC5GEncoder / LDPC5GDecoder\n- AWGN channel\n- BinarySource and GaussianPriorSource\n- Interleaver / deinterleaver\n- Scrambler / descrambler"
"## System Block Diagram\n\nWe introduce the following terminology:\n\n- `u` denotes the `k` uncoded information bits\n- `c` denotes the `n` codewords bits\n- `x` denotes the complex-valued symbols after mapping `m` bits to one symbol\n- `y` denotes the (noisy) channel observations\n- `l_ch` denotes the demappers llr estimate on each bit `c`\n- `u_hat` denotes the estimated information bits at the decoder output"
"## GPU Configuration and Imports\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n# Load the required Sionna components\nfrom sionna.mapping import Constellation, Mapper, Demapper\nfrom sionna.fec.ldpc import LDPC5GEncoder, LDPC5GDecoder, LDPCBPDecoder\nfrom sionna.fec.interleaving import RandomInterleaver, Deinterleaver\nfrom sionna.fec.scrambling import Scrambler, Descrambler\nfrom sionna.fec.utils import GaussianPriorSource, load_parity_check_examples, get_exit_analytic, plot_exit_chart, plot_trajectory\nfrom sionna.utils import BinarySource, ebnodb2no, hard_decisions\nfrom sionna.utils.plotting import PlotBER\nfrom sionna.channel import AWGN\n```\n\n```python\n# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n# For more details, see https://www.tensorflow.org/guide/gpu\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\n```"
"## A Simple BICM System\n\nThe principle idea of higher order modulation is to map *m* bits to one (complex-valued) symbol *x*. As each received symbol now contains information about *m* transmitted bits, the demapper produces *m* bit-wise LLR estimates (one per transmitted bit) where each LLR contains information about an individual bit. This scheme allows a simple binary interface between demapper and decoder.\n\nFrom a decoders perspective, the transmission of all *m* bits - mapped onto one symbol - could be modeled as if they have been transmitted over *m* different *surrogate* channels with certain properties as shown in the figure below.\n\n\nIn the following, we are now interested in the LLR distribution at the decoder input (= demapper output) for each of these *surrogate* channels (denoted as *bit-channels* in the following). Please note that in some scenario these surrogate channels can share the same statistical properties, e.g., for QPSK, both bit-channels behave equally due to symmetry.\n\nAdvanced note: the *m* binary LLR values are treated as independent estimates which is not exactly true for higher order modulation. As a result, the sum of the *bitwise* mutual information of all *m* transmitted bits does not exactly coincide with the *symbol-wise* mutual information describing the relation between channel input / output from a symbol perspective. However, in practice the (small) losses are usually neglected if a QAM with a rectangular grid and Gray labeling is used."
"### Constellations and Bit-Channels\n\nLet us first look at some higher order constellations.\n\n\n```python\n# show QPSK constellation\nconstellation = Constellation(\"qam\", num_bits_per_symbol=2)\nconstellation.show();\n```\n\n\nAssuming an AWGN channel and QPSK modulation all symbols behave equally due to the symmetry (all constellation points are located on a circle). However, for higher order modulation such as 16-QAM the situation changes and the LLRs after demapping are not equally distributed anymore.\n\n\n```python\n# generate 16QAM with Gray labeling\nconstellation = Constellation(\"qam\", num_bits_per_symbol=4)\nconstellation.show();\n```\n\n\nWe can visualize this by applying *a posteriori propability* (APP) demapping and plotting of the corresponding LLR distributions for each of the *m* transmitted bits per symbol individually. As each bit could be either *0* or *1*, we flip the signs of the LLRs *after* demapping accordingly. Otherwise, we would observe two symmetric distributions per bit *b_i* for *b_i=0* and *b_i=1*, respectively. See [10] for a closed-form approximation and further details.\n\n\n```python\n# simulation parameters\nbatch_size = int(1e6) # number of symbols to be analyzed\nnum_bits_per_symbol = 4 # bits per modulated symbol, i.e., 2^4 = 16-QAM\nebno_db = 4 # simulation SNR\n# init system components\nsource = BinarySource() # generates random info bits\n# we use a simple AWGN channel\nchannel = AWGN()\n# calculate noise var for given Eb/No (no code used at the moment)\nno = ebnodb2no(ebno_db, num_bits_per_symbol, coderate=1)\n# and generate bins for the histogram\nllr_bins = np.arange(-20,20,0.1)\n# initialize mapper and demapper for constellation object\nconstellation = Constellation(\"qam\", num_bits_per_symbol=num_bits_per_symbol)\nmapper = Mapper(constellation=constellation)\n# APP demapper\ndemapper = Demapper(\"app\", constellation=constellation)\n# Binary source that generates random 0s/1s\nb = source([batch_size, num_bits_per_symbol])\n# init mapper, channel and demapper\nx = mapper(b)\ny = channel([x, no])\nllr = demapper([y, no])\n# we flip the sign of all LLRs where b_i=0\n# this ensures that all positive LLRs mark correct decisions\n# all negative LLR values would lead to erroneous decisions\nllr_b = tf.multiply(llr, (2.*b-1.))\n# calculate LLR distribution for all bit-channels individually\nllr_dist = []\nfor i in range(num_bits_per_symbol):\n    llr_np = tf.reshape(llr_b[:,i],[-1]).numpy()\n    t, _ = np.histogram(llr_np, bins=llr_bins, density=True);\n    llr_dist.append(t)\n# and plot the results\nplt.figure(figsize=(20,8))\nplt.xticks(fontsize=18)\nplt.yticks(fontsize=18)\nplt.grid(which=\"both\")\nplt.xlabel(\"LLR value\", fontsize=25)\nplt.ylabel(\"Probability density\", fontsize=25)\nfor idx, llr_hist in enumerate(llr_dist):\n    leg_str = f\"Demapper output for bit_channel {idx} (sign corrected)\".format()\n    plt.plot(llr_bins[:-1], llr_hist, label=leg_str)\nplt.title(\"LLR distribution after demapping (16-QAM / AWGN)\", fontsize=25)\nplt.legend(fontsize=20);\n\n```"
"This also shows up in the bit-wise BER without any forward-error correction (FEC).\n\n\n```python\n# calculate bitwise BERs\nb_hat = hard_decisions(llr) # hard decide the LLRs\n# each bit where b != b_hat is defines a decision error\n# cast to tf.float32 to allow tf.reduce_mean operation\nerrors = tf.cast(tf.not_equal(b, b_hat), tf.float32)\n# calculate ber PER bit_channel\n# axis = 0 is the batch-dimension, i.e. contains individual estimates\n# axis = 1 contains the m individual bit channels\nber_per_bit = tf.reduce_mean(errors, axis=0)\nprint(\"BER per bit-channel: \", ber_per_bit.numpy())\n```\n\n\n```python\nBER per bit-channel:  [0.039274 0.039197 0.078234 0.077881]\n```\n\n\nSo far, we have not applied any outer channel coding. However, from the previous histograms it is obvious that the quality of the received LLRs depends bit index within a symbol. Further, LLRs may become correlated and each symbol error may lead to multiple erroneous received bits (mapped to the same symbol). The principle idea of BICM is to *break* the local dependencies by adding an interleaver between channel coding and mapper (or demapper and decoder, respectively).\n\nFor sufficiently long codes (and well-suited interleavers), the channel decoder effectively *sees* one channel. This separation enables the - from engineerings perspective - simplified and elegant design of channel coding schemes based on binary bit-metric decoding while following Masseys original spirit that *the real goal of the modulation system is to create the best discrete memoryless channel (DMC) as seen by the coding system* [1]."
"### Simple BER Simulations\n\nWe are now interested to simulate the BER of the BICM system including LDPC codes. For this, we use the class `PlotBER` which essentially provides convenience functions for BER simulations. It internally calls `sim_ber()` to simulate each SNR point until reaching a pre-defined target number of errors.\n\n**Note**: a custom BER simulation is always possible. However, without early stopping the simulations can take significantly more simulation time and `PlotBER` directly stores the results internally for later comparison.\n\n\n```python\n# generate new figure\nber_plot_allzero = PlotBER(\"BER Performance of All-zero Codeword Simulations\")\n# and define baseline\nnum_bits_per_symbol = 2 # QPSK\nnum_bp_iter = 20 # number of decoder iterations\n# LDPC code parameters\nk = 600 # number of information bits per codeword\nn = 1200 # number of codeword bits\n# and the initialize the LDPC encoder / decoder\nencoder = LDPC5GEncoder(k, n)\ndecoder = LDPC5GDecoder(encoder, # connect encoder (for shared code parameters)\n                        cn_type=\"boxplus-phi\", # use the exact boxplus function\n                        num_iter=num_bp_iter)\n# initialize a random interleaver and corresponding deinterleaver\ninterleaver = RandomInterleaver()\ndeinterleaver = Deinterleaver(interleaver)\n# mapper and demapper\nconstellation = Constellation(\"qam\", num_bits_per_symbol=num_bits_per_symbol)\nmapper = Mapper(constellation=constellation)\ndemapper = Demapper(\"app\", constellation=constellation) # APP demapper\n# define system\n@tf.function() # we enable graph mode for faster simulations\ndef run_ber(batch_size, ebno_db):\n    # calculate noise variance\n    no = ebnodb2no(ebno_db,\n                   num_bits_per_symbol=num_bits_per_symbol,\n                   coderate=k/n)\n    u = source([batch_size, k]) # generate random bit sequence to transmit\n    c = encoder(u) # LDPC encode (incl. rate-matching and CRC concatenation)\n    c_int = interleaver(c)\n    x = mapper(c_int) # map to symbol (QPSK)\n    y = channel([x, no]) # transmit over AWGN channel\n    llr_ch = demapper([y, no]) # demapp\n    llr_deint = deinterleaver(llr_ch)\n    u_hat = decoder(llr_deint) # run LDPC decoder (incl. de-rate-matching)\n    return u, u_hat\n\n```"
"We simulate the BER at each SNR point in `ebno_db` for a given `batch_size` of samples. In total, per SNR point `max_mc_iter` batches are simulated.\n\nTo improve the simulation throughput, several optimizations are available:\n<ol class=\"arabic simple\">\n- ) Continue with next SNR point if `num_target_bit_errors` is reached (or `num_target_block_errors`).\n- ) Stop simulation if current SNR point returned no error (usually the BER is monotonic w.r.t. the SNR, i.e., a higher SNR point will also return BER=0)\n</ol>\n\n**Note**: by setting `forward_keyboard_interrupt`=False, the simulation can be interrupted at any time and returns the intermediate results.\n\n\n```python\n # the first argument must be a callable (function) that yields u and u_hat for batch_size and ebno\nber_plot_allzero.simulate(run_ber, # the function have defined previously\n                          ebno_dbs=np.arange(0, 5, 0.25), # sim SNR range\n                          legend=\"Baseline (with encoder)\",\n                          max_mc_iter=50,\n                          num_target_bit_errors=1000,\n                          batch_size=1000,\n                          soft_estimates=False,\n                          early_stop=True,\n                          show_fig=True,\n                          forward_keyboard_interrupt=False);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 1.6451e-01 | 1.0000e+00 |       98705 |      600000 |         1000 |        1000 |         2.8 |reached target bit errors\n     0.25 | 1.3982e-01 | 9.8800e-01 |       83894 |      600000 |          988 |        1000 |         0.1 |reached target bit errors\n      0.5 | 1.0626e-01 | 9.2300e-01 |       63753 |      600000 |          923 |        1000 |         0.1 |reached target bit errors\n     0.75 | 6.5253e-02 | 7.5400e-01 |       39152 |      600000 |          754 |        1000 |         0.1 |reached target bit errors\n      1.0 | 2.9843e-02 | 4.6000e-01 |       17906 |      600000 |          460 |        1000 |         0.1 |reached target bit errors\n     1.25 | 1.0292e-02 | 2.0900e-01 |        6175 |      600000 |          209 |        1000 |         0.1 |reached target bit errors\n      1.5 | 2.8617e-03 | 7.1000e-02 |        1717 |      600000 |           71 |        1000 |         0.1 |reached target bit errors\n     1.75 | 6.5556e-04 | 1.5000e-02 |        1180 |     1800000 |           45 |        3000 |         0.2 |reached target bit errors\n      2.0 | 7.7955e-05 | 1.9545e-03 |        1029 |    13200000 |           43 |       22000 |         1.8 |reached target bit errors\n     2.25 | 5.4000e-06 | 3.6000e-04 |         162 |    30000000 |           18 |       50000 |         4.1 |reached max iter\n      2.5 | 5.6667e-07 | 1.2000e-04 |          17 |    30000000 |            6 |       50000 |         4.1 |reached max iter\n     2.75 | 2.0000e-07 | 2.0000e-05 |           6 |    30000000 |            1 |       50000 |         4.1 |reached max iter\n      3.0 | 0.0000e+00 | 0.0000e+00 |           0 |    30000000 |            0 |       50000 |         4.1 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 3.0 dB.\n\n```"
"## All-zero Codeword Simulations\n\nIn this section you will learn about how to simulate accurate BER curves without the need for having an actual encoder in-place. We compare each step with the ground truth from the Sionna encoder:\n<ol class=\"arabic simple\">\n- ) Simulate baseline with encoder as done above.\n- ) Remove encoder: Simulate QPSK with all-zero codeword transmission.\n- ) Gaussian approximation (for BPSK/QPSK): Remove (de-)mapping and mimic the LLR distribution for the all-zero codeword.\n- ) Learn that a scrambler is required for higher order modulation schemes.\n</ol>\n\nAn important property of linear codes is that each codewords has - in average - the same behavior. Thus, for BER simulations the all-zero codeword is sufficient.\n\n**Note**: strictly speaking, this requires *symmetric* decoders in a sense that the decoder is not biased towards positive or negative LLRs (e.g., by interpreting $\\ell_\\text{ch}=0$ as positive value). However, in practice this can be either avoided or is often neglected.\n\nRecall that we have simulated the following setup as baseline. Note: for simplicity and readability, the interleaver is omitted in the following.\n\n\nLet us implement a Keras model that can be re-used and configured for the later experiments.\n\n\n```python\nclass LDPC_QAM_AWGN(tf.keras.Model):\n    \"\"\"System model for channel coding BER simulations.\n    This model allows to simulate BERs over an AWGN channel with\n    QAM modulation. It can enable/disable multiple options to analyse all-zero codeword simulations.\n    If active, the system uses the 5G LDPC encoder/decoder module.\n    Parameters\n    ----------\n        k: int\n            number of information bits per codeword.\n        n: int\n            codeword length.\n        num_bits_per_symbol: int\n            number of bits per QAM symbol.\n        demapping_method: str\n            A string defining the demapping method. Can be either \"app\" or \"maxlog\".\n        decoder_type: str\n            A string defining the check node update function type of the LDPC decoder.\n        use_allzero: bool\n            A boolean defaults to False. If True, no encoder is used and all-zero codewords are sent.\n        use_scrambler: bool\n            A boolean defaults to False. If True, a scrambler after the encoder and a descrambler before the decoder\n            is used, respectively.\n        use_ldpc_output_interleaver: bool\n            A boolean defaults to False. If True, the output interleaver as\n            defined in 3GPP 38.212 is applied after rate-matching.\n        no_est_mismatch: float\n            A float defaults to 1.0. Defines the SNR estimation mismatch of the demapper such that the effective demapping\n            noise variance estimate is the scaled by ``no_est_mismatch`` version of the true noise_variance\n    Input\n    -----\n        batch_size: int or tf.int\n            The batch_size used for the simulation.\n        ebno_db: float or tf.float\n            A float defining the simulation SNR.\n    Output\n    ------\n        (u, u_hat):\n            Tuple:\n        u: tf.float32\n            A tensor of shape `[batch_size, k] of 0s and 1s containing the transmitted information bits.\n        u_hat: tf.float32\n            A tensor of shape `[batch_size, k] of 0s and 1s containing the estimated information bits.\n    \"\"\"\n    def __init__(self,\n                 k,\n                 n,\n                 num_bits_per_symbol,\n                 demapping_method=\"app\",\n                 decoder_type=\"boxplus\",\n                 use_allzero=False,\n                 use_scrambler=False,\n                 use_ldpc_output_interleaver=False,\n                 no_est_mismatch=1.):\n        super().__init__()\n        self.k = k\n        self.n = n\n        self.num_bits_per_symbol = num_bits_per_symbol\n        self.use_allzero = use_allzero\n        self.use_scrambler = use_scrambler\n        # adds noise to SNR estimation at demapper\n        # see last section \"mismatched demapping\"\n        self.no_est_mismatch = no_est_mismatch\n        # init components\n        self.source = BinarySource()\n        # initialize mapper and demapper with constellation object\n        self.constellation = Constellation(\"qam\",\n                                num_bits_per_symbol=self.num_bits_per_symbol)\n        self.mapper = Mapper(constellation=self.constellation)\n        self.demapper = Demapper(demapping_method,\n                                 constellation=self.constellation)\n        self.channel = AWGN()\n        # LDPC encoder / decoder\n        if use_ldpc_output_interleaver:\n            # the output interleaver needs knowledge of the modulation order\n            self.encoder = LDPC5GEncoder(self.k, self.n, num_bits_per_symbol)\n        else:\n            self.encoder = LDPC5GEncoder(self.k, self.n)\n        self.decoder = LDPC5GDecoder(self.encoder, cn_type=decoder_type)\n        self.scrambler = Scrambler()\n        # connect descrambler to scrambler\n        self.descrambler = Descrambler(self.scrambler, binary=False)\n    @tf.function() # enable graph mode for higher throughputs\n    def call(self, batch_size, ebno_db):\n        # calculate noise variance\n        no = ebnodb2no(ebno_db,\n                       num_bits_per_symbol=self.num_bits_per_symbol,\n                       coderate=self.k/self.n)\n        if self.use_allzero:\n            u = tf.zeros([batch_size, self.k]) # only needed for\n            c = tf.zeros([batch_size, self.n]) # replace enc. with all-zero codeword\n        else:\n            u = self.source([batch_size, self.k])\n            c = self.encoder(u) # explicitly encode\n        # scramble codeword if actively required\n        if self.use_scrambler:\n            c = self.scrambler(c)\n        x = self.mapper(c) # map c to symbols\n        y = self.channel([x, no]) # transmit over AWGN channel\n        # add noise estimation mismatch for demapper (see last section)\n        # set to 1 per default -> no mismatch\n        no_est = no * self.no_est_mismatch\n        llr_ch = self.demapper([y, no_est]) # demapp\n        if self.use_scrambler:\n            llr_ch = self.descrambler(llr_ch)\n        u_hat = self.decoder(llr_ch) # run LDPC decoder (incl. de-rate-matching)\n        return u, u_hat\n```"
"### Remove Encoder: Simulate QPSK with All-zero Codeword Transmission\n\nWe now simulate the same system *without* encoder and transmit constant *0*s.\n\nDue to the symmetry of the QPSK, no scrambler is required. You will learn about the effect of the scrambler in the last section.\n\n\n```python\nmodel_allzero = LDPC_QAM_AWGN(k,\n                              n,\n                              num_bits_per_symbol=2,\n                              use_allzero=True, # disable encoder\n                              use_scrambler=False) # we do not use a scrambler for the moment (QPSK!)\n# and simulate the new curve\n# Hint: as the model is callable, we can directly pass it to the\n# Monte Carlo simulation\nber_plot_allzero.simulate(model_allzero,\n                          ebno_dbs=np.arange(0, 5, 0.25),\n                          legend=\"All-zero / QPSK (no encoder)\",\n                          max_mc_iter=50,\n                          num_target_bit_errors=1000,\n                          batch_size=1000,\n                          soft_estimates=False,\n                          show_fig=True,\n                          forward_keyboard_interrupt=False);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 1.6225e-01 | 1.0000e+00 |       97348 |      600000 |         1000 |        1000 |         0.7 |reached target bit errors\n     0.25 | 1.3823e-01 | 9.9000e-01 |       82941 |      600000 |          990 |        1000 |         0.0 |reached target bit errors\n      0.5 | 1.0630e-01 | 9.3400e-01 |       63783 |      600000 |          934 |        1000 |         0.0 |reached target bit errors\n     0.75 | 6.3673e-02 | 7.5400e-01 |       38204 |      600000 |          754 |        1000 |         0.0 |reached target bit errors\n      1.0 | 2.8445e-02 | 4.4100e-01 |       17067 |      600000 |          441 |        1000 |         0.0 |reached target bit errors\n     1.25 | 1.0038e-02 | 2.1400e-01 |        6023 |      600000 |          214 |        1000 |         0.0 |reached target bit errors\n      1.5 | 3.2500e-03 | 5.7000e-02 |        1950 |      600000 |           57 |        1000 |         0.0 |reached target bit errors\n     1.75 | 3.9667e-04 | 1.4600e-02 |        1190 |     3000000 |           73 |        5000 |         0.2 |reached target bit errors\n      2.0 | 5.0960e-05 | 1.7273e-03 |        1009 |    19800000 |           57 |       33000 |         1.5 |reached target bit errors\n     2.25 | 9.2333e-06 | 1.8000e-04 |         277 |    30000000 |            9 |       50000 |         2.3 |reached max iter\n      2.5 | 2.0667e-06 | 2.0000e-05 |          62 |    30000000 |            1 |       50000 |         2.4 |reached max iter\n     2.75 | 0.0000e+00 | 0.0000e+00 |           0 |    30000000 |            0 |       50000 |         2.4 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 2.8 dB.\n\n```"
"### Remove (De-)Mapping: Approximate the LLR Distribution of the All-zero Codeword (and BPSK/QPSK)\n\nFor the all-zero codeword, the BPSK mapper generates the *all-one* signal (as each *0* is mapped to a *1*).\n\nAssuming an AWGN channel with noise variance $\\sigma_\\text{ch}^2$, it holds that the output of the channel $y$ is Gaussian distributed with mean $\\mu=1$ and noise variance $\\sigma_\\text{ch}^2$. Demapping of the BPSK symbols is given as $\\ell_\\text{ch} = -\\frac{2}{\\sigma_\\text{ch}^2}y$.\n\nThis leads to the effective LLR distribution of $\\ell_\\text{ch} \\sim \\mathcal{N}(-\\frac{2}{\\sigma_\\text{ch}^2},\\frac{4}{\\sigma_\\text{ch}^2})$ and, thereby, allows to mimic the mapper, AWGN channel and demapper by a Gaussian distribution. The layer `GaussianPriorSource` provides such a source for arbitrary shapes.\n\nThe same derivation holds for QPSK. Let us quickly verify the correctness of these results by a Monte Carlo simulation.\n\n**Note**: the negative sign for the BPSK demapping rule comes from the (in communications) unusual definition of logits $\\ell = \\operatorname{log} \\frac{p(x=1)}{p(x=0)}$.\n\n\n```python\nnum_bits_per_symbol = 2 # we use QPSK\nebno_db = 4 # choose any SNR\nbatch_size = 100000 # we only simulate 1 symbol per batch\n# calculate noise variance\nno = ebnodb2no(ebno_db,\n               num_bits_per_symbol=num_bits_per_symbol,\n               coderate=k/n)\n# generate bins for the histogram\nllr_bins = np.arange(-20, 20, 0.2)\nc = tf.zeros([batch_size, num_bits_per_symbol]) # all-zero codeword\nx = mapper(c) # mapped to constant symbol\ny = channel([x, no])\nllr = demapper([y, no]) # and generate LLRs\nllr_dist, _ = np.histogram(llr.numpy() , bins=llr_bins, density=True);\n# negative mean value due to different logit/llr definition\n# llr = log[(x=1)/p(x=0)]\nmu_llr = -2 / no\nno_llr = 4 / no\n# generate Gaussian pdf\nllr_pred = 1/np.sqrt(2*np.pi*no_llr) * np.exp(-(llr_bins-mu_llr)**2/(2*no_llr))\n# and compare the results\nplt.figure(figsize=(20,8))\nplt.xticks(fontsize=18)\nplt.yticks(fontsize=18)\nplt.grid(which=\"both\")\nplt.xlabel(\"LLR value\", fontsize=25)\nplt.ylabel(\"Probability density\", fontsize=25)\nplt.plot(llr_bins[:-1], llr_dist, label=\"Measured LLR distribution\")\nplt.plot(llr_bins, llr_pred, label=\"Analytical LLR distribution (GA)\")\nplt.title(\"LLR distribution after demapping\", fontsize=25)\nplt.legend(fontsize=20);\n```"
"```python\nnum_bits_per_symbol = 2 # QPSK\n# initialize LLR source\nga_source = GaussianPriorSource()\n@tf.function() # enable graph mode\ndef run_ber_ga(batch_size, ebno_db):\n    # calculate noise variance\n    no = ebnodb2no(ebno_db,\n                   num_bits_per_symbol=num_bits_per_symbol,\n                   coderate=k/n)\n    u = tf.zeros([batch_size, k]) # only needed for ber calculations\n    llr_ch = ga_source([[batch_size, n], no]) # generate LLRs directly\n    u_hat = decoder(llr_ch) # run LDPC decoder (incl. de-rate-matching)\n    return u, u_hat\n# and simulate the new curve\nber_plot_allzero.simulate(run_ber_ga,\n                          ebno_dbs=np.arange(0, 5, 0.25), # simulation SNR,\n                          max_mc_iter=50,\n                          num_target_bit_errors=1000,\n                          legend=\"Gaussian Approximation of LLRs\",\n                          batch_size = 10000,\n                          soft_estimates=False,\n                          show_fig=True,\n                          forward_keyboard_interrupt=False);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 1.6506e-01 | 9.9930e-01 |      990347 |     6000000 |         9993 |       10000 |         1.3 |reached target bit errors\n     0.25 | 1.3984e-01 | 9.9030e-01 |      839044 |     6000000 |         9903 |       10000 |         0.4 |reached target bit errors\n      0.5 | 1.0517e-01 | 9.3200e-01 |      631049 |     6000000 |         9320 |       10000 |         0.4 |reached target bit errors\n     0.75 | 6.5437e-02 | 7.6580e-01 |      392623 |     6000000 |         7658 |       10000 |         0.4 |reached target bit errors\n      1.0 | 3.1496e-02 | 4.7400e-01 |      188979 |     6000000 |         4740 |       10000 |         0.4 |reached target bit errors\n     1.25 | 1.0650e-02 | 2.0850e-01 |       63902 |     6000000 |         2085 |       10000 |         0.4 |reached target bit errors\n      1.5 | 2.5667e-03 | 6.3700e-02 |       15400 |     6000000 |          637 |       10000 |         0.4 |reached target bit errors\n     1.75 | 3.8483e-04 | 1.1200e-02 |        2309 |     6000000 |          112 |       10000 |         0.4 |reached target bit errors\n      2.0 | 4.6333e-05 | 1.9500e-03 |        1112 |    24000000 |           78 |       40000 |         1.5 |reached target bit errors\n     2.25 | 6.7133e-06 | 2.5200e-04 |        1007 |   150000000 |           63 |      250000 |         9.6 |reached target bit errors\n      2.5 | 1.1267e-06 | 4.4000e-05 |         338 |   300000000 |           22 |      500000 |        19.2 |reached max iter\n     2.75 | 5.0000e-08 | 6.0000e-06 |          15 |   300000000 |            3 |      500000 |        19.2 |reached max iter\n      3.0 | 0.0000e+00 | 0.0000e+00 |           0 |   300000000 |            0 |      500000 |        19.2 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 3.0 dB.\n\n```"
"### The Role of the Scrambler\n\nSo far, we have seen that the all-zero codeword yields the same error-rates as any other sequence. Intuitively, the *all-zero codeword trick* generates a constant stream of *0*s at the input of the mapper. However, if the channel is not symmetric we need to ensure that we capture the *average* behavior of all possible symbols equally. Mathematically this symmetry condition can be expressed as $p(Y=y|c=0)=p(Y=-y|c=1)$\n\nAs shown in the previous experiments, for QPSK both *bit-channels* have the same behavior but for 16-QAM systems this does not hold anymore and our simulated BER does not represent the average decoding performance of the original system.\n\nOne possible solution is to scramble the all-zero codeword before transmission and descramble the received LLRs before decoding (i.e., flip the sign accordingly). This ensures that the mapper/demapper (+channel) operate on (pseudo-)random data, but from decoders perspective the the all-zero codeword assumption is still valid. This avoids the need for an actual encoder. For further details, we refer to *i.i.d. channel adapters* in [9].\n\n**Note**: another example is that the recorded LLRs can be even used to evaluate different codes as the all-zero codeword is a valid codeword for all linear codes. Going one step further, one can even simulate codes of different rates with the same pre-recorded LLRs.\n\n\n```python\n# we generate a new plot\nber_plot_allzero16qam = PlotBER(\"BER Performance for 64-QAM\")\n```\n\n```python\n# simulate a new baseline for 16-QAM\nmodel_baseline_16 = LDPC_QAM_AWGN(k,\n                                  n,\n                                  num_bits_per_symbol=4,\n                                  use_allzero=False, # baseline without all-zero\n                                  use_scrambler=False)\n\n# and simulate the new curve\n# Hint: as the model is callable, we can directly pass it to the\n# Monte Carlo simulation\nber_plot_allzero16qam.simulate(model_baseline_16,\n                               ebno_dbs=np.arange(0, 5, 0.25),\n                               legend=\"Baseline 16-QAM\",\n                               max_mc_iter=50,\n                               num_target_bit_errors=2000,\n                               batch_size=1000,\n                               soft_estimates=False,\n                               show_fig=True,\n                               forward_keyboard_interrupt=False);\n```"
"```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 2.4823e-01 | 1.0000e+00 |      148935 |      600000 |         1000 |        1000 |         0.6 |reached target bit errors\n     0.25 | 2.4005e-01 | 1.0000e+00 |      144029 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n      0.5 | 2.3212e-01 | 1.0000e+00 |      139273 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n     0.75 | 2.2350e-01 | 1.0000e+00 |      134100 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n      1.0 | 2.1467e-01 | 1.0000e+00 |      128802 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n     1.25 | 2.0421e-01 | 1.0000e+00 |      122527 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n      1.5 | 1.9363e-01 | 1.0000e+00 |      116180 |      600000 |         1000 |        1000 |         0.1 |reached target bit errors\n     1.75 | 1.8410e-01 | 1.0000e+00 |      110457 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n      2.0 | 1.6776e-01 | 1.0000e+00 |      100654 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n     2.25 | 1.5180e-01 | 9.9800e-01 |       91079 |      600000 |          998 |        1000 |         0.0 |reached target bit errors\n      2.5 | 1.2620e-01 | 9.8100e-01 |       75718 |      600000 |          981 |        1000 |         0.0 |reached target bit errors\n     2.75 | 9.9148e-02 | 9.2800e-01 |       59489 |      600000 |          928 |        1000 |         0.0 |reached target bit errors\n      3.0 | 6.3128e-02 | 7.5700e-01 |       37877 |      600000 |          757 |        1000 |         0.0 |reached target bit errors\n     3.25 | 3.3372e-02 | 5.3100e-01 |       20023 |      600000 |          531 |        1000 |         0.0 |reached target bit errors\n      3.5 | 1.3293e-02 | 2.5000e-01 |        7976 |      600000 |          250 |        1000 |         0.0 |reached target bit errors\n     3.75 | 4.1550e-03 | 9.6000e-02 |        2493 |      600000 |           96 |        1000 |         0.1 |reached target bit errors\n      4.0 | 8.7625e-04 | 2.6750e-02 |        2103 |     2400000 |          107 |        4000 |         0.2 |reached target bit errors\n     4.25 | 2.2256e-04 | 7.4667e-03 |        2003 |     9000000 |          112 |       15000 |         0.7 |reached target bit errors\n      4.5 | 2.8000e-05 | 1.3800e-03 |         840 |    30000000 |           69 |       50000 |         2.5 |reached max iter\n     4.75 | 9.8333e-06 | 2.6000e-04 |         295 |    30000000 |           13 |       50000 |         2.5 |reached max iter\n```"
"We now apply the *all-zero trick* as above and simulate ther BER performance without scrambling.\n\n\n```python\n# and repeat the experiment for a 16QAM WITHOUT scrambler\nmodel_allzero_16_no_sc = LDPC_QAM_AWGN(k,\n                                       n,\n                                       num_bits_per_symbol=4,\n                                       use_allzero=True, # all-zero codeword\n                                       use_scrambler=False) # no scrambler used\n\n# and simulate the new curve\n# Hint: as the model is callable, we can directly pass it to the\n# Monte Carlo simulation\nber_plot_allzero16qam.simulate(model_allzero_16_no_sc,\n                               ebno_dbs=np.arange(0, 5, 0.25),\n                               legend=\"All-zero / 16-QAM (no scrambler!)\",\n                               max_mc_iter=50,\n                               num_target_bit_errors=1000,\n                               batch_size=1000,\n                               soft_estimates=False,\n                               show_fig=True,\n                               forward_keyboard_interrupt=False);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 3.0219e-01 | 1.0000e+00 |      181313 |      600000 |         1000 |        1000 |         0.6 |reached target bit errors\n     0.25 | 2.9814e-01 | 1.0000e+00 |      178883 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n      0.5 | 2.9287e-01 | 1.0000e+00 |      175723 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n     0.75 | 2.8685e-01 | 1.0000e+00 |      172110 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n      1.0 | 2.8033e-01 | 1.0000e+00 |      168200 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n     1.25 | 2.7465e-01 | 1.0000e+00 |      164788 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n      1.5 | 2.6829e-01 | 1.0000e+00 |      160973 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n     1.75 | 2.6168e-01 | 1.0000e+00 |      157010 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n      2.0 | 2.5387e-01 | 1.0000e+00 |      152321 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n     2.25 | 2.4709e-01 | 1.0000e+00 |      148254 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n      2.5 | 2.3761e-01 | 1.0000e+00 |      142565 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n     2.75 | 2.2822e-01 | 1.0000e+00 |      136932 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n      3.0 | 2.1826e-01 | 1.0000e+00 |      130957 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n     3.25 | 2.0818e-01 | 1.0000e+00 |      124910 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n      3.5 | 1.9476e-01 | 1.0000e+00 |      116858 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n     3.75 | 1.8143e-01 | 1.0000e+00 |      108859 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n      4.0 | 1.6426e-01 | 9.9900e-01 |       98558 |      600000 |          999 |        1000 |         0.0 |reached target bit errors\n     4.25 | 1.4198e-01 | 9.9600e-01 |       85186 |      600000 |          996 |        1000 |         0.0 |reached target bit errors\n      4.5 | 1.0259e-01 | 9.4800e-01 |       61554 |      600000 |          948 |        1000 |         0.0 |reached target bit errors\n     4.75 | 6.0183e-02 | 7.6300e-01 |       36110 |      600000 |          763 |        1000 |         0.0 |reached target bit errors\n```"
"As expected the results are wrong as we have transmitted all bits over the *less reliable* channel (cf [BER per bit-channel](https://nvlabs.github.io/sionna/examples/Bit_Interleaved_Coded_Modulation.html#Constellations-and-Bit-Channels)).\n\nLet us repeat this experiment with scrambler and descrambler at the correct position.\n\n\n```python\n# and repeat the experiment for a 16QAM WITHOUT scrambler\nmodel_allzero_16_sc = LDPC_QAM_AWGN(k,\n                                    n,\n                                    num_bits_per_symbol=4,\n                                    use_allzero=True, # all-zero codeword\n                                    use_scrambler=True) # activate scrambler\n\n# and simulate the new curve\n# Hint: as the model is callable, we can directly pass it to the\n# Monte Carlo simulation\nber_plot_allzero16qam.simulate(model_allzero_16_sc,\n                               ebno_dbs=np.arange(0, 5, 0.25),\n                               legend=\"All-zero / 16-QAM (with scrambler)\",\n                               max_mc_iter=50,\n                               num_target_bit_errors=1000,\n                               batch_size=1000,\n                               soft_estimates=False,\n                               show_fig=True,\n                               forward_keyboard_interrupt=False);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 2.4735e-01 | 1.0000e+00 |      148407 |      600000 |         1000 |        1000 |         0.9 |reached target bit errors\n     0.25 | 2.4123e-01 | 1.0000e+00 |      144737 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n      0.5 | 2.3287e-01 | 1.0000e+00 |      139721 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n     0.75 | 2.2510e-01 | 1.0000e+00 |      135062 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n      1.0 | 2.1514e-01 | 1.0000e+00 |      129083 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n     1.25 | 2.0605e-01 | 1.0000e+00 |      123628 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n      1.5 | 1.9327e-01 | 1.0000e+00 |      115961 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n     1.75 | 1.8327e-01 | 1.0000e+00 |      109961 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n      2.0 | 1.6901e-01 | 1.0000e+00 |      101406 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n     2.25 | 1.5102e-01 | 9.9900e-01 |       90611 |      600000 |          999 |        1000 |         0.0 |reached target bit errors\n      2.5 | 1.2854e-01 | 9.7500e-01 |       77123 |      600000 |          975 |        1000 |         0.0 |reached target bit errors\n     2.75 | 9.5707e-02 | 9.1200e-01 |       57424 |      600000 |          912 |        1000 |         0.0 |reached target bit errors\n      3.0 | 6.2627e-02 | 7.5700e-01 |       37576 |      600000 |          757 |        1000 |         0.0 |reached target bit errors\n     3.25 | 3.5712e-02 | 5.2800e-01 |       21427 |      600000 |          528 |        1000 |         0.0 |reached target bit errors\n      3.5 | 1.4118e-02 | 2.6100e-01 |        8471 |      600000 |          261 |        1000 |         0.0 |reached target bit errors\n     3.75 | 4.9117e-03 | 1.0900e-01 |        2947 |      600000 |          109 |        1000 |         0.0 |reached target bit errors\n      4.0 | 9.9583e-04 | 2.9000e-02 |        1195 |     1200000 |           58 |        2000 |         0.1 |reached target bit errors\n     4.25 | 2.8905e-04 | 8.5714e-03 |        1214 |     4200000 |           60 |        7000 |         0.3 |reached target bit errors\n      4.5 | 3.4320e-05 | 1.2857e-03 |        1009 |    29400000 |           63 |       49000 |         2.3 |reached target bit errors\n     4.75 | 4.1000e-06 | 2.6000e-04 |         123 |    30000000 |           13 |       50000 |         2.4 |reached max iter\n```"
"The 5G standard defines an additional output interleaver after the rate-matching (see Sec. 5.4.2.2 in [11]).\n\nWe now activate this additional interleaver to enable additional BER gains.\n\n\n```python\n# activate output interleaver\nmodel_output_interleaver= LDPC_QAM_AWGN(k,\n                                        n,\n                                        num_bits_per_symbol=4,\n                                        use_ldpc_output_interleaver=True,\n                                        use_allzero=False,\n                                        use_scrambler=False)\n\n# and simulate the new curve\n# Hint: as the model is callable, we can directly pass it to the\n# Monte Carlo simulation\nber_plot_allzero16qam.simulate(model_output_interleaver,\n                               ebno_dbs=np.arange(0, 5, 0.25),\n                               legend=\"16-QAM with 5G FEC interleaver\",\n                               max_mc_iter=50,\n                               num_target_bit_errors=1000,\n                               batch_size=1000,\n                               soft_estimates=False,\n                               show_fig=True,\n                               forward_keyboard_interrupt=False);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 1.9663e-01 | 1.0000e+00 |      117980 |      600000 |         1000 |        1000 |         0.7 |reached target bit errors\n     0.25 | 1.9138e-01 | 1.0000e+00 |      114830 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n      0.5 | 1.8279e-01 | 1.0000e+00 |      109673 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n     0.75 | 1.7542e-01 | 1.0000e+00 |      105255 |      600000 |         1000 |        1000 |         0.1 |reached target bit errors\n      1.0 | 1.6715e-01 | 1.0000e+00 |      100289 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n     1.25 | 1.5677e-01 | 1.0000e+00 |       94061 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n      1.5 | 1.4749e-01 | 1.0000e+00 |       88497 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n     1.75 | 1.3550e-01 | 1.0000e+00 |       81298 |      600000 |         1000 |        1000 |         0.1 |reached target bit errors\n      2.0 | 1.1884e-01 | 9.9900e-01 |       71302 |      600000 |          999 |        1000 |         0.0 |reached target bit errors\n     2.25 | 1.0189e-01 | 9.8200e-01 |       61135 |      600000 |          982 |        1000 |         0.1 |reached target bit errors\n      2.5 | 7.6883e-02 | 9.5000e-01 |       46130 |      600000 |          950 |        1000 |         0.0 |reached target bit errors\n     2.75 | 5.0982e-02 | 8.0000e-01 |       30589 |      600000 |          800 |        1000 |         0.0 |reached target bit errors\n      3.0 | 2.9085e-02 | 5.7600e-01 |       17451 |      600000 |          576 |        1000 |         0.0 |reached target bit errors\n     3.25 | 1.0312e-02 | 2.9500e-01 |        6187 |      600000 |          295 |        1000 |         0.0 |reached target bit errors\n      3.5 | 3.6233e-03 | 1.3000e-01 |        2174 |      600000 |          130 |        1000 |         0.1 |reached target bit errors\n     3.75 | 1.0858e-03 | 4.7500e-02 |        1303 |     1200000 |           95 |        2000 |         0.1 |reached target bit errors\n      4.0 | 2.3857e-04 | 1.4286e-02 |        1002 |     4200000 |          100 |        7000 |         0.4 |reached target bit errors\n     4.25 | 3.6146e-05 | 2.4792e-03 |        1041 |    28800000 |          119 |       48000 |         2.4 |reached target bit errors\n      4.5 | 1.2333e-05 | 9.6000e-04 |         370 |    30000000 |           48 |       50000 |         2.5 |reached max iter\n     4.75 | 1.9333e-06 | 1.8000e-04 |          58 |    30000000 |            9 |       50000 |         2.5 |reached max iter\n```"
"## EXIT Charts\n\nYou now learn about how the convergence behavior of iterative receivers can be visualized.\n\nExtrinsic Information Transfer (EXIT) charts [7] are a widely adopted tool to analyze the convergence behavior of iterative receiver algorithms. The principle idea is to treat each component decoder (or demapper etc.) as individual entity with its own EXIT characteristic. EXIT charts not only allow to predict the decoding behavior (*open decoding tunnel*) but also enable LDPC code design (cf.[8]). However, this is beyond the scope of this notebook.\n\nWe can analytically derive the EXIT characteristic for check node (CN) and variable node (VN) decoder for a given code with `get_exit_analytic`. Further, if the `LDPCBPDecoder` is initialized with option `track_exit`=True, it internally stores the average extrinsic mutual information after each iteration at the output of the VN/CN decoder.\n\nPlease note that this is only an approximation for the AWGN channel and assumes infinite code length. However, it turns out that the results are often accurate enough and\n\n\n```python\n# parameters\nebno_db = 2.3\nbatch_size = 10000\nnum_bits_per_symbol = 2\npcm_id = 4 # decide which parity check matrix should be used (0-2: BCH; 3: (3,6)-LDPC 4: LDPC 802.11n\npcm, k_exit, n_exit, coderate = load_parity_check_examples(pcm_id, verbose=True)\n# init components\ndecoder_exit = LDPCBPDecoder(pcm,\n                             hard_out=False,\n                             cn_type=\"boxplus\",\n                             trainable=False,\n                             track_exit=True,\n                             num_iter=20)\n# generates fake llrs as if the all-zero codeword was transmitted over an AWNG channel with BPSK modulation (see early sections)\nllr_source = GaussianPriorSource()\nnoise_var = ebnodb2no(ebno_db=ebno_db,\n                      num_bits_per_symbol=num_bits_per_symbol,\n                      coderate=coderate)\n# use fake llrs from GA\nllr = llr_source([[batch_size, n_exit], noise_var])\n# simulate free runing trajectory\ndecoder_exit(llr)\n# calculate analytical EXIT characteristics\n# Hint: these curves assume asymptotic code length, i.e., may become inaccurate in the short length regime\nIa, Iev, Iec = get_exit_analytic(pcm, ebno_db)\n# and plot the EXIT curves\nplt = plot_exit_chart(Ia, Iev, Iec)\n# however, as track_exit=True, the decoder logs the actual exit trajectory during decoding. This can be accessed by decoder.ie_v/decoder.ie_c after the simulation\n# and add simulated trajectory to plot\nplot_trajectory(plt, decoder_exit.ie_v, decoder_exit.ie_c, ebno_db)\n```"
"```python\n\nn: 648, k: 324, coderate: 0.500\n```\n\n\nAs can be seen, the simulated trajectory of the decoder matches (relatively) well with the predicted EXIT functions of the VN and CN decoder, respectively.\n\nA few things to try:\n\n- Change the SNR; which curves change? Why is one curve constant? Hint: does every component directly *see* the channel?\n- What happens for other codes?\n- Can you predict the *threshold* of this curve (i.e., the minimum SNR required for successful decoding)\n- Verify the correctness of this threshold via BER simulations (hint: the codes are relatively short, thus the prediction is less accurate)"
"## Mismatched Demapping and the Advantages of Min-sum Decoding\n\nSo far, we have demapped with exact knowledge of the underlying noise distribution (including the exact SNR). However, in practice estimating the SNR can be a complicated task and, as such, the estimated SNR used for demapping can be inaccurate.\n\nIn this part, you will learn about the advantages of min-sum decoding and we will see that it is more robust against mismatched demapping.\n\n\n```python\n# let us first remove the non-scrambled result from the previous experiment\nber_plot_allzero16qam.remove(idx=1) # remove curve with index 1\n```\n\n```python\n# simulate with mismatched noise estimation\nmodel_allzero_16_no = LDPC_QAM_AWGN(k,\n                                    n,\n                                    num_bits_per_symbol=4,\n                                    use_allzero=False, # full simulation\n                                    no_est_mismatch=0.15) # noise variance estimation mismatch (no scaled by 0.15 )\nber_plot_allzero16qam.simulate(model_allzero_16_no,\n                               ebno_dbs=np.arange(0, 7, 0.5),\n                               legend=\"Mismatched Demapping / 16-QAM\",\n                               max_mc_iter=50,\n                               num_target_bit_errors=1000,\n                               batch_size=1000,\n                               soft_estimates=False,\n                               show_fig=True,\n                               forward_keyboard_interrupt=False);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 2.9167e-01 | 1.0000e+00 |      175004 |      600000 |         1000 |        1000 |         0.6 |reached target bit errors\n      0.5 | 2.7983e-01 | 1.0000e+00 |      167896 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n      1.0 | 2.6990e-01 | 1.0000e+00 |      161938 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n      1.5 | 2.5992e-01 | 1.0000e+00 |      155954 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n      2.0 | 2.4621e-01 | 1.0000e+00 |      147729 |      600000 |         1000 |        1000 |         0.0 |reached target bit errors\n      2.5 | 2.3175e-01 | 1.0000e+00 |      139048 |      600000 |         1000 |        1000 |         0.1 |reached target bit errors\n      3.0 | 2.0946e-01 | 1.0000e+00 |      125674 |      600000 |         1000 |        1000 |         0.1 |reached target bit errors\n      3.5 | 1.6710e-01 | 9.7600e-01 |      100260 |      600000 |          976 |        1000 |         0.0 |reached target bit errors\n      4.0 | 7.9163e-02 | 7.3300e-01 |       47498 |      600000 |          733 |        1000 |         0.0 |reached target bit errors\n      4.5 | 1.5238e-02 | 3.1200e-01 |        9143 |      600000 |          312 |        1000 |         0.1 |reached target bit errors\n      5.0 | 1.2142e-03 | 1.1600e-01 |        1457 |     1200000 |          232 |        2000 |         0.1 |reached target bit errors\n      5.5 | 2.6595e-04 | 8.9714e-02 |        1117 |     4200000 |          628 |        7000 |         0.4 |reached target bit errors\n      6.0 | 1.9722e-04 | 7.7889e-02 |        1065 |     5400000 |          701 |        9000 |         0.4 |reached target bit errors\n      6.5 | 1.6750e-04 | 7.0700e-02 |        1005 |     6000000 |          707 |       10000 |         0.5 |reached target bit errors\n```"
"```python\n# simulate with mismatched noise estimation\nmodel_allzero_16_ms = LDPC_QAM_AWGN(k,\n                                    n,\n                                    num_bits_per_symbol=4,\n                                    use_allzero=False, # full simulation\n                                    decoder_type=\"minsum\", # activate min-sum decoding\n                                    no_est_mismatch=1.) # no mismatch\nber_plot_allzero16qam.simulate(model_allzero_16_ms,\n                               ebno_dbs=np.arange(0, 7, 0.5),\n                               legend=\"Min-sum decoding / 16-QAM (no mismatch)\",\n                               max_mc_iter=50,\n                               num_target_bit_errors=1000,\n                               batch_size=1000,\n                               soft_estimates=False,\n                               show_fig=True,\n                               forward_keyboard_interrupt=False);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 2.9673e-01 | 1.0000e+00 |      178038 |      600000 |         1000 |        1000 |         1.6 |reached target bit errors\n      0.5 | 2.8642e-01 | 1.0000e+00 |      171853 |      600000 |         1000 |        1000 |         0.1 |reached target bit errors\n      1.0 | 2.7497e-01 | 1.0000e+00 |      164979 |      600000 |         1000 |        1000 |         0.1 |reached target bit errors\n      1.5 | 2.6341e-01 | 1.0000e+00 |      158046 |      600000 |         1000 |        1000 |         0.1 |reached target bit errors\n      2.0 | 2.5386e-01 | 1.0000e+00 |      152316 |      600000 |         1000 |        1000 |         0.1 |reached target bit errors\n      2.5 | 2.3969e-01 | 1.0000e+00 |      143816 |      600000 |         1000 |        1000 |         0.1 |reached target bit errors\n      3.0 | 2.2282e-01 | 9.9800e-01 |      133695 |      600000 |          998 |        1000 |         0.1 |reached target bit errors\n      3.5 | 1.8001e-01 | 9.4100e-01 |      108007 |      600000 |          941 |        1000 |         0.1 |reached target bit errors\n      4.0 | 9.4245e-02 | 6.2100e-01 |       56547 |      600000 |          621 |        1000 |         0.1 |reached target bit errors\n      4.5 | 1.8808e-02 | 1.6300e-01 |       11285 |      600000 |          163 |        1000 |         0.1 |reached target bit errors\n      5.0 | 7.1944e-04 | 8.0000e-03 |        1295 |     1800000 |           24 |        3000 |         0.4 |reached target bit errors\n      5.5 | 5.7667e-06 | 1.0000e-04 |         173 |    30000000 |            5 |       50000 |         6.3 |reached max iter\n      6.0 | 0.0000e+00 | 0.0000e+00 |           0 |    30000000 |            0 |       50000 |         6.3 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 6.0 dB.\n\n```"
"```python\n# simulate with mismatched noise estimation\nmodel_allzero_16_ms = LDPC_QAM_AWGN(k,\n                                    n,\n                                    num_bits_per_symbol=4,\n                                    use_allzero=False, # full simulation\n                                    decoder_type=\"minsum\", # activate min-sum decoding\n                                    no_est_mismatch=0.15) # noise_var mismatch at demapper\nber_plot_allzero16qam.simulate(model_allzero_16_ms,\n                            ebno_dbs=np.arange(0, 7, 0.5),\n                            legend=\"Min-sum decoding / 16-QAM (with mismatch)\",\n                            max_mc_iter=50,\n                            num_target_bit_errors=1000,\n                            batch_size=1000,\n                            soft_estimates=False,\n                            show_fig=True,\n                            forward_keyboard_interrupt=False);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 2.9721e-01 | 1.0000e+00 |      178324 |      600000 |         1000 |        1000 |         1.4 |reached target bit errors\n      0.5 | 2.8528e-01 | 1.0000e+00 |      171168 |      600000 |         1000 |        1000 |         0.1 |reached target bit errors\n      1.0 | 2.7617e-01 | 1.0000e+00 |      165701 |      600000 |         1000 |        1000 |         0.1 |reached target bit errors\n      1.5 | 2.6409e-01 | 1.0000e+00 |      158451 |      600000 |         1000 |        1000 |         0.1 |reached target bit errors\n      2.0 | 2.5094e-01 | 1.0000e+00 |      150564 |      600000 |         1000 |        1000 |         0.1 |reached target bit errors\n      2.5 | 2.3911e-01 | 1.0000e+00 |      143464 |      600000 |         1000 |        1000 |         0.1 |reached target bit errors\n      3.0 | 2.1863e-01 | 9.9900e-01 |      131179 |      600000 |          999 |        1000 |         0.1 |reached target bit errors\n      3.5 | 1.7542e-01 | 9.6100e-01 |      105252 |      600000 |          961 |        1000 |         0.1 |reached target bit errors\n      4.0 | 9.2570e-02 | 7.2900e-01 |       55542 |      600000 |          729 |        1000 |         0.1 |reached target bit errors\n      4.5 | 1.9367e-02 | 2.5800e-01 |       11620 |      600000 |          258 |        1000 |         0.1 |reached target bit errors\n      5.0 | 1.5808e-03 | 4.9000e-02 |        1897 |     1200000 |           98 |        2000 |         0.3 |reached target bit errors\n      5.5 | 9.1930e-05 | 2.6316e-02 |        1048 |    11400000 |          500 |       19000 |         2.4 |reached target bit errors\n      6.0 | 5.5215e-05 | 2.2935e-02 |        1027 |    18600000 |          711 |       31000 |         3.8 |reached target bit errors\n      6.5 | 4.8619e-05 | 2.2029e-02 |        1021 |    21000000 |          771 |       35000 |         4.4 |reached target bit errors\n```"
"Interestingly, *min-sum* decoding is more robust w.r.t. inaccurate LLR estimations. It is worth mentioning that *min-sum* decoding itself causes a performance loss. However, more advanced min-sum-based decoding approaches (offset-corrected min-sum) can operate close to *full BP* decoding.\n\nYou can also try:\n\n- What happens with max-log demapping?\n- Implement offset corrected min-sum decoding\n- Have a closer look at the error-floor behavior\n- Apply the concept of [Weighted BP](https://nvlabs.github.io/sionna/examples/Weighted_BP_Algorithm.html) to mismatched demapping"
"## References\n\n[1] E. Zehavi, 8-PSK Trellis Codes for a Rayleigh Channel, IEEE Transactions on Communications, vol.40, no. 5, 1992.\n\n[2] G. Caire, G. Taricco and E. Biglieri, Bit-interleaved Coded Modulation, IEEE Transactions on Information Theory, vol.44, no. 3, 1998.\n\n[3] G. Ungerbck, Channel Coding with Multilevel/Phase Signals.IEEE Transactions on Information Theory, vol.28, no. 1, 1982.\n\n[4] J. L. Massey, Coding and modulation in digital communications, in Proc. Int. Zurich Seminar Commun., 1974.\n\n[5] G. Bcherer, Principles of Coded Modulation, Habilitation thesis, Tech. Univ. Munich, Munich, Germany, 2018.\n\n[6] F. Schreckenbach, Iterative Decoding of Bit-Interleaved Coded Modulation, PhD thesis, Tech. Univ. Munich, Munich, Germany, 2007.\n\n[7] S. ten Brink, Convergence Behavior of Iteratively Decoded Parallel Concatenated Codes, IEEE Transactions on Communications, vol.49, no. 10, pp.1727-1737, 2001.\n\n[8] S. ten Brink, G. Kramer, and A. Ashikhmin, Design of low-density parity-check codes for modulation and detection, IEEE Trans. Commun., vol.52, no. 4, pp.670678, Apr.2004.\n\n[9] J. Hou, P. H. Siegel, L. B. Milstein, and H. D. Pfister, Capacity-approaching bandwidth-efficient coded modulation schemes based on low-density parity-check codes, IEEE Trans. Inform. Theory, vol.49, no. 9, pp.21412155, 2003.\n\n[10] A. Alvarado, L. Szczecinski, R. Feick, and L. Ahumada, Distribution of L-values in Gray-mapped M 2-QAM: Closed-form approximations and applications, IEEE Transactions on Communications, vol.57, no. 7, pp.2071-2079, 2009.\n\n[11] ETSI 3GPP TS 38.212 5G NR Multiplexing and channel coding, v.16.5.0, 2021-03.[11] ETSI 3GPP TS 38.212 5G NR Multiplexing and channel coding, v.16.5.0, 2021-03.\n[11] ETSI 3GPP TS 38.212 5G NR Multiplexing and channel coding, v.16.5.0, 2021-03.[11] ETSI 3GPP TS 38.212 5G NR Multiplexing and channel coding, v.16.5.0, 2021-03."
"# Channel Models from Datasets\n\nIn this notebook, you will learn how to create a channel model from a [generator](https://wiki.python.org/moin/Generators). This can be used, e.g., to import datasets of channel impulse responses."
"## GPU Configuration and Imports\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna as sn\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna as sn\nimport numpy as np\nimport h5py\n```\n\n```python\n# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n# For more details, see https://www.tensorflow.org/guide/gpu\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\n```"
"## Simulation Parameters\n\n\n```python\nnum_rx = 2\nnum_rx_ant = 2\nnum_tx = 1\nnum_tx_ant = 8\nnum_time_steps = 100\nnum_paths = 10\n```"
"## Creating a Simple Dataset\n\nTo illustrate how to load dataset, we will first create one.\n\nThe next cell creates a very small HDF5 file storing Gaussian distributed i.i.d. path coefficients and uniformly distributed i.i.d. path delays.\n\n\n```python\n# Number of examples in the dataset\ndataset_size = 1000\n# Random path coefficients\na_shape = [dataset_size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps]\na = (np.random.normal(size=a_shape) + 1j*np.random.normal(size=a_shape))/np.sqrt(2)\n# Random path delays\ntau = np.random.uniform(size=[dataset_size, num_rx, num_tx, num_paths])\n```\n\n```python\nfilename = 'my_dataset.h5'\nhf = h5py.File(filename, 'w')\nhf.create_dataset('a', data=a)\nhf.create_dataset('tau', data=tau)\nhf.close()\n```"
"## Generators\n\nThe first step to load a dataset is to create a [generator](https://wiki.python.org/moin/Generators). A generator is a callable object, i.e., a function or a class that implements the `__call__()` method, and that behaves like an iterator.\n\nThe next cell shows how to create a generator that parses an HDF5 file storing path coefficients and delays. Note that how the HDF5 file is parsed depends on its structure. The following generator is specific to the dataset previously created.\n\nIf you have another dataset, you will need to change the way it is parsed in the generator. The generator can also carry out any type of desired pre-processing of your data, e.g., normalization.\n\n\n```python\nclass HD5CIRGen:\n    def __init__(self, filename):\n        self.filename = filename\n    def __call__(self):\n        with h5py.File(self.filename, 'r') as hf:\n            for im in zip(hf[\"a\"], hf[\"tau\"]):\n                a = im[0]\n                tau = im[1]\n                # One could do some preprocessing on the dataset here\n                # ...\n                yield im\n```\n\n```python\ngenerator = HD5CIRGen(filename)\n```\n\n\nWe can use the generator to sample the first 5 items of the dataset:\n\n\n```python\ni = 0\nfor (a,tau) in generator():\n    print(a.shape)\n    print(tau.shape)\n    i = i + 1\n    if i == 5:\n        break\n```\n\n\n```python\n(2, 2, 1, 8, 10, 100)\n(2, 1, 10)\n(2, 2, 1, 8, 10, 100)\n(2, 1, 10)\n(2, 2, 1, 8, 10, 100)\n(2, 1, 10)\n(2, 2, 1, 8, 10, 100)\n(2, 1, 10)\n(2, 2, 1, 8, 10, 100)\n(2, 1, 10)\n```\n\n\nLet us create a channel model from this dataset:\n\n\n```python\nbatch_size = 64 # The batch_size cannot be changed after the creation of the channel model\nchannel_model = sn.channel.CIRDataset(generator,\n                                      batch_size,\n                                      num_rx,\n                                      num_rx_ant,\n                                      num_tx,\n                                      num_tx_ant,\n                                      num_paths,\n                                      num_time_steps)\n```"
"We can now sample from this dataset in the same way as we would from a stochastic channel model:\n\n\n```python\n# Note that the arguments batch_size, num_time_steps, and smapling_frequency\n# of the __call__ function are ignored as they are already specified by the dataset.\na, tau = channel_model()\n```\n\n```python\nprint(a.shape)\nprint(a.dtype)\nprint(tau.shape)\nprint(tau.dtype)\n```\n\n\n```python\n(64, 2, 2, 1, 8, 10, 100)\n<dtype: 'complex64'>\n(64, 2, 1, 10)\n<dtype: 'float32'>\n```"
"## Use the Channel Model for OFDM Transmissions\n\nThe following code demonstrates how you can use the channel model to generate channel frequency responses that can be used for the simulation of communication system based on OFDM.\n\n\n```python\n# Create an OFDM resource grid\n# Each time step is assumed to correspond to one OFDM symbol over which it is constant.\nresource_grid = sn.ofdm.ResourceGrid(num_ofdm_symbols=num_time_steps,\n                                     fft_size=76,\n                                     subcarrier_spacing=15e3,\n                                     num_tx=num_tx,\n                                     num_streams_per_tx=num_tx_ant)\n```\n\n```python\nofdm_channel = sn.channel.GenerateOFDMChannel(channel_model, resource_grid)\n```\n\n```python\n# Generate a batch of frequency responses\n# Shape: [batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_ofdm_symbols, num_subcarriers]\nh_freq = ofdm_channel()\nprint(h_freq.shape)\n```\n\n\n```python\n(64, 2, 2, 1, 8, 100, 76)\n```"
"# End-to-end Learning with Autoencoders\n\nIn this notebook, you will learn how to implement an end-to-end communication system as an autoencoder [1]. The implemented system is shown in the figure below. An additive white Gaussian noise (AWGN) channel is considered. On the transmitter side, joint training of the constellation geometry and bit-labeling is performed, as in [2]. On the receiver side, a neural network-based demapper that computes log-likelihood ratios (LLRs) on the transmitted bits from the received samples is optimized. The\nconsidered autoencoder is benchmarked against a quadrature amplitude modulation (QAM) with Gray labeling and the optimal AWGN demapper.\n\n\nTwo algorithms for training the autoencoder are implemented in this notebook:\n\n- Conventional stochastic gradient descent (SGD) with backpropagation, which assumes a differentiable channel model and therefore optimizes the end-to-end system by backpropagating the gradients through the channel (see, e.g., [1]).\n- The training algorithm from [3], which does not assume a differentiable channel model, and which trains the end-to-end system by alternating between conventional training of the receiver and reinforcement learning (RL)-based training of the transmitter. Compared to [3], an additional step of fine-tuning of the receiver is performed after alternating training.\n\n\n**Note:** For an introduction to the implementation of differentiable communication systems and their optimization through SGD and backpropagation with Sionna, please refer to [the Part 2 of the Sionna tutorial for Beginners](https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part2.html)."
"## GPU Configuration and Imports\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\nfrom sionna.channel import AWGN\nfrom sionna.utils import BinarySource, ebnodb2no, log10, expand_to_rank, insert_dims\nfrom sionna.fec.ldpc.encoding import LDPC5GEncoder\nfrom sionna.fec.ldpc.decoding import LDPC5GDecoder\nfrom sionna.mapping import Mapper, Demapper, Constellation\nfrom sionna.utils import sim_ber\n```\n\n```python\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pickle\n```\n\n```python\n# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n# For more details, see https://www.tensorflow.org/guide/gpu\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Layer, Dense\n```"
"## Simulation Parameters\n\n\n```python\n###############################################\n# SNR range for evaluation and training [dB]\n###############################################\nebno_db_min = 4.0\nebno_db_max = 8.0\n###############################################\n# Modulation and coding configuration\n###############################################\nnum_bits_per_symbol = 6 # Baseline is 64-QAM\nmodulation_order = 2**num_bits_per_symbol\ncoderate = 0.5 # Coderate for the outer code\nn = 1500 # Codeword length [bit]. Must be a multiple of num_bits_per_symbol\nnum_symbols_per_codeword = n//num_bits_per_symbol # Number of modulated baseband symbols per codeword\nk = int(n*coderate) # Number of information bits per codeword\n###############################################\n# Training configuration\n###############################################\nnum_training_iterations_conventional = 10000 # Number of training iterations for conventional training\n# Number of training iterations with RL-based training for the alternating training phase and fine-tuning of the receiver phase\nnum_training_iterations_rl_alt = 7000\nnum_training_iterations_rl_finetuning = 3000\ntraining_batch_size = tf.constant(128, tf.int32) # Training batch size\nrl_perturbation_var = 0.01 # Variance of the perturbation used for RL-based training of the transmitter\nmodel_weights_path_conventional_training = \"awgn_autoencoder_weights_conventional_training\" # Filename to save the autoencoder weights once conventional training is done\nmodel_weights_path_rl_training = \"awgn_autoencoder_weights_rl_training\" # Filename to save the autoencoder weights once RL-based training is done\n###############################################\n# Evaluation configuration\n###############################################\nresults_filename = \"awgn_autoencoder_results\" # Location to save the results\n```"
"## Neural Demapper\n\nThe neural network-based demapper shown in the figure above is made of three dense layers with ReLU activation.\n\nThe input of the demapper consists of a received sample $y \\in \\mathbb{C}$ and the noise power spectral density $N_0$ in log-10 scale to handle different orders of magnitude for the SNR.\n\nAs the neural network can only process real-valued inputs, these values are fed as a 3-dimensional vector\n\n$$\n\\left[ \\mathcal{R}(y), \\mathcal{I}(y), \\log_{10}(N_0) \\right]\n$$\n\nwhere $\\mathcal{R}(y)$ and $\\mathcal{I}(y)$ refer to the real and imaginary component of $y$, respectively.\n\nThe output of the neural network-based demapper consists of LLRs on the `num_bits_per_symbol` bits mapped to a constellation point. Therefore, the last layer consists of `num_bits_per_symbol` units.\n\n**Note**: The neural network-based demapper processes the received samples $y$ forming a block individually. The [neural receiver notebook](https://nvlabs.github.io/sionna/examples/Neural_Receiver.html) provides an example of a more advanced neural network-based receiver that jointly processes a resource grid of received symbols.\n\n\n```python\nclass NeuralDemapper(Layer):\n    def __init__(self):\n        super().__init__()\n        self._dense_1 = Dense(128, 'relu')\n        self._dense_2 = Dense(128, 'relu')\n        self._dense_3 = Dense(num_bits_per_symbol, None) # The feature correspond to the LLRs for every bits carried by a symbol\n    def call(self, inputs):\n        y,no = inputs\n        # Using log10 scale helps with the performance\n        no_db = log10(no)\n        # Stacking the real and imaginary components of the complex received samples\n        # and the noise variance\n        no_db = tf.tile(no_db, [1, num_symbols_per_codeword]) # [batch size, num_symbols_per_codeword]\n        z = tf.stack([tf.math.real(y),\n                      tf.math.imag(y),\n                      no_db], axis=2) # [batch size, num_symbols_per_codeword, 3]\n        llr = self._dense_1(z)\n        llr = self._dense_2(llr)\n        llr = self._dense_3(llr) # [batch size, num_symbols_per_codeword, num_bits_per_symbol]\n        return llr\n```"
"## Trainable End-to-end System: Conventional Training\n\nThe following cell defines an end-to-end communication system that transmits bits modulated using a trainable constellation over an AWGN channel.\n\nThe receiver uses the previously defined neural network-based demapper to compute LLRs on the transmitted (coded) bits.\n\nAs in [1], the constellation and neural network-based demapper are jointly trained through SGD and backpropagation using the binary cross entropy (BCE) as loss function.\n\nTraining on the BCE is known to be equivalent to maximizing an achievable information rate [2].\n\nThe following model can be instantiated either for training (`training` `=` `True`) or evaluation (`training` `=` `False`).\n\nIn the former case, the BCE is returned and no outer code is used to reduce computational complexity and as it does not impact the training of the constellation or demapper.\n\nWhen setting `training` to `False`, an LDPC outer code from 5G NR is applied.\n\n\n```python\nclass E2ESystemConventionalTraining(Model):\n    def __init__(self, training):\n        super().__init__()\n        self._training = training\n        ################\n        ## Transmitter\n        ################\n        self._binary_source = BinarySource()\n        # To reduce the computational complexity of training, the outer code is not used when training,\n        # as it is not required\n        if not self._training:\n            # num_bits_per_symbol is required for the interleaver\n            self._encoder = LDPC5GEncoder(k, n, num_bits_per_symbol)\n        # Trainable constellation\n        constellation = Constellation(\"qam\", num_bits_per_symbol, trainable=True)\n        self.constellation = constellation\n        self._mapper = Mapper(constellation=constellation)\n        ################\n        ## Channel\n        ################\n        self._channel = AWGN()\n        ################\n        ## Receiver\n        ################\n        # We use the previously defined neural network for demapping\n        self._demapper = NeuralDemapper()\n        # To reduce the computational complexity of training, the outer code is not used when training,\n        # as it is not required\n        if not self._training:\n            self._decoder = LDPC5GDecoder(self._encoder, hard_out=True)\n        #################\n        # Loss function\n        #################\n        if self._training:\n            self._bce = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n    @tf.function(jit_compile=True)\n    def call(self, batch_size, ebno_db):\n        # If `ebno_db` is a scalar, a tensor with shape [batch size] is created as it is what is expected by some layers\n        if len(ebno_db.shape) == 0:\n            ebno_db = tf.fill([batch_size], ebno_db)\n        no = ebnodb2no(ebno_db, num_bits_per_symbol, coderate)\n        no = expand_to_rank(no, 2)\n        ################\n        ## Transmitter\n        ################\n        # Outer coding is only performed if not training\n        if self._training:\n            c = self._binary_source([batch_size, n])\n        else:\n            b = self._binary_source([batch_size, k])\n            c = self._encoder(b)\n        # Modulation\n        x = self._mapper(c) # x [batch size, num_symbols_per_codeword]\n        ################\n        ## Channel\n        ################\n        y = self._channel([x, no]) # [batch size, num_symbols_per_codeword]\n        ################\n        ## Receiver\n        ################\n        llr = self._demapper([y, no])\n        llr = tf.reshape(llr, [batch_size, n])\n        # If training, outer decoding is not performed and the BCE is returned\n        if self._training:\n            loss = self._bce(c, llr)\n            return loss\n        else:\n            # Outer decoding\n            b_hat = self._decoder(llr)\n            return b,b_hat # Ground truth and reconstructed information bits returned for BER/BLER computation\n```"
"A simple training loop is defined in the next cell, which performs `num_training_iterations_conventional` training iterations of SGD. Training is done over a range of SNR, by randomly sampling a batch of SNR values at each iteration.\n\n**Note:** For an introduction to the implementation of differentiable communication systems and their optimization through SGD and backpropagation with Sionna, please refer to [the Part 2 of the Sionna tutorial for Beginners](https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part2.html).\n\n\n```python\ndef conventional_training(model):\n    # Optimizer used to apply gradients\n    optimizer = tf.keras.optimizers.Adam()\n    for i in range(num_training_iterations_conventional):\n        # Sampling a batch of SNRs\n        ebno_db = tf.random.uniform(shape=[training_batch_size], minval=ebno_db_min, maxval=ebno_db_max)\n        # Forward pass\n        with tf.GradientTape() as tape:\n            loss = model(training_batch_size, ebno_db) # The model is assumed to return the BMD rate\n        # Computing and applying gradients\n        weights = model.trainable_weights\n        grads = tape.gradient(loss, weights)\n        optimizer.apply_gradients(zip(grads, weights))\n        # Printing periodically the progress\n        if i % 100 == 0:\n            print('Iteration {}/{}  BCE: {:.4f}'.format(i, num_training_iterations_conventional, loss.numpy()), end='\\r')\n```\n\n\nThe next cell defines a utility function for saving the weights using [pickle](https://docs.python.org/3/library/pickle.html).\n\n\n```python\ndef save_weights(model, model_weights_path):\n    weights = model.get_weights()\n    with open(model_weights_path, 'wb') as f:\n        pickle.dump(weights, f)\n```\n\n\nIn the next cell, an instance of the model defined previously is instantiated and trained.\n\n\n```python\n# Fix the seed for reproducible trainings\ntf.random.set_seed(1)\n# Instantiate and train the end-to-end system\nmodel = E2ESystemConventionalTraining(training=True)\nconventional_training(model)\n# Save weights\nsave_weights(model, model_weights_path_conventional_training)\n```\n\n\n```python\nIteration 9900/10000  BCE: 0.2820\n```"
"## Trainable End-to-end System: RL-based Training\n\nThe following cell defines the same end-to-end system as before, but stop the gradients after the channel to simulate a non-differentiable channel.\n\nTo jointly train the transmitter and receiver over a non-differentiable channel, we follow [3], which key idea is to alternate between:\n\n- Training of the receiver on the BCE using conventional backpropagation and SGD.\n- Training of the transmitter by applying (known) perturbations to the transmitter output to enable estimation of the gradient of the transmitter weights with respect to an approximation of the loss function.\n\n\nWhen `training` is set to `True`, both losses for training the receiver and the transmitter are returned.\n\n\n```python\nclass E2ESystemRLTraining(Model):\n    def __init__(self, training):\n        super().__init__()\n        self._training = training\n        ################\n        ## Transmitter\n        ################\n        self._binary_source = BinarySource()\n        # To reduce the computational complexity of training, the outer code is not used when training,\n        # as it is not required\n        if not self._training:\n            self._encoder = LDPC5GEncoder(k, n, num_bits_per_symbol)\n        # Trainable constellation\n        constellation = Constellation(\"qam\", num_bits_per_symbol, trainable=True)\n        self.constellation = constellation\n        self._mapper = Mapper(constellation=constellation)\n        ################\n        ## Channel\n        ################\n        self._channel = AWGN()\n        ################\n        ## Receiver\n        ################\n        # We use the previously defined neural network for demapping\n        self._demapper = NeuralDemapper()\n        # To reduce the computational complexity of training, the outer code is not used when training,\n        # as it is not required\n        if not self._training:\n            self._decoder = LDPC5GDecoder(self._encoder, hard_out=True)\n    @tf.function(jit_compile=True)\n    def call(self, batch_size, ebno_db, perturbation_variance=tf.constant(0.0, tf.float32)):\n        # If `ebno_db` is a scalar, a tensor with shape [batch size] is created as it is what is expected by some layers\n        if len(ebno_db.shape) == 0:\n            ebno_db = tf.fill([batch_size], ebno_db)\n        no = ebnodb2no(ebno_db, num_bits_per_symbol, coderate)\n        no = expand_to_rank(no, 2)\n        ################\n        ## Transmitter\n        ################\n        # Outer coding is only performed if not training\n        if self._training:\n            c = self._binary_source([batch_size, n])\n        else:\n            b = self._binary_source([batch_size, k])\n            c = self._encoder(b)\n        # Modulation\n        x = self._mapper(c) # x [batch size, num_symbols_per_codeword]\n        # Adding perturbation\n        # If ``perturbation_variance`` is 0, then the added perturbation is null\n        epsilon_r = tf.random.normal(tf.shape(x))*tf.sqrt(0.5*perturbation_variance)\n        epsilon_i = tf.random.normal(tf.shape(x))*tf.sqrt(0.5*perturbation_variance)\n        epsilon = tf.complex(epsilon_r, epsilon_i) # [batch size, num_symbols_per_codeword]\n        x_p = x + epsilon # [batch size, num_symbols_per_codeword]\n        ################\n        ## Channel\n        ################\n        y = self._channel([x_p, no]) # [batch size, num_symbols_per_codeword]\n        y = tf.stop_gradient(y) # Stop gradient here\n        ################\n        ## Receiver\n        ################\n        llr = self._demapper([y, no])\n        # If training, outer decoding is not performed\n        if self._training:\n            # Average BCE for each baseband symbol and each batch example\n            c = tf.reshape(c, [-1, num_symbols_per_codeword, num_bits_per_symbol])\n            bce = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(c, llr), axis=2) # Avergare over the bits mapped to a same baseband symbol\n            # The RX loss is the usual average BCE\n            rx_loss = tf.reduce_mean(bce)\n            # From the TX side, the BCE is seen as a feedback from the RX through which backpropagation is not possible\n            bce = tf.stop_gradient(bce) # [batch size, num_symbols_per_codeword]\n            x_p = tf.stop_gradient(x_p)\n            p = x_p-x # [batch size, num_symbols_per_codeword] Gradient is backpropagated through `x`\n            tx_loss = tf.square(tf.math.real(p)) + tf.square(tf.math.imag(p)) # [batch size, num_symbols_per_codeword]\n            tx_loss = -bce*tx_loss/rl_perturbation_var # [batch size, num_symbols_per_codeword]\n            tx_loss = tf.reduce_mean(tx_loss)\n            return tx_loss, rx_loss\n        else:\n            llr = tf.reshape(llr, [-1, n]) # Reshape as expected by the outer decoder\n            b_hat = self._decoder(llr)\n            return b,b_hat\n```"
"The next cell implements the training algorithm from [3], which alternates between conventional training of the neural network-based receiver, and RL-based training of the transmitter.\n\n\n```python\ndef rl_based_training(model):\n    # Optimizers used to apply gradients\n    optimizer_tx = tf.keras.optimizers.Adam() # For training the transmitter\n    optimizer_rx = tf.keras.optimizers.Adam() # For training the receiver\n    # Function that implements one transmitter training iteration using RL.\n    def train_tx():\n        # Sampling a batch of SNRs\n        ebno_db = tf.random.uniform(shape=[training_batch_size], minval=ebno_db_min, maxval=ebno_db_max)\n        # Forward pass\n        with tf.GradientTape() as tape:\n            # Keep only the TX loss\n            tx_loss, _ = model(training_batch_size, ebno_db,\n                               tf.constant(rl_perturbation_var, tf.float32)) # Perturbation are added to enable RL exploration\n        ## Computing and applying gradients\n        weights = model.trainable_weights\n        grads = tape.gradient(tx_loss, weights)\n        optimizer_tx.apply_gradients(zip(grads, weights))\n    # Function that implements one receiver training iteration\n    def train_rx():\n        # Sampling a batch of SNRs\n        ebno_db = tf.random.uniform(shape=[training_batch_size], minval=ebno_db_min, maxval=ebno_db_max)\n        # Forward pass\n        with tf.GradientTape() as tape:\n            # Keep only the RX loss\n            _, rx_loss = model(training_batch_size, ebno_db) # No perturbation is added\n        ## Computing and applying gradients\n        weights = model.trainable_weights\n        grads = tape.gradient(rx_loss, weights)\n        optimizer_rx.apply_gradients(zip(grads, weights))\n        # The RX loss is returned to print the progress\n        return rx_loss\n    # Training loop.\n    for i in range(num_training_iterations_rl_alt):\n        # 10 steps of receiver training are performed to keep it ahead of the transmitter\n        # as it is used for computing the losses when training the transmitter\n        for _ in range(10):\n            rx_loss = train_rx()\n        # One step of transmitter training\n        train_tx()\n        # Printing periodically the progress\n        if i % 100 == 0:\n            print('Iteration {}/{}  BCE {:.4f}'.format(i, num_training_iterations_rl_alt, rx_loss.numpy()), end='\\r')\n    print() # Line break\n    # Once alternating training is done, the receiver is fine-tuned.\n    print('Receiver fine-tuning... ')\n    for i in range(num_training_iterations_rl_finetuning):\n        rx_loss = train_rx()\n        if i % 100 == 0:\n            print('Iteration {}/{}  BCE {:.4f}'.format(i, num_training_iterations_rl_finetuning, rx_loss.numpy()), end='\\r')\n```"
"In the next cell, an instance of the model defined previously is instantiated and trained.\n\n\n```python\n# Fix the seed for reproducible trainings\ntf.random.set_seed(1)\n# Instantiate and train the end-to-end system\nmodel = E2ESystemRLTraining(training=True)\nrl_based_training(model)\n# Save weights\nsave_weights(model, model_weights_path_rl_training)\n```\n\n\n```python\nIteration 6900/7000  BCE 0.2802\nReceiver fine-tuning...\nIteration 2900/3000  BCE 0.2777\n```"
"## Evaluation\n\nThe following cell implements a baseline which uses QAM with Gray labeling and conventional demapping for AWGN channel.\n\n\n```python\nclass Baseline(Model):\n    def __init__(self):\n        super().__init__()\n        ################\n        ## Transmitter\n        ################\n        self._binary_source = BinarySource()\n        self._encoder = LDPC5GEncoder(k, n, num_bits_per_symbol)\n        constellation = Constellation(\"qam\", num_bits_per_symbol, trainable=False)\n        self.constellation = constellation\n        self._mapper = Mapper(constellation=constellation)\n        ################\n        ## Channel\n        ################\n        self._channel = AWGN()\n        ################\n        ## Receiver\n        ################\n        self._demapper = Demapper(\"app\", constellation=constellation)\n        self._decoder = LDPC5GDecoder(self._encoder, hard_out=True)\n    @tf.function(jit_compile=True)\n    def call(self, batch_size, ebno_db, perturbation_variance=tf.constant(0.0, tf.float32)):\n        # If `ebno_db` is a scalar, a tensor with shape [batch size] is created as it is what is expected by some layers\n        if len(ebno_db.shape) == 0:\n            ebno_db = tf.fill([batch_size], ebno_db)\n        no = ebnodb2no(ebno_db, num_bits_per_symbol, coderate)\n        no = expand_to_rank(no, 2)\n        ################\n        ## Transmitter\n        ################\n        b = self._binary_source([batch_size, k])\n        c = self._encoder(b)\n        # Modulation\n        x = self._mapper(c) # x [batch size, num_symbols_per_codeword]\n        ################\n        ## Channel\n        ################\n        y = self._channel([x, no]) # [batch size, num_symbols_per_codeword]\n        ################\n        ## Receiver\n        ################\n        llr = self._demapper([y, no])\n        # Outer decoding\n        b_hat = self._decoder(llr)\n        return b,b_hat # Ground truth and reconstructed information bits returned for BER/BLER computation\n```\n\n```python\n# Range of SNRs over which the systems are evaluated\nebno_dbs = np.arange(ebno_db_min, # Min SNR for evaluation\n                     ebno_db_max, # Max SNR for evaluation\n                     0.5) # Step\n```"
"```python\n# Utility function to load and set weights of a model\ndef load_weights(model, model_weights_path):\n    model(1, tf.constant(10.0, tf.float32))\n    with open(model_weights_path, 'rb') as f:\n        weights = pickle.load(f)\n    model.set_weights(weights)\n```\n\n\nThe next cell evaluate the baseline and the two autoencoder-based communication systems, trained with different method. The results are stored in the dictionary `BLER`.\n\n\n```python\n# Dictionnary storing the results\nBLER = {}\nmodel_baseline = Baseline()\n_,bler = sim_ber(model_baseline, ebno_dbs, batch_size=128, num_target_block_errors=1000, max_mc_iter=1000)\nBLER['baseline'] = bler.numpy()\nmodel_conventional = E2ESystemConventionalTraining(training=False)\nload_weights(model_conventional, model_weights_path_conventional_training)\n_,bler = sim_ber(model_conventional, ebno_dbs, batch_size=128, num_target_block_errors=1000, max_mc_iter=1000)\nBLER['autoencoder-conv'] = bler.numpy()\nmodel_rl = E2ESystemRLTraining(training=False)\nload_weights(model_rl, model_weights_path_rl_training)\n_,bler = sim_ber(model_rl, ebno_dbs, batch_size=128, num_target_block_errors=1000, max_mc_iter=1000)\nBLER['autoencoder-rl'] = bler.numpy()\nwith open(results_filename, 'wb') as f:\n    pickle.dump((ebno_dbs, BLER), f)\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      4.0 | 1.2364e-01 | 1.0000e+00 |       94957 |      768000 |         1024 |        1024 |         3.2 |reached target block errors\n      4.5 | 9.7535e-02 | 9.9805e-01 |       74907 |      768000 |         1022 |        1024 |         0.1 |reached target block errors\n      5.0 | 5.7527e-02 | 9.0712e-01 |       49703 |      864000 |         1045 |        1152 |         0.1 |reached target block errors\n      5.5 | 1.9050e-02 | 5.1562e-01 |       29261 |     1536000 |         1056 |        2048 |         0.2 |reached target block errors\n      6.0 | 2.3017e-03 | 1.0621e-01 |       16351 |     7104000 |         1006 |        9472 |         0.7 |reached target block errors\n      6.5 | 1.2964e-04 | 9.6213e-03 |       10106 |    77952000 |         1000 |      103936 |         7.6 |reached target block errors\n      7.0 | 7.8333e-06 | 7.2656e-04 |         752 |    96000000 |           93 |      128000 |         9.3 |reached max iter\n      7.5 | 1.4583e-07 | 3.1250e-05 |          14 |    96000000 |            4 |      128000 |         9.4 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      4.0 | 1.0696e-01 | 9.9707e-01 |       82149 |      768000 |         1021 |        1024 |         0.9 |reached target block errors\n      4.5 | 6.9547e-02 | 9.3142e-01 |       60089 |      864000 |         1073 |        1152 |         0.1 |reached target block errors\n      5.0 | 2.3789e-02 | 5.4010e-01 |       34256 |     1440000 |         1037 |        1920 |         0.1 |reached target block errors\n      5.5 | 4.2181e-03 | 1.5472e-01 |       20652 |     4896000 |         1010 |        6528 |         0.5 |reached target block errors\n      6.0 | 2.4640e-04 | 1.6292e-02 |       11354 |    46080000 |         1001 |       61440 |         4.3 |reached target block errors\n      6.5 | 1.2156e-05 | 9.3750e-04 |        1167 |    96000000 |          120 |      128000 |         9.1 |reached max iter\n      7.0 | 1.1667e-06 | 7.0312e-05 |         112 |    96000000 |            9 |      128000 |         9.1 |reached max iter\n      7.5 | 8.7500e-07 | 3.9063e-05 |          84 |    96000000 |            5 |      128000 |         9.1 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      4.0 | 1.0489e-01 | 9.9805e-01 |       80553 |      768000 |         1022 |        1024 |         1.1 |reached target block errors\n      4.5 | 6.4516e-02 | 9.2101e-01 |       55742 |      864000 |         1061 |        1152 |         0.1 |reached target block errors\n      5.0 | 2.3047e-02 | 5.2812e-01 |       33187 |     1440000 |         1014 |        1920 |         0.1 |reached target block errors\n      5.5 | 3.7078e-03 | 1.4318e-01 |       19577 |     5280000 |         1008 |        7040 |         0.5 |reached target block errors\n      6.0 | 2.2505e-04 | 1.4167e-02 |       11926 |    52992000 |         1001 |       70656 |         5.0 |reached target block errors\n      6.5 | 8.1771e-06 | 8.5938e-04 |         785 |    96000000 |          110 |      128000 |         9.2 |reached max iter\n      7.0 | 7.0833e-07 | 5.4688e-05 |          68 |    96000000 |            7 |      128000 |         9.1 |reached max iter\n      7.5 | 1.1458e-07 | 1.5625e-05 |          11 |    96000000 |            2 |      128000 |         9.1 |reached max iter\n```"
"```python\nplt.figure(figsize=(10,8))\n# Baseline - Perfect CSI\nplt.semilogy(ebno_dbs, BLER['baseline'], 'o-', c=f'C0', label=f'Baseline')\n# Autoencoder - conventional training\nplt.semilogy(ebno_dbs, BLER['autoencoder-conv'], 'x-.', c=f'C1', label=f'Autoencoder - conventional training')\n# Autoencoder - RL-based training\nplt.semilogy(ebno_dbs, BLER['autoencoder-rl'], 'o-.', c=f'C2', label=f'Autoencoder - RL-based training')\nplt.xlabel(r\"$E_b/N_0$ (dB)\")\nplt.ylabel(\"BLER\")\nplt.grid(which=\"both\")\nplt.ylim((1e-4, 1.0))\nplt.legend()\nplt.tight_layout()\n```"
"## Visualizing the Learned Constellations\n\n\n```python\nmodel_conventional = E2ESystemConventionalTraining(training=True)\nload_weights(model_conventional, model_weights_path_conventional_training)\nfig = model_conventional.constellation.show()\nfig.suptitle('Conventional training');\n```\n\n\n```python\nmodel_rl = E2ESystemRLTraining(training=False)\nload_weights(model_rl, model_weights_path_rl_training)\nfig = model_rl.constellation.show()\nfig.suptitle('RL-based training');\n```"
"## References\n\n[1] T. OShea and J. Hoydis, An Introduction to Deep Learning for the Physical Layer, in IEEE Transactions on Cognitive Communications and Networking, vol.3, no. 4, pp.563-575, Dec.2017, doi: 10.1109/TCCN.2017.2758370.\n\n[2] S. Cammerer, F. Ait Aoudia, S. Drner, M. Stark, J. Hoydis and S. ten Brink, Trainable Communication Systems: Concepts and Prototype, in IEEE Transactions on Communications, vol.68, no. 9, pp.5489-5503, Sept.2020, doi: 10.1109/TCOMM.2020.3002915.\n\n[3] F. Ait Aoudia and J. Hoydis, Model-Free Training of End-to-End Communication Systems, in IEEE Journal on Selected Areas in Communications, vol.37, no. 11, pp.2503-2516, Nov.2019, doi: 10.1109/JSAC.2019.2933891.\n[3] F. Ait Aoudia and J. Hoydis, Model-Free Training of End-to-End Communication Systems, in IEEE Journal on Selected Areas in Communications, vol.37, no. 11, pp.2503-2516, Nov.2019, doi: 10.1109/JSAC.2019.2933891.\n[3] F. Ait Aoudia and J. Hoydis, Model-Free Training of End-to-End Communication Systems, in IEEE Journal on Selected Areas in Communications, vol.37, no. 11, pp.2503-2516, Nov.2019, doi: 10.1109/JSAC.2019.2933891."
"# Introduction to Iterative Detection and Decoding\n\nIn this notebook, you will learn how to set-up an iterative detection and decoding (IDD) scheme (first presented in [1]) by combining multiple available components in Sionna.\n\nFor a gentle introduction to MIMO simulations, we refer to the notebooks [Simple MIMO Simulations](https://nvlabs.github.io/sionna/examples/Simple_MIMO_Simulation.html) and [MIMO OFDM Transmissions over CDL](https://nvlabs.github.io/sionna/examples/MIMO_OFDM_Transmissions_over_CDL.html).\n\nYou will evaluate the performance of IDD with OFDM MIMO detection and soft-input soft-output (SISO) LDPC decoding and compare it againts several non-iterative detectors, such as soft-output LMMSE, K-Best, and expectation propagation (EP), as well as iterative SISO MMSE-PIC detection [2].\n\nFor the non-IDD models, the signal processing pipeline looks as follows:"
"## Iterative Detection and Decoding\n\nThe IDD MIMO receiver iteratively exchanges soft-information between the data detector and the channel decoder, which works as follows:\n\n\nWe denote by $\\mathrm{L}^{D}$ the *a posteriori* information (represented by log-likelihood ratios, LLRs) and by $\\mathrm{L}^{E} = \\mathrm{L}^{D} - \\mathrm{L}^{A}$ the extrinsic information, which corresponds to the information gain in $\\mathrm{L}^{D}$ relative to the *a priori* information $\\mathrm{L}^{A}$. The *a priori* LLRs represent soft information, provided to either the input of the detector (i.e., $\\mathrm{L}^{A}_{Det}$) or the decoder (i.e.,\n$\\mathrm{L}^{A}_{Dec}$). While exchanging extrinsic information is standard for classical IDD, the SISO MMSE-PIC detector [2] turned out to work better when provided with the full *a posteriori* information from the decoder.\n\nOriginally, IDD was proposed with a resetting (Turbo) decoder [1]. However, state-of-the-art IDD with LDPC message passing decoding showed better performance with a non-resetting decoder [3], particularly for a low number of decoding iterations. Therefore, we will forward the decoder state (i.e., the check node to variable node messages) from each IDD iteration to the next."
"## Table of contents\n\n- [GPU Configuration and Imports](https://nvlabs.github.io/sionna/examples/Introduction_to_Iterative_Detection_and_Decoding.html#GPU-Configuration-and-Imports)\n- [Simulation Parameters](https://nvlabs.github.io/sionna/examples/Introduction_to_Iterative_Detection_and_Decoding.html#Simulation-Parameters)\n- [Setting-up the Keras Models](https://nvlabs.github.io/sionna/examples/Introduction_to_Iterative_Detection_and_Decoding.html#Setting-up-the-Keras-Models)\n- [Non-IDD versus IDD Benchmarks](https://nvlabs.github.io/sionna/examples/Introduction_to_Iterative_Detection_and_Decoding.html#Non-IDD-versus-IDD-Benchmarks)\n- [Discussion-Optimizing IDD with Machine Learning](https://nvlabs.github.io/sionna/examples/Introduction_to_Iterative_Detection_and_Decoding.html#Discussion-Optimizing-IDD-with-Machine-Learning)\n- [Comments](https://nvlabs.github.io/sionna/examples/Introduction_to_Iterative_Detection_and_Decoding.html#Comments)\n- [List of References](https://nvlabs.github.io/sionna/examples/Introduction_to_Iterative_Detection_and_Decoding.html#List-of-References)"
"## GPU Configuration and Imports\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sionna.mimo import StreamManagement\nfrom sionna.utils import QAMSource, BinarySource, sim_ber, ebnodb2no, QAMSource, expand_to_rank\nfrom sionna.mapping import Mapper, Constellation\nfrom sionna.ofdm import ResourceGrid, ResourceGridMapper, LSChannelEstimator, LinearDetector, KBestDetector, EPDetector, \\\n    RemoveNulledSubcarriers, MMSEPICDetector\nfrom sionna.channel import GenerateOFDMChannel, OFDMChannel, RayleighBlockFading, gen_single_sector_topology\nfrom sionna.channel.tr38901 import UMa, Antenna, PanelArray\nfrom sionna.fec.ldpc import LDPC5GEncoder\nfrom sionna.fec.ldpc import LDPC5GDecoder\n```\n\n```python\nimport tensorflow as tf\nfrom tensorflow.keras import Model\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\n```"
"## Simulation Parameters\n\nIn the following, we set the simulation parameters. Please modify at will; adapting the batch size to your hardware setup might be beneficial.\n\nThe standard configuration implements a coded 5G inspired MU-MIMO OFDM uplink transmission over 3GPP UMa channels, with 4 single-antenna UEs, 16-QAM modulation, and a 16 element dual-polarized uniform planar antenna array (UPA) at the gNB. We implement least squares channel estimation with linear interpolation. Alternatively, we implement iid Rayleigh fading channels and perfect channel state information (CSI), which can be controlled by the model parameter `perfect_csi_rayleigh`. As channel\ncode, we apply a rate-matched 5G LDPC code at rate 1/2.\n\n\n```python\nSIMPLE_SIM = False   # reduced simulation time for simple simulation if set to True\nif SIMPLE_SIM:\n    batch_size = int(1e1)  # number of OFDM frames to be analyzed per batch\n    num_iter = 5  # number of Monte Carlo Iterations (total number of Monte Carlo trials is num_iter*batch_size)\n    num_steps = 6\n    tf.config.run_functions_eagerly(True)   # run eagerly for better debugging\nelse:\n    batch_size = int(64)  # number of OFDM frames to be analyzed per batch\n    num_iter = 128  # number of Monte Carlo Iterations (total number of Monte Carlo trials is num_iter*batch_size)\n    num_steps = 11\nebno_db_min_perf_csi = -10  # min EbNo value in dB for perfect csi benchmarks\nebno_db_max_perf_csi = 0\nebno_db_min_cest = -10\nebno_db_max_cest = 10\n\nNUM_OFDM_SYMBOLS = 14\nFFT_SIZE = 12*4 # 4 PRBs\nSUBCARRIER_SPACING = 30e3 # Hz\nCARRIER_FREQUENCY = 3.5e9 # Hz\nSPEED = 3. # m/s\nnum_bits_per_symbol = 4 # 16 QAM\nn_ue = 4 # 4 UEs\nNUM_RX_ANT = 16 # 16 BS antennas\nnum_pilot_symbols = 2\n# The user terminals (UTs) are equipped with a single antenna\n# with vertial polarization.\nUT_ANTENNA = Antenna(polarization='single',\n                     polarization_type='V',\n                     antenna_pattern='omni', # Omnidirectional antenna pattern\n                     carrier_frequency=CARRIER_FREQUENCY)\n# The base station is equipped with an antenna\n# array of 8 cross-polarized antennas,\n# resulting in a total of 16 antenna elements.\nBS_ARRAY = PanelArray(num_rows_per_panel=2,\n                      num_cols_per_panel=4,\n                      polarization='dual',\n                      polarization_type='cross',\n                      antenna_pattern='38.901', # 3GPP 38.901 antenna pattern\n                      carrier_frequency=CARRIER_FREQUENCY)\n# 3GPP UMa channel model is considered\nchannel_model_uma = UMa(carrier_frequency=CARRIER_FREQUENCY,\n                    o2i_model='low',\n                    ut_array=UT_ANTENNA,\n                    bs_array=BS_ARRAY,\n                    direction='uplink',\n                    enable_shadow_fading=False,\n                    enable_pathloss=False)\nchannel_model_rayleigh = RayleighBlockFading(num_rx=1, num_rx_ant=NUM_RX_ANT, num_tx=n_ue, num_tx_ant=1)\nconstellation = Constellation(\"qam\", num_bits_per_symbol=num_bits_per_symbol)\nrx_tx_association = np.ones([1, n_ue])\nsm = StreamManagement(rx_tx_association, 1)\n# Parameterize the OFDM channel\nrg = ResourceGrid(num_ofdm_symbols=NUM_OFDM_SYMBOLS, pilot_ofdm_symbol_indices = [2, 11],\n                  fft_size=FFT_SIZE, num_tx=n_ue,\n                  pilot_pattern = \"kronecker\",\n                  subcarrier_spacing=SUBCARRIER_SPACING)\nrg.show()\nplt.show()\n# Parameterize the instruction_answer code\nR = 0.5  # rate 1/2\nN = int(FFT_SIZE * (NUM_OFDM_SYMBOLS - 2) * num_bits_per_symbol)\n# N = int((FFT_SIZE) * (NUM_OFDM_SYMBOLS - 2) * num_bits_per_symbol)\n# code length; - 12 because of 11 guard carriers and 1 DC carrier, - 2 becaues of 2 pilot symbols\nK = int(N * R)  # number of information bits per codeword\n\n```"
"## Setting-up the Keras Models\n\nNow, we define the baseline models for benchmarking. Let us start with the non-IDD models.\n\n\n```python\nclass NonIddModel(Model):\n    def __init__(self, num_bp_iter=12, detector='lmmse', cest_type=\"LS\", interp=\"lin\", perfect_csi_rayleigh=False):\n        super().__init__()\n        self._num_bp_iter = int(num_bp_iter)\n        ######################################\n        ## Transmitter\n        self._binary_source = BinarySource()\n        self._encoder = LDPC5GEncoder(K, N, num_bits_per_symbol=num_bits_per_symbol)\n        self._mapper = Mapper(constellation=constellation)\n        self._rg_mapper = ResourceGridMapper(rg)\n        # Channel\n        if perfect_csi_rayleigh:\n            self._channel_model = channel_model_rayleigh\n        else:\n            self._channel_model = channel_model_uma\n        self._channel = OFDMChannel(channel_model=self._channel_model,\n                                    resource_grid=rg,\n                                    add_awgn=True, normalize_channel=True, return_channel=True)\n        # Receiver\n        self._cest_type = cest_type\n        self._interp = interp\n        # Channel estimation\n        self._perfect_csi_rayleigh = perfect_csi_rayleigh\n        if self._perfect_csi_rayleigh:\n            self._removeNulledSc = RemoveNulledSubcarriers(rg)\n        elif cest_type == \"LS\":\n            self._ls_est = LSChannelEstimator(rg, interpolation_type=interp)\n        else:\n            raise NotImplementedError('Not implemented:' + cest_type)\n        # Detection\n        if detector == \"lmmse\":\n            self._detector = LinearDetector(\"lmmse\", 'bit', \"maxlog\", rg, sm, constellation_type=\"qam\",\n                                            num_bits_per_symbol=num_bits_per_symbol, hard_out=False)\n        elif detector == \"k-best\":\n            k = 64\n            self._detector = KBestDetector('bit', n_ue, k, rg, sm, constellation_type=\"qam\",\n                                           num_bits_per_symbol=num_bits_per_symbol, hard_out=False)\n        elif detector == \"ep\":\n            l = 10\n            self._detector = EPDetector('bit', rg, sm, num_bits_per_symbol, l=l, hard_out=False)\n        # Forward error correction (decoder)\n        self._decoder = LDPC5GDecoder(self._encoder, return_infobits=True, hard_out=True, num_iter=num_bp_iter, cn_type='minsum')\n    def new_topology(self, batch_size):\n        \"\"\"Set new topology\"\"\"\n        if isinstance(self._channel_model, UMa):\n            # sensible values according to 3GPP standard, no mobility by default\n            topology = gen_single_sector_topology(batch_size,\n                                                  n_ue, max_ut_velocity=SPEED,\n                                                  scenario=\"uma\")\n            self._channel_model.set_topology(*topology)\n    @tf.function  # We don't use jit_compile=True to ensure better numerical stability\n    def call(self, batch_size, ebno_db):\n        self.new_topology(batch_size)\n        if len(ebno_db.shape) == 0:\n            ebno_db = tf.fill([batch_size], ebno_db)\n        ######################################\n        ## Transmitter\n        no = ebnodb2no(ebno_db=ebno_db, num_bits_per_symbol=num_bits_per_symbol,\n                       coderate=R)  # normalize in OFDM freq. domain\n        b = self._binary_source([batch_size, n_ue, 1, K])\n        c = self._encoder(b)\n        # Modulation\n        x = self._mapper(c)\n        x_rg = self._rg_mapper(x)\n        ######################################\n        ## Channel\n        # A batch of new channel realizations is sampled and applied at every inference\n        no_ = expand_to_rank(no, tf.rank(x_rg))\n        y, h = self._channel([x_rg, no_])\n        ######################################\n        ## Receiver\n        if self._perfect_csi_rayleigh:\n            h_hat = self._removeNulledSc(h)\n            chan_est_var = tf.zeros(tf.shape(h_hat),\n                                    dtype=tf.float32)  # No channel estimation error when perfect CSI knowledge is assumed\n        else:\n            h_hat, chan_est_var = self._ls_est([y, no])\n        llr_ch = self._detector((y, h_hat, chan_est_var, no))  # detector\n        b_hat = self._decoder((llr_ch))\n        return b, b_hat\n```"
"Next, we implement the IDD model with a non-resetting LDPC decoder, as in [3], i.e., we forward the LLRs and decoder state from one IDD iteration to the following.\n\n\n```python\nclass IddModel(NonIddModel):  # inherited from NonIddModel\n    def __init__(self, num_idd_iter=3, num_bp_iter_per_idd_iter=12, cest_type=\"LS\", interp=\"lin\", perfect_csi_rayleigh=False):\n        super().__init__(num_bp_iter=num_bp_iter_per_idd_iter, detector=\"lmmse\", cest_type=cest_type,\n                         interp=interp, perfect_csi_rayleigh=perfect_csi_rayleigh)\n        # first IDD detector is LMMSE as MMSE-PIC with zero-prior bils down to soft-output LMMSE\n        self._num_idd_iter = num_idd_iter\n        self._siso_detector = MMSEPICDetector(output=\"bit\", resource_grid=rg, stream_management=sm,\n                                              demapping_method='maxlog', constellation=constellation, num_iter=1,\n                                              hard_out=False)\n        self._siso_decoder = LDPC5GDecoder(self._encoder, return_infobits=False,\n                                           num_iter=num_bp_iter_per_idd_iter, stateful=True, hard_out=False, cn_type='minsum')\n        self._decoder = LDPC5GDecoder(self._encoder, return_infobits=True, stateful=True, hard_out=True, num_iter=num_bp_iter_per_idd_iter, cn_type='minsum')\n        # last decoder must also be statefull\n    @tf.function  # We don't use jit_compile=True to ensure better numerical stability\n    def call(self, batch_size, ebno_db):\n        self.new_topology(batch_size)\n        if len(ebno_db.shape) == 0:\n            ebno_db = tf.fill([batch_size], ebno_db)\n        ######################################\n        ## Transmitter\n        no = ebnodb2no(ebno_db=ebno_db, num_bits_per_symbol=num_bits_per_symbol,\n                       coderate=R)  # normalize in OFDM freq. domain\n        b = self._binary_source([batch_size, n_ue, 1, K])\n        c = self._encoder(b)\n        # Modulation\n        x = self._mapper(c)\n        x_rg = self._rg_mapper(x)\n        ######################################\n        ## Channel\n        # A batch of new channel realizations is sampled and applied at every inference\n        no_ = expand_to_rank(no, tf.rank(x_rg))\n        y, h = self._channel([x_rg, no_])\n        ######################################\n        ## Receiver\n        if self._perfect_csi_rayleigh:\n            h_hat = self._removeNulledSc(h)\n            chan_est_var = tf.zeros(tf.shape(h_hat),\n                                    dtype=tf.float32)  # No channel estimation error when perfect CSI knowledge is assumed\n        else:\n            h_hat, chan_est_var = self._ls_est([y, no])\n        llr_ch = self._detector((y, h_hat, chan_est_var, no))  # soft-output LMMSE detection\n        msg_vn = None\n        if self._num_idd_iter >= 2:\n            # perform first iteration outside the while_loop to initialize msg_vn\n            [llr_dec, msg_vn] = self._siso_decoder((llr_ch, msg_vn))\n            # forward a posteriori information from decoder\n            llr_ch = self._siso_detector((y, h_hat, llr_dec, chan_est_var, no))\n            # forward extrinsic information\n            def idd_iter(llr_ch, msg_vn, it):\n                [llr_dec, msg_vn] = self._siso_decoder([llr_ch, msg_vn])\n                # forward a posteriori information from decoder\n                llr_ch = self._siso_detector((y, h_hat, llr_dec, chan_est_var, no))\n                # forward extrinsic information from detector\n                it += 1\n                return llr_ch, msg_vn, it\n            def idd_stop(llr_ch, msg_vn, it):\n                return tf.less(it, self._num_idd_iter - 1)\n            it = tf.constant(1)     # we already performed initial detection and one full iteration\n            llr_ch, msg_vn, it = tf.while_loop(idd_stop, idd_iter, (llr_ch, msg_vn, it), parallel_iterations=1,\n                                               maximum_iterations=self._num_idd_iter - 1)\n        else:\n            # non-idd\n            pass\n        [b_hat, _] = self._decoder((llr_ch, msg_vn))    # final hard-output decoding (only returning information bits)\n        return b, b_hat\n```"
"## Non-IDD versus IDD Benchmarks\n\n\n```python\n# Range of SNR (dB)\nsnr_range_cest = np.linspace(ebno_db_min_cest, ebno_db_max_cest, num_steps)\nsnr_range_perf_csi = np.linspace(ebno_db_min_perf_csi, ebno_db_max_perf_csi, num_steps)\ndef run_idd_sim(snr_range, perfect_csi_rayleigh):\n    lmmse = NonIddModel(detector=\"lmmse\", perfect_csi_rayleigh=perfect_csi_rayleigh)\n    k_best = NonIddModel(detector=\"k-best\", perfect_csi_rayleigh=perfect_csi_rayleigh)\n    ep = NonIddModel(detector=\"ep\", perfect_csi_rayleigh=perfect_csi_rayleigh)\n    idd2 = IddModel(num_idd_iter=2, perfect_csi_rayleigh=perfect_csi_rayleigh)\n    idd3 = IddModel(num_idd_iter=3, perfect_csi_rayleigh=perfect_csi_rayleigh)\n    ber_lmmse, bler_lmmse = sim_ber(lmmse,\n                                    snr_range,\n                                    batch_size=batch_size,\n                                    max_mc_iter=num_iter,\n                                    num_target_block_errors=int(batch_size * num_iter * 0.1))\n    ber_ep, bler_ep = sim_ber(ep,\n                              snr_range,\n                              batch_size=batch_size,\n                              max_mc_iter=num_iter,\n                              num_target_block_errors=int(batch_size * num_iter * 0.1))\n    ber_kbest, bler_kbest = sim_ber(k_best,\n                                    snr_range,\n                                    batch_size=batch_size,\n                                    max_mc_iter=num_iter,\n                                    num_target_block_errors=int(batch_size * num_iter * 0.1))\n    ber_idd2, bler_idd2 = sim_ber(idd2,\n                                  snr_range,\n                                  batch_size=batch_size,\n                                  max_mc_iter=num_iter,\n                                  num_target_block_errors=int(batch_size * num_iter * 0.1))\n    ber_idd3, bler_idd3 = sim_ber(idd3,\n                                  snr_range,\n                                  batch_size=batch_size,\n                                  max_mc_iter=num_iter,\n                                  num_target_block_errors=int(batch_size * num_iter * 0.1))\n    return bler_lmmse, bler_ep, bler_kbest, bler_idd2, bler_idd3\n\nBLER = {}\n# Perfect CSI\nbler_lmmse, bler_ep, bler_kbest, bler_idd2, bler_idd3 = run_idd_sim(snr_range_perf_csi, perfect_csi_rayleigh=True)\nBLER['Perf. CSI / LMMSE'] = bler_lmmse\nBLER['Perf. CSI / EP'] = bler_ep\nBLER['Perf. CSI / K-Best'] = bler_kbest\nBLER['Perf. CSI / IDD2'] = bler_idd2\nBLER['Perf. CSI / IDD3'] = bler_idd3\n# Estimated CSI\nbler_lmmse, bler_ep, bler_kbest, bler_idd2, bler_idd3 = run_idd_sim(snr_range_cest, perfect_csi_rayleigh=False)\nBLER['Ch. Est. / LMMSE'] = bler_lmmse\nBLER['Ch. Est. / EP'] = bler_ep\nBLER['Ch. Est. / K-Best'] = bler_kbest\nBLER['Ch. Est. / IDD2'] = bler_idd2\nBLER['Ch. Est. / IDD3'] = bler_idd3\n```"
"```python\nWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/autograph/pyct/static_analysis/liveness.py:83: Analyzer.lamba_check (from tensorflow.python.autograph.pyct.static_analysis.liveness) is deprecated and will be removed after 2023-09-23.\nInstructions for updating:\nLambda fuctions will be no more assumed to be used in the statement where they are used, or at least in the same block. https://github.com/tensorflow/tensorflow/issues/56089\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 2.1174e-01 | 1.0000e+00 |      249776 |     1179648 |         1024 |        1024 |         5.7 |reached target block errors\n     -9.0 | 1.8563e-01 | 1.0000e+00 |      218982 |     1179648 |         1024 |        1024 |         0.3 |reached target block errors\n     -8.0 | 1.0665e-01 | 9.5898e-01 |      125808 |     1179648 |          982 |        1024 |         0.3 |reached target block errors\n     -7.0 | 1.6909e-02 | 3.3828e-01 |       49867 |     2949120 |          866 |        2560 |         0.9 |reached target block errors\n     -6.0 | 1.1546e-03 | 3.3143e-02 |       33030 |    28606464 |          823 |       24832 |         8.3 |reached target block errors\n     -5.0 | 6.4903e-05 | 2.3804e-03 |        2450 |    37748736 |           78 |       32768 |        11.0 |reached max iter\n     -4.0 | 2.6491e-07 | 1.2207e-04 |          10 |    37748736 |            4 |       32768 |        10.9 |reached max iter\n     -3.0 | 0.0000e+00 | 0.0000e+00 |           0 |    37748736 |            0 |       32768 |        10.9 |reached max iter\nSimulation stopped as no error occurred @ EbNo = -3.0 dB.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 2.1091e-01 | 1.0000e+00 |      248794 |     1179648 |         1024 |        1024 |         3.8 |reached target block errors\n     -9.0 | 1.8493e-01 | 1.0000e+00 |      218155 |     1179648 |         1024 |        1024 |         0.4 |reached target block errors\n     -8.0 | 9.8120e-02 | 9.5508e-01 |      115747 |     1179648 |          978 |        1024 |         0.4 |reached target block errors\n     -7.0 | 1.1955e-02 | 2.8027e-01 |       42309 |     3538944 |          861 |        3072 |         1.2 |reached target block errors\n     -6.0 | 4.5117e-04 | 1.6541e-02 |       17031 |    37748736 |          542 |       32768 |        12.7 |reached max iter\n     -5.0 | 1.5471e-05 | 7.6294e-04 |         584 |    37748736 |           25 |       32768 |        12.5 |reached max iter\n     -4.0 | 0.0000e+00 | 0.0000e+00 |           0 |    37748736 |            0 |       32768 |        12.7 |reached max iter\nSimulation stopped as no error occurred @ EbNo = -4.0 dB.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 2.1164e-01 | 1.0000e+00 |      249660 |     1179648 |         1024 |        1024 |         6.3 |reached target block errors\n     -9.0 | 1.8471e-01 | 1.0000e+00 |      217898 |     1179648 |         1024 |        1024 |         2.1 |reached target block errors\n     -8.0 | 1.1558e-01 | 9.9512e-01 |      136338 |     1179648 |         1019 |        1024 |         2.1 |reached target block errors\n     -7.0 | 1.8488e-02 | 5.6315e-01 |       32714 |     1769472 |          865 |        1536 |         3.2 |reached target block errors\n     -6.0 | 9.5951e-04 | 4.6762e-02 |       19525 |    20348928 |          826 |       17664 |        36.3 |reached target block errors\n     -5.0 | 1.9338e-05 | 1.4343e-03 |         730 |    37748736 |           47 |       32768 |        67.2 |reached max iter\n     -4.0 | 1.5895e-07 | 6.1035e-05 |           6 |    37748736 |            2 |       32768 |        67.2 |reached max iter\n     -3.0 | 0.0000e+00 | 0.0000e+00 |           0 |    37748736 |            0 |       32768 |        67.0 |reached max iter\nSimulation stopped as no error occurred @ EbNo = -3.0 dB.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 2.1164e-01 | 1.0000e+00 |      249662 |     1179648 |         1024 |        1024 |         8.2 |reached target block errors\n     -9.0 | 1.8639e-01 | 1.0000e+00 |      219878 |     1179648 |         1024 |        1024 |         0.6 |reached target block errors\n     -8.0 | 8.6596e-02 | 6.9844e-01 |      127691 |     1474560 |          894 |        1280 |         0.7 |reached target block errors\n     -7.0 | 3.4296e-03 | 4.6535e-02 |       69788 |    20348928 |          822 |       17664 |        10.3 |reached target block errors\n     -6.0 | 6.1750e-05 | 8.5449e-04 |        2331 |    37748736 |           28 |       32768 |        18.9 |reached max iter\n     -5.0 | 1.0596e-06 | 3.0518e-05 |          40 |    37748736 |            1 |       32768 |        18.9 |reached max iter\n     -4.0 | 0.0000e+00 | 0.0000e+00 |           0 |    37748736 |            0 |       32768 |        18.9 |reached max iter\nSimulation stopped as no error occurred @ EbNo = -4.0 dB.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 2.1188e-01 | 1.0000e+00 |      249945 |     1179648 |         1024 |        1024 |         7.8 |reached target block errors\n     -9.0 | 1.8657e-01 | 9.9805e-01 |      220084 |     1179648 |         1022 |        1024 |         0.8 |reached target block errors\n     -8.0 | 7.6331e-02 | 5.7943e-01 |      135065 |     1769472 |          890 |        1536 |         1.2 |reached target block errors\n     -7.0 | 1.6263e-03 | 1.7822e-02 |       61390 |    37748736 |          584 |       32768 |        25.7 |reached max iter\n     -6.0 | 1.7325e-05 | 2.4414e-04 |         654 |    37748736 |            8 |       32768 |        25.5 |reached max iter\n     -5.0 | 0.0000e+00 | 0.0000e+00 |           0 |    37748736 |            0 |       32768 |        25.7 |reached max iter\nSimulation stopped as no error occurred @ EbNo = -5.0 dB.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 2.9984e-01 | 1.0000e+00 |      353711 |     1179648 |         1024 |        1024 |        12.3 |reached target block errors\n     -8.0 | 2.6258e-01 | 1.0000e+00 |      309751 |     1179648 |         1024 |        1024 |         0.4 |reached target block errors\n     -6.0 | 2.2838e-01 | 1.0000e+00 |      269403 |     1179648 |         1024 |        1024 |         0.4 |reached target block errors\n     -4.0 | 1.4912e-01 | 9.0723e-01 |      175910 |     1179648 |          929 |        1024 |         0.4 |reached target block errors\n     -2.0 | 4.0182e-02 | 3.2930e-01 |      118503 |     2949120 |          843 |        2560 |         1.1 |reached target block errors\n      0.0 | 9.7169e-03 | 8.6571e-02 |      106028 |    10911744 |          820 |        9472 |         4.1 |reached target block errors\n      2.0 | 2.8845e-03 | 2.3529e-02 |      108885 |    37748736 |          771 |       32768 |        14.3 |reached max iter\n      4.0 | 1.2734e-03 | 9.0942e-03 |       48069 |    37748736 |          298 |       32768 |        14.1 |reached max iter\n      6.0 | 7.8371e-04 | 5.0354e-03 |       29584 |    37748736 |          165 |       32768 |        14.3 |reached max iter\n      8.0 | 9.9370e-04 | 6.1340e-03 |       37511 |    37748736 |          201 |       32768 |        14.2 |reached max iter\n     10.0 | 7.6546e-04 | 4.9744e-03 |       28895 |    37748736 |          163 |       32768 |        14.4 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 3.0051e-01 | 1.0000e+00 |      354491 |     1179648 |         1024 |        1024 |         6.8 |reached target block errors\n     -8.0 | 2.6452e-01 | 1.0000e+00 |      312037 |     1179648 |         1024 |        1024 |         0.5 |reached target block errors\n     -6.0 | 2.2600e-01 | 1.0000e+00 |      266602 |     1179648 |         1024 |        1024 |         0.5 |reached target block errors\n     -4.0 | 1.4565e-01 | 9.0625e-01 |      171821 |     1179648 |          928 |        1024 |         0.5 |reached target block errors\n     -2.0 | 4.0697e-02 | 3.4258e-01 |      120021 |     2949120 |          877 |        2560 |         1.3 |reached target block errors\n      0.0 | 7.6236e-03 | 6.9633e-02 |      103421 |    13565952 |          820 |       11776 |         5.8 |reached target block errors\n      2.0 | 1.9709e-03 | 1.5198e-02 |       74400 |    37748736 |          498 |       32768 |        16.0 |reached max iter\n      4.0 | 9.2236e-04 | 6.6528e-03 |       34818 |    37748736 |          218 |       32768 |        16.1 |reached max iter\n      6.0 | 7.6371e-04 | 5.6152e-03 |       28829 |    37748736 |          184 |       32768 |        16.1 |reached max iter\n      8.0 | 1.0540e-03 | 6.3477e-03 |       39788 |    37748736 |          208 |       32768 |        15.9 |reached max iter\n     10.0 | 9.5132e-04 | 6.2866e-03 |       35911 |    37748736 |          206 |       32768 |        16.1 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 3.0523e-01 | 1.0000e+00 |      360064 |     1179648 |         1024 |        1024 |         8.7 |reached target block errors\n     -8.0 | 2.6928e-01 | 1.0000e+00 |      317651 |     1179648 |         1024 |        1024 |         2.2 |reached target block errors\n     -6.0 | 2.3226e-01 | 1.0000e+00 |      273984 |     1179648 |         1024 |        1024 |         2.2 |reached target block errors\n     -4.0 | 1.6056e-01 | 9.7266e-01 |      189406 |     1179648 |          996 |        1024 |         2.2 |reached target block errors\n     -2.0 | 3.5856e-02 | 3.6936e-01 |       95168 |     2654208 |          851 |        2304 |         5.0 |reached target block errors\n      0.0 | 6.1384e-03 | 5.8168e-02 |       99566 |    16220160 |          819 |       14080 |        30.4 |reached target block errors\n      2.0 | 1.2737e-03 | 1.0498e-02 |       48079 |    37748736 |          344 |       32768 |        70.6 |reached max iter\n      4.0 | 9.2064e-04 | 5.4932e-03 |       34753 |    37748736 |          180 |       32768 |        70.7 |reached max iter\n      6.0 | 9.2936e-04 | 5.0049e-03 |       35082 |    37748736 |          164 |       32768 |        70.9 |reached max iter\n      8.0 | 7.4246e-04 | 4.6082e-03 |       28027 |    37748736 |          151 |       32768 |        70.6 |reached max iter\n     10.0 | 7.8665e-04 | 5.1270e-03 |       29695 |    37748736 |          168 |       32768 |        70.6 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 3.0156e-01 | 1.0000e+00 |      355731 |     1179648 |         1024 |        1024 |        11.2 |reached target block errors\n     -8.0 | 2.6622e-01 | 1.0000e+00 |      314046 |     1179648 |         1024 |        1024 |         0.7 |reached target block errors\n     -6.0 | 2.3190e-01 | 1.0000e+00 |      273565 |     1179648 |         1024 |        1024 |         0.7 |reached target block errors\n     -4.0 | 1.5164e-01 | 8.2324e-01 |      178884 |     1179648 |          843 |        1024 |         0.7 |reached target block errors\n     -2.0 | 3.0409e-02 | 2.0581e-01 |      143489 |     4718592 |          843 |        4096 |         2.8 |reached target block errors\n      0.0 | 4.0669e-03 | 3.0469e-02 |      125935 |    30965760 |          819 |       26880 |        18.0 |reached target block errors\n      2.0 | 1.4712e-03 | 9.0942e-03 |       55536 |    37748736 |          298 |       32768 |        22.0 |reached max iter\n      4.0 | 6.7668e-04 | 3.9368e-03 |       25544 |    37748736 |          129 |       32768 |        21.9 |reached max iter\n      6.0 | 7.9192e-04 | 4.2725e-03 |       29894 |    37748736 |          140 |       32768 |        21.7 |reached max iter\n      8.0 | 8.3711e-04 | 5.1575e-03 |       31600 |    37748736 |          169 |       32768 |        22.3 |reached max iter\n     10.0 | 7.4954e-04 | 4.7913e-03 |       28294 |    37748736 |          157 |       32768 |        22.0 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 3.0150e-01 | 1.0000e+00 |      355662 |     1179648 |         1024 |        1024 |        11.6 |reached target block errors\n     -8.0 | 2.6787e-01 | 1.0000e+00 |      315993 |     1179648 |         1024 |        1024 |         0.9 |reached target block errors\n     -6.0 | 2.3101e-01 | 1.0000e+00 |      272511 |     1179648 |         1024 |        1024 |         0.9 |reached target block errors\n     -4.0 | 1.4615e-01 | 7.9844e-01 |      215510 |     1474560 |         1022 |        1280 |         1.2 |reached target block errors\n     -2.0 | 2.3105e-02 | 1.4453e-01 |      156722 |     6782976 |          851 |        5888 |         5.3 |reached target block errors\n      0.0 | 3.5593e-03 | 2.1973e-02 |      134358 |    37748736 |          720 |       32768 |        29.4 |reached max iter\n      2.0 | 1.3395e-03 | 7.1411e-03 |       50564 |    37748736 |          234 |       32768 |        29.2 |reached max iter\n      4.0 | 7.4816e-04 | 3.9062e-03 |       28242 |    37748736 |          128 |       32768 |        29.4 |reached max iter\n      6.0 | 7.6657e-04 | 3.9368e-03 |       28937 |    37748736 |          129 |       32768 |        29.4 |reached max iter\n      8.0 | 8.2713e-04 | 4.1504e-03 |       31223 |    37748736 |          136 |       32768 |        29.3 |reached max iter\n     10.0 | 7.2932e-04 | 4.2114e-03 |       27531 |    37748736 |          138 |       32768 |        29.4 |reached max iter\n```"
"Finally, we plot the simulation results and observe that IDD outperforms the non-iterative methods by about 1 dB in the scenario with iid Rayleigh fading channels and perfect CSI. In the scenario with 3GPP UMa channels and estimated CSI, IDD performs slightly better than K-best, at considerably lower runtime.\n\n\n```python\nfig, ax = plt.subplots(1,2, figsize=(16,7))\nfig.suptitle(f\"{n_ue}x{NUM_RX_ANT} MU-MIMO UL | {2**num_bits_per_symbol}-QAM\")\n## Perfect CSI Rayleigh\nax[0].set_title(\"Perfect CSI iid. Rayleigh\")\nax[0].semilogy(snr_range_perf_csi, BLER['Perf. CSI / LMMSE'], 'x-', label='LMMSE', c='C0')\nax[0].semilogy(snr_range_perf_csi, BLER['Perf. CSI / EP'], 'o--', label='EP', c='C0')\nax[0].semilogy(snr_range_perf_csi, BLER['Perf. CSI / K-Best'], 's-.', label='K-Best', c='C0')\nax[0].semilogy(snr_range_perf_csi, BLER['Perf. CSI / IDD2'], 'd:', label=r'IDD $I=2$', c='C1')\nax[0].semilogy(snr_range_perf_csi, BLER['Perf. CSI / IDD3'], 'd:', label=r'IDD $I=3$', c='C2')\nax[0].set_xlabel(r\"$E_b/N0$\")\nax[0].set_ylabel(\"BLER\")\nax[0].set_ylim((1e-4, 1.0))\nax[0].legend()\nax[0].grid(True)\n## Estimated CSI Rayleigh\nax[1].set_title(\"Estimated CSI 3GPP UMa\")\nax[1].semilogy(snr_range_cest, BLER['Ch. Est. / LMMSE'], 'x-', label='LMMSE', c='C0')\nax[1].semilogy(snr_range_cest, BLER['Ch. Est. / EP'], 'o--', label='EP', c='C0')\nax[1].semilogy(snr_range_cest, BLER['Ch. Est. / K-Best'], 's-.', label='K-Best', c='C0')\nax[1].semilogy(snr_range_cest, BLER['Ch. Est. / IDD2'], 'd:', label=r'IDD $I=2$', c='C1')\nax[1].semilogy(snr_range_cest, BLER['Ch. Est. / IDD3'], 'd:', label=r'IDD $I=3$', c='C2')\nax[1].set_xlabel(r\"$E_b/N0$\")\nax[1].set_ylabel(\"BLER\")\nax[1].set_ylim((1e-3, 1.0))\nax[1].legend()\nax[1].grid(True)\nplt.show()\n```"
"## Discussion-Optimizing IDD with Machine Learning\n\nRecent work [4] showed that IDD can be significantly improved by deep-unfolding, which applies machine learning to automatically tune hyperparameters of classical algorithms. The proposed *Deep-Unfolded Interleaved Detection and Decoding* method showed performance gains of up to 1.4 dB at the same computational complexity. A link to the simulation code is available in the <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/made_with_sionna.html#duidd-deep-unfolded-interleaved-detection-and-decoding-for-mimo-wireless-systems\">Made with\nSionna</a> section."
"## Comments\n\n- As discussed in [3], IDD receivers with a non-resetting decoder converge faster than with resetting decoders. However, a resetting decoder (which does not forward `msg_vn`) might perform slightly better for a large number of message passing decoding iterations. Among other quantities, a scaling of the forwarded decoder state is optimized in the DUIDD receiver [4].\n- With estimated channels, we observed that the MMSE-PIC output LLRs become large, much larger as with non-iterative receive processing."
"## List of References\n\n[1] B. Hochwald and S. Ten Brink, [Achieving near-capacity on a multiple-antenna channel,](https://ieeexplore.ieee.org/abstract/document/1194444) IEEE Trans. Commun., vol.51, no. 3, pp.389399, Mar.2003.\n\n[2] C. Studer, S. Fateh, and D. Seethaler, [ASIC implementation of soft-input soft-output MIMO detection using MMSE parallel interference cancellation,](https://ieeexplore.ieee.org/abstract/document/5779722) IEEE Journal of Solid-State Circuits, vol.46, no. 7, pp.17541765, Jul.2011.\n\n[3] W.-C. Sun, W.-H. Wu, C.-H. Yang, and Y.-L. Ueng, [An iterative detection and decoding receiver for LDPC-coded MIMO systems,](https://ieeexplore.ieee.org/abstract/document/7272776) IEEE Trans. Circuits Syst. I, vol.62, no. 10, pp.25122522, Oct.2015.\n\n[4] R. Wiesmayr, C. Dick, J. Hoydis, and C. Studer, [DUIDD: Deep-unfolded interleaved detection and decoding for MIMO wireless systems,](https://arxiv.org/abs/2212.07816) in Asilomar Conf. Signals, Syst., Comput., Oct.2022.[4] R. Wiesmayr, C. Dick, J. Hoydis, and C. Studer, [DUIDD: Deep-unfolded interleaved detection and decoding for MIMO wireless systems,](https://arxiv.org/abs/2212.07816) in Asilomar Conf. Signals, Syst., Comput., Oct.2022.\n[4] R. Wiesmayr, C. Dick, J. Hoydis, and C. Studer, [DUIDD: Deep-unfolded interleaved detection and decoding for MIMO wireless systems,](https://arxiv.org/abs/2212.07816) in Asilomar Conf. Signals, Syst., Comput., Oct.2022.[4] R. Wiesmayr, C. Dick, J. Hoydis, and C. Studer, [DUIDD: Deep-unfolded interleaved detection and decoding for MIMO wireless systems,](https://arxiv.org/abs/2212.07816) in Asilomar Conf. Signals, Syst., Comput., Oct.2022."
"# MIMO OFDM Transmissions over the CDL Channel Model\n\nIn this notebook, you will learn how to setup a realistic simulation of a MIMO point-to-point link between a mobile user terminal (UT) and a base station (BS). Both, uplink and downlink directions are considered. Here is a schematic diagram of the system model with all required components:\n\n\nThe setup includes:\n\n- 5G LDPC FEC\n- QAM modulation\n- OFDM resource grid with configurabel pilot pattern\n- Multiple data streams\n- 3GPP 38.901 CDL channel models and antenna patterns\n- ZF Precoding with perfect channel state information\n- LS Channel estimation with nearest-neighbor interpolation as well as perfect CSI\n- LMMSE MIMO equalization\n\n\nYou will learn how to simulate the channel in the time and frequency domains and understand when to use which option.\n\nIn particular, you will investigate:\n\n- The performance over different CDL models\n- The impact of imperfect CSI\n- Channel aging due to mobility\n- Inter-symbol interference due to insufficient cyclic prefix length\n\n\nWe will first walk through the configuration of all components of the system model, before simulating some simple transmissions in the time and frequency domain. Then, we will build a general Keras model which will allow us to run efficiently simulations with different parameter settings.\n\nThis is a notebook demonstrating a fairly advanced use of the Sionna library. It is recommended that you familiarize yourself with the API documentation of the [Channel](https://nvlabs.github.io/sionna/api/channel.html) module and understand the difference between time- and frequency-domain modeling. Some of the simulations take some time, especially when you have no GPU available. For this reason, we provide the simulation results within the cells generating the figures. If you want to\nvisualize your own results, just comment the corresponding line."
"### Stream Management\n\nFor any type of MIMO simulations, it is useful to setup a [StreamManagement](https://nvlabs.github.io/sionna/api/mimo.html#stream-management) object. It determines which transmitters and receivers communicate data streams with each other. In our scenario, we will configure a single UT and BS with multiple antennas each. Whether the UT or BS is considered as a transmitter depends on the `direction`, which can be either uplink or downlink. The\n[StreamManagement](https://nvlabs.github.io/sionna/api/mimo.html#stream-management) has many properties that are used by other components, such as precoding and equalization.\n\nWe will configure the system here such that the number of streams per transmitter (in both uplink and donwlink) is equal to the number of UT antennas.\n\n\n```python\n# Define the number of UT and BS antennas.\n# For the CDL model, that will be used in this notebook, only\n# a single UT and BS are supported.\nnum_ut = 1\nnum_bs = 1\nnum_ut_ant = 4\nnum_bs_ant = 8\n# The number of transmitted streams is equal to the number of UT antennas\n# in both uplink and downlink\nnum_streams_per_tx = num_ut_ant\n# Create an RX-TX association matrix\n# rx_tx_association[i,j]=1 means that receiver i gets at least one stream\n# from transmitter j. Depending on the transmission direction (uplink or downlink),\n# the role of UT and BS can change. However, as we have only a single\n# transmitter and receiver, this does not matter:\nrx_tx_association = np.array([[1]])\n# Instantiate a StreamManagement object\n# This determines which data streams are determined for which receiver.\n# In this simple setup, this is fairly easy. However, it can get more involved\n# for simulations with many transmitters and receivers.\nsm = StreamManagement(rx_tx_association, num_streams_per_tx)\n```"
"### OFDM Resource Grid & Pilot Pattern\n\nNext, we configure an OFDM [ResourceGrid](https://nvlabs.github.io/sionna/api/ofdm.html#resource-grid) spanning multiple OFDM symbols. The resource grid contains data symbols and pilots and is equivalent to a *slot* in 4G/5G terminology. Although it is not relevant for our simulation, we null the DC subcarrier and a few guard carriers to the left and right of the spectrum. Also a cyclic prefix is added.\n\nDuring the creation of the [ResourceGrid](https://nvlabs.github.io/sionna/api/ofdm.html#resource-grid), a [PilotPattern](https://nvlabs.github.io/sionna/api/ofdm.html#pilot-pattern) is automatically generated. We could have alternatively created a [PilotPattern](https://nvlabs.github.io/sionna/api/ofdm.html#pilot-pattern) first and then provided it as initialization parameter.\n\n\n```python\nrg = ResourceGrid(num_ofdm_symbols=14,\n                  fft_size=76,\n                  subcarrier_spacing=15e3,\n                  num_tx=1,\n                  num_streams_per_tx=num_streams_per_tx,\n                  cyclic_prefix_length=6,\n                  num_guard_carriers=[5,6],\n                  dc_null=True,\n                  pilot_pattern=\"kronecker\",\n                  pilot_ofdm_symbol_indices=[2,11])\nrg.show();\n```\n\n\nAs can be seen in the figure above, the resource grid spans 76 subcarriers over 14 OFDM symbols. A DC guard carrier as well as some guard carriers to the left and right of the spectrum are nulled. The third and twelfth OFDM symbol are dedicated to pilot transmissions.\n\nLet us now have a look at the pilot pattern used by the transmitter.\n\n\n```python\nrg.pilot_pattern.show();\n```\n\n\nThe pilot patterns are defined over the resource grid of *effective subcarriers* from which the nulled DC and guard carriers have been removed. This leaves us in our case with 76 - 1 (DC) - 5 (left guards) - 6 (right guards) = 64 effective subcarriers.\n\nWhile the resource grid only knows which resource elements are reserved for pilots, it is the pilot pattern that defines what is actually transmitted on them. In our scenario, we have four transmit streams and configured the [KroneckerPilotPattern](https://nvlabs.github.io/sionna/api/ofdm.html#kroneckerpilotpattern). All streams use orthogonal pilot sequences, i.e., one pilot on every fourth subcarrier. You have full freedom to configure your own\n[PilotPattern](https://nvlabs.github.io/sionna/api/ofdm.html#pilotpattern).\n\nLet us now have a look at the actual pilot sequences for all streams which consists of random QPSK symbols. By default, the pilot sequences are normalized, such that the average power per pilot symbol is equal to one. As only every fourth pilot symbol in the sequence is used, their amplitude is scaled by a factor of two."
"```python\nplt.figure()\nplt.title(\"Real Part of the Pilot Sequences\")\nfor i in range(num_streams_per_tx):\n    plt.stem(np.real(rg.pilot_pattern.pilots[0, i]),\n             markerfmt=\"C{}.\".format(i), linefmt=\"C{}-\".format(i),\n             label=\"Stream {}\".format(i))\nplt.legend()\nprint(\"Average energy per pilot symbol: {:1.2f}\".format(np.mean(np.abs(rg.pilot_pattern.pilots[0,0])**2)))\n```\n\n\n```python\nAverage energy per pilot symbol: 1.00\n```"
"### Antenna Arrays\n\nNext, we need to configure the antenna arrays used by the UT and BS. This can be ignored for simple channel models, such as [AWGN](https://nvlabs.github.io/sionna/api/channel.html#awgn), [flat-fading](https://nvlabs.github.io/sionna/api/channel.html#flat-fading-channel), [RayleighBlockFading](https://nvlabs.github.io/sionna/api/channel.html#rayleigh-block-fading), or [TDL](https://nvlabs.github.io/sionna/api/channel.html#tapped-delay-line-tdl) which do not account for antenna array\ngeometries and antenna radiation patterns. However, other models, such as [CDL](https://nvlabs.github.io/sionna/api/channel.html#clustered-delay-line-cdl), [UMi](https://nvlabs.github.io/sionna/api/channel.html#urban-microcell-umi), [UMa](https://nvlabs.github.io/sionna/api/channel.html#urban-macrocell-uma), and [RMa](https://nvlabs.github.io/sionna/api/channel.html#rural-macrocell-rma) from the 3GPP 38.901 specification, require it.\n\nWe will assume here that UT and BS antenna arrays are composed of dual cross-polarized antenna elements with an antenna pattern defined in the 3GPP 38.901 specification. By default, the antenna elements are spaced half of a wavelength apart in both vertical and horizontal directions. You can define your own antenna geometries an radiation patterns if needed.\n\nAn [AntennaArray](https://nvlabs.github.io/sionna/api/channel.html#antennaarray) is always defined in the y-z plane. Its final orientation will be determined by the orientation of the UT or BS. This parameter can be configured in the [ChannelModel](https://nvlabs.github.io/sionna/api/channel.html#channel-model-interface) that we will create later.\n\n\n```python\ncarrier_frequency = 2.6e9 # Carrier frequency in Hz.\n                          # This is needed here to define the antenna element spacing.\nut_array = AntennaArray(num_rows=1,\n                        num_cols=int(num_ut_ant/2),\n                        polarization=\"dual\",\n                        polarization_type=\"cross\",\n                        antenna_pattern=\"38.901\",\n                        carrier_frequency=carrier_frequency)\nut_array.show()\nbs_array = AntennaArray(num_rows=1,\n                        num_cols=int(num_bs_ant/2),\n                        polarization=\"dual\",\n                        polarization_type=\"cross\",\n                        antenna_pattern=\"38.901\",\n                        carrier_frequency=carrier_frequency)\nbs_array.show()\n```"
"### CDL Channel Model\n\nNow, we will create an instance of the CDL channel model.\n\n\n```python\ndelay_spread = 300e-9 # Nominal delay spread in [s]. Please see the CDL documentation\n                      # about how to choose this value.\ndirection = \"uplink\"  # The `direction` determines if the UT or BS is transmitting.\n                      # In the `uplink`, the UT is transmitting.\ncdl_model = \"B\"       # Suitable values are [\"A\", \"B\", \"C\", \"D\", \"E\"]\nspeed = 10            # UT speed [m/s]. BSs are always assumed to be fixed.\n                      # The direction of travel will chosen randomly within the x-y plane.\n# Configure a channel impulse reponse (CIR) generator for the CDL model.\n# cdl() will generate CIRs that can be converted to discrete time or discrete frequency.\ncdl = CDL(cdl_model, delay_spread, carrier_frequency, ut_array, bs_array, direction, min_speed=speed)\n```"
"#### CIR Sampling Process\n\nThe instance `cdl` of the [CDL](https://nvlabs.github.io/sionna/api/channel.html#clustered-delay-line-cdl) [ChannelModel](https://nvlabs.github.io/sionna/api/channel.html#channel-model-interface) can be used to generate batches of random realizations of continuous-time channel impulse responses, consisting of complex gains `a` and delays `tau` for each path. To account for time-varying channels, a channel impulse responses is sampled at the `sampling_frequency` for\n`num_time_samples` samples. For more details on this, please have a look at the [API documentation](https://nvlabs.github.io/sionna/api/channel.html) of the channel models.\n\nIn order to model the channel in the frequency domain, we need `num_ofdm_symbols` samples that are taken once per `ofdm_symbol_duration`, which corresponds to the length of an OFDM symbol plus the cyclic prefix.\n\n\n```python\na, tau = cdl(batch_size=32, num_time_steps=rg.num_ofdm_symbols, sampling_frequency=1/rg.ofdm_symbol_duration)\n```\nThe path gains `a` have shape\n`[batch` `size,` `num_rx,` `num_rx_ant,` `num_tx,` `num_tx_ant,` `num_paths,` `num_time_steps]`\nand the delays `tau` have shape\n`[batch_size,` `num_rx,` `num_tx,` `num_paths]`.\n\n\n```python\nprint(\"Shape of the path gains: \", a.shape)\nprint(\"Shape of the delays:\", tau.shape)\n```\n\n\n```python\nShape of the path gains:  (32, 1, 8, 1, 4, 23, 14)\nShape of the delays: (32, 1, 1, 23)\n```\n\n\nThe delays are assumed to be static within the time-window of interest. Only the complex path gains change over time. The following two figures depict the channel impulse response at a particular time instant and the time-evolution of the gain of one path, respectively.\n\n\n```python\nplt.figure()\nplt.title(\"Channel impulse response realization\")\nplt.stem(tau[0,0,0,:]/1e-9, np.abs(a)[0,0,0,0,0,:,0])\nplt.xlabel(r\"$\\tau$ [ns]\")\nplt.ylabel(r\"$|a|$\")\n\nplt.figure()\nplt.title(\"Time evolution of path gain\")\nplt.plot(np.arange(rg.num_ofdm_symbols)*rg.ofdm_symbol_duration/1e-6, np.real(a)[0,0,0,0,0,0,:])\nplt.plot(np.arange(rg.num_ofdm_symbols)*rg.ofdm_symbol_duration/1e-6, np.imag(a)[0,0,0,0,0,0,:])\nplt.legend([\"Real part\", \"Imaginary part\"])\nplt.xlabel(r\"$t$ [us]\")\nplt.ylabel(r\"$a$\");\n```"
"#### Generate the Channel Frequency Response\n\nIf we want to use the continuous-time channel impulse response to simulate OFDM transmissions under ideal conditions, i.e., no inter-symbol interference, inter-carrier interference, etc., we need to convert it to the frequency domain.\n\nThis can be done with the function [cir_to_ofdm_channel](https://nvlabs.github.io/sionna/api/channel.html#cir-to-ofdm-channel) that computes the Fourier transform of the continuous-time channel impulse response at a set of `frequencies`, corresponding to the different subcarriers. The frequencies can be obtained with the help of the convenience function [subcarrier_frequencies](https://nvlabs.github.io/sionna/api/channel.html#subcarrier-frequencies).\n\n\n```python\nfrequencies = subcarrier_frequencies(rg.fft_size, rg.subcarrier_spacing)\nh_freq = cir_to_ofdm_channel(frequencies, a, tau, normalize=True)\n```\n\n\nLet us have a look at the channel frequency response at a given time instant:\n\n\n```python\nplt.figure()\nplt.title(\"Channel frequency response\")\nplt.plot(np.real(h_freq[0,0,0,0,0,0,:]))\nplt.plot(np.imag(h_freq[0,0,0,0,0,0,:]))\nplt.xlabel(\"OFDM Symbol Index\")\nplt.ylabel(r\"$h$\")\nplt.legend([\"Real part\", \"Imaginary part\"]);\n```\n\n\nWe can apply the channel frequency response to a given input with the [ApplyOFDMChannel](https://nvlabs.github.io/sionna/api/channel.html#applyofdmchannel) layer. This layer can also add additive white Gaussian noise (AWGN) to the channel output.\n\n\n```python\n# Function that will apply the channel frequency response to an input signal\nchannel_freq = ApplyOFDMChannel(add_awgn=True)\n```"
"#### Generate the Discrete-Time Channel Impulse Response\n\nIn the same way as we have created the frequency channel impulse response from the continuous-time response, we can use the latter to compute a discrete-time impulse response. This can then be used to model the channel in the time-domain through discrete convolution with an input signal. Time-domain channel modeling is necessary whenever we want to deviate from the perfect OFDM scenario, e.g., OFDM without cyclic prefix, inter-subcarrier interference due to carrier-frequency offsets, phase\nnoise, or very high Doppler spread scenarios, as well as other single or multicarrier waveforms (OTFS, FBMC, UFMC, etc).\n\nA discrete-time impulse response can be obtained with the help of the function [cir_to_time_channel](https://nvlabs.github.io/sionna/api/channel.html#cir-to-time-channel) that requires a `bandwidth` parameter. This function first applies a perfect low-pass filter of the provided `bandwith` to the continuous-time channel impulse response and then samples the filtered response at the Nyquist rate. The resulting discrete-time impulse response is then truncated to finite length, depending on\nthe delay spread. `l_min` and `l_max` denote truncation boundaries and the resulting channel has `l_tot=l_max-l_min+1` filter taps. A detailed mathematical description of this process is provided in the API documentation of the channel models. You can freely chose both parameters if you do not want to rely on the default values.\n\nIn order to model the channel in the domain, the continuous-time channel impulse response must be sampled at the Nyquist rate. We also need now `num_ofdm_symbols` `x` `(fft_size` `+` `cyclic_prefix_length)` `+` `l_tot-1` samples in contrast to `num_ofdm_symbols` samples for modeling in the frequency domain. This implies that the memory requirements of time-domain channel modeling is significantly higher. We therefore recommend to only use this feature if it is really necessary. Simulations with many\ntransmitters, receivers, and/or large antenna arrays become otherwise quickly prohibitively complex.\n\n\n```python\n# The following values for truncation are recommended.\n# Please feel free to tailor them to you needs.\nl_min, l_max = time_lag_discrete_time_channel(rg.bandwidth)\nl_tot = l_max-l_min+1\na, tau = cdl(batch_size=2, num_time_steps=rg.num_time_samples+l_tot-1, sampling_frequency=rg.bandwidth)\n```"
"```python\nh_time = cir_to_time_channel(rg.bandwidth, a, tau, l_min=l_min, l_max=l_max, normalize=True)\n```\n\n```python\nplt.figure()\nplt.title(\"Discrete-time channel impulse response\")\nplt.stem(np.abs(h_time[0,0,0,0,0,0]))\nplt.xlabel(r\"Time step $\\ell$\")\nplt.ylabel(r\"$|\\bar{h}|$\");\n```\n\n\nWe can apply the discrete-time impulse response to a given input with the [ApplyTimeChannel](https://nvlabs.github.io/sionna/api/channel.html#applytimechannel) layer. This layer can also add additive white Gaussian noise (AWGN) to the channel output.\n\n\n```python\n# Function that will apply the discrete-time channel impulse response to an input signal\nchannel_time = ApplyTimeChannel(rg.num_time_samples, l_tot=l_tot, add_awgn=True)\n```"
"### Other Physical Layer Components\n\nFinally, we create instances of all other physical layer components we need. Most of these layers are self-explanatory. For more information, please have a look at the API documentation.\n\n\n```python\nnum_bits_per_symbol = 2 # QPSK modulation\ncoderate = 0.5 # Code rate\nn = int(rg.num_data_symbols*num_bits_per_symbol) # Number of coded bits\nk = int(n*coderate) # Number of information bits\n# The binary source will create batches of information bits\nbinary_source = BinarySource()\n# The encoder maps information bits to coded bits\nencoder = LDPC5GEncoder(k, n)\n# The mapper maps blocks of information bits to constellation symbols\nmapper = Mapper(\"qam\", num_bits_per_symbol)\n# The resource grid mapper maps symbols onto an OFDM resource grid\nrg_mapper = ResourceGridMapper(rg)\n# The zero forcing precoder precodes the transmit stream towards the intended antennas\nzf_precoder = ZFPrecoder(rg, sm, return_effective_channel=True)\n# OFDM modulator and demodulator\nmodulator = OFDMModulator(rg.cyclic_prefix_length)\ndemodulator = OFDMDemodulator(rg.fft_size, l_min, rg.cyclic_prefix_length)\n# This function removes nulled subcarriers from any tensor having the shape of a resource grid\nremove_nulled_scs = RemoveNulledSubcarriers(rg)\n# The LS channel estimator will provide channel estimates and error variances\nls_est = LSChannelEstimator(rg, interpolation_type=\"nn\")\n# The LMMSE equalizer will provide soft symbols together with noise variance estimates\nlmmse_equ = LMMSEEqualizer(rg, sm)\n# The demapper produces LLR for all coded bits\ndemapper = Demapper(\"app\", \"qam\", num_bits_per_symbol)\n# The decoder provides hard-decisions on the information bits\ndecoder = LDPC5GDecoder(encoder, hard_out=True)\n```"
"### Uplink Transmission in the Frequency Domain\n\nNow, we will simulate our first uplink transmission! Inspect the code to understand how perfect CSI at the receiver can be simulated.\n\n\n```python\nbatch_size = 32 # Depending on the memory of your GPU (or system when a CPU is used),\n                # you can in(de)crease the batch size. The larger the batch size, the\n                # more memory is required. However, simulations will also run much faster.\nebno_db = 40\nperfect_csi = False # Change to switch between perfect and imperfect CSI\n# Compute the noise power for a given Eb/No value.\n# This takes not only the coderate but also the overheads related pilot\n# transmissions and nulled carriers\nno = ebnodb2no(ebno_db, num_bits_per_symbol, coderate, rg)\nb = binary_source([batch_size, 1, rg.num_streams_per_tx, encoder.k])\nc = encoder(b)\nx = mapper(c)\nx_rg = rg_mapper(x)\n# As explained above, we generate random batches of CIR, transform them\n# in the frequency domain and apply them to the resource grid in the\n# frequency domain.\ncir = cdl(batch_size, rg.num_ofdm_symbols, 1/rg.ofdm_symbol_duration)\nh_freq = cir_to_ofdm_channel(frequencies, *cir, normalize=True)\ny = channel_freq([x_rg, h_freq, no])\nif perfect_csi:\n    # For perfect CSI, the receiver gets the channel frequency response as input\n    # However, the channel estimator only computes estimates on the non-nulled\n    # subcarriers. Therefore, we need to remove them here from `h_freq`.\n    # This step can be skipped if no subcarriers are nulled.\n    h_hat, err_var = remove_nulled_scs(h_freq), 0.\nelse:\n    h_hat, err_var = ls_est ([y, no])\nx_hat, no_eff = lmmse_equ([y, h_hat, err_var, no])\nllr = demapper([x_hat, no_eff])\nb_hat = decoder(llr)\nber = compute_ber(b, b_hat)\nprint(\"BER: {}\".format(ber))\n```\n\n\n```python\nBER: 0.0\n```\n\n\nAn alternative approach to simulations in the frequency domain is to use the convenience function [OFDMChannel](https://nvlabs.github.io/sionna/api/channel.html#ofdmchannel) that jointly generates and applies the channel frequency response. Using this function, we could have used the following code:"
"```python\nofdm_channel = OFDMChannel(cdl, rg, add_awgn=True, normalize_channel=True, return_channel=True)\ny, h_freq = ofdm_channel([x_rg, no])\n```"
"### Uplink Transmission in the Time Domain\n\nIn the previous example, OFDM modulation/demodulation were not needed as the entire system was simulated in the frequency domain. However, this modeling approach is not able to capture many realistic effects.\n\nWith the following modifications, the system can be modeled in the time domain.\n\nHave a careful look at how perfect CSI of the channel frequency response is simulated here.\n\n\n```python\nbatch_size = 4 # We pick a small batch_size as executing this code in Eager mode could consume a lot of memory\nebno_db = 30\nperfect_csi = True\nno = ebnodb2no(ebno_db, num_bits_per_symbol, coderate, rg)\nb = binary_source([batch_size, 1, rg.num_streams_per_tx, encoder.k])\nc = encoder(b)\nx = mapper(c)\nx_rg = rg_mapper(x)\n# The CIR needs to be sampled every 1/bandwith [s].\n# In contrast to frequency-domain modeling, this implies\n# that the channel can change over the duration of a single\n# OFDM symbol. We now also need to simulate more\n# time steps.\ncir = cdl(batch_size, rg.num_time_samples+l_tot-1, rg.bandwidth)\n# OFDM modulation with cyclic prefix insertion\nx_time = modulator(x_rg)\n# Compute the discrete-time channel impulse reponse\nh_time = cir_to_time_channel(rg.bandwidth, *cir, l_min, l_max, normalize=True)\n# Compute the channel output\n# This computes the full convolution between the time-varying\n# discrete-time channel impulse reponse and the discrete-time\n# transmit signal. With this technique, the effects of an\n# insufficiently long cyclic prefix will become visible. This\n# is in contrast to frequency-domain modeling which imposes\n# no inter-symbol interfernce.\ny_time = channel_time([x_time, h_time, no])\n# OFDM demodulation and cyclic prefix removal\ny = demodulator(y_time)\nif perfect_csi:\n    a, tau = cir\n    # We need to sub-sample the channel impulse reponse to compute perfect CSI\n    # for the receiver as it only needs one channel realization per OFDM symbol\n    a_freq = a[...,rg.cyclic_prefix_length:-1:(rg.fft_size+rg.cyclic_prefix_length)]\n    a_freq = a_freq[...,:rg.num_ofdm_symbols]\n    # Compute the channel frequency response\n    h_freq = cir_to_ofdm_channel(frequencies, a_freq, tau, normalize=True)\n    h_hat, err_var = remove_nulled_scs(h_freq), 0.\nelse:\n    h_hat, err_var = ls_est ([y, no])\nx_hat, no_eff = lmmse_equ([y, h_hat, err_var, no])\nllr = demapper([x_hat, no_eff])\nb_hat = decoder(llr)\nber = compute_ber(b, b_hat)\nprint(\"BER: {}\".format(ber))\n```"
"```python\nBER: 0.0\n```\n\n\nAn alternative approach to simulations in the time domain is to use the convenience function [TimeChannel](https://nvlabs.github.io/sionna/api/channel.html#timechannel) that jointly generates and applies the discrete-time channel impulse response. Using this function, we could have used the following code:\n\n\n```python\ntime_channel = TimeChannel(cdl, rg.bandwidth, rg.num_time_samples,\n                           l_min=l_min, l_max=l_max, normalize_channel=True,\n                           add_awgn=True, return_channel=True)\ny_time, h_time = time_channel([x_time, no])\n```\n\n\nNext, we will compare the perfect CSI that we computed above using the ideal channel frequency response and the estimated channel response that we obtain from pilots with nearest-neighbor interpolation based on simulated transmissions in the time domain.\n\n\n```python\n# In the example above, we assumed perfect CSI, i.e.,\n# h_hat correpsond to the exact ideal channel frequency response.\nh_perf = h_hat[0,0,0,0,0,0]\n# We now compute the LS channel estimate from the pilots.\nh_est, _ = ls_est ([y, no])\nh_est = h_est[0,0,0,0,0,0]\n```\n\n```python\nplt.figure()\nplt.plot(np.real(h_perf))\nplt.plot(np.imag(h_perf))\nplt.plot(np.real(h_est), \"--\")\nplt.plot(np.imag(h_est), \"--\")\nplt.xlabel(\"Subcarrier index\")\nplt.ylabel(\"Channel frequency response\")\nplt.legend([\"Ideal (real part)\", \"Ideal (imaginary part)\", \"Estimated (real part)\", \"Estimated (imaginary part)\"]);\nplt.title(\"Comparison of channel frequency responses\");\n```"
"### Downlink Transmission in the Frequency Domain\n\nWe will now simulate a simple downlink transmission in the frequency domain. In contrast to the uplink, the transmitter is now assumed to precode independent data streams to each antenna of the receiver based on perfect CSI.\n\nThe receiver can either estimate the channel or get access to the effective channel after precoding.\n\nThe first thing to do, is to change the `direction` within the CDL model.This makes the BS the transmitter and the UT the receiver.\n\n\n```python\ndirection = \"downlink\"\ncdl = CDL(cdl_model, delay_spread, carrier_frequency, ut_array, bs_array, direction, min_speed=speed)\n```\n\n\nThe following code shows the other necessary modifications:\n\n\n```python\nperfect_csi = True # Change to switch between perfect and imperfect CSI\nno = ebnodb2no(ebno_db, num_bits_per_symbol, coderate, rg)\nb = binary_source([batch_size, 1, rg.num_streams_per_tx, encoder.k])\nc = encoder(b)\nx = mapper(c)\nx_rg = rg_mapper(x)\ncir = cdl(batch_size, rg.num_ofdm_symbols, 1/rg.ofdm_symbol_duration)\nh_freq = cir_to_ofdm_channel(frequencies, *cir, normalize=True)\n# Precode the transmit signal in the frequency domain\n# It is here assumed that the transmitter has perfect knowledge of the channel\n# One could here reduce this to perfect knowledge of the channel for the first\n# OFDM symbol, or a noisy version of it to take outdated transmit CSI into account.\n# `g` is the post-beamforming or `effective channel` that can be\n# used to simulate perfect CSI at the receiver.\nx_rg, g = zf_precoder([x_rg, h_freq])\ny = channel_freq([x_rg, h_freq, no])\nif perfect_csi:\n    # The receiver gets here the effective channel after precoding as CSI\n    h_hat, err_var = g, 0.\nelse:\n    h_hat, err_var = ls_est ([y, no])\nx_hat, no_eff = lmmse_equ([y, h_hat, err_var, no])\nllr = demapper([x_hat, no_eff])\nb_hat = decoder(llr)\nber = compute_ber(b, b_hat)\nprint(\"BER: {}\".format(ber))\n```\n\n\n```python\nBER: 0.0\n```"
"We do not explain here on purpose how to model the downlink transmission in the time domain as it is a good exercise for the reader to do it her/himself. The key steps are:\n\n- Sample the channel impulse response at the Nyquist rate.\n- Downsample it to the OFDM symbol (+ cyclic prefix) rate (look at the uplink example).\n- Convert the downsampled CIR to the frequency domain.\n- Give this CSI to the transmitter for precoding.\n- Convert the CIR to discrete-time to compute the channel output in the time domain."
"### Understand the Difference Between the CDL Models\n\nBefore we proceed with more advanced simulations, it is important to understand the differences between the different CDL models. The models A, B, and C are non-line-of-sight (NLOS) models, while D and E are LOS. In the following code snippet, we compute the empirical cummulative distribution function (CDF) of the condition number of the channel frequency response matrix between all receiver and transmit antennas.\n\n\n```python\ndef fun(cdl_model):\n    \"\"\"Generates a histogram of the channel condition numbers\"\"\"\n    # Setup a CIR generator\n    cdl = CDL(cdl_model, delay_spread, carrier_frequency,\n              ut_array, bs_array, \"uplink\", min_speed=0)\n    # Generate random CIR realizations\n    # As we nned only a single sample in time, the sampling_frequency\n    # does not matter.\n    cir = cdl(2000, 1, 1)\n    # Compute the frequency response\n    h = cir_to_ofdm_channel(frequencies, *cir, normalize=True)\n    # Reshape to [batch_size, fft_size, num_rx_ant, num_tx_ant]\n    h = tf.squeeze(h)\n    h = tf.transpose(h, [0,3,1,2])\n    # Compute condition number\n    c = np.reshape(np.linalg.cond(h), [-1])\n    # Compute normalized histogram\n    hist, bins = np.histogram(c, 150, (1, 150))\n    hist = hist/np.sum(hist)\n    return bins[:-1], hist\nplt.figure()\nfor cdl_model in [\"A\", \"B\", \"C\", \"D\", \"E\"]:\n    bins, hist = fun(cdl_model)\n    plt.plot(bins, np.cumsum(hist))\nplt.xlim([0,150])\nplt.legend([\"CDL-A\", \"CDL-B\", \"CDL-C\", \"CDL-D\", \"CDL-E\"]);\nplt.xlabel(\"Channel Condition Number\")\nplt.ylabel(\"CDF\")\nplt.title(\"CDF of the condition number of 8x4 MIMO channels\");\n```\n\n\nFrom the figure above, you can observe that the CDL-B and CDL-C models are substantially better conditioned than the other models. This makes them more suitable for MIMO transmissions as we will observe in the next section."
"### Create an End-to-End Keras Model\n\nFor longer simulations, it is often convenient to pack all code into a single Keras model that outputs batches of transmitted and received information bits at a given Eb/No point. The following code defines a very general model that can simulate uplink and downlink transmissions with time or frequency domain modeling over the different CDL models. It allows to configure perfect or imperfect CSI, UT speed, cyclic prefix length, and the number of OFDM symbols for pilot transmissions.\n\n\n```python\n# We need to enable sionna.config.xla_compat before we can use\n# tf.function with jit_compile=True.\nsionna.config.xla_compat=True\nclass Model(tf.keras.Model):\n    \"\"\"This Keras model simulates OFDM MIMO transmissions over the CDL model.\n    Simulates point-to-point transmissions between a UT and a BS.\n    Uplink and downlink transmissions can be realized with either perfect CSI\n    or channel estimation. ZF Precoding for downlink transmissions is assumed.\n    The receiver (in both uplink and downlink) applies LS channel estimation\n    and LMMSE MIMO equalization. A 5G instruction_answer code as well as QAM modulation are\n    used.\n    Parameters\n    ----------\n    domain : One of [\"time\", \"freq\"], str\n        Determines if the channel is modeled in the time or frequency domain.\n        Time-domain simulations are generally slower and consume more memory.\n        They allow modeling of inter-symbol interference and channel changes\n        during the duration of an OFDM symbol.\n    direction : One of [\"uplink\", \"downlink\"], str\n        For \"uplink\", the UT transmits. For \"downlink\" the BS transmits.\n    cdl_model : One of [\"A\", \"B\", \"C\", \"D\", \"E\"], str\n        The CDL model to use. Note that \"D\" and \"E\" are LOS models that are\n        not well suited for the transmissions of multiple streams.\n    delay_spread : float\n        The nominal delay spread [s].\n    perfect_csi : bool\n        Indicates if perfect CSI at the receiver should be assumed. For downlink\n        transmissions, the transmitter is always assumed to have perfect CSI.\n    speed : float\n        The UT speed [m/s].\n    cyclic_prefix_length : int\n        The length of the cyclic prefix in number of samples.\n    pilot_ofdm_symbol_indices : list, int\n        List of integers defining the OFDM symbol indices that are reserved\n        for pilots.\n    subcarrier_spacing : float\n        The subcarrier spacing [Hz]. Defaults to 15e3.\n    Input\n    -----\n    batch_size : int\n        The batch size, i.e., the number of independent Mote Carlo simulations\n        to be performed at once. The larger this number, the larger the memory\n        requiremens.\n    ebno_db : float\n        The Eb/No [dB]. This value is converted to an equivalent noise power\n        by taking the modulation order, coderate, pilot and OFDM-related\n        overheads into account.\n    Output\n    ------\n    b : [batch_size, 1, num_streams, k], tf.float32\n        The tensor of transmitted information bits for each stream.\n    b_hat : [batch_size, 1, num_streams, k], tf.float32\n        The tensor of received information bits for each stream.\n    \"\"\"\n    def __init__(self,\n                 domain,\n                 direction,\n                 cdl_model,\n                 delay_spread,\n                 perfect_csi,\n                 speed,\n                 cyclic_prefix_length,\n                 pilot_ofdm_symbol_indices,\n                 subcarrier_spacing = 15e3\n                ):\n        super().__init__()\n        # Provided parameters\n        self._domain = domain\n        self._direction = direction\n        self._cdl_model = cdl_model\n        self._delay_spread = delay_spread\n        self._perfect_csi = perfect_csi\n        self._speed = speed\n        self._cyclic_prefix_length = cyclic_prefix_length\n        self._pilot_ofdm_symbol_indices = pilot_ofdm_symbol_indices\n        # System parameters\n        self._carrier_frequency = 2.6e9\n        self._subcarrier_spacing = subcarrier_spacing\n        self._fft_size = 72\n        self._num_ofdm_symbols = 14\n        self._num_ut_ant = 4 # Must be a multiple of two as dual-polarized antennas are used\n        self._num_bs_ant = 8 # Must be a multiple of two as dual-polarized antennas are used\n        self._num_streams_per_tx = self._num_ut_ant\n        self._dc_null = True\n        self._num_guard_carriers = [5, 6]\n        self._pilot_pattern = \"kronecker\"\n        self._pilot_ofdm_symbol_indices = pilot_ofdm_symbol_indices\n        self._num_bits_per_symbol = 2\n        self._coderate = 0.5\n        # Required system components\n        self._sm = StreamManagement(np.array([[1]]), self._num_streams_per_tx)\n        self._rg = ResourceGrid(num_ofdm_symbols=self._num_ofdm_symbols,\n                                fft_size=self._fft_size,\n                                subcarrier_spacing = self._subcarrier_spacing,\n                                num_tx=1,\n                                num_streams_per_tx=self._num_streams_per_tx,\n                                cyclic_prefix_length=self._cyclic_prefix_length,\n                                num_guard_carriers=self._num_guard_carriers,\n                                dc_null=self._dc_null,\n                                pilot_pattern=self._pilot_pattern,\n                                pilot_ofdm_symbol_indices=self._pilot_ofdm_symbol_indices)\n        self._n = int(self._rg.num_data_symbols * self._num_bits_per_symbol)\n        self._k = int(self._n * self._coderate)\n        self._ut_array = AntennaArray(num_rows=1,\n                                      num_cols=int(self._num_ut_ant/2),\n                                      polarization=\"dual\",\n                                      polarization_type=\"cross\",\n                                      antenna_pattern=\"38.901\",\n                                      carrier_frequency=self._carrier_frequency)\n        self._bs_array = AntennaArray(num_rows=1,\n                                      num_cols=int(self._num_bs_ant/2),\n                                      polarization=\"dual\",\n                                      polarization_type=\"cross\",\n                                      antenna_pattern=\"38.901\",\n                                      carrier_frequency=self._carrier_frequency)\n        self._cdl = CDL(model=self._cdl_model,\n                        delay_spread=self._delay_spread,\n                        carrier_frequency=self._carrier_frequency,\n                        ut_array=self._ut_array,\n                        bs_array=self._bs_array,\n                        direction=self._direction,\n                        min_speed=self._speed)\n        self._frequencies = subcarrier_frequencies(self._rg.fft_size, self._rg.subcarrier_spacing)\n        if self._domain == \"freq\":\n            self._channel_freq = ApplyOFDMChannel(add_awgn=True)\n        elif self._domain == \"time\":\n            self._l_min, self._l_max = time_lag_discrete_time_channel(self._rg.bandwidth)\n            self._l_tot = self._l_max - self._l_min + 1\n            self._channel_time = ApplyTimeChannel(self._rg.num_time_samples,\n                                                  l_tot=self._l_tot,\n                                                  add_awgn=True)\n            self._modulator = OFDMModulator(self._cyclic_prefix_length)\n            self._demodulator = OFDMDemodulator(self._fft_size, self._l_min, self._cyclic_prefix_length)\n        self._binary_source = BinarySource()\n        self._encoder = LDPC5GEncoder(self._k, self._n)\n        self._mapper = Mapper(\"qam\", self._num_bits_per_symbol)\n        self._rg_mapper = ResourceGridMapper(self._rg)\n        if self._direction == \"downlink\":\n            self._zf_precoder = ZFPrecoder(self._rg, self._sm, return_effective_channel=True)\n        self._ls_est = LSChannelEstimator(self._rg, interpolation_type=\"nn\")\n        self._lmmse_equ = LMMSEEqualizer(self._rg, self._sm)\n        self._demapper = Demapper(\"app\", \"qam\", self._num_bits_per_symbol)\n        self._decoder = LDPC5GDecoder(self._encoder, hard_out=True)\n        self._remove_nulled_scs = RemoveNulledSubcarriers(self._rg)\n    @tf.function(jit_compile=True) # See the following guide: https://www.tensorflow.org/guide/function\n    def call(self, batch_size, ebno_db):\n        no = ebnodb2no(ebno_db, self._num_bits_per_symbol, self._coderate, self._rg)\n        b = self._binary_source([batch_size, 1, self._num_streams_per_tx, self._k])\n        c = self._encoder(b)\n        x = self._mapper(c)\n        x_rg = self._rg_mapper(x)\n        if self._domain == \"time\":\n            # Time-domain simulations\n            a, tau = self._cdl(batch_size, self._rg.num_time_samples+self._l_tot-1, self._rg.bandwidth)\n            h_time = cir_to_time_channel(self._rg.bandwidth, a, tau,\n                                         l_min=self._l_min, l_max=self._l_max, normalize=True)\n            # As precoding is done in the frequency domain, we need to downsample\n            # the path gains `a` to the OFDM symbol rate prior to converting the CIR\n            # to the channel frequency response.\n            a_freq = a[...,self._rg.cyclic_prefix_length:-1:(self._rg.fft_size+self._rg.cyclic_prefix_length)]\n            a_freq = a_freq[...,:self._rg.num_ofdm_symbols]\n            h_freq = cir_to_ofdm_channel(self._frequencies, a_freq, tau, normalize=True)\n            if self._direction == \"downlink\":\n                x_rg, g = self._zf_precoder([x_rg, h_freq])\n            x_time = self._modulator(x_rg)\n            y_time = self._channel_time([x_time, h_time, no])\n            y = self._demodulator(y_time)\n        elif self._domain == \"freq\":\n            # Frequency-domain simulations\n            cir = self._cdl(batch_size, self._rg.num_ofdm_symbols, 1/self._rg.ofdm_symbol_duration)\n            h_freq = cir_to_ofdm_channel(self._frequencies, *cir, normalize=True)\n            if self._direction == \"downlink\":\n                x_rg, g = self._zf_precoder([x_rg, h_freq])\n            y = self._channel_freq([x_rg, h_freq, no])\n        if self._perfect_csi:\n            if self._direction == \"uplink\":\n                h_hat = self._remove_nulled_scs(h_freq)\n            elif self._direction ==\"downlink\":\n                h_hat = g\n            err_var = 0.0\n        else:\n            h_hat, err_var = self._ls_est ([y, no])\n        x_hat, no_eff = self._lmmse_equ([y, h_hat, err_var, no])\n        llr = self._demapper([x_hat, no_eff])\n        b_hat = self._decoder(llr)\n        return b, b_hat\n```"
"### Compare Uplink Performance Over the Different CDL Models\n\nWe will now compare the uplink performance over the various CDL models assuming perfect CSI at the receiver. Note that these simulations might take some time depending or you available hardware. You can reduce the `batch_size` if the model does not fit into the memory of your GPU. The code will also run on CPU if not GPU is available.\n\nIf you do not want to run the simulation your self, you skip the next cell and visualize the result in the next cell.\n\n\n```python\nUL_SIMS = {\n    \"ebno_db\" : list(np.arange(-5, 20, 4.0)),\n    \"cdl_model\" : [\"A\", \"B\", \"C\", \"D\", \"E\"],\n    \"delay_spread\" : 100e-9,\n    \"domain\" : \"freq\",\n    \"direction\" : \"uplink\",\n    \"perfect_csi\" : True,\n    \"speed\" : 0.0,\n    \"cyclic_prefix_length\" : 6,\n    \"pilot_ofdm_symbol_indices\" : [2, 11],\n    \"ber\" : [],\n    \"bler\" : [],\n    \"duration\" : None\n}\nstart = time.time()\nfor cdl_model in UL_SIMS[\"cdl_model\"]:\n    model = Model(domain=UL_SIMS[\"domain\"],\n                  direction=UL_SIMS[\"direction\"],\n                  cdl_model=cdl_model,\n                  delay_spread=UL_SIMS[\"delay_spread\"],\n                  perfect_csi=UL_SIMS[\"perfect_csi\"],\n                  speed=UL_SIMS[\"speed\"],\n                  cyclic_prefix_length=UL_SIMS[\"cyclic_prefix_length\"],\n                  pilot_ofdm_symbol_indices=UL_SIMS[\"pilot_ofdm_symbol_indices\"])\n    ber, bler = sim_ber(model,\n                        UL_SIMS[\"ebno_db\"],\n                        batch_size=256,\n                        max_mc_iter=100,\n                        num_target_block_errors=1000)\n    UL_SIMS[\"ber\"].append(list(ber.numpy()))\n    UL_SIMS[\"bler\"].append(list(bler.numpy()))\nUL_SIMS[\"duration\"] = time.time() - start\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -5.0 | 1.6160e-01 | 6.7627e-01 |      238284 |     1474560 |         1385 |        2048 |        16.5 |reached target block errors\n     -1.0 | 8.6594e-02 | 3.8932e-01 |      191532 |     2211840 |         1196 |        3072 |         0.1 |reached target block errors\n      3.0 | 3.6839e-02 | 1.7790e-01 |      162964 |     4423680 |         1093 |        6144 |         0.3 |reached target block errors\n      7.0 | 1.0374e-02 | 5.3660e-02 |      145327 |    14008320 |         1044 |       19456 |         0.9 |reached target block errors\n     11.0 | 2.2704e-03 | 1.2545e-02 |      130566 |    57507840 |         1002 |       79872 |         3.5 |reached target block errors\n     15.0 | 3.6389e-04 | 2.0898e-03 |       26829 |    73728000 |          214 |      102400 |         4.5 |reached max iter\n     19.0 | 3.5034e-05 | 2.0508e-04 |        2583 |    73728000 |           21 |      102400 |         4.5 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -5.0 | 8.4574e-03 | 5.4416e-02 |      112238 |    13271040 |         1003 |       18432 |        12.9 |reached target block errors\n     -1.0 | 4.3053e-04 | 2.8906e-03 |       31742 |    73728000 |          296 |      102400 |         4.5 |reached max iter\n      3.0 | 1.1136e-05 | 7.8125e-05 |         821 |    73728000 |            8 |      102400 |         4.5 |reached max iter\n      7.0 | 0.0000e+00 | 0.0000e+00 |           0 |    73728000 |            0 |      102400 |         4.5 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 7.0 dB.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -5.0 | 5.0412e-02 | 2.6050e-01 |      148671 |     2949120 |         1067 |        4096 |        12.3 |reached target block errors\n     -1.0 | 1.0788e-02 | 5.9398e-02 |      135220 |    12533760 |         1034 |       17408 |         0.8 |reached target block errors\n      3.0 | 1.3094e-03 | 7.8125e-03 |       96541 |    73728000 |          800 |      102400 |         4.5 |reached max iter\n      7.0 | 1.0550e-04 | 6.5430e-04 |        7778 |    73728000 |           67 |      102400 |         4.5 |reached max iter\n     11.0 | 1.1271e-05 | 5.8594e-05 |         831 |    73728000 |            6 |      102400 |         4.5 |reached max iter\n     15.0 | 0.0000e+00 | 0.0000e+00 |           0 |    73728000 |            0 |      102400 |         4.5 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 15.0 dB.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -5.0 | 2.6213e-01 | 9.9219e-01 |      193264 |      737280 |         1016 |        1024 |        12.4 |reached target block errors\n     -1.0 | 1.9558e-01 | 8.5205e-01 |      288389 |     1474560 |         1745 |        2048 |         0.1 |reached target block errors\n      3.0 | 7.7571e-02 | 3.9583e-01 |      171574 |     2211840 |         1216 |        3072 |         0.1 |reached target block errors\n      7.0 | 9.2380e-03 | 5.4796e-02 |      122598 |    13271040 |         1010 |       18432 |         0.8 |reached target block errors\n     11.0 | 3.0828e-04 | 2.1289e-03 |       22729 |    73728000 |          218 |      102400 |         4.4 |reached max iter\n     15.0 | 0.0000e+00 | 0.0000e+00 |           0 |    73728000 |            0 |      102400 |         4.4 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 15.0 dB.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -5.0 | 2.6030e-01 | 9.8730e-01 |      191916 |      737280 |         1011 |        1024 |        12.3 |reached target block errors\n     -1.0 | 1.9360e-01 | 8.4131e-01 |      285471 |     1474560 |         1723 |        2048 |         0.1 |reached target block errors\n      3.0 | 9.0027e-02 | 4.3815e-01 |      199126 |     2211840 |         1346 |        3072 |         0.1 |reached target block errors\n      7.0 | 2.2223e-02 | 1.1892e-01 |      147458 |     6635520 |         1096 |        9216 |         0.4 |reached target block errors\n     11.0 | 2.6109e-03 | 1.5174e-02 |      125123 |    47923200 |         1010 |       66560 |         2.9 |reached target block errors\n     15.0 | 1.5816e-04 | 1.0254e-03 |       11661 |    73728000 |          105 |      102400 |         4.4 |reached max iter\n     19.0 | 5.3575e-06 | 2.9297e-05 |         395 |    73728000 |            3 |      102400 |         4.5 |reached max iter\n```"
"```python\n# Load results (un comment to show saved results from the cell above)\n#UL_SIMS = eval(\" {'ebno_db': [-5.0, -1.0, 3.0, 7.0, 11.0, 15.0, 19.0], 'cdl_model': ['A', 'B', 'C', 'D', 'E'], 'delay_spread': 1e-07, 'domain': 'freq', 'direction': 'uplink', 'perfect_csi': True, 'speed': 0.0, 'cyclic_prefix_length': 6, 'pilot_ofdm_symbol_indices': [2, 11], 'ber': [[0.15734931098090277, 0.08457483362268518, 0.037556287977430554, 0.010201009114583333, 0.0021562364366319443, 0.0004007025824652778, 3.371853298611111e-05], [0.00840893126370614, 0.0004711371527777778, 6.686740451388889e-06, 0.0, 0.0, 0.0, 0.0], [0.05171542697482639, 0.010815988179125817, 0.0012970784505208334, 7.362196180555556e-05, 2.292209201388889e-06, 2.4142795138888887e-06, 0.0], [0.2598809136284722, 0.19302435980902777, 0.07624737774884259, 0.01058502197265625, 0.0003685031467013889, 2.102322048611111e-06, 0.0], [0.25929497612847224, 0.1982150607638889, 0.08891149450231481, 0.021271128713348766, 0.002695751694775132, 0.00017363823784722222, 5.126953125e-06]], 'bler': [[0.65869140625, 0.3756510416666667, 0.18131510416666666, 0.05242598684210526, 0.011625744047619048, 0.00220703125, 0.00017578125], [0.05396792763157895, 0.0032421875, 7.8125e-05, 0.0, 0.0, 0.0, 0.0], [0.26513671875, 0.05962775735294118, 0.007724609375, 0.0005078125, 9.765625e-06, 9.765625e-06, 0.0], [0.986328125, 0.84765625, 0.390625, 0.06243896484375, 0.00248046875, 1.953125e-05, 0.0], [0.98046875, 0.8515625, 0.4348958333333333, 0.115234375, 0.015562996031746032, 0.001083984375, 2.9296875e-05]], 'duration': 679.6544234752655} \")\nprint(\"Simulation duration: {:1.2f} [h]\".format(UL_SIMS[\"duration\"]/3600))\nplt.figure()\nplt.xlabel(r\"$E_b/N_0$ (dB)\")\nplt.ylabel(\"BLER\")\nplt.grid(which=\"both\")\nplt.title(\"8x4 MIMO Uplink - Frequency Domain Modeling\");\nplt.ylim([1e-3, 1.1])\nlegend = []\nfor i, bler in enumerate(UL_SIMS[\"bler\"]):\n    plt.semilogy(UL_SIMS[\"ebno_db\"], bler)\n    legend.append(\"CDL-{}\".format(UL_SIMS[\"cdl_model\"][i]))\nplt.legend(legend);\n```"
"### Compare Downlink Performance Over the Different CDL Models\n\nWe will now compare the downlink performance over the various CDL models assuming perfect CSI at the receiver.\n\nIf you do not want to run the simulation your self, you skip the next cell and visualize the result in the next cell.\n\n\n```python\nDL_SIMS = {\n    \"ebno_db\" : list(np.arange(-5, 20, 4.0)),\n    \"cdl_model\" : [\"A\", \"B\", \"C\", \"D\", \"E\"],\n    \"delay_spread\" : 100e-9,\n    \"domain\" : \"freq\",\n    \"direction\" : \"downlink\",\n    \"perfect_csi\" : True,\n    \"speed\" : 0.0,\n    \"cyclic_prefix_length\" : 6,\n    \"pilot_ofdm_symbol_indices\" : [2, 11],\n    \"ber\" : [],\n    \"bler\" : [],\n    \"duration\" : None\n}\nstart = time.time()\nfor cdl_model in DL_SIMS[\"cdl_model\"]:\n    model = Model(domain=DL_SIMS[\"domain\"],\n                  direction=DL_SIMS[\"direction\"],\n                  cdl_model=cdl_model,\n                  delay_spread=DL_SIMS[\"delay_spread\"],\n                  perfect_csi=DL_SIMS[\"perfect_csi\"],\n                  speed=DL_SIMS[\"speed\"],\n                  cyclic_prefix_length=DL_SIMS[\"cyclic_prefix_length\"],\n                  pilot_ofdm_symbol_indices=DL_SIMS[\"pilot_ofdm_symbol_indices\"])\n    ber, bler = sim_ber(model,\n                        DL_SIMS[\"ebno_db\"],\n                        batch_size=256,\n                        max_mc_iter=100,\n                        num_target_block_errors=1000)\n    DL_SIMS[\"ber\"].append(list(ber.numpy()))\n    DL_SIMS[\"bler\"].append(list(bler.numpy()))\nDL_SIMS[\"duration\"] = time.time() -  start\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -5.0 | 3.5227e-01 | 9.6191e-01 |      519446 |     1474560 |         1970 |        2048 |        12.5 |reached target block errors\n     -1.0 | 2.6469e-01 | 8.3008e-01 |      390294 |     1474560 |         1700 |        2048 |         0.1 |reached target block errors\n      3.0 | 1.5529e-01 | 5.5908e-01 |      228982 |     1474560 |         1145 |        2048 |         0.1 |reached target block errors\n      7.0 | 7.4751e-02 | 3.0664e-01 |      220451 |     2949120 |         1256 |        4096 |         0.2 |reached target block errors\n     11.0 | 2.4375e-02 | 1.1241e-01 |      161742 |     6635520 |         1036 |        9216 |         0.5 |reached target block errors\n     15.0 | 6.6249e-03 | 3.3366e-02 |      146532 |    22118400 |         1025 |       30720 |         1.7 |reached target block errors\n     19.0 | 1.0675e-03 | 5.7227e-03 |       78701 |    73728000 |          586 |      102400 |         5.7 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -5.0 | 3.9004e-02 | 2.1270e-01 |      143784 |     3686400 |         1089 |        5120 |        12.0 |reached target block errors\n     -1.0 | 3.3153e-03 | 2.2070e-02 |      109994 |    33177600 |         1017 |       46080 |         2.5 |reached target block errors\n      3.0 | 1.0097e-04 | 7.4219e-04 |        7444 |    73728000 |           76 |      102400 |         5.6 |reached max iter\n      7.0 | 4.6115e-06 | 1.9531e-05 |         340 |    73728000 |            2 |      102400 |         5.6 |reached max iter\n     11.0 | 0.0000e+00 | 0.0000e+00 |           0 |    73728000 |            0 |      102400 |         5.6 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 11.0 dB.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -5.0 | 1.6099e-01 | 6.4209e-01 |      237390 |     1474560 |         1315 |        2048 |        11.9 |reached target block errors\n     -1.0 | 5.1753e-02 | 2.4277e-01 |      190784 |     3686400 |         1243 |        5120 |         0.3 |reached target block errors\n      3.0 | 8.7685e-03 | 4.8363e-02 |      135762 |    15482880 |         1040 |       21504 |         1.2 |reached target block errors\n      7.0 | 9.0055e-04 | 5.4492e-03 |       66396 |    73728000 |          558 |      102400 |         5.6 |reached max iter\n     11.0 | 4.9045e-05 | 3.2227e-04 |        3616 |    73728000 |           33 |      102400 |         5.6 |reached max iter\n     15.0 | 5.0863e-06 | 3.9063e-05 |         375 |    73728000 |            4 |      102400 |         5.6 |reached max iter\n     19.0 | 0.0000e+00 | 0.0000e+00 |           0 |    73728000 |            0 |      102400 |         5.6 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 19.0 dB.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -5.0 | 4.2063e-01 | 1.0000e+00 |      310120 |      737280 |         1024 |        1024 |        11.9 |reached target block errors\n     -1.0 | 3.7341e-01 | 1.0000e+00 |      275310 |      737280 |         1024 |        1024 |         0.1 |reached target block errors\n      3.0 | 2.9153e-01 | 9.7070e-01 |      429878 |     1474560 |         1988 |        2048 |         0.1 |reached target block errors\n      7.0 | 1.5083e-01 | 6.7578e-01 |      222415 |     1474560 |         1384 |        2048 |         0.1 |reached target block errors\n     11.0 | 2.8208e-02 | 1.6455e-01 |      124781 |     4423680 |         1011 |        6144 |         0.3 |reached target block errors\n     15.0 | 1.4907e-03 | 1.1038e-02 |       97819 |    65617920 |         1006 |       91136 |         5.0 |reached target block errors\n     19.0 | 9.5622e-06 | 8.7891e-05 |         705 |    73728000 |            9 |      102400 |         5.6 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -5.0 | 4.2489e-01 | 1.0000e+00 |      313263 |      737280 |         1024 |        1024 |        11.8 |reached target block errors\n     -1.0 | 3.8312e-01 | 1.0000e+00 |      282469 |      737280 |         1024 |        1024 |         0.1 |reached target block errors\n      3.0 | 3.1855e-01 | 9.7754e-01 |      234862 |      737280 |         1001 |        1024 |         0.1 |reached target block errors\n      7.0 | 1.9283e-01 | 7.3975e-01 |      284333 |     1474560 |         1515 |        2048 |         0.1 |reached target block errors\n     11.0 | 7.3378e-02 | 3.4017e-01 |      162301 |     2211840 |         1045 |        3072 |         0.2 |reached target block errors\n     15.0 | 1.3921e-02 | 7.7374e-02 |      133424 |     9584640 |         1030 |       13312 |         0.7 |reached target block errors\n     19.0 | 9.6602e-04 | 6.3379e-03 |       71223 |    73728000 |          649 |      102400 |         5.6 |reached max iter\n```"
"```python\n# Load results (uncomment to show saved results from the cell above)\n#DL_SIMS = eval(\" {'ebno_db': [-5.0, -1.0, 3.0, 7.0, 11.0, 15.0, 19.0], 'cdl_model': ['A', 'B', 'C', 'D', 'E'], 'delay_spread': 1e-07, 'domain': 'freq', 'direction': 'downlink', 'perfect_csi': True, 'speed': 0.0, 'cyclic_prefix_length': 6, 'pilot_ofdm_symbol_indices': [2, 11], 'ber': [[0.3537068684895833, 0.270849609375, 0.15740831163194444, 0.06897718641493056, 0.027840169270833333, 0.0057531419143178105, 0.0009830457899305555], [0.03906005859375, 0.003267002566425121, 7.911512586805555e-05, 2.1158854166666666e-06, 0.0, 0.0, 0.0], [0.16080593532986112, 0.048251139322916664, 0.008695991960152116, 0.0008932291666666666, 4.695638020833333e-05, 3.2416449652777776e-06, 0.0], [0.41819661458333335, 0.37223714192708335, 0.29248792860243056, 0.14547797309027777, 0.025933353484623015, 0.0015725519627700617, 2.2610134548611112e-05], [0.4292819552951389, 0.3885362413194444, 0.30676472981770836, 0.18775770399305555, 0.06542392306857639, 0.01351276625934829, 0.0008977457682291666]], 'bler': [[0.96337890625, 0.84423828125, 0.5703125, 0.287353515625, 0.12337239583333333, 0.028894761029411766, 0.005400390625], [0.2185546875, 0.021505604619565216, 0.000576171875, 9.765625e-06, 0.0, 0.0, 0.0], [0.6484375, 0.2392578125, 0.04682849702380952, 0.0053125, 0.000322265625, 1.953125e-05, 0.0], [1.0, 1.0, 0.9716796875, 0.6572265625, 0.15457589285714285, 0.010883246527777777, 0.000166015625], [1.0, 1.0, 0.9638671875, 0.71240234375, 0.306640625, 0.07647235576923077, 0.0060546875]], 'duration': 558.1218893527985} \")\nprint(\"Simulation duration: {:1.2f} [h]\".format(DL_SIMS[\"duration\"]/3600))\nplt.figure()\nplt.xlabel(r\"$E_b/N_0$ (dB)\")\nplt.ylabel(\"BLER\")\nplt.grid(which=\"both\")\nplt.title(\"8x4 MIMO Downlink - Frequency Domain Modeling\");\nplt.ylim([1e-3, 1.1])\nlegend = []\nfor i, bler in enumerate(DL_SIMS[\"bler\"]):\n    plt.semilogy(DL_SIMS[\"ebno_db\"], bler)\n    legend.append(\"CDL-{}\".format(DL_SIMS[\"cdl_model\"][i]))\nplt.legend(legend);\n```"
"### Evaluate the Impact of Mobility\n\nLet us now have a look at the impact of the UT speed on the uplink performance. We compare the scenarios of perfect and imperfect CSI and 0 m/s and 20 m/s speed. To amplify the detrimental effects of high mobility, we only configure a single OFDM symbol for pilot transmissions at the beginning of the resource grid. With perfect CSI, mobility plays hardly any role. However, once channel estimation is taken into acount, the BLER saturates.\n\nIf you do not want to run the simulation your self, you skip the next cell and visualize the result in the next cell.\n\n\n```python\nMOBILITY_SIMS = {\n    \"ebno_db\" : list(np.arange(0, 32, 2.0)),\n    \"cdl_model\" : \"D\",\n    \"delay_spread\" : 100e-9,\n    \"domain\" : \"freq\",\n    \"direction\" : \"uplink\",\n    \"perfect_csi\" : [True, False],\n    \"speed\" : [0.0, 20.0],\n    \"cyclic_prefix_length\" : 6,\n    \"pilot_ofdm_symbol_indices\" : [0],\n    \"ber\" : [],\n    \"bler\" : [],\n    \"duration\" : None\n}\nstart = time.time()\nfor perfect_csi in MOBILITY_SIMS[\"perfect_csi\"]:\n    for speed in MOBILITY_SIMS[\"speed\"]:\n        model = Model(domain=MOBILITY_SIMS[\"domain\"],\n                  direction=MOBILITY_SIMS[\"direction\"],\n                  cdl_model=MOBILITY_SIMS[\"cdl_model\"],\n                  delay_spread=MOBILITY_SIMS[\"delay_spread\"],\n                  perfect_csi=perfect_csi,\n                  speed=speed,\n                  cyclic_prefix_length=MOBILITY_SIMS[\"cyclic_prefix_length\"],\n                  pilot_ofdm_symbol_indices=MOBILITY_SIMS[\"pilot_ofdm_symbol_indices\"])\n        ber, bler = sim_ber(model,\n                        MOBILITY_SIMS[\"ebno_db\"],\n                        batch_size=256,\n                        max_mc_iter=100,\n                        num_target_block_errors=1000)\n        MOBILITY_SIMS[\"ber\"].append(list(ber.numpy()))\n        MOBILITY_SIMS[\"bler\"].append(list(bler.numpy()))\nMOBILITY_SIMS[\"duration\"] = time.time() - start\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 1.6161e-01 | 7.3291e-01 |      258170 |     1597440 |         1501 |        2048 |        12.6 |reached target block errors\n      2.0 | 9.3824e-02 | 4.7624e-01 |      224817 |     2396160 |         1463 |        3072 |         0.1 |reached target block errors\n      4.0 | 4.4328e-02 | 2.3594e-01 |      177027 |     3993600 |         1208 |        5120 |         0.2 |reached target block errors\n      6.0 | 1.5049e-02 | 8.7891e-02 |      144242 |     9584640 |         1080 |       12288 |         0.5 |reached target block errors\n      8.0 | 3.4631e-03 | 2.1315e-02 |      127238 |    36741120 |         1004 |       47104 |         2.1 |reached target block errors\n     10.0 | 6.0279e-04 | 4.0527e-03 |       48146 |    79872000 |          415 |      102400 |         4.6 |reached max iter\n     12.0 | 5.9683e-05 | 3.8086e-04 |        4767 |    79872000 |           39 |      102400 |         4.6 |reached max iter\n     14.0 | 6.9611e-06 | 6.8359e-05 |         556 |    79872000 |            7 |      102400 |         4.6 |reached max iter\n     16.0 | 1.7278e-06 | 9.7656e-06 |         138 |    79872000 |            1 |      102400 |         4.5 |reached max iter\n     18.0 | 0.0000e+00 | 0.0000e+00 |           0 |    79872000 |            0 |      102400 |         4.6 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 18.0 dB.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 1.6147e-01 | 7.3779e-01 |      257937 |     1597440 |         1511 |        2048 |        12.7 |reached target block errors\n      2.0 | 9.9016e-02 | 4.8796e-01 |      237258 |     2396160 |         1499 |        3072 |         0.1 |reached target block errors\n      4.0 | 4.2508e-02 | 2.3145e-01 |      169761 |     3993600 |         1185 |        5120 |         0.2 |reached target block errors\n      6.0 | 1.3701e-02 | 8.1806e-02 |      142266 |    10383360 |         1089 |       13312 |         0.6 |reached target block errors\n      8.0 | 3.5065e-03 | 2.2070e-02 |      126033 |    35942400 |         1017 |       46080 |         2.1 |reached target block errors\n     10.0 | 6.4011e-04 | 4.0039e-03 |       51127 |    79872000 |          410 |      102400 |         4.6 |reached max iter\n     12.0 | 7.5120e-05 | 4.9805e-04 |        6000 |    79872000 |           51 |      102400 |         4.6 |reached max iter\n     14.0 | 2.7168e-06 | 1.9531e-05 |         217 |    79872000 |            2 |      102400 |         4.6 |reached max iter\n     16.0 | 0.0000e+00 | 0.0000e+00 |           0 |    79872000 |            0 |      102400 |         4.6 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 16.0 dB.\nWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\nInstructions for updating:\nThe `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 2.7695e-01 | 1.0000e+00 |      221203 |      798720 |         1024 |        1024 |        12.8 |reached target block errors\n      2.0 | 2.6110e-01 | 9.8145e-01 |      208544 |      798720 |         1005 |        1024 |         0.0 |reached target block errors\n      4.0 | 2.2669e-01 | 9.1016e-01 |      362117 |     1597440 |         1864 |        2048 |         0.1 |reached target block errors\n      6.0 | 1.7395e-01 | 7.6221e-01 |      277872 |     1597440 |         1561 |        2048 |         0.1 |reached target block errors\n      8.0 | 1.0000e-01 | 4.6777e-01 |      239622 |     2396160 |         1437 |        3072 |         0.1 |reached target block errors\n     10.0 | 5.1870e-02 | 2.6343e-01 |      165718 |     3194880 |         1079 |        4096 |         0.2 |reached target block errors\n     12.0 | 1.6063e-02 | 8.9933e-02 |      141124 |     8785920 |         1013 |       11264 |         0.5 |reached target block errors\n     14.0 | 3.7753e-03 | 2.2179e-02 |      135694 |    35942400 |         1022 |       46080 |         2.1 |reached target block errors\n     16.0 | 6.5346e-04 | 4.0527e-03 |       52193 |    79872000 |          415 |      102400 |         4.6 |reached max iter\n     18.0 | 5.6778e-05 | 4.1016e-04 |        4535 |    79872000 |           42 |      102400 |         4.6 |reached max iter\n     20.0 | 1.7904e-05 | 9.7656e-05 |        1430 |    79872000 |           10 |      102400 |         4.6 |reached max iter\n     22.0 | 1.6777e-06 | 9.7656e-06 |         134 |    79872000 |            1 |      102400 |         4.6 |reached max iter\n     24.0 | 0.0000e+00 | 0.0000e+00 |           0 |    79872000 |            0 |      102400 |         4.6 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 24.0 dB.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 2.8459e-01 | 9.9902e-01 |      227307 |      798720 |         1023 |        1024 |        12.6 |reached target block errors\n      2.0 | 2.6964e-01 | 9.9121e-01 |      215368 |      798720 |         1015 |        1024 |         0.0 |reached target block errors\n      4.0 | 2.5126e-01 | 9.7510e-01 |      401371 |     1597440 |         1997 |        2048 |         0.1 |reached target block errors\n      6.0 | 2.0439e-01 | 8.5352e-01 |      326507 |     1597440 |         1748 |        2048 |         0.1 |reached target block errors\n      8.0 | 1.6192e-01 | 7.2461e-01 |      258655 |     1597440 |         1484 |        2048 |         0.1 |reached target block errors\n     10.0 | 9.7994e-02 | 4.6973e-01 |      234809 |     2396160 |         1443 |        3072 |         0.1 |reached target block errors\n     12.0 | 6.3871e-02 | 3.3854e-01 |      153046 |     2396160 |         1040 |        3072 |         0.1 |reached target block errors\n     14.0 | 3.0211e-02 | 1.7334e-01 |      144779 |     4792320 |         1065 |        6144 |         0.3 |reached target block errors\n     16.0 | 1.2865e-02 | 8.5449e-02 |      123302 |     9584640 |         1050 |       12288 |         0.6 |reached target block errors\n     18.0 | 5.1862e-03 | 3.9688e-02 |      103558 |    19968000 |         1016 |       25600 |         1.2 |reached target block errors\n     20.0 | 1.5217e-03 | 1.8175e-02 |       65631 |    43130880 |         1005 |       55296 |         2.5 |reached target block errors\n     22.0 | 4.3807e-04 | 1.1489e-02 |       29741 |    67891200 |         1000 |       87040 |         3.9 |reached target block errors\n     24.0 | 1.3831e-04 | 1.0574e-02 |       10274 |    74280960 |         1007 |       95232 |         4.3 |reached target block errors\n     26.0 | 3.8288e-05 | 1.0015e-02 |        2997 |    78274560 |         1005 |      100352 |         4.5 |reached target block errors\n     28.0 | 2.4988e-05 | 1.0234e-02 |        1916 |    76677120 |         1006 |       98304 |         4.4 |reached target block errors\n     30.0 | 2.1836e-05 | 1.0595e-02 |        1622 |    74280960 |         1009 |       95232 |         4.3 |reached target block errors\n```"
"```python\n# Load results (uncomment to show saved results from the cell above)\n#MOBILITY_SIMS = eval(\" {'ebno_db': [0.0, 2.0, 4.0, 6.0, 8.0, 10.0, 12.0, 14.0, 16.0, 18.0, 20.0, 22.0, 24.0, 26.0, 28.0, 30.0], 'cdl_model': 'D', 'delay_spread': 1e-07, 'domain': 'freq', 'direction': 'uplink', 'perfect_csi': [True, False], 'speed': [0.0, 20.0], 'cyclic_prefix_length': 6, 'pilot_ofdm_symbol_indices': [0], 'ber': [[0.15169959435096153, 0.10006385216346154, 0.04578732221554487, 0.014152748564369658, 0.003497385589670746, 0.0006175756209935898, 4.672475961538461e-05, 3.342848557692308e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.15599834735576923, 0.09424036792200854, 0.043501602564102564, 0.015064206897702992, 0.0034728119338768115, 0.000610752203525641, 6.844701522435897e-05, 1.4072516025641026e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.27565479767628204, 0.25848482572115383, 0.22961112780448717, 0.16972468449519232, 0.1010475093482906, 0.04783954326923077, 0.016199555652680653, 0.004016548428705441, 0.0006721880008012821, 7.454427083333334e-05, 8.526141826923077e-06, 0.0, 0.0, 0.0, 0.0, 0.0], [0.2835011017628205, 0.2701497395833333, 0.2480888171073718, 0.21193033854166668, 0.16006485376602564, 0.1103377904647436, 0.06517052283653846, 0.0286998781383547, 0.012703033186431624, 0.005103715945512821, 0.0016146116805757136, 0.000522487214110478, 0.00014040694277510683, 4.0696557791435366e-05, 2.5298629981884056e-05, 2.4334147401800328e-05]], 'bler': [[0.708984375, 0.4964192708333333, 0.248046875, 0.08406575520833333, 0.022349964488636364, 0.0041796875, 0.000322265625, 2.9296875e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.71630859375, 0.4788411458333333, 0.237890625, 0.08780924479166667, 0.021739130434782608, 0.004091796875, 0.000556640625, 0.000107421875, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9970703125, 0.9765625, 0.92138671875, 0.74755859375, 0.478515625, 0.2455078125, 0.09064275568181818, 0.023890053353658538, 0.00423828125, 0.00052734375, 6.8359375e-05, 0.0, 0.0, 0.0, 0.0, 0.0], [0.9990234375, 0.9931640625, 0.962890625, 0.88232421875, 0.71533203125, 0.5322265625, 0.3470052083333333, 0.16276041666666666, 0.082763671875, 0.0407421875, 0.01862839033018868, 0.012176890432098766, 0.010203043619791666, 0.01010792525773196, 0.010646654211956522, 0.010409740691489361]], 'duration': 705.361558675766} \")\nprint(\"Simulation duration: {:1.2f} [h]\".format(MOBILITY_SIMS[\"duration\"]/3600))\nplt.figure()\nplt.xlabel(r\"$E_b/N_0$ (dB)\")\nplt.ylabel(\"BLER\")\nplt.grid(which=\"both\")\nplt.title(\"CDL-D MIMO Uplink - Impact of UT mobility\")\ni = 0\nfor perfect_csi in MOBILITY_SIMS[\"perfect_csi\"]:\n    for speed in MOBILITY_SIMS[\"speed\"]:\n        style = \"{}\".format(\"-\" if perfect_csi else \"--\")\n        s = \"{} CSI {}[m/s]\".format(\"Perf.\" if perfect_csi else \"Imperf.\", speed)\n        plt.semilogy(MOBILITY_SIMS[\"ebno_db\"],\n                     MOBILITY_SIMS[\"bler\"][i],\n                      style, label=s,)\n        i += 1\nplt.legend();\nplt.ylim([1e-3, 1]);\n```"
"### Evaluate the Impact of Insufficient Cyclic Prefix Length\n\nAs a final example, let us have a look at how to simulate OFDM with an insufficiently long cyclic prefix.\n\nIt is important to notice, that ISI cannot be simulated in the frequency domain as the [OFDMChannel](https://nvlabs.github.io/sionna/api/channel.html#channel-with-ofdm-waveform) implicitly assumes perfectly synchronized and ISI-free transmissions. Having no cyclic prefix translates simply into an improved Eb/No as no energy for its transmission is used.\n\nSimulating a channel in the time domain requires significantly more memory and compute which might limit the scenarios for which it can be used.\n\nIf you do not want to run the simulation your self, you skip the next cell and visualize the result in the next cell.\n\n\n```python\nCP_SIMS = {\n    \"ebno_db\" : list(np.arange(0, 16, 1.0)),\n    \"cdl_model\" : \"C\",\n    \"delay_spread\" : 100e-9,\n    \"subcarrier_spacing\" : 15e3,\n    \"domain\" : [\"freq\", \"time\"],\n    \"direction\" : \"uplink\",\n    \"perfect_csi\" : False,\n    \"speed\" : 3.0,\n    \"cyclic_prefix_length\" : [20, 4],\n    \"pilot_ofdm_symbol_indices\" : [2, 11],\n    \"ber\" : [],\n    \"bler\" : [],\n    \"duration\": None\n}\nstart = time.time()\nfor cyclic_prefix_length in CP_SIMS[\"cyclic_prefix_length\"]:\n    for domain in CP_SIMS[\"domain\"]:\n        model = Model(domain=domain,\n                  direction=CP_SIMS[\"direction\"],\n                  cdl_model=CP_SIMS[\"cdl_model\"],\n                  delay_spread=CP_SIMS[\"delay_spread\"],\n                  perfect_csi=CP_SIMS[\"perfect_csi\"],\n                  speed=CP_SIMS[\"speed\"],\n                  cyclic_prefix_length=cyclic_prefix_length,\n                  pilot_ofdm_symbol_indices=CP_SIMS[\"pilot_ofdm_symbol_indices\"],\n                  subcarrier_spacing=CP_SIMS[\"subcarrier_spacing\"])\n        ber, bler = sim_ber(model,\n                        CP_SIMS[\"ebno_db\"],\n                        batch_size=256,\n                        max_mc_iter=100,\n                        num_target_block_errors=1000)\n        CP_SIMS[\"ber\"].append(list(ber.numpy()))\n        CP_SIMS[\"bler\"].append(list(bler.numpy()))\nCP_SIMS[\"duration\"] = time.time() - start\n```"
"```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 7.1097e-02 | 3.2300e-01 |      209674 |     2949120 |         1323 |        4096 |        12.5 |reached target block errors\n      1.0 | 4.9494e-02 | 2.3516e-01 |      182453 |     3686400 |         1204 |        5120 |         0.2 |reached target block errors\n      2.0 | 3.7691e-02 | 1.7497e-01 |      166733 |     4423680 |         1075 |        6144 |         0.3 |reached target block errors\n      3.0 | 2.4792e-02 | 1.2012e-01 |      164506 |     6635520 |         1107 |        9216 |         0.4 |reached target block errors\n      4.0 | 1.7193e-02 | 8.5449e-02 |      152113 |     8847360 |         1050 |       12288 |         0.5 |reached target block errors\n      5.0 | 1.0395e-02 | 5.2375e-02 |      145610 |    14008320 |         1019 |       19456 |         0.9 |reached target block errors\n      6.0 | 6.8724e-03 | 3.4853e-02 |      146939 |    21381120 |         1035 |       29696 |         1.3 |reached target block errors\n      7.0 | 4.3218e-03 | 2.1897e-02 |      143387 |    33177600 |         1009 |       46080 |         2.0 |reached target block errors\n      8.0 | 2.3735e-03 | 1.2280e-02 |      139996 |    58982400 |         1006 |       81920 |         3.6 |reached target block errors\n      9.0 | 1.3166e-03 | 6.6992e-03 |       97071 |    73728000 |          686 |      102400 |         4.5 |reached max iter\n     10.0 | 7.2675e-04 | 3.9648e-03 |       53582 |    73728000 |          406 |      102400 |         4.6 |reached max iter\n     11.0 | 3.7358e-04 | 2.0508e-03 |       27543 |    73728000 |          210 |      102400 |         4.6 |reached max iter\n     12.0 | 2.2316e-04 | 1.2500e-03 |       16453 |    73728000 |          128 |      102400 |         4.6 |reached max iter\n     13.0 | 1.1392e-04 | 6.2500e-04 |        8399 |    73728000 |           64 |      102400 |         4.6 |reached max iter\n     14.0 | 5.2070e-05 | 2.8320e-04 |        3839 |    73728000 |           29 |      102400 |         4.6 |reached max iter\n     15.0 | 2.2176e-05 | 1.4648e-04 |        1635 |    73728000 |           15 |      102400 |         4.6 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 7.2379e-02 | 3.2812e-01 |      160091 |     2211840 |         1008 |        3072 |        13.3 |reached target block errors\n      1.0 | 5.1294e-02 | 2.3750e-01 |      189090 |     3686400 |         1216 |        5120 |         0.8 |reached target block errors\n      2.0 | 3.7019e-02 | 1.7594e-01 |      163760 |     4423680 |         1081 |        6144 |         0.9 |reached target block errors\n      3.0 | 2.4789e-02 | 1.1784e-01 |      164486 |     6635520 |         1086 |        9216 |         1.4 |reached target block errors\n      4.0 | 1.7723e-02 | 8.4066e-02 |      156805 |     8847360 |         1033 |       12288 |         1.8 |reached target block errors\n      5.0 | 1.0601e-02 | 5.2375e-02 |      148504 |    14008320 |         1019 |       19456 |         2.9 |reached target block errors\n      6.0 | 6.7902e-03 | 3.4982e-02 |      140175 |    20643840 |         1003 |       28672 |         4.3 |reached target block errors\n      7.0 | 4.1687e-03 | 2.1569e-02 |      141380 |    33914880 |         1016 |       47104 |         7.0 |reached target block errors\n      8.0 | 2.3207e-03 | 1.2231e-02 |      136878 |    58982400 |         1002 |       81920 |        12.2 |reached target block errors\n      9.0 | 1.4165e-03 | 7.4805e-03 |      104439 |    73728000 |          766 |      102400 |        15.3 |reached max iter\n     10.0 | 7.3530e-04 | 3.9453e-03 |       54212 |    73728000 |          404 |      102400 |        15.3 |reached max iter\n     11.0 | 4.2832e-04 | 2.3633e-03 |       31579 |    73728000 |          242 |      102400 |        15.3 |reached max iter\n     12.0 | 1.6987e-04 | 1.0156e-03 |       12524 |    73728000 |          104 |      102400 |        15.3 |reached max iter\n     13.0 | 1.1386e-04 | 5.6641e-04 |        8395 |    73728000 |           58 |      102400 |        15.3 |reached max iter\n     14.0 | 7.5345e-05 | 3.8086e-04 |        5555 |    73728000 |           39 |      102400 |        15.2 |reached max iter\n     15.0 | 2.2108e-05 | 1.4648e-04 |        1630 |    73728000 |           15 |      102400 |        15.2 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 5.1978e-02 | 2.4141e-01 |      191610 |     3686400 |         1236 |        5120 |        12.8 |reached target block errors\n      1.0 | 4.0247e-02 | 1.8587e-01 |      178038 |     4423680 |         1142 |        6144 |         0.3 |reached target block errors\n      2.0 | 2.6527e-02 | 1.2805e-01 |      156465 |     5898240 |         1049 |        8192 |         0.4 |reached target block errors\n      3.0 | 1.8807e-02 | 9.1797e-02 |      152526 |     8110080 |         1034 |       11264 |         0.5 |reached target block errors\n      4.0 | 1.1853e-02 | 5.9053e-02 |      148558 |    12533760 |         1028 |       17408 |         0.8 |reached target block errors\n      5.0 | 7.4701e-03 | 3.6856e-02 |      148704 |    19906560 |         1019 |       27648 |         1.2 |reached target block errors\n      6.0 | 4.4296e-03 | 2.2705e-02 |      143698 |    32440320 |         1023 |       45056 |         2.0 |reached target block errors\n      7.0 | 2.6306e-03 | 1.3498e-02 |      141584 |    53821440 |         1009 |       74752 |         3.3 |reached target block errors\n      8.0 | 1.4671e-03 | 7.6660e-03 |      108163 |    73728000 |          785 |      102400 |         4.6 |reached max iter\n      9.0 | 8.5364e-04 | 4.5996e-03 |       62937 |    73728000 |          471 |      102400 |         4.6 |reached max iter\n     10.0 | 4.6239e-04 | 2.4512e-03 |       34091 |    73728000 |          251 |      102400 |         4.6 |reached max iter\n     11.0 | 2.3062e-04 | 1.3184e-03 |       17003 |    73728000 |          135 |      102400 |         4.5 |reached max iter\n     12.0 | 1.2603e-04 | 6.8359e-04 |        9292 |    73728000 |           70 |      102400 |         4.6 |reached max iter\n     13.0 | 5.4796e-05 | 3.3203e-04 |        4040 |    73728000 |           34 |      102400 |         4.6 |reached max iter\n     14.0 | 2.2366e-05 | 1.4648e-04 |        1649 |    73728000 |           15 |      102400 |         4.6 |reached max iter\n     15.0 | 7.2293e-06 | 4.8828e-05 |         533 |    73728000 |            5 |      102400 |         4.6 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 8.7329e-02 | 3.9030e-01 |      193157 |     2211840 |         1199 |        3072 |        13.0 |reached target block errors\n      1.0 | 6.4305e-02 | 2.9126e-01 |      189644 |     2949120 |         1193 |        4096 |         0.5 |reached target block errors\n      2.0 | 4.9408e-02 | 2.3145e-01 |      182138 |     3686400 |         1185 |        5120 |         0.7 |reached target block errors\n      3.0 | 3.5916e-02 | 1.7188e-01 |      158880 |     4423680 |         1056 |        6144 |         0.8 |reached target block errors\n      4.0 | 2.5862e-02 | 1.2294e-01 |      171605 |     6635520 |         1133 |        9216 |         1.2 |reached target block errors\n      5.0 | 1.6486e-02 | 8.1868e-02 |      145861 |     8847360 |         1006 |       12288 |         1.6 |reached target block errors\n      6.0 | 1.1784e-02 | 5.9513e-02 |      147692 |    12533760 |         1036 |       17408 |         2.2 |reached target block errors\n      7.0 | 7.1154e-03 | 3.7507e-02 |      141643 |    19906560 |         1037 |       27648 |         3.5 |reached target block errors\n      8.0 | 4.3708e-03 | 2.5566e-02 |      125677 |    28753920 |         1021 |       39936 |         5.1 |reached target block errors\n      9.0 | 2.5687e-03 | 1.7822e-02 |      106057 |    41287680 |         1022 |       57344 |         7.4 |reached target block errors\n     10.0 | 1.6852e-03 | 1.6341e-02 |       74550 |    44236800 |         1004 |       61440 |         7.9 |reached target block errors\n     11.0 | 8.9164e-04 | 1.6817e-02 |       38786 |    43499520 |         1016 |       60416 |         7.8 |reached target block errors\n     12.0 | 4.7879e-04 | 2.1235e-02 |       16591 |    34652160 |         1022 |       48128 |         6.2 |reached target block errors\n     13.0 | 3.3972e-04 | 3.1250e-02 |        8015 |    23592960 |         1024 |       32768 |         4.2 |reached target block errors\n     14.0 | 1.8072e-04 | 3.9492e-02 |        3331 |    18432000 |         1011 |       25600 |         3.3 |reached target block errors\n     15.0 | 1.4855e-04 | 5.2066e-02 |        2081 |    14008320 |         1013 |       19456 |         2.5 |reached target block errors\n```"
"```python\n# Load results (uncomment to show saved results from the cell above)\n#CP_SIMS = eval(\" {'ebno_db': [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0], 'cdl_model': 'C', 'delay_spread': 1e-07, 'subcarrier_spacing': 15000.0, 'domain': ['freq', 'time'], 'direction': 'uplink', 'perfect_csi': False, 'speed': 3.0, 'cyclic_prefix_length': [20, 4], 'pilot_ofdm_symbol_indices': [2, 11], 'ber': [[0.06557798032407407, 0.05356038411458333, 0.036498360339506174, 0.02517761752136752, 0.017377266589506172, 0.011118797019675926, 0.006675488753019323, 0.004243488387664524, 0.002491552599862259, 0.0012659071180555555, 0.0007226888020833333, 0.0004105794270833333, 0.00021171875, 0.00011207682291666667, 4.0809461805555556e-05, 2.279730902777778e-05], [0.06876168536324787, 0.051859085648148145, 0.03822603202160494, 0.02548694577991453, 0.016959404550827423, 0.011013454861111112, 0.006892088627304434, 0.004137017877252252, 0.002463582466684675, 0.0014250651041666667, 0.0007145616319444444, 0.00037141927083333336, 0.00019383680555555555, 0.00010481770833333334, 4.1644965277777777e-05, 1.9932725694444446e-05], [0.05217441340488215, 0.03722222222222222, 0.027770973104990583, 0.018300805910669193, 0.012147801143483709, 0.0072280695408950615, 0.004458076408844189, 0.0026281823645104897, 0.0016104890352813088, 0.0008862955729166666, 0.00046706814236111113, 0.0002002495659722222, 0.00011341145833333334, 4.968532986111111e-05, 2.0464409722222224e-05, 1.4811197916666667e-05], [0.0816061000631313, 0.06929166666666667, 0.052485826280381946, 0.035026493778935186, 0.023676058021336554, 0.017314453125, 0.011337403130032207, 0.007286241319444445, 0.004440556877759382, 0.0027163238447260626, 0.0013986585930973266, 0.0009150437801932367, 0.0006104324281090033, 0.00034796381644684255, 0.00018975482723577235, 0.00016822318007662836]], 'bler': [[0.2960069444444444, 0.248046875, 0.17447916666666666, 0.12139423076923077, 0.08697916666666666, 0.05490451388888889, 0.03400135869565218, 0.021543560606060608, 0.012939049586776859, 0.0068515625, 0.0037109375, 0.002203125, 0.001171875, 0.0006171875, 0.000234375, 0.0001171875], [0.3097956730769231, 0.23910984848484848, 0.17604166666666668, 0.12163461538461538, 0.08352726063829788, 0.055182658450704226, 0.03506866591928251, 0.021114864864864864, 0.012662074554294975, 0.0074375, 0.0037265625, 0.0019609375, 0.0010234375, 0.0005703125, 0.0002265625, 0.000109375], [0.24076704545454544, 0.1751736111111111, 0.1340042372881356, 0.08939985795454546, 0.05891682330827068, 0.036205150462962965, 0.022494612068965518, 0.013671875, 0.008275953389830509, 0.0046953125, 0.0024296875, 0.001171875, 0.000609375, 0.00025, 0.000125, 8.59375e-05], [0.37073863636363635, 0.315, 0.246337890625, 0.16438802083333334, 0.1146965579710145, 0.0875, 0.05672554347826087, 0.03807645631067961, 0.025895074503311258, 0.018019153225806453, 0.01474389097744361, 0.016983695652173912, 0.021193258807588076, 0.028158723021582732, 0.038147865853658536, 0.05387931034482758]], 'duration': 5074.19091796875} \")\nprint(\"Simulation duration: {:1.2f} [h]\".format(CP_SIMS[\"duration\"]/3600))\nplt.figure()\nplt.xlabel(r\"$E_b/N_0$ (dB)\")\nplt.ylabel(\"BLER\")\nplt.grid(which=\"both\")\nplt.title(\"CDL-B MIMO Uplink - Impact of Cyclic Prefix Length\")\ni = 0\nfor cyclic_prefix_length in CP_SIMS[\"cyclic_prefix_length\"]:\n    for domain in CP_SIMS[\"domain\"]:\n        s = \"{} Domain, CP length: {}\".format(\"Freq\" if domain==\"freq\" else \"Time\",\n                                               cyclic_prefix_length)\n        plt.semilogy(CP_SIMS[\"ebno_db\"],\n                     CP_SIMS[\"bler\"][i],\n                     label=s)\n        i += 1\nplt.legend();\nplt.ylim([1e-3, 1]);\n```"
"```python\nSimulation duration: 0.09 [h]\n```\n\n\nOne can make a few important observations from the figure above:\n<ol class=\"arabic simple\">\n- The length of the cyclic prefix has no impact on the performance if the system is simulated in the frequency domain.\nThe reason why the two curves for both frequency-domain simulations do not overlap is that the cyclic prefix length affects the way the Eb/No is computed.\n- With a sufficiently large cyclic prefix (in our case `cyclic_prefix_length` `=` `20` `>=` `l_tot` `=` `17` ), the performance of time and frequency-domain simulations are identical.\n- With a too small cyclic prefix length, the performance degrades. At high SNR, inter-symbol interference (from multiple streams) becomes the dominating source of interference.\n</ol>\n</ol>\n</ol>"
"# Neural Receiver for OFDM SIMO Systems\n\nIn this notebook, you will learn how to train a neural receiver that implements OFDM detection. The considered setup is shown in the figure below. As one can see, the neural receiver substitutes channel estimation, equalization, and demapping. It takes as input the post-DFT (discrete Fourier transform) received samples, which form the received resource grid, and computes log-likelihood ratios (LLRs) on the transmitted coded bits. These LLRs are then fed to the outer decoder to reconstruct the\ntransmitted information bits.\n\n\nTwo baselines are considered for benchmarking, which are shown in the figure above. Both baselines use linear minimum mean square error (LMMSE) equalization and demapping assuming additive white Gaussian noise (AWGN). They differ by how channel estimation is performed:\n\n- **Pefect CSI**: Perfect channel state information (CSI) knowledge is assumed.\n- **LS estimation**: Uses the transmitted pilots to perform least squares (LS) estimation of the channel with nearest-neighbor interpolation.\n\n\nAll the considered end-to-end systems use an LDPC outer code from the 5G NR specification, QPSK modulation, and a 3GPP CDL channel model simulated in the frequency domain."
"## GPU Configuration and Imports\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n# For more details, see https://www.tensorflow.org/guide/gpu\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\n```\n\n```python\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pickle\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.layers import Layer, Conv2D, LayerNormalization\nfrom tensorflow.nn import relu\nfrom sionna.channel.tr38901 import Antenna, AntennaArray, CDL\nfrom sionna.channel import OFDMChannel\nfrom sionna.mimo import StreamManagement\nfrom sionna.ofdm import ResourceGrid, ResourceGridMapper, LSChannelEstimator, LMMSEEqualizer, RemoveNulledSubcarriers, ResourceGridDemapper\nfrom sionna.utils import BinarySource, ebnodb2no, insert_dims, flatten_last_dims, log10, expand_to_rank\nfrom sionna.fec.ldpc.encoding import LDPC5GEncoder\nfrom sionna.fec.ldpc.decoding import LDPC5GDecoder\nfrom sionna.mapping import Mapper, Demapper\nfrom sionna.utils.metrics import compute_ber\nfrom sionna.utils import sim_ber\n```"
"## Simulation Parameters\n\n\n```python\n############################################\n## Channel configuration\ncarrier_frequency = 3.5e9 # Hz\ndelay_spread = 100e-9 # s\ncdl_model = \"C\" # CDL model to use\nspeed = 10.0 # Speed for evaluation and training [m/s]\n# SNR range for evaluation and training [dB]\nebno_db_min = -5.0\nebno_db_max = 10.0\n############################################\n## OFDM waveform configuration\nsubcarrier_spacing = 30e3 # Hz\nfft_size = 128 # Number of subcarriers forming the resource grid, including the null-subcarrier and the guard bands\nnum_ofdm_symbols = 14 # Number of OFDM symbols forming the resource grid\ndc_null = True # Null the DC subcarrier\nnum_guard_carriers = [5, 6] # Number of guard carriers on each side\npilot_pattern = \"kronecker\" # Pilot pattern\npilot_ofdm_symbol_indices = [2, 11] # Index of OFDM symbols carrying pilots\ncyclic_prefix_length = 0 # Simulation in frequency domain. This is useless\n############################################\n## Modulation and coding configuration\nnum_bits_per_symbol = 2 # QPSK\ncoderate = 0.5 # Coderate for instruction_answer code\n############################################\n## Neural receiver configuration\nnum_conv_channels = 128 # Number of convolutional channels for the convolutional layers forming the neural receiver\n############################################\n## Training configuration\nnum_training_iterations = 30000 # Number of training iterations\ntraining_batch_size = 128 # Training batch size\nmodel_weights_path = \"neural_receiver_weights\" # Location to save the neural receiver weights once training is done\n############################################\n## Evaluation configuration\nresults_filename = \"neural_receiver_results\" # Location to save the results\n```\n\n\nThe `StreamManagement` class is used to configure the receiver-transmitter association and the number of streams per transmitter. A SIMO system is considered, with a single transmitter equipped with a single non-polarized antenna. Therefore, there is only a single stream, and the receiver-transmitter association matrix is $[1]$. The receiver is equipped with an antenna array.\n\n\n```python\nstream_manager = StreamManagement(np.array([[1]]), # Receiver-transmitter association matrix\n                                  1)               # One stream per transmitter\n```"
"The `ResourceGrid` class is used to configure the OFDM resource grid. It is initialized with the parameters defined above.\n\n\n```python\nresource_grid = ResourceGrid(num_ofdm_symbols = num_ofdm_symbols,\n                             fft_size = fft_size,\n                             subcarrier_spacing = subcarrier_spacing,\n                             num_tx = 1,\n                             num_streams_per_tx = 1,\n                             cyclic_prefix_length = cyclic_prefix_length,\n                             dc_null = dc_null,\n                             pilot_pattern = pilot_pattern,\n                             pilot_ofdm_symbol_indices = pilot_ofdm_symbol_indices,\n                             num_guard_carriers = num_guard_carriers)\n```\n\n\nOuter coding is performed such that all the databits carried by the resource grid with size `fft_size`x`num_ofdm_symbols` form a single codeword.\n\n\n```python\n# Codeword length. It is calculated from the total number of databits carried by the resource grid, and the number of bits transmitted per resource element\nn = int(resource_grid.num_data_symbols*num_bits_per_symbol)\n# Number of information bits per codeword\nk = int(n*coderate)\n```\n\n\nThe SIMO link is setup by considering an uplink transmission with one user terminal (UT) equipped with a single non-polarized antenna, and a base station (BS) equipped with an antenna array. One can try other configurations for the BS antenna array.\n\n\n```python\nut_antenna = Antenna(polarization=\"single\",\n                     polarization_type=\"V\",\n                     antenna_pattern=\"38.901\",\n                     carrier_frequency=carrier_frequency)\nbs_array = AntennaArray(num_rows=1,\n                        num_cols=1,\n                        polarization=\"dual\",\n                        polarization_type=\"VH\",\n                        antenna_pattern=\"38.901\",\n                        carrier_frequency=carrier_frequency)\n```"
"## Neural Receiver\n\nThe next cell defines the Keras layers that implement the neural receiver. As in [1] and [2], a neural receiver using residual convolutional layers is implemented. Convolutional layers are leveraged to efficienly process the 2D resource grid, that is fed as an input to the neural receiver. Residual (skip) connections are used to avoid gradient vanishing [3].\n\nFor convinience, a Keras layer that implements a *residual block* is first defined. The Keras layer that implements the neural receiver is built by stacking such blocks. The following figure shows the architecture of the neural receiver.\n\n\n```python\nclass ResidualBlock(Layer):\n    r\"\"\"\n    This Keras layer implements a convolutional residual block made of two convolutional layers with ReLU activation, layer normalization, and a skip connection.\n    The number of convolutional channels of the input must match the number of kernel of the convolutional layers ``num_conv_channel`` for the skip connection to work.\n    Input\n    ------\n    : [batch size, num time samples, num subcarriers, num_conv_channel], tf.float\n        Input of the layer\n    Output\n    -------\n    : [batch size, num time samples, num subcarriers, num_conv_channel], tf.float\n        Output of the layer\n    \"\"\"\n    def build(self, input_shape):\n        # Layer normalization is done over the last three dimensions: time, frequency, conv 'channels'\n        self._layer_norm_1 = LayerNormalization(axis=(-1, -2, -3))\n        self._conv_1 = Conv2D(filters=num_conv_channels,\n                              kernel_size=[3,3],\n                              padding='same',\n                              activation=None)\n        # Layer normalization is done over the last three dimensions: time, frequency, conv 'channels'\n        self._layer_norm_2 = LayerNormalization(axis=(-1, -2, -3))\n        self._conv_2 = Conv2D(filters=num_conv_channels,\n                              kernel_size=[3,3],\n                              padding='same',\n                              activation=None)\n    def call(self, inputs):\n        z = self._layer_norm_1(inputs)\n        z = relu(z)\n        z = self._conv_1(z)\n        z = self._layer_norm_2(z)\n        z = relu(z)\n        z = self._conv_2(z) # [batch size, num time samples, num subcarriers, num_channels]\n        # Skip connection\n        z = z + inputs\n        return z\nclass NeuralReceiver(Layer):\n    r\"\"\"\n    Keras layer implementing a residual convolutional neural receiver.\n    This neural receiver is fed with the post-DFT received samples, forming a resource grid of size num_of_symbols x fft_size, and computes LLRs on the transmitted coded bits.\n    These LLRs can then be fed to an outer decoder to reconstruct the information bits.\n    As the neural receiver is fed with the entire resource grid, including the guard bands and pilots, it also computes LLRs for these resource elements.\n    They must be discarded to only keep the LLRs corresponding to the data-carrying resource elements.\n    Input\n    ------\n    y : [batch size, num rx antenna, num ofdm symbols, num subcarriers], tf.complex\n        Received post-DFT samples.\n    no : [batch size], tf.float32\n        Noise variance. At training, a different noise variance value is sampled for each batch example.\n    Output\n    -------\n    : [batch size, num ofdm symbols, num subcarriers, num_bits_per_symbol]\n        LLRs on the transmitted bits.\n        LLRs computed for resource elements not carrying data (pilots, guard bands...) must be discarded.\n    \"\"\"\n    def build(self, input_shape):\n        # Input convolution\n        self._input_conv = Conv2D(filters=num_conv_channels,\n                                  kernel_size=[3,3],\n                                  padding='same',\n                                  activation=None)\n        # Residual blocks\n        self._res_block_1 = ResidualBlock()\n        self._res_block_2 = ResidualBlock()\n        self._res_block_3 = ResidualBlock()\n        self._res_block_4 = ResidualBlock()\n        # Output conv\n        self._output_conv = Conv2D(filters=num_bits_per_symbol,\n                                   kernel_size=[3,3],\n                                   padding='same',\n                                   activation=None)\n    def call(self, inputs):\n        y, no = inputs\n        # Feeding the noise power in log10 scale helps with the performance\n        no = log10(no)\n        # Stacking the real and imaginary components of the different antennas along the 'channel' dimension\n        y = tf.transpose(y, [0, 2, 3, 1]) # Putting antenna dimension last\n        no = insert_dims(no, 3, 1)\n        no = tf.tile(no, [1, y.shape[1], y.shape[2], 1])\n        # z : [batch size, num ofdm symbols, num subcarriers, 2*num rx antenna + 1]\n        z = tf.concat([tf.math.real(y),\n                       tf.math.imag(y),\n                       no], axis=-1)\n        # Input conv\n        z = self._input_conv(z)\n        # Residual blocks\n        z = self._res_block_1(z)\n        z = self._res_block_2(z)\n        z = self._res_block_3(z)\n        z = self._res_block_4(z)\n        # Output conv\n        z = self._output_conv(z)\n        return z\n```"
"## End-to-end System\n\nThe following cell defines the end-to-end system.\n\nTraining is done on the bit-metric decoding (BMD) rate which is computed from the transmitted bits and LLRs:\n\n\\begin{equation}\nR = 1 - \\frac{1}{SNMK} \\sum_{s = 0}^{S-1} \\sum_{n = 0}^{N-1} \\sum_{m = 0}^{M-1} \\sum_{k = 0}^{K-1} \\texttt{BCE} \\left( B_{s,n,m,k}, \\texttt{LLR}_{s,n,m,k} \\right)\n\\end{equation}\n\nwhere\n\n- $S$ is the batch size\n- $N$ the number of subcarriers\n- $M$ the number of OFDM symbols\n- $K$ the number of bits per symbol\n- $B_{s,n,m,k}$ the $k^{th}$ coded bit transmitted on the resource element $(n,m)$ and for the $s^{th}$ batch example\n- $\\texttt{LLR}_{s,n,m,k}$ the LLR (logit) computed by the neural receiver corresponding to the $k^{th}$ coded bit transmitted on the resource element $(n,m)$ and for the $s^{th}$ batch example\n- $\\texttt{BCE} \\left( \\cdot, \\cdot \\right)$ the binary cross-entropy in log base 2\n\n\nBecause no outer code is required at training, the outer encoder and decoder are not used at training to reduce computational complexity.\n\nThe BMD rate is known to be an achievable information rate for BICM systems, which motivates its used as objective function [4].\n\n\n```python\n## Transmitter\nbinary_source = BinarySource()\nmapper = Mapper(\"qam\", num_bits_per_symbol)\nrg_mapper = ResourceGridMapper(resource_grid)\n## Channel\ncdl = CDL(cdl_model, delay_spread, carrier_frequency,\n          ut_antenna, bs_array, \"uplink\", min_speed=speed)\nchannel = OFDMChannel(cdl, resource_grid, normalize_channel=True, return_channel=True)\n## Receiver\nneural_receiver = NeuralReceiver()\nrg_demapper = ResourceGridDemapper(resource_grid, stream_manager) # Used to extract data-carrying resource elements\n```\n\n\nThe following cell performs one forward step through the end-to-end system:"
"```python\nbatch_size = 64\nebno_db = tf.fill([batch_size], 5.0)\nno = ebnodb2no(ebno_db, num_bits_per_symbol, coderate)\n\n## Transmitter\n# Generate codewords\nc = binary_source([batch_size, 1, 1, n])\nprint(\"c shape: \", c.shape)\n# Map bits to QAM symbols\nx = mapper(c)\nprint(\"x shape: \", x.shape)\n# Map the QAM symbols to a resource grid\nx_rg = rg_mapper(x)\nprint(\"x_rg shape: \", x_rg.shape)\n######################################\n## Channel\n# A batch of new channel realizations is sampled and applied at every inference\nno_ = expand_to_rank(no, tf.rank(x_rg))\ny,_ = channel([x_rg, no_])\nprint(\"y shape: \", y.shape)\n######################################\n## Receiver\n# The neural receover computes LLRs from the frequency domain received symbols and N0\ny = tf.squeeze(y, axis=1)\nllr = neural_receiver([y, no])\nprint(\"llr shape: \", llr.shape)\n# Reshape the input to fit what the resource grid demapper is expected\nllr = insert_dims(llr, 2, 1)\n# Extract data-carrying resource elements. The other LLRs are discarded\nllr = rg_demapper(llr)\nllr = tf.reshape(llr, [batch_size, 1, 1, n])\nprint(\"Post RG-demapper LLRs: \", llr.shape)\n```\n\n\n```python\nc shape:  (64, 1, 1, 2784)\nx shape:  (64, 1, 1, 1392)\nx_rg shape:  (64, 1, 1, 14, 128)\ny shape:  (64, 1, 2, 14, 128)\nllr shape:  (64, 14, 128, 2)\nPost RG-demapper LLRs:  (64, 1, 1, 2784)\n```\n\n\nThe BMD rate is computed from the LLRs and transmitted bits as follows:\n\n\n```python\nbce = tf.nn.sigmoid_cross_entropy_with_logits(c, llr)\nbce = tf.reduce_mean(bce)\nrate = tf.constant(1.0, tf.float32) - bce/tf.math.log(2.)\nprint(f\"Rate: {rate:.2E} bit\")\n```"
"## End-to-end System as a Keras Model\n\nThe following Keras *Model* implements the three considered end-to-end systems (perfect CSI baseline, LS estimation baseline, and neural receiver).\n\nWhen instantiating the Keras model, the parameter `system` is used to specify the system to setup, and the parameter `training` is used to specified if the system is instantiated to be trained or to be evaluated. The `training` parameter is only relevant when the neural receiver is used.\n\nAt each call of this model:\n\n- A batch of codewords is randomly sampled, modulated, and mapped to resource grids to form the channel inputs\n- A batch of channel realizations is randomly sampled and applied to the channel inputs\n- The receiver is executed on the post-DFT received samples to compute LLRs on the coded bits. Which receiver is executed (baseline with perfect CSI knowledge, baseline with LS estimation, or neural receiver) depends on the specified `system` parameter.\n- If not training, the outer decoder is applied to reconstruct the information bits\n- If training, the BMD rate is estimated over the batch from the LLRs and the transmitted bits\n\n```python\nclass E2ESystem(Model):\n    r\"\"\"\n    Keras model that implements the end-to-end systems.\n    As the three considered end-to-end systems (perfect CSI baseline, LS estimation baseline, and neural receiver) share most of\n    the link components (transmitter, channel model, outer code...), they are implemented using the same Keras model.\n    When instantiating the Keras model, the parameter ``system`` is used to specify the system to setup,\n    and the parameter ``training`` is used to specified if the system is instantiated to be trained or to be evaluated.\n    The ``training`` parameter is only relevant when the neural\n    At each call of this model:\n    * A batch of codewords is randomly sampled, modulated, and mapped to resource grids to form the channel inputs\n    * A batch of channel realizations is randomly sampled and applied to the channel inputs\n    * The receiver is executed on the post-DFT received samples to compute LLRs on the coded bits.\n      Which receiver is executed (baseline with perfect CSI knowledge, baseline with LS estimation, or neural receiver) depends\n      on the specified ``system`` parameter.\n    * If not training, the outer decoder is applied to reconstruct the information bits\n    * If training, the BMD rate is estimated over the batch from the LLRs and the transmitted bits\n    Parameters\n    -----------\n    system : str\n        Specify the receiver to use. Should be one of 'baseline-perfect-csi', 'baseline-ls-estimation' or 'neural-receiver'\n    training : bool\n        Set to `True` if the system is instantiated to be trained. Set to `False` otherwise. Defaults to `False`.\n        If the system is instantiated to be trained, the outer encoder and decoder are not instantiated as they are not required for training.\n        This significantly reduces the computational complexity of training.\n        If training, the bit-metric decoding (BMD) rate is computed from the transmitted bits and the LLRs. The BMD rate is known to be\n        an achievable information rate for BICM systems, and therefore training of the neural receiver aims at maximizing this rate.\n    Input\n    ------\n    batch_size : int\n        Batch size\n    no : scalar or [batch_size], tf.float\n        Noise variance.\n        At training, a different noise variance should be sampled for each batch example.\n    Output\n    -------\n    If ``training`` is set to `True`, then the output is a single scalar, which is an estimation of the BMD rate computed over the batch. It\n    should be used as objective for training.\n    If ``training`` is set to `False`, the transmitted information bits and their reconstruction on the receiver side are returned to\n    compute the block/bit error rate.\n    \"\"\"\n    def __init__(self, system, training=False):\n        super().__init__()\n        self._system = system\n        self._training = training\n        ######################################\n        ## Transmitter\n        self._binary_source = BinarySource()\n        # To reduce the computational complexity of training, the outer code is not used when training,\n        # as it is not required\n        if not training:\n            self._encoder = LDPC5GEncoder(k, n)\n        self._mapper = Mapper(\"qam\", num_bits_per_symbol)\n        self._rg_mapper = ResourceGridMapper(resource_grid)\n        ######################################\n        ## Channel\n        # A 3GPP CDL channel model is used\n        cdl = CDL(cdl_model, delay_spread, carrier_frequency,\n                  ut_antenna, bs_array, \"uplink\", min_speed=speed)\n        self._channel = OFDMChannel(cdl, resource_grid, normalize_channel=True, return_channel=True)\n        ######################################\n        ## Receiver\n        # Three options for the receiver depending on the value of `system`\n        if \"baseline\" in system:\n            if system == 'baseline-perfect-csi': # Perfect CSI\n                self._removed_null_subc = RemoveNulledSubcarriers(resource_grid)\n            elif system == 'baseline-ls-estimation': # LS estimation\n                self._ls_est = LSChannelEstimator(resource_grid, interpolation_type=\"nn\")\n            # Components required by both baselines\n            self._lmmse_equ = LMMSEEqualizer(resource_grid, stream_manager, )\n            self._demapper = Demapper(\"app\", \"qam\", num_bits_per_symbol)\n        elif system == \"neural-receiver\": # Neural receiver\n            self._neural_receiver = NeuralReceiver()\n            self._rg_demapper = ResourceGridDemapper(resource_grid, stream_manager) # Used to extract data-carrying resource elements\n        # To reduce the computational complexity of training, the outer code is not used when training,\n        # as it is not required\n        if not training:\n            self._decoder = LDPC5GDecoder(self._encoder, hard_out=True)\n    @tf.function\n    def call(self, batch_size, ebno_db):\n        # If `ebno_db` is a scalar, a tensor with shape [batch size] is created as it is what is expected by some layers\n        if len(ebno_db.shape) == 0:\n            ebno_db = tf.fill([batch_size], ebno_db)\n        ######################################\n        ## Transmitter\n        no = ebnodb2no(ebno_db, num_bits_per_symbol, coderate)\n        # Outer coding is only performed if not training\n        if self._training:\n            c = self._binary_source([batch_size, 1, 1, n])\n        else:\n            b = self._binary_source([batch_size, 1, 1, k])\n            c = self._encoder(b)\n        # Modulation\n        x = self._mapper(c)\n        x_rg = self._rg_mapper(x)\n        ######################################\n        ## Channel\n        # A batch of new channel realizations is sampled and applied at every inference\n        no_ = expand_to_rank(no, tf.rank(x_rg))\n        y,h = self._channel([x_rg, no_])\n        ######################################\n        ## Receiver\n        # Three options for the receiver depending on the value of ``system``\n        if \"baseline\" in self._system:\n            if self._system == 'baseline-perfect-csi':\n                h_hat = self._removed_null_subc(h) # Extract non-null subcarriers\n                err_var = 0.0 # No channel estimation error when perfect CSI knowledge is assumed\n            elif self._system == 'baseline-ls-estimation':\n                h_hat, err_var = self._ls_est([y, no]) # LS channel estimation with nearest-neighbor\n            x_hat, no_eff = self._lmmse_equ([y, h_hat, err_var, no]) # LMMSE equalization\n            no_eff_= expand_to_rank(no_eff, tf.rank(x_hat))\n            llr = self._demapper([x_hat, no_eff_]) # Demapping\n        elif self._system == \"neural-receiver\":\n            # The neural receover computes LLRs from the frequency domain received symbols and N0\n            y = tf.squeeze(y, axis=1)\n            llr = self._neural_receiver([y, no])\n            llr = insert_dims(llr, 2, 1) # Reshape the input to fit what the resource grid demapper is expected\n            llr = self._rg_demapper(llr) # Extract data-carrying resource elements. The other LLrs are discarded\n            llr = tf.reshape(llr, [batch_size, 1, 1, n]) # Reshape the LLRs to fit what the outer decoder is expected\n        # Outer coding is not needed if the information rate is returned\n        if self._training:\n            # Compute and return BMD rate (in bit), which is known to be an achievable\n            # information rate for BICM systems.\n            # Training aims at maximizing the BMD rate\n            bce = tf.nn.sigmoid_cross_entropy_with_logits(c, llr)\n            bce = tf.reduce_mean(bce)\n            rate = tf.constant(1.0, tf.float32) - bce/tf.math.log(2.)\n            return rate\n        else:\n            # Outer decoding\n            b_hat = self._decoder(llr)\n            return b,b_hat # Ground truth and reconstructed information bits returned for BER/BLER computation\n```"
"## Evaluation of the Baselines\n\nWe evaluate the BERs achieved by the baselines in the next cell.\n\n**Note:** Evaluation of the two systems can take a while. Therefore, we provide pre-computed results at the end of this notebook.\n\n\n```python\n# Range of SNRs over which the systems are evaluated\nebno_dbs = np.arange(ebno_db_min, # Min SNR for evaluation\n                     ebno_db_max, # Max SNR for evaluation\n                     0.5) # Step\n```\n\n```python\n# Dictionnary storing the evaluation results\nBLER = {}\nmodel = E2ESystem('baseline-perfect-csi')\n_,bler = sim_ber(model, ebno_dbs, batch_size=128, num_target_block_errors=100, max_mc_iter=100)\nBLER['baseline-perfect-csi'] = bler.numpy()\nmodel = E2ESystem('baseline-ls-estimation')\n_,bler = sim_ber(model, ebno_dbs, batch_size=128, num_target_block_errors=100, max_mc_iter=100)\nBLER['baseline-ls-estimation'] = bler.numpy()\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -5.0 | 2.5345e-01 | 1.0000e+00 |       45158 |      178176 |          128 |         128 |         7.3 |reached target block errors\n     -4.5 | 2.3644e-01 | 1.0000e+00 |       42128 |      178176 |          128 |         128 |         0.1 |reached target block errors\n     -4.0 | 2.1466e-01 | 1.0000e+00 |       38248 |      178176 |          128 |         128 |         0.1 |reached target block errors\n     -3.5 | 1.9506e-01 | 1.0000e+00 |       34755 |      178176 |          128 |         128 |         0.1 |reached target block errors\n     -3.0 | 1.6194e-01 | 1.0000e+00 |       28853 |      178176 |          128 |         128 |         0.1 |reached target block errors\n     -2.5 | 1.0628e-01 | 9.9219e-01 |       18937 |      178176 |          127 |         128 |         0.1 |reached target block errors\n     -2.0 | 1.8395e-02 | 5.6250e-01 |        6555 |      356352 |          144 |         256 |         0.2 |reached target block errors\n     -1.5 | 6.6440e-04 | 2.7478e-02 |        3433 |     5167104 |          102 |        3712 |         3.2 |reached target block errors\n     -1.0 | 8.7161e-05 | 1.4844e-03 |        1553 |    17817600 |           19 |       12800 |        10.9 |reached max iter\n     -0.5 | 2.8904e-05 | 7.8125e-04 |         515 |    17817600 |           10 |       12800 |        10.9 |reached max iter\n      0.0 | 1.2347e-05 | 1.5625e-04 |         220 |    17817600 |            2 |       12800 |        10.9 |reached max iter\n      0.5 | 1.1337e-05 | 7.8125e-05 |         202 |    17817600 |            1 |       12800 |        10.8 |reached max iter\n      1.0 | 8.0819e-06 | 7.8125e-05 |         144 |    17817600 |            1 |       12800 |        10.9 |reached max iter\n      1.5 | 1.6837e-07 | 7.8125e-05 |           3 |    17817600 |            1 |       12800 |        10.9 |reached max iter\n      2.0 | 0.0000e+00 | 0.0000e+00 |           0 |    17817600 |            0 |       12800 |        10.9 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 2.0 dB.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -5.0 | 3.9096e-01 | 1.0000e+00 |       69659 |      178176 |          128 |         128 |         2.8 |reached target block errors\n     -4.5 | 3.8028e-01 | 1.0000e+00 |       67756 |      178176 |          128 |         128 |         0.1 |reached target block errors\n     -4.0 | 3.6582e-01 | 1.0000e+00 |       65180 |      178176 |          128 |         128 |         0.1 |reached target block errors\n     -3.5 | 3.5540e-01 | 1.0000e+00 |       63324 |      178176 |          128 |         128 |         0.1 |reached target block errors\n     -3.0 | 3.4142e-01 | 1.0000e+00 |       60833 |      178176 |          128 |         128 |         0.1 |reached target block errors\n     -2.5 | 3.2873e-01 | 1.0000e+00 |       58572 |      178176 |          128 |         128 |         0.1 |reached target block errors\n     -2.0 | 3.1137e-01 | 1.0000e+00 |       55478 |      178176 |          128 |         128 |         0.1 |reached target block errors\n     -1.5 | 2.9676e-01 | 1.0000e+00 |       52875 |      178176 |          128 |         128 |         0.1 |reached target block errors\n     -1.0 | 2.7707e-01 | 1.0000e+00 |       49368 |      178176 |          128 |         128 |         0.1 |reached target block errors\n     -0.5 | 2.5655e-01 | 1.0000e+00 |       45711 |      178176 |          128 |         128 |         0.1 |reached target block errors\n      0.0 | 2.3697e-01 | 1.0000e+00 |       42223 |      178176 |          128 |         128 |         0.1 |reached target block errors\n      0.5 | 2.0973e-01 | 1.0000e+00 |       37369 |      178176 |          128 |         128 |         0.1 |reached target block errors\n      1.0 | 1.6844e-01 | 1.0000e+00 |       30012 |      178176 |          128 |         128 |         0.1 |reached target block errors\n      1.5 | 8.5578e-02 | 9.2969e-01 |       15248 |      178176 |          119 |         128 |         0.1 |reached target block errors\n      2.0 | 1.0147e-02 | 2.5195e-01 |        7232 |      712704 |          129 |         512 |         0.4 |reached target block errors\n      2.5 | 7.8271e-04 | 1.2401e-02 |        8786 |    11225088 |          100 |        8064 |         6.9 |reached target block errors\n      3.0 | 2.1866e-04 | 2.1094e-03 |        3896 |    17817600 |           27 |       12800 |        11.0 |reached max iter\n      3.5 | 9.0528e-05 | 7.0312e-04 |        1613 |    17817600 |            9 |       12800 |        10.9 |reached max iter\n      4.0 | 2.9634e-05 | 2.3437e-04 |         528 |    17817600 |            3 |       12800 |        11.0 |reached max iter\n      4.5 | 1.9868e-05 | 1.5625e-04 |         354 |    17817600 |            2 |       12800 |        10.9 |reached max iter\n      5.0 | 3.8445e-05 | 2.3437e-04 |         685 |    17817600 |            3 |       12800 |        10.9 |reached max iter\n      5.5 | 0.0000e+00 | 0.0000e+00 |           0 |    17817600 |            0 |       12800 |        10.9 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 5.5 dB.\n\n```"
"## Training the Neural Receiver\n\nIn the next cell, one forward pass is performed within a *gradient tape*, which enables the computation of gradient and therefore the optimization of the neural network through stochastic gradient descent (SGD).\n\n**Note:** For an introduction to the implementation of differentiable communication systems and their optimization through SGD and backpropagation with Sionna, please refer to [the Part 2 of the Sionna tutorial for Beginners](https://nvlabs.github.io/sionna/examples/Sionna_tutorial_part2.html).\n\n\n```python\n# The end-to-end system equipped with the neural receiver is instantiated for training.\n# When called, it therefore returns the estimated BMD rate\nmodel = E2ESystem('neural-receiver', training=True)\n# Sampling a batch of SNRs\nebno_db = tf.random.uniform(shape=[], minval=ebno_db_min, maxval=ebno_db_max)\n# Forward pass\nwith tf.GradientTape() as tape:\n    rate = model(training_batch_size, ebno_db)\n    # Tensorflow optimizers only know how to minimize loss function.\n    # Therefore, a loss function is defined as the additive inverse of the BMD rate\n    loss = -rate\n```\n\n\nNext, one can perform one step of stochastic gradient descent (SGD). The Adam optimizer is used\n\n\n```python\noptimizer = tf.keras.optimizers.Adam()\n# Computing and applying gradients\nweights = model.trainable_weights\ngrads = tape.gradient(loss, weights)\noptimizer.apply_gradients(zip(grads, weights))\n```\n\n```python\n<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=1>\n```\n\n\nTraining consists in looping over SGD steps. The next cell implements a training loop.\n\nAt each iteration: - A batch of SNRs $E_b/N_0$ is sampled - A forward pass through the end-to-end system is performed within a gradient tape - The gradients are computed using the gradient tape, and applied using the Adam optimizer - The achieved BMD rate is periodically shown\n\nAfter training, the weights of the models are saved in a file\n\n**Note:** Training can take a while. Therefore, [we have made pre-trained weights available](https://drive.google.com/file/d/1W9WkWhup6H_vXx0-CojJHJatuPmHJNRF/view?usp=sharing). Do not execute the next cell if you dont want to train the model from scratch."
"```python\n[ ]:\n```\n\n```python\nmodel = E2ESystem('neural-receiver', training=True)\noptimizer = tf.keras.optimizers.Adam()\nfor i in range(num_training_iterations):\n    # Sampling a batch of SNRs\n    ebno_db = tf.random.uniform(shape=[], minval=ebno_db_min, maxval=ebno_db_max)\n    # Forward pass\n    with tf.GradientTape() as tape:\n        rate = model(training_batch_size, ebno_db)\n        # Tensorflow optimizers only know how to minimize loss function.\n        # Therefore, a loss function is defined as the additive inverse of the BMD rate\n        loss = -rate\n    # Computing and applying gradients\n    weights = model.trainable_weights\n    grads = tape.gradient(loss, weights)\n    optimizer.apply_gradients(zip(grads, weights))\n    # Periodically printing the progress\n    if i % 100 == 0:\n        print('Iteration {}/{}  Rate: {:.4f} bit'.format(i, num_training_iterations, rate.numpy()), end='\\r')\n# Save the weights in a file\nweights = model.get_weights()\nwith open(model_weights_path, 'wb') as f:\n    pickle.dump(weights, f)\n```"
"## Evaluation of the Neural Receiver\n\nThe next cell evaluates the neural receiver.\n\n**Note:** Evaluation of the system can take a while and requires having the trained weights of the neural receiver. Therefore, we provide pre-computed results at the end of this notebook.\n\n\n```python\nmodel = E2ESystem('neural-receiver')\n# Run one inference to build the layers and loading the weights\nmodel(1, tf.constant(10.0, tf.float32))\nwith open(model_weights_path, 'rb') as f:\n    weights = pickle.load(f)\nmodel.set_weights(weights)\n# Evaluations\n_,bler = sim_ber(model, ebno_dbs, batch_size=128, num_target_block_errors=100, max_mc_iter=100)\nBLER['neural-receiver'] = bler.numpy()\n\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -5.0 | 2.5993e-01 | 1.0000e+00 |       46314 |      178176 |          128 |         128 |         0.2 |reached target block errors\n     -4.5 | 2.4351e-01 | 1.0000e+00 |       43387 |      178176 |          128 |         128 |         0.1 |reached target block errors\n     -4.0 | 2.2642e-01 | 1.0000e+00 |       40343 |      178176 |          128 |         128 |         0.1 |reached target block errors\n     -3.5 | 2.0519e-01 | 1.0000e+00 |       36560 |      178176 |          128 |         128 |         0.1 |reached target block errors\n     -3.0 | 1.7735e-01 | 1.0000e+00 |       31600 |      178176 |          128 |         128 |         0.1 |reached target block errors\n     -2.5 | 1.2847e-01 | 1.0000e+00 |       22890 |      178176 |          128 |         128 |         0.1 |reached target block errors\n     -2.0 | 4.3592e-02 | 7.9688e-01 |        7767 |      178176 |          102 |         128 |         0.1 |reached target block errors\n     -1.5 | 3.0379e-03 | 1.1830e-01 |        3789 |     1247232 |          106 |         896 |         0.9 |reached target block errors\n     -1.0 | 4.8306e-04 | 7.4219e-03 |        8607 |    17817600 |           95 |       12800 |        13.3 |reached max iter\n     -0.5 | 2.4481e-04 | 2.1875e-03 |        4362 |    17817600 |           28 |       12800 |        13.2 |reached max iter\n      0.0 | 1.9026e-04 | 1.4844e-03 |        3390 |    17817600 |           19 |       12800 |        13.2 |reached max iter\n      0.5 | 7.0436e-05 | 5.4688e-04 |        1255 |    17817600 |            7 |       12800 |        13.3 |reached max iter\n      1.0 | 4.5405e-05 | 3.1250e-04 |         809 |    17817600 |            4 |       12800 |        13.2 |reached max iter\n      1.5 | 3.0083e-05 | 3.1250e-04 |         536 |    17817600 |            4 |       12800 |        13.2 |reached max iter\n      2.0 | 5.8145e-05 | 3.1250e-04 |        1036 |    17817600 |            4 |       12800 |        13.3 |reached max iter\n      2.5 | 1.6276e-05 | 1.5625e-04 |         290 |    17817600 |            2 |       12800 |        13.2 |reached max iter\n      3.0 | 0.0000e+00 | 0.0000e+00 |           0 |    17817600 |            0 |       12800 |        13.2 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 3.0 dB.\n\n```"
"Finally, we plots the BLERs\n\n\n```python\nplt.figure(figsize=(10,6))\n# Baseline - Perfect CSI\nplt.semilogy(ebno_dbs, BLER['baseline-perfect-csi'], 'o-', c=f'C0', label=f'Baseline - Perfect CSI')\n# Baseline - LS Estimation\nplt.semilogy(ebno_dbs, BLER['baseline-ls-estimation'], 'x--', c=f'C1', label=f'Baseline - LS Estimation')\n# Neural receiver\nplt.semilogy(ebno_dbs, BLER['neural-receiver'], 's-.', c=f'C2', label=f'Neural receiver')\n#\nplt.xlabel(r\"$E_b/N_0$ (dB)\")\nplt.ylabel(\"BLER\")\nplt.grid(which=\"both\")\nplt.ylim((1e-4, 1.0))\nplt.legend()\nplt.tight_layout()\n```"
"## Pre-computed Results\n\n```python\n[ ]:\n```\n\n```python\npre_computed_results = \"{'baseline-perfect-csi': [1.0, 1.0, 1.0, 1.0, 1.0, 0.9916930379746836, 0.5367080479452054, 0.0285078125, 0.0017890625, 0.0006171875, 0.0002265625, 9.375e-05, 2.34375e-05, 7.8125e-06, 1.5625e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'baseline-ls-estimation': [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9998022151898734, 0.9199448529411764, 0.25374190938511326, 0.0110234375, 0.002078125, 0.0008359375, 0.0004375, 0.000171875, 9.375e-05, 4.6875e-05, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], 'neural-receiver': [1.0, 1.0, 1.0, 1.0, 1.0, 0.9984177215189873, 0.7505952380952381, 0.10016025641025642, 0.00740625, 0.0021640625, 0.000984375, 0.0003671875, 0.000203125, 0.0001484375, 3.125e-05, 2.34375e-05, 7.8125e-06, 7.8125e-06, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]}\"\nBLER = eval(pre_computed_results)\n```"
"## References\n\n[1] M. Honkala, D. Korpi and J. M. J. Huttunen, DeepRx: Fully Convolutional Deep Learning Receiver, in IEEE Transactions on Wireless Communications, vol.20, no. 6, pp.3925-3940, June 2021, doi: 10.1109/TWC.2021.3054520.\n\n[2] F. Ait Aoudia and J. Hoydis, End-to-end Learning for OFDM: From Neural Receivers to Pilotless Communication, in IEEE Transactions on Wireless Communications, doi: 10.1109/TWC.2021.3101364.\n\n[3] Kaiming He, Xiangyu Zhang, Shaoqing Ren, Jian Sun, Deep Residual Learning for Image Recognition, Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2016, pp.770-778\n\n[4] G. Bcherer, Achievable Rates for Probabilistic Shaping, arXiv:1707.01134, 2017.\n[4] G. Bcherer, Achievable Rates for Probabilistic Shaping, arXiv:1707.01134, 2017.\n[4] G. Bcherer, Achievable Rates for Probabilistic Shaping, arXiv:1707.01134, 2017."
"# OFDM MIMO Channel Estimation and Detection\n\nIn this notebook, we will evaluate some of the OFDM channel estimation and MIMO detection algorithms available in Sionna.\n\nWe will start by evaluating the mean square error (MSE) preformance of various channel estimation and interpolation methods.\n\nThen, we will compare some of the MIMO detection algorithms under both perfect and imperfect channel state information (CSI) in terms of uncoded symbol error rate (SER) and coded bit error rate (BER).\n\nThe developed end-to-end Keras models in this notebook are a great tool for benchmarking of MIMO receivers under realistic conditions. They can be easily extended to new channel estimation methods or MIMO detection algorithms.\n\nFor MSE evaluations, the block diagram of the system looks as follows:\n\n\nwhere the channel estimation module is highlighted as it is the focus of this evaluation. The channel covariance matrices are required for linear minimum mean square error (LMMSE) channel interpolation.\n\nFor uncoded SER evaluations, the block diagram of the system looks as follows:\n\n\nwhere the channel estimation and detection modules are highlighted as they are the focus of this evaluation.\n\nFinally, for coded BER evaluations, the block diagram of the system looks as follows:"
"## GPU Configuration and Imports\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n# For more details, see https://www.tensorflow.org/guide/gpu\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\n```\n\n```python\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pickle\nfrom tensorflow.keras import Model\nfrom sionna.mimo import StreamManagement\nfrom sionna.utils import QAMSource, compute_ser, BinarySource, sim_ber, ebnodb2no, QAMSource\nfrom sionna.mapping import Mapper\nfrom sionna.ofdm import ResourceGrid, ResourceGridMapper, LSChannelEstimator, LMMSEInterpolator, LinearDetector, KBestDetector, EPDetector, MMSEPICDetector\nfrom sionna.channel import GenerateOFDMChannel, OFDMChannel, gen_single_sector_topology\nfrom sionna.channel.tr38901 import UMi, Antenna, PanelArray\nfrom sionna.fec.ldpc import LDPC5GEncoder\nfrom sionna.fec.ldpc import LDPC5GDecoder\n```"
"## Simulation parameters\n\nThe next cell defines the simulation parameters used throughout this notebook.\n\nThis includes the OFDM waveform parameters, [antennas geometries and patterns](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.tr38901.PanelArray), and the [3GPP UMi channel model](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.tr38901.UMi).\n\n\n```python\nNUM_OFDM_SYMBOLS = 14\nFFT_SIZE = 12*4 # 4 PRBs\nSUBCARRIER_SPACING = 30e3 # Hz\nCARRIER_FREQUENCY = 3.5e9 # Hz\nSPEED = 3. # m/s\n# The user terminals (UTs) are equipped with a single antenna\n# with vertial polarization.\nUT_ANTENNA = Antenna(polarization='single',\n                     polarization_type='V',\n                     antenna_pattern='omni', # Omnidirectional antenna pattern\n                     carrier_frequency=CARRIER_FREQUENCY)\n# The base station is equipped with an antenna\n# array of 8 cross-polarized antennas,\n# resulting in a total of 16 antenna elements.\nNUM_RX_ANT = 16\nBS_ARRAY = PanelArray(num_rows_per_panel=4,\n                      num_cols_per_panel=2,\n                      polarization='dual',\n                      polarization_type='cross',\n                      antenna_pattern='38.901', # 3GPP 38.901 antenna pattern\n                      carrier_frequency=CARRIER_FREQUENCY)\n# 3GPP UMi channel model is considered\nCHANNEL_MODEL = UMi(carrier_frequency=CARRIER_FREQUENCY,\n                    o2i_model='low',\n                    ut_array=UT_ANTENNA,\n                    bs_array=BS_ARRAY,\n                    direction='uplink',\n                    enable_shadow_fading=False,\n                    enable_pathloss=False)\n```"
"## Estimation of the channel time, frequency, and spatial covariance matrices\n\nThe linear minimum mean square (LMMSE) interpolation method requires knowledge of the time (i.e., across OFDM symbols), frequency (i.e., across sub-carriers), and spatial (i.e., across receive antennas) covariance matrices of the channel frequency response.\n\nThese are estimated in this section using Monte Carlo sampling.\n\nWe explain below how this is achieved for the frequency covariance matrix. The same approach is used for the time and spatial covariance matrices.\n\nLet $N$ be the number of sub-carriers. The first step for estimating the frequency covariance matrix is to sample the channel model in order to build a set of frequency-domain channel realizations $\\left\\{ \\mathbf{h}_k \\right\\}, 1 \\leq k \\leq K$, where $K$ is the number of samples and $\\mathbf{h}_k \\in \\mathbb{C}^{N}$ are complex-valued samples of the channel frequency response.\n\nThe frequency covariance matrix $\\mathbf{R}^{(f)} \\in \\mathbb{C}^{N \\times N}$ is then estimated by\n\n\\begin{equation}\n\\mathbf{R}^{(f)} \\approx \\frac{1}{K} \\sum_{k = 1}^K \\mathbf{h}_k \\mathbf{h}_k^{\\mathrm{H}}\n\\end{equation}\n\nwhere we assume that the frequency-domain channel response has zero mean.\n\nThe following cells implement this process for all three dimensions (frequency, time, and space).\n\nThe next cell defines a [resource grid](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.ResourceGrid) and an [OFDM channel generator](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.GenerateOFDMChannel) for sampling the channel in the frequency domain.\n\n\n```python\nrg = ResourceGrid(num_ofdm_symbols=NUM_OFDM_SYMBOLS,\n                  fft_size=FFT_SIZE,\n                  subcarrier_spacing=SUBCARRIER_SPACING)\nchannel_sampler = GenerateOFDMChannel(CHANNEL_MODEL, rg)\n```\n\n\nThen, a function that samples the channel is defined. It randomly samples a network topology for every batch and for every batch example using the [appropriate utility function](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.gen_single_sector_topology)."
"```python\ndef sample_channel(batch_size):\n    # Sample random topologies\n    topology = gen_single_sector_topology(batch_size, 1, 'umi', min_ut_velocity=SPEED, max_ut_velocity=SPEED)\n    CHANNEL_MODEL.set_topology(*topology)\n    # Sample channel frequency responses\n    # [batch size, 1, num_rx_ant, 1, 1, num_ofdm_symbols, fft_size]\n    h_freq = channel_sampler(batch_size)\n    # [batch size, num_rx_ant, num_ofdm_symbols, fft_size]\n    h_freq = h_freq[:,0,:,0,0]\n    return h_freq\n```\n\n\nWe now define a function that estimates the frequency, time, and spatial covariance matrcies using Monte Carlo sampling.\n\n\n```python\n@tf.function(jit_compile=True) # Use XLA for speed-up\ndef estimate_covariance_matrices(num_it, batch_size):\n    freq_cov_mat = tf.zeros([FFT_SIZE, FFT_SIZE], tf.complex64)\n    time_cov_mat = tf.zeros([NUM_OFDM_SYMBOLS, NUM_OFDM_SYMBOLS], tf.complex64)\n    space_cov_mat = tf.zeros([NUM_RX_ANT, NUM_RX_ANT], tf.complex64)\n    for _ in tf.range(num_it):\n        # [batch size, num_rx_ant, num_ofdm_symbols, fft_size]\n        h_samples = sample_channel(batch_size)\n        #################################\n        # Estimate frequency covariance\n        #################################\n        # [batch size, num_rx_ant, fft_size, num_ofdm_symbols]\n        h_samples_ = tf.transpose(h_samples, [0,1,3,2])\n        # [batch size, num_rx_ant, fft_size, fft_size]\n        freq_cov_mat_ = tf.matmul(h_samples_, h_samples_, adjoint_b=True)\n        # [fft_size, fft_size]\n        freq_cov_mat_ = tf.reduce_mean(freq_cov_mat_, axis=(0,1))\n        # [fft_size, fft_size]\n        freq_cov_mat += freq_cov_mat_\n        ################################\n        # Estimate time covariance\n        ################################\n        # [batch size, num_rx_ant, num_ofdm_symbols, fft_size]\n        time_cov_mat_ = tf.matmul(h_samples, h_samples, adjoint_b=True)\n        # [num_ofdm_symbols, num_ofdm_symbols]\n        time_cov_mat_ = tf.reduce_mean(time_cov_mat_, axis=(0,1))\n        # [num_ofdm_symbols, num_ofdm_symbols]\n        time_cov_mat += time_cov_mat_\n        ###############################\n        #Estimate spatial covariance\n        ###############################\n        # [batch size, num_ofdm_symbols, num_rx_ant, fft_size]\n        h_samples_ = tf.transpose(h_samples, [0,2,1,3])\n        # [batch size, num_ofdm_symbols, num_rx_ant, num_rx_ant]\n        space_cov_mat_ = tf.matmul(h_samples_, h_samples_, adjoint_b=True)\n        # [num_rx_ant, num_rx_ant]\n        space_cov_mat_ = tf.reduce_mean(space_cov_mat_, axis=(0,1))\n        # [num_rx_ant, num_rx_ant]\n        space_cov_mat += space_cov_mat_\n    freq_cov_mat /= tf.complex(tf.cast(NUM_OFDM_SYMBOLS*num_it, tf.float32), 0.0)\n    time_cov_mat /= tf.complex(tf.cast(FFT_SIZE*num_it, tf.float32), 0.0)\n    space_cov_mat /= tf.complex(tf.cast(FFT_SIZE*num_it, tf.float32), 0.0)\n    return freq_cov_mat, time_cov_mat, space_cov_mat\n```"
"We then compute the estimates by executing the function defined in the previous cell.\n\nThe batch size and number of iterations determine the total number of samples, i.e.,\n```python\nnumber of samples = batch_size x num_iterations\n```\n\n\nand hence control the tradeoff between the accuracy of the estimates and the time needed for their computation.\n\n\n```python\nbatch_size = 1000\nnum_iterations = 100\nsionna.Config.xla_compat = True # Enable Sionna's support of XLA\nFREQ_COV_MAT, TIME_COV_MAT, SPACE_COV_MAT = estimate_covariance_matrices(batch_size, num_iterations)\nsionna.Config.xla_compat = False # Disable Sionna's support of XLA\n```\n\n\nFinally, the estimated matrices are saved (as numpy arrays) for future use.\n\n\n```python\n# FREQ_COV_MAT : [fft_size, fft_size]\n# TIME_COV_MAT : [num_ofdm_symbols, num_ofdm_symbols]\n# SPACE_COV_MAT : [num_rx_ant, num_rx_ant]\nnp.save('freq_cov_mat', FREQ_COV_MAT.numpy())\nnp.save('time_cov_mat', TIME_COV_MAT.numpy())\nnp.save('space_cov_mat', SPACE_COV_MAT.numpy())\n```"
"## Loading the channel covariance matrices\n\nThe next cell loads saved estimates of the time, frequency, and space covariance matrices.\n\n\n```python\nFREQ_COV_MAT = np.load('freq_cov_mat.npy')\nTIME_COV_MAT = np.load('time_cov_mat.npy')\nSPACE_COV_MAT = np.load('space_cov_mat.npy')\n```\n\n\nWe then visualize the loaded matrices.\n\nAs one can see, the frequency correlation slowly decays with increasing spectral distance.\n\nThe time-correlation is much stronger as the mobility low. The covariance matrix is hence very badly conditioned with rank almost equal to one.\n\nThe spatial covariance matrix has a regular structure which is determined by the array geometry and polarization of its elements.\n\n\n```python\nfig, ax = plt.subplots(3,2, figsize=(10,12))\nfig.suptitle(\"Time and frequency channel covariance matrices\")\nax[0,0].set_title(\"Freq. cov. Real\")\nim = ax[0,0].imshow(FREQ_COV_MAT.real, vmin=-0.3, vmax=1.8)\nax[0,1].set_title(\"Freq. cov. Imag\")\nim = ax[0,1].imshow(FREQ_COV_MAT.imag, vmin=-0.3, vmax=1.8)\nax[1,0].set_title(\"Time cov. Real\")\nim = ax[1,0].imshow(TIME_COV_MAT.real, vmin=-0.3, vmax=1.8)\nax[1,1].set_title(\"Time cov. Imag\")\nim = ax[1,1].imshow(TIME_COV_MAT.imag, vmin=-0.3, vmax=1.8)\nax[2,0].set_title(\"Space cov. Real\")\nim = ax[2,0].imshow(SPACE_COV_MAT.real, vmin=-0.3, vmax=1.8)\nax[2,1].set_title(\"Space cov. Imag\")\nim = ax[2,1].imshow(SPACE_COV_MAT.imag, vmin=-0.3, vmax=1.8)\nfig.subplots_adjust(right=0.8)\ncbar_ax = fig.add_axes([0.85, 0.15, 0.05, 0.7])\nfig.colorbar(im, cax=cbar_ax);\n```\n```python\n<matplotlib.colorbar.Colorbar at 0x7effa863f0d0>\n```"
"## Comparison of OFDM estimators\n\nThis section focuses on comparing the available OFDM channel estimators in Sionna for the considered setup.\n\nOFDM channel estimation consists of two steps:\n<ol class=\"arabic simple\">\n- Channel estimation at pilot-carrying resource elements using [least-squares (LS)](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.LSChannelEstimator).\n- Interpolation for data-carrying resource elements, for which three methods are available in Sionna:\n</ol>\n\n- [Nearest-neighbor](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.NearestNeighborInterpolator), which uses the channel estimate of the nearest pilot\n- [Linear](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.LinearInterpolator), with optional averaging over the OFDM symbols (time dimension) for low mobility scenarios\n- [LMMSE](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.LMMSEInterpolator), which requires knowledge of the time and frequency covariance matrices\n\n\nThe LMMSE interpolator also features optional spatial smoothin, which requires the spatial covarance matrix. The [API documentation](https://nvlabs.github.io/sionna/api/ofdm.html#sionna.ofdm.LMMSEInterpolator) explains in more detail how this interpolator operates."
"### End-to-end model\n\nIn the next cell, we will create a Keras model which uses the interpolation method specified at initialization.\n\nIt computes the mean square error (MSE) for a specified batch size and signal-to-noise ratio (SNR) (in dB).\n\nThe following interpolation methods are available (set through the `int_method` parameter):\n\n- `\"nn\"` : Nearest-neighbor interpolation\n- `\"lin\"` : Linear interpolation\n- `\"lmmse\"` : LMMSE interpolation\n\n\nWhen LMMSE interpolation is used, it is required to specified the order in which interpolation and optional spatial smoothing is performed. This is achieved using the `lmmse_order` parameter. For example, setting this parameter to `\"f-t\"` leads to frequency interpolation being performed first followed by time interpolation, and no spatial smoothing. Setting it to `\"t-f-s\"` leads to time interpolation being performed first, followed by frequency interpolation, and finally spatial smoothing.\n\n\n```python\nclass MIMOOFDMLink(Model):\n    def __init__(self, int_method, lmmse_order=None, **kwargs):\n        super().__init__(kwargs)\n        assert int_method in ('nn', 'lin', 'lmmse')\n\n        # Configure the resource grid\n        rg = ResourceGrid(num_ofdm_symbols=NUM_OFDM_SYMBOLS,\n                          fft_size=FFT_SIZE,\n                          subcarrier_spacing=SUBCARRIER_SPACING,\n                          num_tx=1,\n                          pilot_pattern=\"kronecker\",\n                          pilot_ofdm_symbol_indices=[2,11])\n        self.rg = rg\n        # Stream management\n        # Only a sinlge UT is considered for channel estimation\n        sm = StreamManagement([[1]], 1)\n        ##################################\n        # Transmitter\n        ##################################\n        self.qam_source = QAMSource(num_bits_per_symbol=2) # Modulation order does not impact the channel estimation. Set to QPSK\n        self.rg_mapper = ResourceGridMapper(rg)\n        ##################################\n        # Channel\n        ##################################\n        self.channel = OFDMChannel(CHANNEL_MODEL, rg, return_channel=True)\n        ###################################\n        # Receiver\n        ###################################\n        # Channel estimation\n        freq_cov_mat = tf.constant(FREQ_COV_MAT, tf.complex64)\n        time_cov_mat = tf.constant(TIME_COV_MAT, tf.complex64)\n        space_cov_mat = tf.constant(SPACE_COV_MAT, tf.complex64)\n        if int_method == 'nn':\n            self.channel_estimator = LSChannelEstimator(rg, interpolation_type='nn')\n        elif int_method == 'lin':\n            self.channel_estimator = LSChannelEstimator(rg, interpolation_type='lin')\n        elif int_method == 'lmmse':\n            lmmse_int_freq_first = LMMSEInterpolator(rg.pilot_pattern, time_cov_mat, freq_cov_mat, space_cov_mat, order=lmmse_order)\n            self.channel_estimator = LSChannelEstimator(rg, interpolator=lmmse_int_freq_first)\n    @tf.function\n    def call(self, batch_size, snr_db):\n\n        ##################################\n        # Transmitter\n        ##################################\n        x = self.qam_source([batch_size, 1, 1, self.rg.num_data_symbols])\n        x_rg = self.rg_mapper(x)\n        ##################################\n        # Channel\n        ##################################\n        no = tf.pow(10.0, -snr_db/10.0)\n        topology = gen_single_sector_topology(batch_size, 1, 'umi', min_ut_velocity=SPEED, max_ut_velocity=SPEED)\n        CHANNEL_MODEL.set_topology(*topology)\n        y_rg, h_freq = self.channel((x_rg, no))\n        ###################################\n        # Channel estimation\n        ###################################\n        h_hat,_ = self.channel_estimator((y_rg,no))\n        ###################################\n        # MSE\n        ###################################\n        mse = tf.reduce_mean(tf.square(tf.abs(h_freq-h_hat)))\n        return mse\n```"
"The next cell defines a function for evaluating the mean square error (MSE) of a `model` over a range of SNRs (`snr_dbs`).\n\nThe `batch_size` and `num_it` parameters control the number of samples used to compute the MSE for each SNR value.\n\n\n```python\ndef evaluate_mse(model, snr_dbs, batch_size, num_it):\n    # Casting model inputs to TensorFlow types to avoid\n    # re-building of the graph\n    snr_dbs = tf.cast(snr_dbs, tf.float32)\n    batch_size = tf.cast(batch_size, tf.int32)\n    mses = []\n    for snr_db in snr_dbs:\n        mse_ = 0.0\n        for _ in range(num_it):\n            mse_ += model(batch_size, snr_db).numpy()\n        # Averaging over the number of iterations\n        mse_ /= float(num_it)\n        mses.append(mse_)\n    return mses\n```\n\n\nThe next cell defines the evaluation parameters.\n\n\n```python\n# Range of SNR (in dB)\nSNR_DBs = np.linspace(-10.0, 20.0, 20)\n# Number of iterations and batch size.\n# These parameters control the number of samples used to compute each SNR value.\n# The higher the number of samples is, the more accurate the MSE estimation is, at\n# the cost of longer compute time.\nBATCH_SIZE = 512\nNUM_IT = 10\n# Interpolation/filtering order for the LMMSE interpolator.\n# All valid configurations are listed.\n# Some are commented to speed-up simulations.\n# Uncomment configurations to evaluate them!\nORDERS = ['s-t-f', # Space - time - frequency\n          #'s-f-t', # Space - frequency - time\n          #'t-s-f', # Time - space - frequency\n          't-f-s', # Time - frequency - space\n          #'f-t-s', # Frequency - time - space\n          #'f-s-t', # Frequency - space- time\n          #'f-t',   # Frequency - time (no spatial smoothing)\n          't-f'   # Time - frequency (no spatial smoothing)\n          ]\n```\n\n\nThe next cell evaluates the nearest-neighbor, linear, and LMMSE interpolator. For the LMMSE interpolator, we loop through the configuration listed in `ORDERS`."
"```python\nMSES = {}\n# Nearest-neighbor interpolation\ne2e = MIMOOFDMLink(\"nn\")\nMSES['nn'] = evaluate_mse(e2e, SNR_DBs, BATCH_SIZE, NUM_IT)\n# Linear interpolation\ne2e = MIMOOFDMLink(\"lin\")\nMSES['lin'] = evaluate_mse(e2e, SNR_DBs, BATCH_SIZE, NUM_IT)\n# LMMSE\nfor order in ORDERS:\n    e2e = MIMOOFDMLink(\"lmmse\", order)\n    MSES[f\"lmmse: {order}\"] = evaluate_mse(e2e, SNR_DBs, BATCH_SIZE, NUM_IT)\n\n```\n\n\n```python\nWARNING:tensorflow:From /home/faycal/.local/lib/python3.8/site-packages/tensorflow/python/util/dispatch.py:1176: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\nInstructions for updating:\nThe `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\n```\n\n\nFinally, we plot the MSE.\n\n\n```python\nplt.figure(figsize=(8,6))\nfor est_label in MSES:\n    plt.semilogy(SNR_DBs, MSES[est_label], label=est_label)\nplt.xlabel(r\"SNR (dB)\")\nplt.ylabel(\"MSE\")\nplt.legend()\nplt.grid(True)\n```\n\n\nUnsurprisingly, the LMMSE interpolator leads to more accurate estimates compared to the two other methods, as it leverages knowledge of the the channel statistics. Moreover, the order in which the LMMSE interpolation steps are performed strongly impacts the accuracy of the estimator. This is because the LMMSE interpolation operates in one dimension at a time which is not equivalent to full-blown LMMSE estimation across all dimensions at one.\n\nAlso note that the order that leads to the best accuracy depends on the channel statistics. As a rule of thumb, it might be good to start with the dimension that is most strongly correlated (i.e., time in our example)."
"## Comparison of MIMO detectors\n\nAn OFDM MIMO receiver consists of two stages: **OFDM channel estimation** and **MIMO detection**.\n\nWhile the previous section focused on OFDM channel estimation, this section focuses now on MIMO detection.\n\nThe following MIMO detection algorithms, all available out-of-the-box in Sionna, are considered:\n\n- [LMMSE equalization followed by APP demapping](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.LinearDetector)\n- [K-Best detection](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.KBestDetector)\n- [EP detection](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.EPDetector)\n- [MMSE-PIC detection](https://nvlabs.github.io/sionna/api/mimo.html#sionna.mimo.MMSEPICDetector)\n\n\nBoth perfect and imperfect channel state information is considered in the simulations. LS estimation combined with LMMSE interpolation is used, with time-frequency-space smoothing (in this order, i.e., `order='t-f-s'`)."
"### End-to-end model\n\nA Keras model is created in the next cell, which uses the detection method specified at initialization.\n\nIt computes either the coded bit error rate (BER) or the uncoded symbol error rate (SER), for a specified batch size, $E_b/N_0$ (in dB), and QAM modulation with a specified modulation order. When computing the BER, a 5G LDPC code is used with the specified coderate.\n\nThe following MIMO detection methods are considered (set through the `det_param` parameter):\n\n- `\"lmmse\"` : No parameter needed\n- `\"k-best\"` : List size `k`, defaults to 64\n- `\"ep\"` : Number of iterations `l`, defaults to 10\n- `\"mmse-pic\"` : Number of self-iterations `num_it`, defaults to 4\n\n\nThe `det_param` parameter corresponds to either `k`, `l`, or `num_it`, for K-Best, EP, or MMSE-PIC, respectively. If set to `None`, a default value is used according to the selected detector.\n\nThe `perf_csi` parameter controls whether perfect CSI is assumed or not. If set to `False`, then LS combined with LMMSE interpolation is used to estimate the channel.\n\nYou can easily add your own MIMO detector and channel estimator to this model for a fair and realistic benchmark.\n\n\n```python\nclass MIMOOFDMLink(Model):\n    def __init__(self, output, det_method, perf_csi, num_tx, num_bits_per_symbol, det_param=None, coderate=0.5, **kwargs):\n        super().__init__(kwargs)\n        assert det_method in ('lmmse', 'k-best', 'ep', 'mmse-pic'), \"Unknown detection method\"\n        self._output = output\n        self.num_tx = num_tx\n        self.num_bits_per_symbol = num_bits_per_symbol\n        self.coderate = coderate\n        self.det_method = det_method\n        self.perf_csi = perf_csi\n        # Configure the resource grid\n        rg = ResourceGrid(num_ofdm_symbols=NUM_OFDM_SYMBOLS,\n                          fft_size=FFT_SIZE,\n                          subcarrier_spacing=SUBCARRIER_SPACING,\n                          num_tx=num_tx,\n                          pilot_pattern=\"kronecker\",\n                          pilot_ofdm_symbol_indices=[2,11])\n        self.rg = rg\n        # Stream management\n        sm = StreamManagement(np.ones([1,num_tx], int), 1)\n        # Codeword length and number of information bits per codeword\n        n = int(rg.num_data_symbols*num_bits_per_symbol)\n        k = int(coderate*n)\n        self.n = n\n        self.k = k\n        # If output is symbol, then no FEC is used and hard decision are output\n        hard_out = (output == \"symbol\")\n        coded = (output == \"bit\")\n        self.hard_out = hard_out\n        self.coded = coded\n        ##################################\n        # Transmitter\n        ##################################\n        self.binary_source = BinarySource()\n        self.mapper = Mapper(constellation_type=\"qam\", num_bits_per_symbol=num_bits_per_symbol, return_indices=True)\n        self.rg_mapper = ResourceGridMapper(rg)\n        if coded:\n            self.encoder = LDPC5GEncoder(k, n, num_bits_per_symbol=num_bits_per_symbol)\n        ##################################\n        # Channel\n        ##################################\n        self.channel = OFDMChannel(CHANNEL_MODEL, rg, return_channel=True)\n        ###################################\n        # Receiver\n        ###################################\n        # Channel estimation\n        if not self.perf_csi:\n            freq_cov_mat = tf.constant(FREQ_COV_MAT, tf.complex64)\n            time_cov_mat = tf.constant(TIME_COV_MAT, tf.complex64)\n            space_cov_mat = tf.constant(SPACE_COV_MAT, tf.complex64)\n            lmmse_int_time_first = LMMSEInterpolator(rg.pilot_pattern, time_cov_mat, freq_cov_mat, space_cov_mat, order='t-f-s')\n            self.channel_estimator = LSChannelEstimator(rg, interpolator=lmmse_int_time_first)\n        # Detection\n        if det_method == \"lmmse\":\n            self.detector = LinearDetector(\"lmmse\", output, \"app\", rg, sm, constellation_type=\"qam\", num_bits_per_symbol=num_bits_per_symbol, hard_out=hard_out)\n        elif det_method == 'k-best':\n            if det_param is None:\n                k = 64\n            else:\n                k = det_param\n            self.detector = KBestDetector(output, num_tx, k, rg, sm, constellation_type=\"qam\", num_bits_per_symbol=num_bits_per_symbol, hard_out=hard_out)\n        elif det_method == \"ep\":\n            if det_param is None:\n                l = 10\n            else:\n                l = det_param\n            self.detector = EPDetector(output, rg, sm, num_bits_per_symbol, l=l, hard_out=hard_out)\n        elif det_method == 'mmse-pic':\n            if det_param is None:\n                l = 4\n            else:\n                l = det_param\n            self.detector = MMSEPICDetector(output, rg, sm, 'app', num_iter=l, constellation_type=\"qam\", num_bits_per_symbol=num_bits_per_symbol, hard_out=hard_out)\n        if coded:\n            self.decoder = LDPC5GDecoder(self.encoder, hard_out=False)\n    @tf.function\n    def call(self, batch_size, ebno_db):\n\n        ##################################\n        # Transmitter\n        ##################################\n        if self.coded:\n            b = self.binary_source([batch_size, self.num_tx, 1, self.k])\n            c = self.encoder(b)\n        else:\n            c = self.binary_source([batch_size, self.num_tx, 1, self.n])\n        bits_shape = tf.shape(c)\n        x,x_ind = self.mapper(c)\n        x_rg = self.rg_mapper(x)\n        ##################################\n        # Channel\n        ##################################\n        no = ebnodb2no(ebno_db, self.num_bits_per_symbol, self.coderate, resource_grid=self.rg)\n        topology = gen_single_sector_topology(batch_size, self.num_tx, 'umi', min_ut_velocity=SPEED, max_ut_velocity=SPEED)\n        CHANNEL_MODEL.set_topology(*topology)\n        y_rg, h_freq = self.channel((x_rg, no))\n        ###################################\n        # Receiver\n        ###################################\n        # Channel estimation\n        if self.perf_csi:\n            h_hat = h_freq\n            err_var = 0.0\n        else:\n            h_hat,err_var = self.channel_estimator((y_rg,no))\n        # Detection\n        if self.det_method == \"mmse-pic\":\n            if self._output == \"bit\":\n                prior_shape = bits_shape\n            elif self._output == \"symbol\":\n                prior_shape = tf.concat([tf.shape(x), [self.num_bits_per_symbol]], axis=0)\n            prior = tf.zeros(prior_shape)\n            det_out = self.detector((y_rg,h_hat,prior,err_var,no))\n        else:\n            det_out = self.detector((y_rg,h_hat,err_var,no))\n        # (Decoding) and output\n        if self._output == \"bit\":\n            llr = tf.reshape(det_out, bits_shape)\n            b_hat = self.decoder(llr)\n            return b, b_hat\n        elif self._output == \"symbol\":\n            x_hat = tf.reshape(det_out, tf.shape(x_ind))\n            return x_ind, x_hat\n```"
"The following function is used to evaluate all of the considered detectors for a given setup: It instantiates the end-to-end systems, runs the simulations, and returns the BER or SER.\n\n\n```python\ndef run_sim(num_tx, num_bits_per_symbol, output, ebno_dbs, perf_csi, det_param=None):\n    lmmse = MIMOOFDMLink(output, \"lmmse\", perf_csi, num_tx, num_bits_per_symbol, det_param)\n    k_best = MIMOOFDMLink(output, \"k-best\", perf_csi, num_tx, num_bits_per_symbol, det_param)\n    ep = MIMOOFDMLink(output, \"ep\", perf_csi, num_tx, num_bits_per_symbol, det_param)\n    mmse_pic = MIMOOFDMLink(output, \"mmse-pic\", perf_csi, num_tx, num_bits_per_symbol, det_param)\n    if output == \"symbol\":\n        soft_estimates = False\n        ylabel = \"Uncoded SER\"\n    else:\n        soft_estimates = True\n        ylabel = \"Coded BER\"\n    er_lmmse,_ = sim_ber(lmmse,\n        ebno_dbs,\n        batch_size=64,\n        max_mc_iter=200,\n        num_target_block_errors=200,\n        soft_estimates=soft_estimates);\n    er_ep,_ = sim_ber(ep,\n        ebno_dbs,\n        batch_size=64,\n        max_mc_iter=200,\n        num_target_block_errors=200,\n        soft_estimates=soft_estimates);\n    er_kbest,_ = sim_ber(k_best,\n       ebno_dbs,\n       batch_size=64,\n       max_mc_iter=200,\n       num_target_block_errors=200,\n       soft_estimates=soft_estimates);\n    er_mmse_pic,_ = sim_ber(mmse_pic,\n       ebno_dbs,\n       batch_size=64,\n       max_mc_iter=200,\n       num_target_block_errors=200,\n       soft_estimates=soft_estimates);\n    return er_lmmse, er_ep, er_kbest, er_mmse_pic\n```\n\n\nThe next cell defines the simulation parameters.\n\n\n```python\n# Range of SNR (dB)\nEBN0_DBs = np.linspace(-10., 20.0, 10)\n# Number of transmitters\nNUM_TX = 4\n# Modulation order (number of bits per symbol)\nNUM_BITS_PER_SYMBOL = 4 # 16-QAM\n```"
"We start by evaluating the uncoded SER. The next cell runs the simulations with perfect CSI and channel estimation. Results are stored in the `SER` dictionnary.\n\n\n```python\nSER = {} # Store the results\n# Perfect CSI\nser_lmmse, ser_ep, ser_kbest, ser_mmse_pic = run_sim(NUM_TX, NUM_BITS_PER_SYMBOL, \"symbol\", EBN0_DBs, True)\nSER['Perf. CSI / LMMSE'] = ser_lmmse\nSER['Perf. CSI / EP'] = ser_ep\nSER['Perf. CSI / K-Best'] = ser_kbest\nSER['Perf. CSI / MMSE-PIC'] = ser_mmse_pic\n# Imperfect CSI\nser_lmmse, ser_ep, ser_kbest, ser_mmse_pic = run_sim(NUM_TX, NUM_BITS_PER_SYMBOL, \"symbol\", EBN0_DBs, False)\nSER['Ch. Est. / LMMSE'] = ser_lmmse\nSER['Ch. Est. / EP'] = ser_ep\nSER['Ch. Est. / K-Best'] = ser_kbest\nSER['Ch. Est. / MMSE-PIC'] = ser_mmse_pic\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 6.3274e-01 | 1.0000e+00 |       93302 |      147456 |          256 |         256 |         4.7 |reached target block errors\n   -6.667 | 5.0724e-01 | 1.0000e+00 |       74796 |      147456 |          256 |         256 |         0.1 |reached target block errors\n   -3.333 | 3.7246e-01 | 9.9609e-01 |       54922 |      147456 |          255 |         256 |         0.1 |reached target block errors\n      0.0 | 2.3949e-01 | 9.7656e-01 |       35314 |      147456 |          250 |         256 |         0.1 |reached target block errors\n    3.333 | 1.2375e-01 | 8.4766e-01 |       18247 |      147456 |          217 |         256 |         0.1 |reached target block errors\n    6.667 | 5.7034e-02 | 6.6211e-01 |       16820 |      294912 |          339 |         512 |         0.1 |reached target block errors\n     10.0 | 2.5584e-02 | 4.6680e-01 |        7545 |      294912 |          239 |         512 |         0.1 |reached target block errors\n   13.333 | 6.7546e-03 | 2.6302e-01 |        2988 |      442368 |          202 |         768 |         0.2 |reached target block errors\n   16.667 | 2.0913e-03 | 1.0840e-01 |        2467 |     1179648 |          222 |        2048 |         0.5 |reached target block errors\n     20.0 | 5.6708e-04 | 3.9621e-02 |        1756 |     3096576 |          213 |        5376 |         1.4 |reached target block errors\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 6.1009e-01 | 1.0000e+00 |       89961 |      147456 |          256 |         256 |         5.3 |reached target block errors\n   -6.667 | 4.8094e-01 | 1.0000e+00 |       70918 |      147456 |          256 |         256 |         0.1 |reached target block errors\n   -3.333 | 2.9869e-01 | 9.9609e-01 |       44044 |      147456 |          255 |         256 |         0.1 |reached target block errors\n      0.0 | 1.4774e-01 | 9.7656e-01 |       21785 |      147456 |          250 |         256 |         0.1 |reached target block errors\n    3.333 | 6.1442e-02 | 7.9688e-01 |        9060 |      147456 |          204 |         256 |         0.1 |reached target block errors\n    6.667 | 2.0511e-02 | 4.3750e-01 |        6049 |      294912 |          224 |         512 |         0.2 |reached target block errors\n     10.0 | 4.6556e-03 | 1.4453e-01 |        4119 |      884736 |          222 |        1536 |         0.5 |reached target block errors\n   13.333 | 8.7167e-04 | 5.3385e-02 |        1928 |     2211840 |          205 |        3840 |         1.2 |reached target block errors\n   16.667 | 1.0502e-04 | 1.1217e-02 |        1084 |    10321920 |          201 |       17920 |         5.6 |reached target block errors\n     20.0 | 2.3600e-05 | 2.9688e-03 |         696 |    29491200 |          152 |       51200 |        15.8 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 6.1452e-01 | 1.0000e+00 |       90615 |      147456 |          256 |         256 |         5.6 |reached target block errors\n   -6.667 | 4.8480e-01 | 1.0000e+00 |       71487 |      147456 |          256 |         256 |         0.5 |reached target block errors\n   -3.333 | 3.0013e-01 | 9.8828e-01 |       44256 |      147456 |          253 |         256 |         0.5 |reached target block errors\n      0.0 | 1.2075e-01 | 9.4141e-01 |       17806 |      147456 |          241 |         256 |         0.5 |reached target block errors\n    3.333 | 4.2379e-02 | 7.3242e-01 |       12498 |      294912 |          375 |         512 |         0.9 |reached target block errors\n    6.667 | 1.5837e-02 | 3.4635e-01 |        7006 |      442368 |          266 |         768 |         1.4 |reached target block errors\n     10.0 | 4.0855e-03 | 1.1775e-01 |        4217 |     1032192 |          211 |        1792 |         3.3 |reached target block errors\n   13.333 | 7.5164e-04 | 3.3040e-02 |        2660 |     3538944 |          203 |        6144 |        11.1 |reached target block errors\n   16.667 | 9.1727e-05 | 1.0116e-02 |        1055 |    11501568 |          202 |       19968 |        36.2 |reached target block errors\n     20.0 | 2.4482e-05 | 2.5000e-03 |         722 |    29491200 |          128 |       51200 |        92.6 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 6.0616e-01 | 1.0000e+00 |       89382 |      147456 |          256 |         256 |         5.0 |reached target block errors\n   -6.667 | 4.9781e-01 | 1.0000e+00 |       73405 |      147456 |          256 |         256 |         0.1 |reached target block errors\n   -3.333 | 2.9688e-01 | 1.0000e+00 |       43777 |      147456 |          256 |         256 |         0.1 |reached target block errors\n      0.0 | 1.3372e-01 | 9.5703e-01 |       19718 |      147456 |          245 |         256 |         0.1 |reached target block errors\n    3.333 | 4.9093e-02 | 8.1250e-01 |        7239 |      147456 |          208 |         256 |         0.1 |reached target block errors\n    6.667 | 1.7320e-02 | 4.4531e-01 |        5108 |      294912 |          228 |         512 |         0.2 |reached target block errors\n     10.0 | 4.3996e-03 | 2.3438e-01 |        2595 |      589824 |          240 |        1024 |         0.3 |reached target block errors\n   13.333 | 7.8729e-04 | 7.3509e-02 |        1277 |     1622016 |          207 |        2816 |         0.9 |reached target block errors\n   16.667 | 1.5014e-04 | 1.8714e-02 |         952 |     6340608 |          206 |       11008 |         3.6 |reached target block errors\n     20.0 | 2.7364e-05 | 3.7695e-03 |         807 |    29491200 |          193 |       51200 |        16.9 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 6.5757e-01 | 1.0000e+00 |       96962 |      147456 |          256 |         256 |         4.5 |reached target block errors\n   -6.667 | 5.3936e-01 | 1.0000e+00 |       79532 |      147456 |          256 |         256 |         0.2 |reached target block errors\n   -3.333 | 4.2834e-01 | 1.0000e+00 |       63161 |      147456 |          256 |         256 |         0.2 |reached target block errors\n      0.0 | 3.2353e-01 | 9.8828e-01 |       47706 |      147456 |          253 |         256 |         0.2 |reached target block errors\n    3.333 | 1.8555e-01 | 9.4141e-01 |       27360 |      147456 |          241 |         256 |         0.2 |reached target block errors\n    6.667 | 1.0126e-01 | 7.9297e-01 |       14931 |      147456 |          203 |         256 |         0.2 |reached target block errors\n     10.0 | 3.7248e-02 | 5.4492e-01 |       10985 |      294912 |          279 |         512 |         0.4 |reached target block errors\n   13.333 | 2.3170e-02 | 4.2773e-01 |        6833 |      294912 |          219 |         512 |         0.4 |reached target block errors\n   16.667 | 6.8410e-03 | 2.1777e-01 |        4035 |      589824 |          223 |        1024 |         0.9 |reached target block errors\n     20.0 | 4.8977e-03 | 1.7188e-01 |        3611 |      737280 |          220 |        1280 |         1.1 |reached target block errors\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 6.5626e-01 | 1.0000e+00 |       96770 |      147456 |          256 |         256 |         5.3 |reached target block errors\n   -6.667 | 5.3429e-01 | 1.0000e+00 |       78785 |      147456 |          256 |         256 |         0.2 |reached target block errors\n   -3.333 | 3.4984e-01 | 1.0000e+00 |       51586 |      147456 |          256 |         256 |         0.2 |reached target block errors\n      0.0 | 2.3107e-01 | 9.8828e-01 |       34072 |      147456 |          253 |         256 |         0.2 |reached target block errors\n    3.333 | 9.8416e-02 | 8.3203e-01 |       14512 |      147456 |          213 |         256 |         0.2 |reached target block errors\n    6.667 | 3.5495e-02 | 6.2305e-01 |       10468 |      294912 |          319 |         512 |         0.5 |reached target block errors\n     10.0 | 1.1027e-02 | 3.7370e-01 |        4878 |      442368 |          287 |         768 |         0.7 |reached target block errors\n   13.333 | 4.2103e-03 | 1.7057e-01 |        3725 |      884736 |          262 |        1536 |         1.4 |reached target block errors\n   16.667 | 1.5082e-03 | 7.8125e-02 |        2224 |     1474560 |          200 |        2560 |         2.4 |reached target block errors\n     20.0 | 1.9312e-03 | 6.3101e-02 |        3702 |     1916928 |          210 |        3328 |         3.0 |reached target block errors\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 6.5530e-01 | 1.0000e+00 |       96628 |      147456 |          256 |         256 |         5.9 |reached target block errors\n   -6.667 | 5.4480e-01 | 1.0000e+00 |       80334 |      147456 |          256 |         256 |         0.6 |reached target block errors\n   -3.333 | 3.8673e-01 | 9.9219e-01 |       57026 |      147456 |          254 |         256 |         0.6 |reached target block errors\n      0.0 | 2.1018e-01 | 9.8438e-01 |       30993 |      147456 |          252 |         256 |         0.6 |reached target block errors\n    3.333 | 8.1733e-02 | 8.1250e-01 |       12052 |      147456 |          208 |         256 |         0.6 |reached target block errors\n    6.667 | 3.1857e-02 | 5.5859e-01 |        9395 |      294912 |          286 |         512 |         1.2 |reached target block errors\n     10.0 | 9.6594e-03 | 2.7995e-01 |        4273 |      442368 |          215 |         768 |         1.9 |reached target block errors\n   13.333 | 3.6594e-03 | 1.5937e-01 |        2698 |      737280 |          204 |        1280 |         3.1 |reached target block errors\n   16.667 | 2.2942e-03 | 8.4375e-02 |        3383 |     1474560 |          216 |        2560 |         6.2 |reached target block errors\n     20.0 | 1.4678e-03 | 5.6920e-02 |        3030 |     2064384 |          204 |        3584 |         8.7 |reached target block errors\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 6.5718e-01 | 1.0000e+00 |       96905 |      147456 |          256 |         256 |         5.3 |reached target block errors\n   -6.667 | 5.3097e-01 | 1.0000e+00 |       78294 |      147456 |          256 |         256 |         0.2 |reached target block errors\n   -3.333 | 3.6694e-01 | 1.0000e+00 |       54108 |      147456 |          256 |         256 |         0.2 |reached target block errors\n      0.0 | 2.3520e-01 | 9.7656e-01 |       34682 |      147456 |          250 |         256 |         0.2 |reached target block errors\n    3.333 | 9.2502e-02 | 8.5156e-01 |       13640 |      147456 |          218 |         256 |         0.2 |reached target block errors\n    6.667 | 3.4912e-02 | 6.6211e-01 |       10296 |      294912 |          339 |         512 |         0.5 |reached target block errors\n     10.0 | 1.3431e-02 | 4.2383e-01 |        3961 |      294912 |          217 |         512 |         0.5 |reached target block errors\n   13.333 | 5.7865e-03 | 2.5098e-01 |        3413 |      589824 |          257 |        1024 |         0.9 |reached target block errors\n   16.667 | 2.7466e-03 | 1.1279e-01 |        3240 |     1179648 |          231 |        2048 |         1.9 |reached target block errors\n     20.0 | 1.2919e-03 | 6.6732e-02 |        2286 |     1769472 |          205 |        3072 |         2.9 |reached target block errors\n```"
"Next, we evaluate the coded BER. The cell below runs the simulations with perfect CSI and channel estimation. Results are stored in the `BER` dictionnary.\n\n\n```python\nBER = {} # Store the results\n# Perfect CSI\nber_lmmse, ber_ep, ber_kbest, ber_mmse_pic = run_sim(NUM_TX, NUM_BITS_PER_SYMBOL, \"bit\", EBN0_DBs, True)\nBER['Perf. CSI / LMMSE'] = ber_lmmse\nBER['Perf. CSI / EP'] = ber_ep\nBER['Perf. CSI / K-Best'] = ber_kbest\nBER['Perf. CSI / MMSE-PIC'] = ber_mmse_pic\n# Imperfect CSI\nber_lmmse, ber_ep, ber_kbest, ber_mmse_pic = run_sim(NUM_TX, NUM_BITS_PER_SYMBOL, \"bit\", EBN0_DBs, False)\nBER['Ch. Est. / LMMSE'] = ber_lmmse\nBER['Ch. Est. / EP'] = ber_ep\nBER['Ch. Est. / K-Best'] = ber_kbest\nBER['Ch. Est. / MMSE-PIC'] = ber_mmse_pic\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 1.8888e-01 | 8.5547e-01 |       55703 |      294912 |          219 |         256 |         5.8 |reached target block errors\n   -6.667 | 1.1261e-01 | 5.8984e-01 |       66421 |      589824 |          302 |         512 |         0.2 |reached target block errors\n   -3.333 | 5.7696e-02 | 3.1641e-01 |       51046 |      884736 |          243 |         768 |         0.3 |reached target block errors\n      0.0 | 2.5274e-02 | 1.5039e-01 |       44721 |     1769472 |          231 |        1536 |         0.7 |reached target block errors\n    3.333 | 1.0029e-02 | 6.6732e-02 |       35491 |     3538944 |          205 |        3072 |         1.4 |reached target block errors\n    6.667 | 2.6471e-03 | 1.9627e-02 |       32007 |    12091392 |          206 |       10496 |         4.6 |reached target block errors\n     10.0 | 5.2647e-04 | 4.3645e-03 |       27792 |    52789248 |          200 |       45824 |        20.0 |reached target block errors\n   13.333 | 8.6721e-05 | 5.6641e-04 |        5115 |    58982400 |           29 |       51200 |        22.2 |reached max iter\n   16.667 | 1.6174e-05 | 9.7656e-05 |         954 |    58982400 |            5 |       51200 |        22.2 |reached max iter\n     20.0 | 1.5428e-06 | 1.9531e-05 |          91 |    58982400 |            1 |       51200 |        22.2 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 1.6863e-01 | 7.8125e-01 |       49731 |      294912 |          200 |         256 |         5.6 |reached target block errors\n   -6.667 | 9.9314e-02 | 5.1172e-01 |       58578 |      589824 |          262 |         512 |         0.3 |reached target block errors\n   -3.333 | 4.7239e-02 | 2.7474e-01 |       41794 |      884736 |          211 |         768 |         0.4 |reached target block errors\n      0.0 | 1.4008e-02 | 8.8108e-02 |       37181 |     2654208 |          203 |        2304 |         1.2 |reached target block errors\n    3.333 | 2.2594e-03 | 1.6276e-02 |       31983 |    14155776 |          200 |       12288 |         6.1 |reached target block errors\n    6.667 | 3.9112e-04 | 2.9883e-03 |       23069 |    58982400 |          153 |       51200 |        25.2 |reached max iter\n     10.0 | 2.0972e-05 | 2.7344e-04 |        1237 |    58982400 |           14 |       51200 |        25.1 |reached max iter\n   13.333 | 0.0000e+00 | 0.0000e+00 |           0 |    58982400 |            0 |       51200 |        25.1 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 13.3 dB.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 2.1076e-01 | 9.2969e-01 |       62155 |      294912 |          238 |         256 |         6.5 |reached target block errors\n   -6.667 | 1.0710e-01 | 6.1914e-01 |       63171 |      589824 |          317 |         512 |         1.1 |reached target block errors\n   -3.333 | 3.8923e-02 | 2.4023e-01 |       45916 |     1179648 |          246 |        1024 |         2.2 |reached target block errors\n      0.0 | 1.1103e-02 | 7.1378e-02 |       36018 |     3244032 |          201 |        2816 |         6.2 |reached target block errors\n    3.333 | 2.2757e-03 | 1.6927e-02 |       32215 |    14155776 |          208 |       12288 |        27.0 |reached target block errors\n    6.667 | 2.9185e-04 | 2.1875e-03 |       17214 |    58982400 |          112 |       51200 |       112.1 |reached max iter\n     10.0 | 3.9978e-05 | 2.9297e-04 |        2358 |    58982400 |           15 |       51200 |       112.1 |reached max iter\n   13.333 | 0.0000e+00 | 0.0000e+00 |           0 |    58982400 |            0 |       51200 |       112.1 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 13.3 dB.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 1.8315e-01 | 8.5547e-01 |       54013 |      294912 |          219 |         256 |         5.2 |reached target block errors\n   -6.667 | 1.1446e-01 | 5.9180e-01 |       67512 |      589824 |          303 |         512 |         0.3 |reached target block errors\n   -3.333 | 5.0348e-02 | 2.9297e-01 |       44545 |      884736 |          225 |         768 |         0.4 |reached target block errors\n      0.0 | 1.6928e-02 | 1.0596e-01 |       39937 |     2359296 |          217 |        2048 |         1.1 |reached target block errors\n    3.333 | 2.9010e-03 | 2.4148e-02 |       28233 |     9732096 |          204 |        8448 |         4.4 |reached target block errors\n    6.667 | 5.5365e-04 | 4.4611e-03 |       28737 |    51904512 |          201 |       45056 |        23.3 |reached target block errors\n     10.0 | 6.0560e-05 | 7.4219e-04 |        3572 |    58982400 |           38 |       51200 |        26.5 |reached max iter\n   13.333 | 2.7466e-06 | 3.9063e-05 |         162 |    58982400 |            2 |       51200 |        26.5 |reached max iter\n   16.667 | 1.6954e-08 | 1.9531e-05 |           1 |    58982400 |            1 |       51200 |        26.6 |reached max iter\n     20.0 | 0.0000e+00 | 0.0000e+00 |           0 |    58982400 |            0 |       51200 |        26.4 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 20.0 dB.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 2.0073e-01 | 8.4375e-01 |       59199 |      294912 |          216 |         256 |         5.9 |reached target block errors\n   -6.667 | 1.5016e-01 | 6.8750e-01 |       88566 |      589824 |          352 |         512 |         0.5 |reached target block errors\n   -3.333 | 7.8442e-02 | 4.0430e-01 |       46267 |      589824 |          207 |         512 |         0.5 |reached target block errors\n      0.0 | 3.9502e-02 | 2.1777e-01 |       46598 |     1179648 |          223 |        1024 |         1.1 |reached target block errors\n    3.333 | 1.7726e-02 | 1.0791e-01 |       41822 |     2359296 |          221 |        2048 |         2.1 |reached target block errors\n    6.667 | 6.3252e-03 | 3.7946e-02 |       39173 |     6193152 |          204 |        5376 |         5.6 |reached target block errors\n     10.0 | 2.4057e-03 | 1.5855e-02 |       36183 |    15040512 |          207 |       13056 |        13.6 |reached target block errors\n   13.333 | 9.3448e-04 | 5.5962e-03 |       38858 |    41582592 |          202 |       36096 |        37.5 |reached target block errors\n   16.667 | 2.7039e-04 | 2.0117e-03 |       15948 |    58982400 |          103 |       51200 |        53.3 |reached max iter\n     20.0 | 2.7354e-04 | 1.8555e-03 |       16134 |    58982400 |           95 |       51200 |        53.3 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 1.9646e-01 | 8.9453e-01 |       57939 |      294912 |          229 |         256 |         6.6 |reached target block errors\n   -6.667 | 1.3310e-01 | 6.5625e-01 |       78508 |      589824 |          336 |         512 |         0.6 |reached target block errors\n   -3.333 | 6.3611e-02 | 3.4505e-01 |       56279 |      884736 |          265 |         768 |         0.8 |reached target block errors\n      0.0 | 2.7651e-02 | 1.6562e-01 |       40773 |     1474560 |          212 |        1280 |         1.4 |reached target block errors\n    3.333 | 8.5775e-03 | 5.2083e-02 |       37944 |     4423680 |          200 |        3840 |         4.2 |reached target block errors\n    6.667 | 2.0052e-03 | 1.3470e-02 |       34298 |    17104896 |          200 |       14848 |        16.4 |reached target block errors\n     10.0 | 7.6427e-04 | 5.2083e-03 |       33809 |    44236800 |          200 |       38400 |        42.3 |reached target block errors\n   13.333 | 4.1326e-04 | 2.8516e-03 |       24375 |    58982400 |          146 |       51200 |        56.1 |reached max iter\n   16.667 | 2.0630e-04 | 1.6602e-03 |       12168 |    58982400 |           85 |       51200 |        56.0 |reached max iter\n     20.0 | 1.7263e-04 | 1.6211e-03 |       10182 |    58982400 |           83 |       51200 |        56.3 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 2.4428e-01 | 9.7266e-01 |       72041 |      294912 |          249 |         256 |         7.3 |reached target block errors\n   -6.667 | 1.5539e-01 | 7.4414e-01 |       91650 |      589824 |          381 |         512 |         1.4 |reached target block errors\n   -3.333 | 6.4181e-02 | 3.5286e-01 |       56783 |      884736 |          271 |         768 |         2.1 |reached target block errors\n      0.0 | 2.6555e-02 | 1.4844e-01 |       46988 |     1769472 |          228 |        1536 |         4.3 |reached target block errors\n    3.333 | 5.6042e-03 | 3.4307e-02 |       38013 |     6782976 |          202 |        5888 |        16.4 |reached target block errors\n    6.667 | 1.4845e-03 | 9.5538e-03 |       36337 |    24477696 |          203 |       21248 |        59.0 |reached target block errors\n     10.0 | 5.6710e-04 | 3.6719e-03 |       33449 |    58982400 |          188 |       51200 |       142.6 |reached max iter\n   13.333 | 3.0056e-04 | 1.9727e-03 |       17728 |    58982400 |          101 |       51200 |       142.7 |reached max iter\n   16.667 | 2.2124e-04 | 1.5625e-03 |       13049 |    58982400 |           80 |       51200 |       142.7 |reached max iter\n     20.0 | 1.3379e-04 | 1.0156e-03 |        7891 |    58982400 |           52 |       51200 |       142.5 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n    -10.0 | 2.1431e-01 | 9.0234e-01 |       63203 |      294912 |          231 |         256 |         6.1 |reached target block errors\n   -6.667 | 1.3881e-01 | 6.6016e-01 |       81876 |      589824 |          338 |         512 |         0.6 |reached target block errors\n   -3.333 | 8.4296e-02 | 4.5117e-01 |       49720 |      589824 |          231 |         512 |         0.6 |reached target block errors\n      0.0 | 3.1447e-02 | 1.9062e-01 |       46370 |     1474560 |          244 |        1280 |         1.4 |reached target block errors\n    3.333 | 9.9915e-03 | 6.5505e-02 |       38306 |     3833856 |          218 |        3328 |         3.7 |reached target block errors\n    6.667 | 2.2112e-03 | 1.6342e-02 |       31954 |    14450688 |          205 |       12544 |        14.0 |reached target block errors\n     10.0 | 8.0055e-04 | 6.0562e-03 |       30456 |    38043648 |          200 |       33024 |        36.9 |reached target block errors\n   13.333 | 5.1027e-04 | 3.6719e-03 |       30097 |    58982400 |          188 |       51200 |        57.3 |reached max iter\n   16.667 | 2.7083e-04 | 2.4609e-03 |       15974 |    58982400 |          126 |       51200 |        57.2 |reached max iter\n     20.0 | 2.3241e-04 | 1.7383e-03 |       13708 |    58982400 |           89 |       51200 |        57.2 |reached max iter\n```"
"Finally, we plot the results.\n\n\n```python\nfig, ax = plt.subplots(1,2, figsize=(16,7))\nfig.suptitle(f\"{NUM_TX}x{NUM_RX_ANT} UMi | {2**NUM_BITS_PER_SYMBOL}-QAM\")\n## SER\nax[0].set_title(\"Symbol error rate\")\n# Perfect CSI\nax[0].semilogy(EBN0_DBs, SER['Perf. CSI / LMMSE'], 'x-', label='Perf. CSI / LMMSE', c='C0')\nax[0].semilogy(EBN0_DBs, SER['Perf. CSI / EP'], 'o--', label='Perf. CSI / EP', c='C0')\nax[0].semilogy(EBN0_DBs, SER['Perf. CSI / K-Best'], 's-.', label='Perf. CSI / K-Best', c='C0')\nax[0].semilogy(EBN0_DBs, SER['Perf. CSI / MMSE-PIC'], 'd:', label='Perf. CSI / MMSE-PIC', c='C0')\n# Imperfect CSI\nax[0].semilogy(EBN0_DBs, SER['Ch. Est. / LMMSE'], 'x-', label='Ch. Est. / LMMSE', c='C1')\nax[0].semilogy(EBN0_DBs, SER['Ch. Est. / EP'], 'o--', label='Ch. Est. / EP', c='C1')\nax[0].semilogy(EBN0_DBs, SER['Ch. Est. / K-Best'], 's-.', label='Ch. Est. / K-Best', c='C1')\nax[0].semilogy(EBN0_DBs, SER['Ch. Est. / MMSE-PIC'], 'd:', label='Ch. Est. / MMSE-PIC', c='C1')\nax[0].set_xlabel(r\"$E_b/N0$\")\nax[0].set_ylabel(\"SER\")\nax[0].set_ylim((1e-4, 1.0))\nax[0].legend()\nax[0].grid(True)\n## SER\nax[1].set_title(\"Bit error rate\")\n# Perfect CSI\nax[1].semilogy(EBN0_DBs, BER['Perf. CSI / LMMSE'], 'x-', label='Perf. CSI / LMMSE', c='C0')\nax[1].semilogy(EBN0_DBs, BER['Perf. CSI / EP'], 'o--', label='Perf. CSI / EP', c='C0')\nax[1].semilogy(EBN0_DBs, BER['Perf. CSI / K-Best'], 's-.', label='Perf. CSI / K-Best', c='C0')\nax[1].semilogy(EBN0_DBs, BER['Perf. CSI / MMSE-PIC'], 'd:', label='Perf. CSI / MMSE-PIC', c='C0')\n# Imperfect CSI\nax[1].semilogy(EBN0_DBs, BER['Ch. Est. / LMMSE'], 'x-', label='Ch. Est. / LMMSE', c='C1')\nax[1].semilogy(EBN0_DBs, BER['Ch. Est. / EP'], 'o--', label='Ch. Est. / EP', c='C1')\nax[1].semilogy(EBN0_DBs, BER['Ch. Est. / K-Best'], 's-.', label='Ch. Est. / K-Best', c='C1')\nax[1].semilogy(EBN0_DBs, BER['Ch. Est. / MMSE-PIC'], 'd:', label='Ch. Est. / MMSE-PIC', c='C1')\nax[1].set_xlabel(r\"$E_b/N0$\")\nax[1].set_ylabel(\"BER\")\nax[1].set_ylim((1e-4, 1.0))\nax[1].legend()\nax[1].grid(True)\n```"
"For this setup, the non-linear detection algorithms K-Best, EP, and MMSE-PIC, outperform the linear MMSE detection method. It is remarkable that K-Best and EP with imperfect CSI achieve lower BER than LMMSE detection with perfect CSI.\n\nHowever, one should keep in mind that:\n\n- EP is prone to numerical imprecision and could therefore achieve better BER/SER with double precision (`dtype=tf.complex128`). The number of iterations `l` as well as the update smoothing parameter `beta` impact performance.\n- For K-Best, there is not a unique way to compute soft information and better performance could be achieved with improved methods for computing soft information from a list of candidates (see [list2llr](https://nvlabs.github.io/sionna/api/mimo.html#list2llr)). Increasing the list size `k` results in improved accuracy at the cost of higher complexity.\n- MMSE-PIC can be easily combined with a decoder to implement iterative detection and decoding, as it takes as input soft prior information on the bits/symbols."
"# Realistic Multiuser MIMO OFDM Simulations\n\nIn this notebook, you will learn how to setup realistic simulations of multiuser MIMO uplink transmissions. Multiple user terminals (UTs) are randomly distributed in a cell sector and communicate with a multi-antenna base station.\n\n\nThe block-diagramm of the system model looks as follows:\n\n\nIt includes the following components:\n\n- 5G LDPC FEC\n- QAM modulation\n- OFDM resource grid with configurable pilot pattern\n- Multiple single-antenna transmitters and a multi-antenna receiver\n- 3GPP 38.901 UMi, UMa, and RMa channel models and antenna patterns\n- LS Channel estimation with nearest-neighbor interpolation as well as perfect CSI\n- LMMSE MIMO equalization\n\n\nYou will learn how to setup the topologies required to simulate such scenarios and investigate\n\n- the performance over different models, and\n- the impact of imperfect CSI.\n\n\nWe will first walk through the configuration of all components of the system model, before simulating some simple uplink transmissions in the frequency domain. We will then simulate CDFs of the channel condition number and look into frequency-selectivity of the different channel models to understand the reasons for the observed performance differences.\n\nIt is recommended that you familiarize yourself with the [API documentation](https://nvlabs.github.io/sionna/api/channel.html) of the `Channel` module and, in particular, the 3GPP 38,901 models that require a substantial amount of configuration. The last set of simulations in this notebook take some time, especially when you have no GPU available. For this reason, we provide the simulation results directly in the cells generating the figures. Simply uncomment the corresponding lines to show\nthis results."
"## GPU Configuration and Imports\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n# For more details, see https://www.tensorflow.org/guide/gpu\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\n```\n\n```python\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\nimport pickle\nfrom sionna.mimo import StreamManagement\nfrom sionna.ofdm import ResourceGrid, ResourceGridMapper, LSChannelEstimator, LMMSEEqualizer\nfrom sionna.ofdm import OFDMModulator, OFDMDemodulator, ZFPrecoder, RemoveNulledSubcarriers\nfrom sionna.channel.tr38901 import Antenna, AntennaArray, CDL, UMi, UMa, RMa\nfrom sionna.channel import gen_single_sector_topology as gen_topology\nfrom sionna.channel import subcarrier_frequencies, cir_to_ofdm_channel, cir_to_time_channel\nfrom sionna.channel import ApplyOFDMChannel, ApplyTimeChannel, OFDMChannel\nfrom sionna.fec.ldpc.encoding import LDPC5GEncoder\nfrom sionna.fec.ldpc.decoding import LDPC5GDecoder\nfrom sionna.mapping import Mapper, Demapper\nfrom sionna.utils import BinarySource, ebnodb2no, sim_ber, QAMSource\nfrom sionna.utils.metrics import compute_ber\n```"
"## System Setup\n\nWe will now configure all components of the system model step-by-step.\n\n\n```python\nscenario = \"umi\"\ncarrier_frequency = 3.5e9\ndirection = \"uplink\"\nnum_ut = 4\nbatch_size = 32\n```\n\n```python\ntf.random.set_seed(1)\n# Define the UT antenna array\nut_array = Antenna(polarization=\"single\",\n                   polarization_type=\"V\",\n                   antenna_pattern=\"omni\",\n                   carrier_frequency=carrier_frequency)\n# Define the BS antenna array\nbs_array = AntennaArray(num_rows=1,\n                        num_cols=4,\n                        polarization=\"dual\",\n                        polarization_type=\"VH\",\n                        antenna_pattern=\"38.901\",\n                        carrier_frequency=carrier_frequency)\n# Create channel model\nchannel_model = UMi(carrier_frequency=carrier_frequency,\n                    o2i_model=\"low\",\n                    ut_array=ut_array,\n                    bs_array=bs_array,\n                    direction=direction,\n                    enable_pathloss=False,\n                    enable_shadow_fading=False)\n# Generate the topology\ntopology = gen_topology(batch_size, num_ut, scenario)\n# Set the topology\nchannel_model.set_topology(*topology)\n# Visualize the topology\nchannel_model.show_topology()\n```\n\n\n```python\n# The number of transmitted streams is equal to the number of UT antennas\nnum_streams_per_tx = 1\n# Create an RX-TX association matrix\n# rx_tx_association[i,j]=1 means that receiver i gets at least one stream\n# from transmitter j. Depending on the transmission direction (uplink or downlink),\n# the role of UT and BS can change. However, as we have only a single\n# transmitter and receiver, this does not matter:\nrx_tx_association = np.zeros([1, num_ut])\nrx_tx_association[0, :] = 1\n# Instantiate a StreamManagement object\n# This determines which data streams are determined for which receiver.\n# In this simple setup, this is fairly simple. However, it can get complicated\n# for simulations with many transmitters and receivers.\nsm = StreamManagement(rx_tx_association, num_streams_per_tx)\n```\n\n```python\nrg = ResourceGrid(num_ofdm_symbols=14,\n                  fft_size=128,\n                  subcarrier_spacing=30e3,\n                  num_tx=num_ut,\n                  num_streams_per_tx=num_streams_per_tx,\n                  cyclic_prefix_length=20,\n                  pilot_pattern=\"kronecker\",\n                  pilot_ofdm_symbol_indices=[2,11])\nrg.show();\n```"
"```python\nnum_bits_per_symbol = 2 # QPSK modulation\ncoderate = 0.5 # The code rate\nn = int(rg.num_data_symbols*num_bits_per_symbol) # Number of coded bits\nk = int(n*coderate) # Number of information bits\n# The binary source will create batches of information bits\nbinary_source = BinarySource()\nqam_source = QAMSource(num_bits_per_symbol)\n# The encoder maps information bits to coded bits\nencoder = LDPC5GEncoder(k, n)\n# The mapper maps blocks of information bits to constellation symbols\nmapper = Mapper(\"qam\", num_bits_per_symbol)\n# The resource grid mapper maps symbols onto an OFDM resource grid\nrg_mapper = ResourceGridMapper(rg)\n# This function removes nulled subcarriers from any tensor having the shape of a resource grid\nremove_nulled_scs = RemoveNulledSubcarriers(rg)\n# The LS channel estimator will provide channel estimates and error variances\nls_est = LSChannelEstimator(rg, interpolation_type=\"nn\")\n# The LMMSE equalizer will provide soft symbols together with noise variance estimates\nlmmse_equ = LMMSEEqualizer(rg, sm)\n# The demapper produces LLR for all coded bits\ndemapper = Demapper(\"app\", \"qam\", num_bits_per_symbol)\n# The decoder provides hard-decisions on the information bits\ndecoder = LDPC5GDecoder(encoder, hard_out=True)\n# OFDM CHannel\nofdm_channel = OFDMChannel(channel_model, rg, add_awgn=True, normalize_channel=False, return_channel=True)\nchannel_freq = ApplyOFDMChannel(add_awgn=True)\nfrequencies = subcarrier_frequencies(rg.fft_size, rg.subcarrier_spacing)\n```"
"## Uplink Transmissions in the Frequency Domain\n\nWe now simulate a batch of uplink transmissions. We keep references to the estimated and actual channel frequency responses.\n\n\n```python\nebno_db = 10\nno = ebnodb2no(ebno_db, num_bits_per_symbol, coderate, rg)\nb = binary_source([batch_size, num_ut, rg.num_streams_per_tx, encoder.k])\nc = encoder(b)\nx = mapper(c)\nx_rg = rg_mapper(x)\na, tau = channel_model(num_time_samples=rg.num_ofdm_symbols, sampling_frequency=1/rg.ofdm_symbol_duration)\nh_freq = cir_to_ofdm_channel(frequencies, a, tau, normalize=True)\ny = channel_freq([x_rg, h_freq, no])\nh_hat, err_var = ls_est ([y, no])\nx_hat, no_eff = lmmse_equ([y, h_hat, err_var, no])\nllr = demapper([x_hat, no_eff])\nb_hat = decoder(llr)\nprint(\"BER: {}\".format(compute_ber(b, b_hat).numpy()))\n```\n\n\n```python\nBER: 6.103515625e-05\n```"
"### Compare Estimated and Actual Frequency Responses\n\nWe can now compare the estimated frequency responses and ground truth:\n\n\n```python\n# In the example above, we assumed perfect CSI, i.e.,\n# h_hat correpsond to the exact ideal channel frequency response.\nh_perf = remove_nulled_scs(h_freq)[0,0,0,0,0,0]\n# We now compute the LS channel estimate from the pilots.\nh_est = h_hat[0,0,0,0,0,0]\nplt.figure()\nplt.plot(np.real(h_perf))\nplt.plot(np.imag(h_perf))\nplt.plot(np.real(h_est), \"--\")\nplt.plot(np.imag(h_est), \"--\")\nplt.xlabel(\"Subcarrier index\")\nplt.ylabel(\"Channel frequency response\")\nplt.legend([\"Ideal (real part)\", \"Ideal (imaginary part)\", \"Estimated (real part)\", \"Estimated (imaginary part)\"]);\nplt.title(\"Comparison of channel frequency responses\");\n```"
"### Understand the Difference Between the Channel Models\n\nBefore we proceed with more advanced simulations, it is important to understand the differences between the UMi, UMa, and RMa models. In the following code snippet, we compute the empirical cummulative distribution function (CDF) of the condition number of the channel frequency response matrix between all receiver and transmit antennas.\n\n\n```python\ndef cond_hist(scenario):\n    \"\"\"Generates a histogram of the channel condition numbers\"\"\"\n    # Setup a CIR generator\n    if scenario == \"umi\":\n        channel_model = UMi(carrier_frequency=carrier_frequency,\n                                      o2i_model=\"low\",\n                                      ut_array=ut_array,\n                                      bs_array=bs_array,\n                                      direction=\"uplink\",\n                                      enable_pathloss=False,\n                                      enable_shadow_fading=False)\n    elif scenario == \"uma\":\n        channel_model = UMa(carrier_frequency=carrier_frequency,\n                                      o2i_model=\"low\",\n                                      ut_array=ut_array,\n                                      bs_array=bs_array,\n                                      direction=\"uplink\",\n                                      enable_pathloss=False,\n                                      enable_shadow_fading=False)\n    elif scenario == \"rma\":\n        channel_model = RMa(carrier_frequency=carrier_frequency,\n                                      ut_array=ut_array,\n                                      bs_array=bs_array,\n                                      direction=\"uplink\",\n                                      enable_pathloss=False,\n                                      enable_shadow_fading=False)\n    topology = gen_topology(1024, num_ut, scenario)\n    # Set the topology\n    channel_model.set_topology(*topology)\n    # Generate random CIR realizations\n    # As we nned only a single sample in time, the sampling_frequency\n    # does not matter.\n    cir = channel_model(1, 1)\n    # Compute the frequency response\n    h = cir_to_ofdm_channel(frequencies, *cir, normalize=True)\n    h = tf.squeeze(h)\n    h = tf.transpose(h, [0,3,1,2])\n    # Compute condition number\n    c = np.reshape(np.linalg.cond(h), [-1])\n    # Compute normalized histogram\n    hist, bins = np.histogram(c, 100, (1, 100))\n    hist = hist/np.sum(hist)\n    return bins[:-1], hist\nplt.figure()\nfor cdl_model in [\"umi\", \"uma\", \"rma\"]:\n    bins, hist = cond_hist(cdl_model)\n    plt.plot(bins, np.cumsum(hist))\nplt.xlim([0,40])\nplt.legend([\"UMi\", \"UMa\", \"RMa\"]);\nplt.xlabel(\"Channel Condition Number\")\nplt.ylabel(\"CDF\")\nplt.title(\"CDF of the channel condition number\");\n```"
"From the figure above, you can observe that the UMi and UMa models are substantially better conditioned than the RMa models. This makes them more suitable for MIMO transmissions as we will observe in the next section.\n\nIt is also interesting to look at the channel frequency responses of these different models, as done in the next cell:\n\n\n```python\ndef freq_response(scenario):\n    \"\"\"Generates an example frequency response\"\"\"\n    tf.random.set_seed(2)\n    # Setup a CIR generator\n    if scenario == \"umi\":\n        channel_model = UMi(carrier_frequency=carrier_frequency,\n                                      o2i_model=\"low\",\n                                      ut_array=ut_array,\n                                      bs_array=bs_array,\n                                      direction=\"uplink\",\n                                      enable_pathloss=False,\n                                      enable_shadow_fading=False)\n    elif scenario == \"uma\":\n        channel_model = UMa(carrier_frequency=carrier_frequency,\n                                      o2i_model=\"low\",\n                                      ut_array=ut_array,\n                                      bs_array=bs_array,\n                                      direction=\"uplink\",\n                                      enable_pathloss=False,\n                                      enable_shadow_fading=False)\n    elif scenario == \"rma\":\n        channel_model = RMa(carrier_frequency=carrier_frequency,\n                                      ut_array=ut_array,\n                                      bs_array=bs_array,\n                                      direction=\"uplink\",\n                                      enable_pathloss=False,\n                                      enable_shadow_fading=False)\n    topology = gen_topology(1, num_ut, scenario)\n    # Set the topology\n    channel_model.set_topology(*topology)\n    # Generate random CIR realizations\n    # As we nned only a single sample in time, the sampling_frequency\n    # does not matter.\n    cir = channel_model(1, 1)\n    # Compute the frequency response\n    h = cir_to_ofdm_channel(frequencies, *cir, normalize=True)\n    h = tf.squeeze(h)\n    return h[0,0]\nplt.figure()\nfor cdl_model in [\"umi\", \"uma\", \"rma\"]:\n    h = freq_response(cdl_model)\n    plt.plot(np.real(h))\nplt.legend([\"UMi\", \"UMa\", \"RMa\"]);\nplt.xlabel(\"Subcarrier Index\")\nplt.ylabel(r\"$\\Re(h)$\")\nplt.title(\"Channel frequency response\");\n```\n\n\nThe RMa model has significantly less frequency selectivity than the other models which makes channel estimation easier."
"### Setup a Keras Model for BER simulations\n\n\n```python\n# We need to enable sionna.config.xla_compat before we can use\n# tf.function with jit_compile=True.\n# See https://nvlabs.github.io/sionna/api/config.html#sionna.Config.xla_compat\nsionna.config.xla_compat=True\nclass Model(tf.keras.Model):\n    \"\"\"Simulate OFDM MIMO transmissions over a 3GPP 38.901 model.\n    \"\"\"\n    def __init__(self, scenario, perfect_csi):\n        super().__init__()\n        self._scenario = scenario\n        self._perfect_csi = perfect_csi\n        # Internally set parameters\n        self._carrier_frequency = 3.5e9\n        self._fft_size = 128\n        self._subcarrier_spacing = 30e3\n        self._num_ofdm_symbols = 14\n        self._cyclic_prefix_length = 20\n        self._pilot_ofdm_symbol_indices = [2, 11]\n        self._num_bs_ant = 8\n        self._num_ut = 4\n        self._num_ut_ant = 1\n        self._num_bits_per_symbol = 2\n        self._coderate = 0.5\n        # Create an RX-TX association matrix\n        # rx_tx_association[i,j]=1 means that receiver i gets at least one stream\n        # from transmitter j. Depending on the transmission direction (uplink or downlink),\n        # the role of UT and BS can change.\n        bs_ut_association = np.zeros([1, self._num_ut])\n        bs_ut_association[0, :] = 1\n        self._rx_tx_association = bs_ut_association\n        self._num_tx = self._num_ut\n        self._num_streams_per_tx = self._num_ut_ant\n\n        # Setup an OFDM Resource Grid\n        self._rg = ResourceGrid(num_ofdm_symbols=self._num_ofdm_symbols,\n                                fft_size=self._fft_size,\n                                subcarrier_spacing=self._subcarrier_spacing,\n                                num_tx=self._num_tx,\n                                num_streams_per_tx=self._num_streams_per_tx,\n                                cyclic_prefix_length=self._cyclic_prefix_length,\n                                pilot_pattern=\"kronecker\",\n                                pilot_ofdm_symbol_indices=self._pilot_ofdm_symbol_indices)\n        # Setup StreamManagement\n        self._sm = StreamManagement(self._rx_tx_association, self._num_streams_per_tx)\n        # Configure antenna arrays\n        self._ut_array = AntennaArray(\n                                 num_rows=1,\n                                 num_cols=1,\n                                 polarization=\"single\",\n                                 polarization_type=\"V\",\n                                 antenna_pattern=\"omni\",\n                                 carrier_frequency=self._carrier_frequency)\n        self._bs_array = AntennaArray(num_rows=1,\n                                      num_cols=int(self._num_bs_ant/2),\n                                      polarization=\"dual\",\n                                      polarization_type=\"cross\",\n                                      antenna_pattern=\"38.901\",\n                                      carrier_frequency=self._carrier_frequency)\n        # Configure the channel model\n        if self._scenario == \"umi\":\n            self._channel_model = UMi(carrier_frequency=self._carrier_frequency,\n                                      o2i_model=\"low\",\n                                      ut_array=self._ut_array,\n                                      bs_array=self._bs_array,\n                                      direction=\"uplink\",\n                                      enable_pathloss=False,\n                                      enable_shadow_fading=False)\n        elif self._scenario == \"uma\":\n            self._channel_model = UMa(carrier_frequency=self._carrier_frequency,\n                                      o2i_model=\"low\",\n                                      ut_array=self._ut_array,\n                                      bs_array=self._bs_array,\n                                      direction=\"uplink\",\n                                      enable_pathloss=False,\n                                      enable_shadow_fading=False)\n        elif self._scenario == \"rma\":\n            self._channel_model = RMa(carrier_frequency=self._carrier_frequency,\n                                      ut_array=self._ut_array,\n                                      bs_array=self._bs_array,\n                                      direction=\"uplink\",\n                                      enable_pathloss=False,\n                                      enable_shadow_fading=False)\n        # Instantiate other building blocks\n        self._binary_source = BinarySource()\n        self._qam_source = QAMSource(self._num_bits_per_symbol)\n        self._n = int(self._rg.num_data_symbols*self._num_bits_per_symbol) # Number of coded bits\n        self._k = int(self._n*self._coderate)                              # Number of information bits\n        self._encoder = LDPC5GEncoder(self._k, self._n)\n        self._decoder = LDPC5GDecoder(self._encoder)\n        self._mapper = Mapper(\"qam\", self._num_bits_per_symbol)\n        self._rg_mapper = ResourceGridMapper(self._rg)\n        self._ofdm_channel = OFDMChannel(self._channel_model, self._rg, add_awgn=True,\n                                         normalize_channel=True, return_channel=True)\n        self._remove_nulled_subcarriers = RemoveNulledSubcarriers(self._rg)\n        self._ls_est = LSChannelEstimator(self._rg, interpolation_type=\"nn\")\n        self._lmmse_equ = LMMSEEqualizer(self._rg, self._sm)\n        self._demapper = Demapper(\"app\", \"qam\", self._num_bits_per_symbol)\n    def new_topology(self, batch_size):\n        \"\"\"Set new topology\"\"\"\n        topology = gen_topology(batch_size,\n                                self._num_ut,\n                                self._scenario,\n                                min_ut_velocity=0.0,\n                                max_ut_velocity=0.0)\n        self._channel_model.set_topology(*topology)\n    @tf.function(jit_compile=True)\n    def call(self, batch_size, ebno_db):\n        self.new_topology(batch_size)\n        no = ebnodb2no(ebno_db, self._num_bits_per_symbol, self._coderate, self._rg)\n        b = self._binary_source([batch_size, self._num_tx, self._num_streams_per_tx, self._k])\n        c = self._encoder(b)\n        x = self._mapper(c)\n        x_rg = self._rg_mapper(x)\n        y, h = self._ofdm_channel([x_rg, no])\n        if self._perfect_csi:\n            h_hat = self._remove_nulled_subcarriers(h)\n            err_var = 0.0\n        else:\n            h_hat, err_var = self._ls_est ([y, no])\n        x_hat, no_eff = self._lmmse_equ([y, h_hat, err_var, no])\n        llr = self._demapper([x_hat, no_eff])\n        b_hat = self._decoder(llr)\n        return b, b_hat\n```"
"If you do not want to run the simulations (which can take quite some time) yourself, you can skip the next cell and simply visualize the results in the next cell. The reason why we simulate for a rather large number of `max_mc_iter`, is that for every batch, a new topology (i.e., user drop with new large-scale parameters) is generated. Our goal is here to average over many such topologies.\n\n\n```python\nSIMS = {\n    \"ebno_db\" : list(np.arange(-5, 16, 1.0)),\n    \"scenario\" : [\"umi\", \"uma\", \"rma\"],\n    \"perfect_csi\" : [True, False],\n    \"ber\" : [],\n    \"bler\" : [],\n    \"duration\" : None\n}\nstart = time.time()\nfor scenario in SIMS[\"scenario\"]:\n    for perfect_csi in SIMS[\"perfect_csi\"]:\n        model = Model(scenario=scenario,\n                      perfect_csi=perfect_csi)\n        ber, bler = sim_ber(model,\n                            SIMS[\"ebno_db\"],\n                            batch_size=128,\n                            max_mc_iter=1000,\n                            num_target_block_errors=1000)\n        SIMS[\"ber\"].append(list(ber.numpy()))\n        SIMS[\"bler\"].append(list(bler.numpy()))\nSIMS[\"duration\"] = time.time() -  start\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -5.0 | 7.1096e-02 | 5.0537e-01 |      223649 |     3145728 |         1035 |        2048 |        27.9 |reached target block errors\n     -4.0 | 3.9041e-02 | 2.6855e-01 |      245625 |     6291456 |         1100 |        4096 |         0.4 |reached target block errors\n     -3.0 | 2.1455e-02 | 1.3979e-01 |      236218 |    11010048 |         1002 |        7168 |         0.7 |reached target block errors\n     -2.0 | 1.1953e-02 | 7.8281e-02 |      235015 |    19660800 |         1002 |       12800 |         1.3 |reached target block errors\n     -1.0 | 6.6370e-03 | 4.1260e-02 |      250538 |    37748736 |         1014 |       24576 |         2.5 |reached target block errors\n      0.0 | 3.9849e-03 | 2.3321e-02 |      263243 |    66060288 |         1003 |       43008 |         4.4 |reached target block errors\n      1.0 | 2.4968e-03 | 1.5171e-02 |      253302 |   101449728 |         1002 |       66048 |         6.7 |reached target block errors\n      2.0 | 1.5606e-03 | 9.0965e-03 |      265100 |   169869312 |         1006 |      110592 |        11.3 |reached target block errors\n      3.0 | 9.8858e-04 | 5.6669e-03 |      268220 |   271319040 |         1001 |      176640 |        18.1 |reached target block errors\n      4.0 | 5.9893e-04 | 3.5849e-03 |      257647 |   430178304 |         1004 |      280064 |        28.7 |reached target block errors\n      5.0 | 3.7780e-04 | 2.2014e-03 |      264134 |   699138048 |         1002 |      455168 |        46.8 |reached target block errors\n      6.0 | 2.2261e-04 | 1.2910e-03 |      175069 |   786432000 |          661 |      512000 |        52.8 |reached max iter\n      7.0 | 1.4676e-04 | 8.3203e-04 |      115414 |   786432000 |          426 |      512000 |        52.8 |reached max iter\n      8.0 | 8.2901e-05 | 4.9609e-04 |       65196 |   786432000 |          254 |      512000 |        52.8 |reached max iter\n      9.0 | 6.4590e-05 | 3.8477e-04 |       50796 |   786432000 |          197 |      512000 |        52.6 |reached max iter\n     10.0 | 3.7591e-05 | 2.5000e-04 |       29563 |   786432000 |          128 |      512000 |        52.7 |reached max iter\n     11.0 | 2.3387e-05 | 1.5820e-04 |       18392 |   786432000 |           81 |      512000 |        52.6 |reached max iter\n     12.0 | 1.9283e-05 | 1.2305e-04 |       15165 |   786432000 |           63 |      512000 |        52.6 |reached max iter\n     13.0 | 8.9823e-06 | 7.0312e-05 |        7064 |   786432000 |           36 |      512000 |        52.6 |reached max iter\n     14.0 | 5.1371e-06 | 5.2734e-05 |        4040 |   786432000 |           27 |      512000 |        52.6 |reached max iter\n     15.0 | 2.2189e-06 | 2.5391e-05 |        1745 |   786432000 |           13 |      512000 |        52.6 |reached max iter\nWARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/util/dispatch.py:1082: calling gather (from tensorflow.python.ops.array_ops) with validate_indices is deprecated and will be removed in a future version.\nInstructions for updating:\nThe `validate_indices` argument has no effect. Indices are always validated on CPU and never validated on GPU.\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -5.0 | 2.9643e-01 | 1.0000e+00 |      466249 |     1572864 |         1024 |        1024 |        21.3 |reached target block errors\n     -4.0 | 2.6703e-01 | 1.0000e+00 |      420009 |     1572864 |         1024 |        1024 |         0.1 |reached target block errors\n     -3.0 | 2.2791e-01 | 9.9609e-01 |      358464 |     1572864 |         1020 |        1024 |         0.1 |reached target block errors\n     -2.0 | 1.6929e-01 | 8.5156e-01 |      399413 |     2359296 |         1308 |        1536 |         0.2 |reached target block errors\n     -1.0 | 1.1276e-01 | 5.9424e-01 |      354712 |     3145728 |         1217 |        2048 |         0.2 |reached target block errors\n      0.0 | 7.0166e-02 | 3.7630e-01 |      331083 |     4718592 |         1156 |        3072 |         0.3 |reached target block errors\n      1.0 | 3.9429e-02 | 2.1723e-01 |      279074 |     7077888 |         1001 |        4608 |         0.5 |reached target block errors\n      2.0 | 2.5046e-02 | 1.4089e-01 |      295455 |    11796480 |         1082 |        7680 |         0.8 |reached target block errors\n      3.0 | 1.6036e-02 | 8.6362e-02 |      290063 |    18087936 |         1017 |       11776 |         1.2 |reached target block errors\n      4.0 | 1.0529e-02 | 5.5971e-02 |      289820 |    27525120 |         1003 |       17920 |         1.9 |reached target block errors\n      5.0 | 7.5292e-03 | 3.8274e-02 |      307901 |    40894464 |         1019 |       26624 |         2.8 |reached target block errors\n      6.0 | 5.1773e-03 | 2.5930e-02 |      309443 |    59768832 |         1009 |       38912 |         4.0 |reached target block errors\n      7.0 | 3.6257e-03 | 1.8008e-02 |      310801 |    85721088 |         1005 |       55808 |         5.8 |reached target block errors\n      8.0 | 2.6579e-03 | 1.3781e-02 |      298907 |   112459776 |         1009 |       73216 |         7.6 |reached target block errors\n      9.0 | 2.2009e-03 | 1.1557e-02 |      292515 |   132907008 |         1000 |       86528 |         9.0 |reached target block errors\n     10.0 | 1.6736e-03 | 9.7851e-03 |      264557 |   158072832 |         1007 |      102912 |        10.7 |reached target block errors\n     11.0 | 1.3004e-03 | 8.8067e-03 |      227037 |   174587904 |         1001 |      113664 |        11.8 |reached target block errors\n     12.0 | 1.2042e-03 | 9.6689e-03 |      191298 |   158859264 |         1000 |      103424 |        10.8 |reached target block errors\n     13.0 | 1.1146e-03 | 1.0589e-02 |      162159 |   145489920 |         1003 |       94720 |         9.8 |reached target block errors\n     14.0 | 1.0679e-03 | 1.2168e-02 |      135214 |   126615552 |         1003 |       82432 |         8.6 |reached target block errors\n     15.0 | 1.1502e-03 | 1.4826e-02 |      119396 |   103809024 |         1002 |       67584 |         7.0 |reached target block errors\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -5.0 | 7.2186e-02 | 5.1758e-01 |      227077 |     3145728 |         1060 |        2048 |        21.7 |reached target block errors\n     -4.0 | 3.4300e-02 | 2.4609e-01 |      242769 |     7077888 |         1134 |        4608 |         0.5 |reached target block errors\n     -3.0 | 1.6501e-02 | 1.2017e-01 |      220608 |    13369344 |         1046 |        8704 |         0.9 |reached target block errors\n     -2.0 | 8.1806e-03 | 5.9837e-02 |      212304 |    25952256 |         1011 |       16896 |         1.7 |reached target block errors\n     -1.0 | 4.3676e-03 | 3.0048e-02 |      223264 |    51118080 |         1000 |       33280 |         3.4 |reached target block errors\n      0.0 | 2.6359e-03 | 1.7006e-02 |      240466 |    91226112 |         1010 |       59392 |         6.1 |reached target block errors\n      1.0 | 1.3907e-03 | 8.9862e-03 |      238431 |   171442176 |         1003 |      111616 |        11.5 |reached target block errors\n      2.0 | 8.0677e-04 | 5.0052e-03 |      248078 |   307494912 |         1002 |      200192 |        20.7 |reached target block errors\n      3.0 | 4.0438e-04 | 2.5365e-03 |      244874 |   605552640 |         1000 |      394240 |        40.9 |reached target block errors\n      4.0 | 2.1496e-04 | 1.3184e-03 |      169054 |   786432000 |          675 |      512000 |        53.1 |reached max iter\n      5.0 | 1.2614e-04 | 8.0664e-04 |       99201 |   786432000 |          413 |      512000 |        53.0 |reached max iter\n      6.0 | 6.7013e-05 | 4.1016e-04 |       52701 |   786432000 |          210 |      512000 |        53.0 |reached max iter\n      7.0 | 3.5152e-05 | 2.0508e-04 |       27645 |   786432000 |          105 |      512000 |        52.9 |reached max iter\n      8.0 | 2.0339e-05 | 1.3477e-04 |       15995 |   786432000 |           69 |      512000 |        52.9 |reached max iter\n      9.0 | 1.2319e-05 | 6.4453e-05 |        9688 |   786432000 |           33 |      512000 |        52.9 |reached max iter\n     10.0 | 7.5582e-06 | 5.2734e-05 |        5944 |   786432000 |           27 |      512000 |        53.0 |reached max iter\n     11.0 | 3.7626e-06 | 2.9297e-05 |        2959 |   786432000 |           15 |      512000 |        53.0 |reached max iter\n     12.0 | 1.7904e-06 | 2.1484e-05 |        1408 |   786432000 |           11 |      512000 |        53.0 |reached max iter\n     13.0 | 1.1584e-06 | 1.1719e-05 |         911 |   786432000 |            6 |      512000 |        53.0 |reached max iter\n     14.0 | 7.2988e-07 | 3.9063e-06 |         574 |   786432000 |            2 |      512000 |        53.0 |reached max iter\n     15.0 | 1.0351e-06 | 5.8594e-06 |         814 |   786432000 |            3 |      512000 |        53.0 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -5.0 | 2.9996e-01 | 1.0000e+00 |      471791 |     1572864 |         1024 |        1024 |        21.1 |reached target block errors\n     -4.0 | 2.7072e-01 | 1.0000e+00 |      425811 |     1572864 |         1024 |        1024 |         0.1 |reached target block errors\n     -3.0 | 2.3427e-01 | 1.0000e+00 |      368467 |     1572864 |         1024 |        1024 |         0.1 |reached target block errors\n     -2.0 | 1.7587e-01 | 8.7174e-01 |      414940 |     2359296 |         1339 |        1536 |         0.2 |reached target block errors\n     -1.0 | 1.2033e-01 | 6.3867e-01 |      378535 |     3145728 |         1308 |        2048 |         0.2 |reached target block errors\n      0.0 | 6.9556e-02 | 3.9141e-01 |      273507 |     3932160 |         1002 |        2560 |         0.3 |reached target block errors\n      1.0 | 4.4011e-02 | 2.4132e-01 |      311505 |     7077888 |         1112 |        4608 |         0.5 |reached target block errors\n      2.0 | 2.8742e-02 | 1.5415e-01 |      293844 |    10223616 |         1026 |        6656 |         0.7 |reached target block errors\n      3.0 | 1.7114e-02 | 9.0376e-02 |      296091 |    17301504 |         1018 |       11264 |         1.1 |reached target block errors\n      4.0 | 1.0157e-02 | 5.1282e-02 |      311521 |    30670848 |         1024 |       19968 |         2.0 |reached target block errors\n      5.0 | 8.0138e-03 | 3.9414e-02 |      315114 |    39321600 |         1009 |       25600 |         2.6 |reached target block errors\n      6.0 | 5.7654e-03 | 2.7103e-02 |      330990 |    57409536 |         1013 |       37376 |         3.8 |reached target block errors\n      7.0 | 4.3783e-03 | 2.0406e-02 |      330547 |    75497472 |         1003 |       49152 |         5.0 |reached target block errors\n      8.0 | 3.5508e-03 | 1.6734e-02 |      329507 |    92798976 |         1011 |       60416 |         6.1 |reached target block errors\n      9.0 | 3.0306e-03 | 1.5171e-02 |      307449 |   101449728 |         1002 |       66048 |         6.7 |reached target block errors\n     10.0 | 2.6278e-03 | 1.4482e-02 |      278990 |   106168320 |         1001 |       69120 |         7.0 |reached target block errors\n     11.0 | 2.3524e-03 | 1.5159e-02 |      240503 |   102236160 |         1009 |       66560 |         6.7 |reached target block errors\n     12.0 | 2.5297e-03 | 1.8139e-02 |      214857 |    84934656 |         1003 |       55296 |         5.6 |reached target block errors\n     13.0 | 2.3190e-03 | 2.1918e-02 |      164137 |    70778880 |         1010 |       46080 |         4.7 |reached target block errors\n     14.0 | 2.2989e-03 | 2.5619e-02 |      139211 |    60555264 |         1010 |       39424 |         4.0 |reached target block errors\n     15.0 | 2.2612e-03 | 2.8674e-02 |      122701 |    54263808 |         1013 |       35328 |         3.6 |reached target block errors\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -5.0 | 1.1218e-01 | 6.0400e-01 |      352900 |     3145728 |         1237 |        2048 |        20.2 |reached target block errors\n     -4.0 | 7.6053e-02 | 4.0469e-01 |      299052 |     3932160 |         1036 |        2560 |         0.3 |reached target block errors\n     -3.0 | 6.6383e-02 | 3.2878e-01 |      313232 |     4718592 |         1010 |        3072 |         0.3 |reached target block errors\n     -2.0 | 5.0129e-02 | 2.5195e-01 |      315385 |     6291456 |         1032 |        4096 |         0.4 |reached target block errors\n     -1.0 | 3.3127e-02 | 1.7057e-01 |      312623 |     9437184 |         1048 |        6144 |         0.6 |reached target block errors\n      0.0 | 2.7713e-02 | 1.3984e-01 |      326920 |    11796480 |         1074 |        7680 |         0.8 |reached target block errors\n      1.0 | 1.9857e-02 | 9.7656e-02 |      312320 |    15728640 |         1000 |       10240 |         1.0 |reached target block errors\n      2.0 | 1.6031e-02 | 8.0078e-02 |      315191 |    19660800 |         1025 |       12800 |         1.3 |reached target block errors\n      3.0 | 1.1741e-02 | 5.7904e-02 |      313944 |    26738688 |         1008 |       17408 |         1.7 |reached target block errors\n      4.0 | 9.4707e-03 | 4.6596e-02 |      312820 |    33030144 |         1002 |       21504 |         2.1 |reached target block errors\n      5.0 | 7.3535e-03 | 3.6350e-02 |      312285 |    42467328 |         1005 |       27648 |         2.7 |reached target block errors\n      6.0 | 5.7442e-03 | 2.8292e-02 |      316219 |    55050240 |         1014 |       35840 |         3.6 |reached target block errors\n      7.0 | 4.3868e-03 | 2.2978e-02 |      293242 |    66846720 |         1000 |       43520 |         4.3 |reached target block errors\n      8.0 | 3.4328e-03 | 1.7235e-02 |      307761 |    89653248 |         1006 |       58368 |         5.8 |reached target block errors\n      9.0 | 2.7156e-03 | 1.3672e-02 |      305395 |   112459776 |         1001 |       73216 |         7.3 |reached target block errors\n     10.0 | 2.0763e-03 | 1.1172e-02 |      285749 |   137625600 |         1001 |       89600 |         8.9 |reached target block errors\n     11.0 | 1.5832e-03 | 8.3993e-03 |      290097 |   183238656 |         1002 |      119296 |        11.9 |reached target block errors\n     12.0 | 1.1819e-03 | 6.4524e-03 |      281639 |   238288896 |         1001 |      155136 |        15.4 |reached target block errors\n     13.0 | 9.3162e-04 | 4.9874e-03 |      287202 |   308281344 |         1001 |      200704 |        20.0 |reached target block errors\n     14.0 | 7.0943e-04 | 3.9981e-03 |      272823 |   384565248 |         1001 |      250368 |        24.9 |reached target block errors\n     15.0 | 5.7079e-04 | 3.2230e-03 |      272025 |   476577792 |         1000 |      310272 |        30.9 |reached target block errors\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -5.0 | 2.9893e-01 | 1.0000e+00 |      470184 |     1572864 |         1024 |        1024 |        21.0 |reached target block errors\n     -4.0 | 2.7396e-01 | 1.0000e+00 |      430909 |     1572864 |         1024 |        1024 |         0.1 |reached target block errors\n     -3.0 | 2.2892e-01 | 9.8145e-01 |      360059 |     1572864 |         1005 |        1024 |         0.1 |reached target block errors\n     -2.0 | 1.7590e-01 | 7.8841e-01 |      414991 |     2359296 |         1211 |        1536 |         0.2 |reached target block errors\n     -1.0 | 1.2533e-01 | 5.8057e-01 |      394240 |     3145728 |         1189 |        2048 |         0.2 |reached target block errors\n      0.0 | 1.0202e-01 | 4.6133e-01 |      401178 |     3932160 |         1181 |        2560 |         0.3 |reached target block errors\n      1.0 | 7.9942e-02 | 3.6165e-01 |      377212 |     4718592 |         1111 |        3072 |         0.3 |reached target block errors\n      2.0 | 6.4012e-02 | 2.9492e-01 |      352387 |     5505024 |         1057 |        3584 |         0.4 |reached target block errors\n      3.0 | 5.1941e-02 | 2.3698e-01 |      367634 |     7077888 |         1092 |        4608 |         0.5 |reached target block errors\n      4.0 | 3.8278e-02 | 1.7464e-01 |      361239 |     9437184 |         1073 |        6144 |         0.6 |reached target block errors\n      5.0 | 2.9897e-02 | 1.3503e-01 |      352682 |    11796480 |         1037 |        7680 |         0.8 |reached target block errors\n      6.0 | 2.4803e-02 | 1.1306e-01 |      351106 |    14155776 |         1042 |        9216 |         0.9 |reached target block errors\n      7.0 | 1.8750e-02 | 8.5003e-02 |      339141 |    18087936 |         1001 |       11776 |         1.2 |reached target block errors\n      8.0 | 1.4703e-02 | 6.7619e-02 |      335327 |    22806528 |         1004 |       14848 |         1.5 |reached target block errors\n      9.0 | 1.1462e-02 | 5.3262e-02 |      333508 |    29097984 |         1009 |       18944 |         1.9 |reached target block errors\n     10.0 | 8.3913e-03 | 3.9570e-02 |      329960 |    39321600 |         1013 |       25600 |         2.5 |reached target block errors\n     11.0 | 7.3333e-03 | 3.3766e-02 |      340262 |    46399488 |         1020 |       30208 |         3.0 |reached target block errors\n     12.0 | 5.8008e-03 | 2.7127e-02 |      328462 |    56623104 |         1000 |       36864 |         3.7 |reached target block errors\n     13.0 | 4.6824e-03 | 2.1832e-02 |      331412 |    70778880 |         1006 |       46080 |         4.6 |reached target block errors\n     14.0 | 3.4007e-03 | 1.6544e-02 |      318254 |    93585408 |         1008 |       60928 |         6.1 |reached target block errors\n     15.0 | 2.5160e-03 | 1.2143e-02 |      318566 |   126615552 |         1001 |       82432 |         8.2 |reached target block errors\n```"
"```python\n# Load results (uncomment to show saved results from the cell above)\n#SIMS = eval(\"{'ebno_db': [-5.0, -4.0, -3.0, -2.0, -1.0, 0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 11.0, 12.0, 13.0, 14.0, 15.0], 'scenario': ['umi', 'uma', 'rma'], 'perfect_csi': [True, False], 'ber': [[0.07905292510986328, 0.03808736801147461, 0.017681360244750977, 0.009239894087596606, 0.0050665537516276045, 0.0027629886053304755, 0.0016827532040175571, 0.0008500541736877042, 0.0004983015045593167, 0.00031632105509440104, 0.00018594996134440104, 0.00010455576578776041, 6.090927124023438e-05, 3.9520263671875e-05, 2.5684356689453124e-05, 1.4940897623697916e-05, 7.539113362630208e-06, 4.683176676432292e-06, 3.59344482421875e-06, 1.5436808268229167e-06, 7.578531901041666e-07], [0.29719797770182294, 0.26843706766764325, 0.2296581268310547, 0.17483605278862846, 0.10778331756591797, 0.07155566745334202, 0.04232830471462674, 0.022064606348673504, 0.015027618408203125, 0.008189432548754143, 0.005684130119554924, 0.00370962642928929, 0.002616008663393743, 0.0019156403011745876, 0.0015677095994417248, 0.0013081868489583333, 0.0010344430083840252, 0.0010432377567997685, 0.0009155009900555915, 0.0009102860117346291, 0.0008864811488560267], [0.06746260325113933, 0.0329127311706543, 0.014757650869864004, 0.007593437477394387, 0.003813561333550347, 0.0018911941496331237, 0.001028917273696588, 0.000513251788663255, 0.0002842496236165365, 0.00016032155354817708, 8.596547444661459e-05, 4.677454630533854e-05, 2.0359039306640624e-05, 1.1446634928385416e-05, 1.0133107503255209e-05, 3.92913818359375e-07, 1.682281494140625e-06, 6.421407063802083e-07, 1.3987223307291666e-08, 4.895528157552083e-07, 1.2715657552083333e-09], [0.2960662841796875, 0.2712268829345703, 0.2315998077392578, 0.17950481838650173, 0.11626561482747395, 0.0681504143608941, 0.04071949146412037, 0.02562223161969866, 0.014265790397738233, 0.009787991515591614, 0.006755871242947049, 0.004930473776424632, 0.003845776165569867, 0.003375189644949777, 0.0026965757616523173, 0.002434003298685431, 0.002402254330214634, 0.0021742226420969203, 0.0020746665425819925, 0.0021730139552350023, 0.0022606077648344492], [0.09145228068033855, 0.06702995300292969, 0.05034939448038737, 0.03308937766335227, 0.024936834971110027, 0.018199747258966618, 0.014243278974368249, 0.010329062478584155, 0.00815982288784451, 0.006009458884214744, 0.004231770833333333, 0.0033478243597622574, 0.0025576324126052015, 0.0019759736530521373, 0.0014438384618514623, 0.001123528113731971, 0.0008716690492438504, 0.0006736387408842243, 0.0004936694871486797, 0.00040878831294544955, 0.0002836583455403646], [0.2979132334391276, 0.2661628723144531, 0.22218640645345053, 0.1630952623155382, 0.11636797587076823, 0.08418807983398438, 0.06609598795572917, 0.047115184642650465, 0.035385449727376304, 0.026970704396565754, 0.02249379743609512, 0.016286409818209134, 0.011899021693638392, 0.008838085418051861, 0.007266274813948007, 0.005744590415610923, 0.0042660244551720895, 0.003129789240790991, 0.002527833716269651, 0.002067384265718006, 0.0014839694274598686]], 'bler': [[0.53173828125, 0.26806640625, 0.1279296875, 0.0637600806451613, 0.03380926724137931, 0.017422566371681415, 0.010500672043010752, 0.00547640931372549, 0.0030405569595645414, 0.001916015625, 0.0010703125, 0.00063671875, 0.00039453125, 0.000236328125, 0.000154296875, 9.1796875e-05, 6.25e-05, 3.515625e-05, 2.5390625e-05, 1.5625e-05, 1.171875e-05], [1.0, 1.0, 0.994140625, 0.86328125, 0.59619140625, 0.392578125, 0.2348090277777778, 0.127197265625, 0.081484375, 0.04469992897727273, 0.03009588068181818, 0.019152002427184466, 0.01331313775510204, 0.01019287109375, 0.008390893240343348, 0.00784375, 0.007462130248091603, 0.008697916666666666, 0.01016029792746114, 0.011945026676829269, 0.014048549107142858], [0.49609375, 0.25244140625, 0.10894097222222222, 0.05495876736111111, 0.026328125, 0.01235750786163522, 0.006649925595238095, 0.0034094621080139375, 0.001748046875, 0.0010078125, 0.000537109375, 0.000291015625, 0.000130859375, 9.1796875e-05, 6.0546875e-05, 9.765625e-06, 1.953125e-05, 1.3671875e-05, 5.859375e-06, 3.90625e-06, 1.953125e-06], [1.0, 1.0, 0.9951171875, 0.8912760416666666, 0.62353515625, 0.3834635416666667, 0.2265625, 0.14020647321428573, 0.07458043981481481, 0.050380608974358976, 0.03264973958333333, 0.023115808823529413, 0.017648507882882882, 0.015516493055555556, 0.013366284013605442, 0.013377568493150685, 0.015814012096774195, 0.017085597826086957, 0.0193958849009901, 0.02383753765060241, 0.02837611607142857], [0.5185546875, 0.3645833333333333, 0.267822265625, 0.17844460227272727, 0.128662109375, 0.09259588068181818, 0.07241030092592593, 0.05180921052631579, 0.041056315104166664, 0.030048076923076924, 0.021399456521739132, 0.016904633620689655, 0.013012210264900662, 0.01011981865284974, 0.007512019230769231, 0.0060276442307692305, 0.004715737951807229, 0.0035807291666666665, 0.0027969644134477824, 0.0022843567251461987, 0.001625], [1.0, 1.0, 0.9765625, 0.7649739583333334, 0.55517578125, 0.40625, 0.30747767857142855, 0.22200520833333334, 0.169921875, 0.1259765625, 0.10546875, 0.0751953125, 0.05613839285714286, 0.041555851063829786, 0.034078663793103446, 0.026551942567567568, 0.02025612113402062, 0.014954079198473283, 0.012090203220858896, 0.009994818239795918, 0.007302355410447761]], 'duration': 14960.869339227676}\")\nplt.figure()\nplt.xlabel(r\"$E_b/N_0$ (dB)\")\nplt.ylabel(\"BLER\")\nplt.grid(which=\"both\")\ni=0\nlegend = []\nfor scenario in SIMS[\"scenario\"]:\n    for perfect_csi in SIMS[\"perfect_csi\"]:\n        if scenario==\"umi\":\n            r = \"r\"\n            t = \"UMi\"\n        elif scenario==\"uma\":\n            r = \"b\"\n            t = \"UMa\"\n        else:\n            r = \"g\"\n            t = \"RMa\"\n        if perfect_csi:\n            r += \"-\"\n        else:\n            r += \"--\"\n        plt.semilogy(SIMS[\"ebno_db\"], SIMS[\"bler\"][i], r);\n        s = \"{} - {} CSI\".format(t,\"perf.\" if perfect_csi else \"imperf.\")\n        legend.append(s)\n        i += 1\nplt.legend(legend)\nplt.ylim([1e-3, 1])\nplt.title(\"Multiuser 4x8 MIMO Uplink over Different 3GPP 38.901 Models\");\n```"
"Due to the worse channel conditioning, the RMa model achieves the worst performance with perfect CSI. However, as a result of the smaller frequency selectivity, imperfect channel estimation only leads to a constant 5dB performace loss. For the UMI and UMa models, the used channel estimator with nearest-neighbor interpolation is not accurate enough so that the BER curves saturate at high SNR. This could, for example, be circumvented with another interpolation method (e.g., <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/api/ofdm.html#linearinterpolator\">linear interpolation\nwith time averaging</a>) or a different pilot pattern.\nwith time averaging</a>) or a different pilot pattern.\nwith time averaging</a>) or a different pilot pattern."
"# Using the DeepMIMO Dataset with Sionna\n\nIn this example, you will learn how to use the ray-tracing based DeepMIMO dataset.\n\n[DeepMIMO](https://deepmimo.net/) is a generic dataset that enables a wide range of machine/deep learning applications for MIMO systems. It takes as input a set of parameters (such as antenna array configurations and time-domain/OFDM parameters) and generates MIMO channel realizations, corresponding locations, angles of arrival/departure, etc., based on these parameters and on a ray-tracing scenario selected [from those available in DeepMIMO](https://deepmimo.net/scenarios/)."
"## GPU Configuration and Imports\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\n```python\n# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n# For more details, see https://www.tensorflow.org/guide/gpu\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\n```\n\n```python\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pickle\nimport time\nimport os\n# Load the required Sionna components\nfrom sionna.mimo import StreamManagement\nfrom sionna.ofdm import ResourceGrid, ResourceGridMapper, LSChannelEstimator, LMMSEEqualizer\nfrom sionna.ofdm import OFDMModulator, OFDMDemodulator, ZFPrecoder, RemoveNulledSubcarriers\nfrom sionna.channel.tr38901 import AntennaArray, CDL, Antenna\nfrom sionna.channel import subcarrier_frequencies, cir_to_ofdm_channel, cir_to_time_channel, time_lag_discrete_time_channel\nfrom sionna.channel import ApplyOFDMChannel, ApplyTimeChannel, OFDMChannel, TimeChannel\nfrom sionna.fec.ldpc.encoding import LDPC5GEncoder\nfrom sionna.fec.ldpc.decoding import LDPC5GDecoder\nfrom sionna.mapping import Mapper, Demapper\nfrom sionna.utils import BinarySource, ebnodb2no, sim_ber\nfrom sionna.utils.metrics import compute_ber\n```"
"## Configuration of DeepMIMO\n\nDeepMIMO provides multiple [scenarios](https://deepmimo.net/scenarios/) that one can select from. In this example, we use the O1 scenario with the carrier frequency set to 60 GHz (O1_60). To run this example, please download the O1_60 data files [from this page](https://deepmimo.net/scenarios/o1-scenario/). The downloaded zip file should be extracted into a folder, and the parameter `DeepMIMO_params['dataset_folder']` should be set to point to this folder, as done below.\n\nTo use DeepMIMO with Sionna, the DeepMIMO dataset first needs to be generated. The generated DeepMIMO dataset contains channels for different locations of the users and basestations. The layout of the O1 scenario is shown in the figure below.\n\n\nIn this example, we generate a dataset that consists of channels for the links from the basestation 6 to the users located on the rows 400 to 450. Each of these rows consists of 181 user locations, resulting in $51 \\times 181 = 9231$ basestation-user channels.\n\nThe antenna arrays in the DeepMIMO dataset are defined through the x-y-z axes. In the following example, a single-user MISO downlink is considered. The basestation is equipped with a uniform linear array of 16 elements spread along the x-axis. The users are each equipped with a single antenna. These parameters can be configured using the code below (for more information about the DeepMIMO parameters, please check [the DeepMIMO configurations](https://deepmimo.net/versions/v2-python/)).\n\n\n```python\n# Import DeepMIMO\ntry:\n    import DeepMIMO\nexcept ImportError as e:\n    # Install DeepMIMO if package is not already installed\n    import os\n    os.system(\"pip install DeepMIMO\")\n    import DeepMIMO\n# Channel generation\nDeepMIMO_params = DeepMIMO.default_params() # Load the default parameters\nDeepMIMO_params['dataset_folder'] = r'./scenarios' # Path to the downloaded scenarios\nDeepMIMO_params['scenario'] = 'O1_60' # DeepMIMO scenario\nDeepMIMO_params['num_paths'] = 10 # Maximum number of paths\nDeepMIMO_params['active_BS'] = np.array([6]) # Basestation indices to be included in the dataset\n# Selected rows of users, whose channels are to be generated.\nDeepMIMO_params['user_row_first'] = 400 # First user row to be included in the dataset\nDeepMIMO_params['user_row_last'] = 450 # Last user row to be included in the dataset\n# Configuration of the antenna arrays\nDeepMIMO_params['bs_antenna']['shape'] = np.array([16, 1, 1]) # BS antenna shape through [x, y, z] axes\nDeepMIMO_params['ue_antenna']['shape'] = np.array([1, 1, 1]) # UE antenna shape through [x, y, z] axes\n# The OFDM_channels parameter allows choosing between the generation of channel impulse\n# responses (if set to 0) or frequency domain channels (if set to 1).\n# It is set to 0 for this simulation, as the channel responses in frequency domain\n# will be generated using Sionna.\nDeepMIMO_params['OFDM_channels'] = 0\n# Generates a DeepMIMO dataset\nDeepMIMO_dataset = DeepMIMO.generate_data(DeepMIMO_params)\n```"
"```python\n\nBasestation 6\nUE-BS Channels\n```\n\n```python\nReading ray-tracing: 100%|| 81450/81450 [00:00<00:00, 129737.29it/s]\nGenerating channels: 100%|| 9231/9231 [00:00<00:00, 17426.44it/s]\n```\n\n```python\n\nBS-BS Channels\n```\n\n```python\nReading ray-tracing: 100%|| 6/6 [00:00<00:00, 33509.75it/s]\nGenerating channels: 100%|| 1/1 [00:00<00:00, 2589.08it/s]\n```"
"### Visualization of the dataset\n\nTo provide a better understanding of the user and basestation locations, we next visualize the locations of the users, highlighting the first active row of users (row 400), and basestation 6.\n\n\n```python\nplt.figure(figsize=(12,8))\n## User locations\nactive_bs_idx = 0 # Select the first active basestation in the dataset\nplt.scatter(DeepMIMO_dataset[active_bs_idx]['user']['location'][:, 1], # y-axis location of the users\n         DeepMIMO_dataset[active_bs_idx]['user']['location'][:, 0], # x-axis location of the users\n         s=1, marker='x', c='C0', label='The users located on the rows %i to %i (R%i to R%i)'%\n           (DeepMIMO_params['user_row_first'], DeepMIMO_params['user_row_last'],\n           DeepMIMO_params['user_row_first'], DeepMIMO_params['user_row_last']))\n# First 181 users correspond to the first row\nplt.scatter(DeepMIMO_dataset[active_bs_idx]['user']['location'][0:181, 1],\n         DeepMIMO_dataset[active_bs_idx]['user']['location'][0:181, 0],\n         s=1, marker='x', c='C1', label='First row of users (R%i)'% (DeepMIMO_params['user_row_first']))\n## Basestation location\nplt.scatter(DeepMIMO_dataset[active_bs_idx]['location'][1],\n         DeepMIMO_dataset[active_bs_idx]['location'][0],\n         s=50.0, marker='o', c='C2', label='Basestation')\nplt.gca().invert_xaxis() # Invert the x-axis to align the figure with the figure above\nplt.ylabel('x-axis')\nplt.xlabel('y-axis')\nplt.grid()\nplt.legend();\n```"
"## Using DeepMIMO with Sionna\n\nThe DeepMIMO Python package provides [a Sionna-compliant channel impulse response generator](https://nvlabs.github.io/sionna/examples/CIR_Dataset.html#Generators) that adapts the structure of the DeepMIMO dataset to be consistent with Sionna.\n\nAn adapter is instantiated for a given DeepMIMO dataset. In addition to the dataset, the adapter takes the indices of the basestations and users, to generate the channels between these basestations and users:\n\n`DeepMIMOSionnaAdapter(DeepMIMO_dataset,` `bs_idx,` `ue_idx)`\n\n**Note:** `bs_idx` and `ue_idx` set the links from which the channels are drawn. For instance, if `bs_idx` `=` `[0,` `1]` and `ue_idx` `=` `[2,` `3]`, the adapter then outputs the 4 channels formed by the combination of the first and second basestations with the third and fourth users.\n\nThe default behavior for `bs_idx` and `ue_idx` are defined as follows: - If value for `bs_idx` is not given, it will be set to `[0]` (i.e., the first basestation in the `DeepMIMO_dataset`). - If value for `ue_idx` is not given, then channels are provided for the links between the `bs_idx` and all users (i.e., `ue_idx=range(len(DeepMIMO_dataset[0]['user']['channel']))`. - If the both `bs_idx` and `ue_idx` are not given, the channels between the first basestation and all the\nusers are provided by the adapter. For this example, `DeepMIMOSionnaAdapter(DeepMIMO_dataset)` returns the channels from the basestation 6 and the 9231 available user locations.\n\n**Note:** The adapter assumes basestations are transmitters and users are receivers. Uplink channels can be obtained using (transpose) reciprocity."
"### Random Sampling of Multi-User Channels\n\nWhen considering multiple basestations, `bs_idx` can be set to a 2D numpy matrix of shape $($ # of samples $\\times$ # of basestations per sample $)$. In this case, for each sample of basestations, the `DeepMIMOSionnaAdapter` returns a set of $($ # of basestations per sample $\\times$ # of users $)$ channels, which can be provided as a multi-transmitter sample for the Sionna model. For example, `bs_idx` `=` `np.array([[0,` `1],` `[2,` `3],` `[4,` `5]])` provides three\nsets of $($ 2 basestations $\\times$ # of users $)$ channels. These three channel sets are from the basestation sets `[0,` `1]`, `[2,` `3]`, and `[4,` `5]`, respectively, to the users.\n\nTo use the adapter for multi-user channels, `ue_idx` can be set to a 2D numpy matrix of shape $($ # of samples $\\times$ # of users per sample $)$. In this case, for each sample of users, the `DeepMIMOSionnaAdapter` returns a set of $($ # of basestations $\\times$ # of users per sample $)$ channels, which can be provided as a multi-receiver sample for the Sionna model. For example, `ue_idx` `=` `np.array([[0,` `1` `,2],` `[4,` `5,` `6]])` provides two sets of $($"
"# Weighted Belief Propagation Decoding\n\nThis notebooks implements the *Weighted Belief Propagation* (BP) algorithm as proposed by Nachmani *et al.* in [1]. The main idea is to leverage BP decoding by additional trainable weights that scale each outgoing variable node (VN) and check node (CN) message. These weights provide additional degrees of freedom and can be trained by stochastic gradient descent (SGD) to improve the BP performance for the given code. If all weights are initialized with *1*, the algorithm equals the *classical* BP\nalgorithm and, thus, the concept can be seen as a generalized BP decoder.\n\nOur main focus is to show how Sionna can lower the barrier-to-entry for state-of-the-art research. For this, you will investigate:\n\n- How to implement the multi-loss BP decoding with Sionna\n- How a single scaling factor can lead to similar results\n- What happens for training of the 5G LDPC code\n\n\nThe setup includes the following components:\n\n- LDPC BP Decoder\n- Gaussian LLR source\n\n\nPlease note that we implement a simplified version of the original algorithm consisting of two major simplifications:\n<ol class=\"arabic simple\">\n- ) Only outgoing variable node (VN) messages are weighted. This is possible as the VN operation is linear and it would only increase the memory complexity without increasing the *expressive* power of the neural network.\n- ) We use the same shared weights for all iterations. This can potentially influence the final performance, however, simplifies the implementation and allows to run the decoder with different number of iterations.\n</ol>\n\n**Note**: If you are not familiar with all-zero codeword-based simulations please have a look into the [Bit-Interleaved Coded Modulation](https://nvlabs.github.io/sionna/examples/Bit_Interleaved_Coded_Modulation.html) example notebook first."
"## GPU Configuration and Imports\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n# Import required Sionna components\nfrom sionna.fec.ldpc import LDPCBPDecoder, LDPC5GEncoder, LDPC5GDecoder\nfrom sionna.utils.metrics import BitwiseMutualInformation\nfrom sionna.fec.utils import GaussianPriorSource, load_parity_check_examples\nfrom sionna.utils import ebnodb2no, hard_decisions\nfrom sionna.utils.metrics import compute_ber\nfrom sionna.utils.plotting import PlotBER\nfrom tensorflow.keras.losses import BinaryCrossentropy\n```\n\n```python\nimport tensorflow as tf\n# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n# For more details, see https://www.tensorflow.org/guide/gpu\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\n```\n\n```python\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\n```"
"## Weighted BP for BCH Codes\n\nFirst, we define the trainable model consisting of:\n\n- LDPC BP decoder\n- Gaussian LLR source\n\n\nThe idea of the multi-loss function in [1]is to average the loss overall iterations, i.e., not just the final estimate is evaluated. This requires to call the BP decoder *iteration-wise* by setting `num_iter=1` and `stateful=True` such that the decoder will perform a single iteration and returns its current estimate while also providing the internal messages for the next iteration.\n\nA few comments:\n\n- We assume the transmission of the all-zero codeword. This allows to train and analyze the decoder without the need of an encoder. Remark: The final decoder can be used for arbitrary codewords.\n- We directly generate the channel LLRs with `GaussianPriorSource`. The equivalent LLR distribution could be achieved by transmitting the all-zero codeword over an AWGN channel with BPSK modulation.\n- For the proposed *multi-loss* [1] (i.e., the loss is averaged over all iterations), we need to access the decoders intermediate output after each iteration. This is done by calling the decoding function multiple times while setting `stateful` to True, i.e., the decoder continuous the decoding process at the last message state.\n\n```python\nclass WeightedBP(tf.keras.Model):\n    \"\"\"System model for BER simulations of weighted BP decoding.\n    This model uses `GaussianPriorSource` to mimic the LLRs after demapping of\n    QPSK symbols transmitted over an AWGN channel.\n    Parameters\n    ----------\n        pcm: ndarray\n            The parity-check matrix of the code under investigation.\n        num_iter: int\n            Number of BP decoding iterations.\n\n    Input\n    -----\n        batch_size: int or tf.int\n            The batch_size used for the simulation.\n        ebno_db: float or tf.float\n            A float defining the simulation SNR.\n    Output\n    ------\n        (u, u_hat, loss):\n            Tuple:\n        u: tf.float32\n            A tensor of shape `[batch_size, k] of 0s and 1s containing the transmitted information bits.\n        u_hat: tf.float32\n            A tensor of shape `[batch_size, k] of 0s and 1s containing the estimated information bits.\n        loss: tf.float32\n            Binary cross-entropy loss between `u` and `u_hat`.\n    \"\"\"\n    def __init__(self, pcm, num_iter=5):\n        super().__init__()\n        # init components\n        self.decoder = LDPCBPDecoder(pcm,\n                                     num_iter=1, # iterations are done via outer loop (to access intermediate results for multi-loss)\n                                     stateful=True, # decoder stores internal messages after call\n                                     hard_out=False, # we need to access soft-information\n                                     cn_type=\"boxplus\",\n                                     trainable=True) # the decoder must be trainable, otherwise no weights are generated\n        # used to generate llrs during training (see example notebook on all-zero codeword trick)\n        self.llr_source = GaussianPriorSource()\n        self._num_iter = num_iter\n        self._bce = BinaryCrossentropy(from_logits=True)\n    def call(self, batch_size, ebno_db):\n        noise_var = ebnodb2no(ebno_db,\n                              num_bits_per_symbol=2, # QPSK\n                              coderate=coderate)\n        # all-zero CW to calculate loss / BER\n        c = tf.zeros([batch_size, n])\n        # Gaussian LLR source\n        llr = self.llr_source([[batch_size, n], noise_var])\n        # --- implement multi-loss as proposed by Nachmani et al. [1]---\n        loss = 0\n        msg_vn = None # internal state of decoder\n        for i in range(self._num_iter):\n            c_hat, msg_vn = self.decoder((llr, msg_vn)) # perform one decoding iteration; decoder returns soft-values\n            loss += self._bce(c, c_hat)  # add loss after each iteration\n        loss /= self._num_iter # scale loss by number of iterations\n        return c, c_hat, loss\n```"
"Load a parity-check matrix used for the experiment. We use the same BCH(63,45) code as in [1]. The code can be replaced by any parity-check matrix of your choice.\n\n\n```python\npcm_id = 1 # (63,45) BCH code parity check matrix\npcm, k , n, coderate = load_parity_check_examples(pcm_id=pcm_id, verbose=True)\nnum_iter = 10 # set number of decoding iterations\n# and initialize the model\nmodel = WeightedBP(pcm=pcm, num_iter=num_iter)\n```\n\n\n```python\n\nn: 63, k: 45, coderate: 0.714\n```\n\n\n**Note**: weighted BP tends to work better for small number of iterations. The effective gains (compared to the baseline with same number of iterations) vanish with more iterations."
"### Weights before Training and Simulation of BER\n\nLet us plot the weights after initialization of the decoder to verify that everything is properly initialized. This is equivalent the *classical* BP decoder.\n\n\n```python\n# count number of weights/edges\nprint(\"Total number of weights: \", np.size(model.decoder.get_weights()))\n# and show the weight distribution\nmodel.decoder.show_weights()\n```\n\n\n```python\nTotal number of weights:  432\n```\n\n\nWe first simulate (and store) the BER performance *before* training. For this, we use the `PlotBER` class, which provides a convenient way to store the results for later comparison.\n\n\n```python\n# SNR to simulate the results\nebno_dbs = np.array(np.arange(1, 7, 0.5))\nmc_iters = 100 # number of Monte Carlo iterations\n# we generate a new PlotBER() object to simulate, store and plot the BER results\nber_plot = PlotBER(\"Weighted BP\")\n# simulate and plot the BER curve of the untrained decoder\nber_plot.simulate(model,\n                  ebno_dbs=ebno_dbs,\n                  batch_size=1000,\n                  num_target_bit_errors=2000, # stop sim after 2000 bit errors\n                  legend=\"Untrained\",\n                  soft_estimates=True,\n                  max_mc_iter=mc_iters,\n                  forward_keyboard_interrupt=False);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      1.0 | 8.9492e-02 | 9.7600e-01 |        5638 |       63000 |          976 |        1000 |         0.2 |reached target bit errors\n      1.5 | 7.4079e-02 | 9.0800e-01 |        4667 |       63000 |          908 |        1000 |         0.2 |reached target bit errors\n      2.0 | 5.9444e-02 | 8.1300e-01 |        3745 |       63000 |          813 |        1000 |         0.2 |reached target bit errors\n      2.5 | 4.4667e-02 | 6.6400e-01 |        2814 |       63000 |          664 |        1000 |         0.2 |reached target bit errors\n      3.0 | 3.4365e-02 | 5.1700e-01 |        2165 |       63000 |          517 |        1000 |         0.2 |reached target bit errors\n      3.5 | 2.1563e-02 | 3.4950e-01 |        2717 |      126000 |          699 |        2000 |         0.3 |reached target bit errors\n      4.0 | 1.3460e-02 | 2.3200e-01 |        2544 |      189000 |          696 |        3000 |         0.5 |reached target bit errors\n      4.5 | 7.1778e-03 | 1.2880e-01 |        2261 |      315000 |          644 |        5000 |         0.8 |reached target bit errors\n      5.0 | 3.9877e-03 | 7.5889e-02 |        2261 |      567000 |          683 |        9000 |         1.4 |reached target bit errors\n      5.5 | 2.1240e-03 | 3.9188e-02 |        2141 |     1008000 |          627 |       16000 |         2.5 |reached target bit errors\n      6.0 | 1.0169e-03 | 2.0406e-02 |        2050 |     2016000 |          653 |       32000 |         4.9 |reached target bit errors\n      6.5 | 4.4312e-04 | 8.5417e-03 |        2010 |     4536000 |          615 |       72000 |        11.1 |reached target bit errors\n```"
"### Training\n\nWe now train the model for a fixed number of SGD training iterations.\n\n**Note**: this is a very basic implementation of the training loop. You can also try more sophisticated training loops with early stopping, different hyper-parameters or optimizers etc.\n\n\n```python\n# training parameters\nbatch_size = 1000\ntrain_iter = 200\nebno_db = 4.0\nclip_value_grad = 10 # gradient clipping for stable training convergence\n# bmi is used as metric to evaluate the intermediate results\nbmi = BitwiseMutualInformation()\n# try also different optimizers or different hyperparameters\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\nfor it in range(0, train_iter):\n    with tf.GradientTape() as tape:\n        b, llr, loss = model(batch_size, ebno_db)\n    grads = tape.gradient(loss, model.trainable_variables)\n    grads = tf.clip_by_value(grads, -clip_value_grad, clip_value_grad, name=None)\n    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n    # calculate and print intermediate metrics\n    # only for information\n    # this has no impact on the training\n    if it%10==0: # evaluate every 10 iterations\n        # calculate ber from received LLRs\n        b_hat = hard_decisions(llr) # hard decided LLRs first\n        ber = compute_ber(b, b_hat)\n        # and print results\n        mi = bmi(b, llr).numpy() # calculate bit-wise mutual information\n        l = loss.numpy() # copy loss to numpy for printing\n        print(f\"Current loss: {l:3f} ber: {ber:.4f} bmi: {mi:.3f}\".format())\n        bmi.reset_states() # reset the BMI metric\n```\n\n\n```python\nCurrent loss: 0.048708 ber: 0.0120 bmi: 0.934\nCurrent loss: 0.058506 ber: 0.0139 bmi: 0.923\nCurrent loss: 0.052293 ber: 0.0125 bmi: 0.934\nCurrent loss: 0.054314 ber: 0.0134 bmi: 0.928\nCurrent loss: 0.051650 ber: 0.0125 bmi: 0.924\nCurrent loss: 0.047477 ber: 0.0133 bmi: 0.931\nCurrent loss: 0.045135 ber: 0.0122 bmi: 0.935\nCurrent loss: 0.050638 ber: 0.0125 bmi: 0.938\nCurrent loss: 0.045256 ber: 0.0119 bmi: 0.949\nCurrent loss: 0.041335 ber: 0.0124 bmi: 0.952\nCurrent loss: 0.040905 ber: 0.0107 bmi: 0.937\nCurrent loss: 0.043627 ber: 0.0125 bmi: 0.949\nCurrent loss: 0.044397 ber: 0.0126 bmi: 0.942\nCurrent loss: 0.043392 ber: 0.0126 bmi: 0.938\nCurrent loss: 0.043059 ber: 0.0133 bmi: 0.947\nCurrent loss: 0.047521 ber: 0.0130 bmi: 0.937\nCurrent loss: 0.040529 ber: 0.0116 bmi: 0.944\nCurrent loss: 0.041838 ber: 0.0128 bmi: 0.942\nCurrent loss: 0.041801 ber: 0.0130 bmi: 0.940\nCurrent loss: 0.042754 ber: 0.0142 bmi: 0.946\n```"
"### Results\n\nAfter training, the weights of the decoder have changed. In average, the weights are smaller after training.\n\n\n```python\nmodel.decoder.show_weights() # show weights AFTER training\n```\n\n\nAnd let us compare the new BER performance. For this, we can simply call the ber_plot.simulate() function again as it internally stores all previous results (if `add_results` is True).\n\n\n```python\nebno_dbs = np.array(np.arange(1, 7, 0.5))\nbatch_size = 10000\nmc_ites = 100\nber_plot.simulate(model,\n                  ebno_dbs=ebno_dbs,\n                  batch_size=1000,\n                  num_target_bit_errors=2000, # stop sim after 2000 bit errors\n                  legend=\"Trained\",\n                  max_mc_iter=mc_iters,\n                  soft_estimates=True);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      1.0 | 9.0730e-02 | 9.9600e-01 |        5716 |       63000 |          996 |        1000 |         0.2 |reached target bit errors\n      1.5 | 7.8889e-02 | 9.8400e-01 |        4970 |       63000 |          984 |        1000 |         0.1 |reached target bit errors\n      2.0 | 6.6365e-02 | 9.2500e-01 |        4181 |       63000 |          925 |        1000 |         0.1 |reached target bit errors\n      2.5 | 4.9825e-02 | 8.2000e-01 |        3139 |       63000 |          820 |        1000 |         0.1 |reached target bit errors\n      3.0 | 3.6603e-02 | 6.4400e-01 |        2306 |       63000 |          644 |        1000 |         0.1 |reached target bit errors\n      3.5 | 2.2302e-02 | 4.2000e-01 |        2810 |      126000 |          840 |        2000 |         0.3 |reached target bit errors\n      4.0 | 1.2577e-02 | 2.4400e-01 |        2377 |      189000 |          732 |        3000 |         0.5 |reached target bit errors\n      4.5 | 6.5778e-03 | 1.3460e-01 |        2072 |      315000 |          673 |        5000 |         0.7 |reached target bit errors\n      5.0 | 2.9769e-03 | 6.2818e-02 |        2063 |      693000 |          691 |       11000 |         1.7 |reached target bit errors\n      5.5 | 1.3287e-03 | 2.9667e-02 |        2009 |     1512000 |          712 |       24000 |         3.6 |reached target bit errors\n      6.0 | 5.2511e-04 | 1.2967e-02 |        2018 |     3843000 |          791 |       61000 |         9.2 |reached target bit errors\n      6.5 | 2.0333e-04 | 5.6000e-03 |        1281 |     6300000 |          560 |      100000 |        15.0 |reached max iter\n```"
"## Further Experiments\n\nYou will now see that the memory footprint can be drastically reduced by using the same weight for all messages. In the second part we will apply the concept to the 5G LDPC codes."
"### Damped BP\n\nIt is well-known that scaling of LLRs / messages can help to improve the performance of BP decoding in some scenarios [3,4]. In particular, this works well for very short codes such as the code we are currently analyzing.\n\nWe now follow the basic idea of [2] and scale all weights with the same scalar.\n\n\n```python\n# get weights of trained model\nweights_bp = model.decoder.get_weights()\n# calc mean value of weights\ndamping_factor = tf.reduce_mean(weights_bp)\n# set all weights to the SAME constant scaling\nweights_damped = tf.ones_like(weights_bp) * damping_factor\n# and apply the new weights\nmodel.decoder.set_weights(weights_damped)\n# let us have look at the new weights again\nmodel.decoder.show_weights()\n# and simulate the BER again\nleg_str = f\"Damped BP (scaling factor {damping_factor.numpy():.3f})\"\nber_plot.simulate(model,\n                  ebno_dbs=ebno_dbs,\n                  batch_size=1000,\n                  num_target_bit_errors=2000, # stop sim after 2000 bit errors\n                  legend=leg_str,\n                  max_mc_iter=mc_iters,\n                  soft_estimates=True);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      1.0 | 9.0333e-02 | 9.9500e-01 |        5691 |       63000 |          995 |        1000 |         0.2 |reached target bit errors\n      1.5 | 7.6413e-02 | 9.7800e-01 |        4814 |       63000 |          978 |        1000 |         0.2 |reached target bit errors\n      2.0 | 6.1556e-02 | 8.9800e-01 |        3878 |       63000 |          898 |        1000 |         0.1 |reached target bit errors\n      2.5 | 4.8746e-02 | 7.9700e-01 |        3071 |       63000 |          797 |        1000 |         0.2 |reached target bit errors\n      3.0 | 3.5746e-02 | 6.0800e-01 |        2252 |       63000 |          608 |        1000 |         0.1 |reached target bit errors\n      3.5 | 2.0857e-02 | 3.7950e-01 |        2628 |      126000 |          759 |        2000 |         0.3 |reached target bit errors\n      4.0 | 1.2222e-02 | 2.3433e-01 |        2310 |      189000 |          703 |        3000 |         0.5 |reached target bit errors\n      4.5 | 6.4524e-03 | 1.2967e-01 |        2439 |      378000 |          778 |        6000 |         0.9 |reached target bit errors\n      5.0 | 2.7712e-03 | 5.8667e-02 |        2095 |      756000 |          704 |       12000 |         1.8 |reached target bit errors\n      5.5 | 1.2844e-03 | 2.8960e-02 |        2023 |     1575000 |          724 |       25000 |         3.7 |reached target bit errors\n      6.0 | 5.0743e-04 | 1.2032e-02 |        2014 |     3969000 |          758 |       63000 |         9.5 |reached target bit errors\n      6.5 | 2.1730e-04 | 5.5200e-03 |        1369 |     6300000 |          552 |      100000 |        15.2 |reached max iter\n```"
"When looking at the results, we observe almost the same performance although we only scale by a single scalar. This implies that the number of weights of our model is by far too large and the memory footprint could be reduced significantly. However, isnt it fascinating to see that this simple concept of weighted BP leads to the same results as the concept of *damped BP*?\n\n**Note**: for more iterations it could be beneficial to implement an individual damping per iteration."
"### Learning the 5G LDPC Code\n\nIn this Section, you will experience what happens if we apply the same concept to the 5G LDPC code (including rate matching).\n\nFor this, we need to define a new model.\n\n\n```python\nclass WeightedBP5G(tf.keras.Model):\n    \"\"\"System model for BER simulations of weighted BP decoding for 5G instruction_answer codes.\n    This model uses `GaussianPriorSource` to mimic the LLRs after demapping of\n    QPSK symbols transmitted over an AWGN channel.\n    Parameters\n    ----------\n        k: int\n            Number of information bits per codeword.\n        n: int\n            Codeword length.\n        num_iter: int\n            Number of BP decoding iterations.\n    Input\n    -----\n        batch_size: int or tf.int\n            The batch_size used for the simulation.\n        ebno_db: float or tf.float\n            A float defining the simulation SNR.\n    Output\n    ------\n        (u, u_hat, loss):\n            Tuple:\n        u: tf.float32\n            A tensor of shape `[batch_size, k] of 0s and 1s containing the transmitted information bits.\n        u_hat: tf.float32\n            A tensor of shape `[batch_size, k] of 0s and 1s containing the estimated information bits.\n        loss: tf.float32\n            Binary cross-entropy loss between `u` and `u_hat`.\n    \"\"\"\n    def __init__(self, k, n, num_iter=20):\n        super().__init__()\n        # we need to initialize an encoder for the 5G parameters\n        self.encoder = LDPC5GEncoder(k, n)\n        self.decoder = LDPC5GDecoder(self.encoder,\n                                     num_iter=1, # iterations are done via outer loop (to access intermediate results for multi-loss)\n                                     stateful=True,\n                                     hard_out=False,\n                                     cn_type=\"boxplus\",\n                                     trainable=True)\n        self.llr_source = GaussianPriorSource()\n        self._num_iter = num_iter\n        self._coderate = k/n\n        self._bce = BinaryCrossentropy(from_logits=True)\n    def call(self, batch_size, ebno_db):\n        noise_var = ebnodb2no(ebno_db,\n                              num_bits_per_symbol=2, # QPSK\n                              coderate=self._coderate)\n        # BPSK modulated all-zero CW\n        c = tf.zeros([batch_size, k]) # decoder only returns info bits\n        # use fake llrs from GA\n        # works as BP is symmetric\n        llr = self.llr_source([[batch_size, n], noise_var])\n        # --- implement multi-loss is proposed by Nachmani et al. ---\n        loss = 0\n        msg_vn = None\n        for i in range(self._num_iter):\n            c_hat, msg_vn = self.decoder((llr, msg_vn)) # perform one decoding iteration; decoder returns soft-values\n            loss += self._bce(c, c_hat)  # add loss after each iteration\n        return c, c_hat, loss\n```"
"```python\n# generate model\nnum_iter = 10\nk = 400\nn = 800\nmodel5G = WeightedBP5G(k, n, num_iter=num_iter)\n# generate baseline BER\nebno_dbs = np.array(np.arange(0, 4, 0.25))\nmc_iters = 100 # number of monte carlo iterations\nber_plot_5G = PlotBER(\"Weighted BP for 5G instruction_answer\")\n# simulate the untrained performance\nber_plot_5G.simulate(model5G,\n                     ebno_dbs=ebno_dbs,\n                     batch_size=1000,\n                     num_target_bit_errors=2000, # stop sim after 2000 bit errors\n                     legend=\"Untrained\",\n                     soft_estimates=True,\n                     max_mc_iter=mc_iters);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 1.6660e-01 | 1.0000e+00 |       66640 |      400000 |         1000 |        1000 |         0.2 |reached target bit errors\n     0.25 | 1.4864e-01 | 1.0000e+00 |       59455 |      400000 |         1000 |        1000 |         0.2 |reached target bit errors\n      0.5 | 1.2470e-01 | 9.9700e-01 |       49880 |      400000 |          997 |        1000 |         0.2 |reached target bit errors\n     0.75 | 9.4408e-02 | 9.8000e-01 |       37763 |      400000 |          980 |        1000 |         0.2 |reached target bit errors\n      1.0 | 6.6635e-02 | 9.3900e-01 |       26654 |      400000 |          939 |        1000 |         0.2 |reached target bit errors\n     1.25 | 4.1078e-02 | 8.1100e-01 |       16431 |      400000 |          811 |        1000 |         0.2 |reached target bit errors\n      1.5 | 2.1237e-02 | 6.1200e-01 |        8495 |      400000 |          612 |        1000 |         0.2 |reached target bit errors\n     1.75 | 9.2050e-03 | 3.7600e-01 |        3682 |      400000 |          376 |        1000 |         0.2 |reached target bit errors\n      2.0 | 2.7175e-03 | 1.7050e-01 |        2174 |      800000 |          341 |        2000 |         0.5 |reached target bit errors\n     2.25 | 8.8167e-04 | 6.3833e-02 |        2116 |     2400000 |          383 |        6000 |         1.5 |reached target bit errors\n      2.5 | 2.1781e-04 | 2.1875e-02 |        2091 |     9600000 |          525 |       24000 |         5.9 |reached target bit errors\n     2.75 | 4.2950e-05 | 4.9600e-03 |        1718 |    40000000 |          496 |      100000 |        24.5 |reached max iter\n      3.0 | 6.8000e-06 | 9.1000e-04 |         272 |    40000000 |           91 |      100000 |        24.5 |reached max iter\n     3.25 | 9.2500e-07 | 1.8000e-04 |          37 |    40000000 |           18 |      100000 |        24.5 |reached max iter\n      3.5 | 2.5000e-08 | 1.0000e-05 |           1 |    40000000 |            1 |      100000 |        24.5 |reached max iter\n     3.75 | 0.0000e+00 | 0.0000e+00 |           0 |    40000000 |            0 |      100000 |        24.1 |reached max iter\nSimulation stopped as no error occurred @ EbNo = 3.8 dB.\n\n```"
"And lets train this new model.\n\n\n```python\n# training parameters\nbatch_size = 1000\ntrain_iter = 200\nclip_value_grad = 10 # gradient clipping seems to be important\n# smaller training SNR as the new code is longer (=stronger) than before\nebno_db = 1.5 # rule of thumb: train at ber = 1e-2\n# only used as metric\nbmi = BitwiseMutualInformation()\n# try also different optimizers or different hyperparameters\noptimizer = tf.keras.optimizers.Adam(learning_rate=1e-2)\n# and let's go\nfor it in range(0, train_iter):\n    with tf.GradientTape() as tape:\n        b, llr, loss = model5G(batch_size, ebno_db)\n    grads = tape.gradient(loss, model5G.trainable_variables)\n    grads = tf.clip_by_value(grads, -clip_value_grad, clip_value_grad, name=None)\n    optimizer.apply_gradients(zip(grads, model5G.trainable_weights))\n    # calculate and print intermediate metrics\n    if it%10==0:\n        # calculate ber\n        b_hat = hard_decisions(llr)\n        ber = compute_ber(b, b_hat)\n        # and print results\n        mi = bmi(b, llr).numpy()\n        l = loss.numpy()\n        print(f\"Current loss: {l:3f} ber: {ber:.4f} bmi: {mi:.3f}\".format())\n        bmi.reset_states()\n```\n\n\n```python\nCurrent loss: 1.708751 ber: 0.0204 bmi: 0.925\nCurrent loss: 1.745474 ber: 0.0219 bmi: 0.918\nCurrent loss: 1.741312 ber: 0.0224 bmi: 0.917\nCurrent loss: 1.707712 ber: 0.0208 bmi: 0.923\nCurrent loss: 1.705274 ber: 0.0209 bmi: 0.923\nCurrent loss: 1.706761 ber: 0.0211 bmi: 0.922\nCurrent loss: 1.711995 ber: 0.0212 bmi: 0.921\nCurrent loss: 1.729707 ber: 0.0223 bmi: 0.917\nCurrent loss: 1.692947 ber: 0.0205 bmi: 0.924\nCurrent loss: 1.703924 ber: 0.0203 bmi: 0.924\nCurrent loss: 1.743640 ber: 0.0220 bmi: 0.919\nCurrent loss: 1.719159 ber: 0.0220 bmi: 0.919\nCurrent loss: 1.728399 ber: 0.0221 bmi: 0.920\nCurrent loss: 1.717423 ber: 0.0211 bmi: 0.922\nCurrent loss: 1.743661 ber: 0.0225 bmi: 0.918\nCurrent loss: 1.704675 ber: 0.0212 bmi: 0.923\nCurrent loss: 1.690425 ber: 0.0206 bmi: 0.924\nCurrent loss: 1.728023 ber: 0.0212 bmi: 0.922\nCurrent loss: 1.724549 ber: 0.0212 bmi: 0.922\nCurrent loss: 1.739966 ber: 0.0224 bmi: 0.917\n```"
"We now simulate the new results and compare it to the untrained results.\n\n\n```python\nebno_dbs = np.array(np.arange(0, 4, 0.25))\nbatch_size = 1000\nmc_iters = 100\nber_plot_5G.simulate(model5G,\n                     ebno_dbs=ebno_dbs,\n                     batch_size=batch_size,\n                     num_target_bit_errors=2000, # stop sim after 2000 bit errors\n                     legend=\"Trained\",\n                     max_mc_iter=mc_iters,\n                     soft_estimates=True);\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n      0.0 | 1.6568e-01 | 1.0000e+00 |       66273 |      400000 |         1000 |        1000 |         0.2 |reached target bit errors\n     0.25 | 1.4965e-01 | 9.9900e-01 |       59858 |      400000 |          999 |        1000 |         0.2 |reached target bit errors\n      0.5 | 1.2336e-01 | 9.9900e-01 |       49342 |      400000 |          999 |        1000 |         0.2 |reached target bit errors\n     0.75 | 9.6135e-02 | 9.9100e-01 |       38454 |      400000 |          991 |        1000 |         0.3 |reached target bit errors\n      1.0 | 6.8543e-02 | 9.4500e-01 |       27417 |      400000 |          945 |        1000 |         0.2 |reached target bit errors\n     1.25 | 3.9152e-02 | 8.3300e-01 |       15661 |      400000 |          833 |        1000 |         0.2 |reached target bit errors\n      1.5 | 2.2040e-02 | 6.2400e-01 |        8816 |      400000 |          624 |        1000 |         0.2 |reached target bit errors\n     1.75 | 9.1300e-03 | 3.8400e-01 |        3652 |      400000 |          384 |        1000 |         0.2 |reached target bit errors\n      2.0 | 2.8075e-03 | 1.6600e-01 |        2246 |      800000 |          332 |        2000 |         0.5 |reached target bit errors\n     2.25 | 8.5500e-04 | 6.2000e-02 |        2052 |     2400000 |          372 |        6000 |         1.4 |reached target bit errors\n      2.5 | 1.9837e-04 | 2.1115e-02 |        2063 |    10400000 |          549 |       26000 |         6.3 |reached target bit errors\n     2.75 | 2.9600e-05 | 4.1000e-03 |        1184 |    40000000 |          410 |      100000 |        24.3 |reached max iter\n      3.0 | 6.5750e-06 | 9.1000e-04 |         263 |    40000000 |           91 |      100000 |        24.3 |reached max iter\n     3.25 | 5.5000e-07 | 1.4000e-04 |          22 |    40000000 |           14 |      100000 |        24.3 |reached max iter\n      3.5 | 7.5000e-08 | 3.0000e-05 |           3 |    40000000 |            3 |      100000 |        24.5 |reached max iter\n     3.75 | 2.5000e-08 | 1.0000e-05 |           1 |    40000000 |            1 |      100000 |        24.3 |reached max iter\n```"
"Unfortunately, we observe only very minor gains for the 5G LDPC code. We empirically observed that gain vanishes for more iterations and longer codewords, i.e., for most practical use-cases of the 5G LDPC code the gains are only minor.\n\nHowever, there may be other `codes` `on` `graphs` that benefit from the principle idea of weighted BP - or other channel setups? Feel free to adjust this notebook and train for your favorite code / channel.\n\nOther ideas for own experiments:\n\n- Implement weighted BP with unique weights per iteration.\n- Apply the concept to (scaled) min-sum decoding as in [5].\n- Can you replace the complete CN update by a neural network?\n- Verify the results from all-zero simulations for a *real* system simulation with explicit encoder and random data\n- What happens in combination with higher order modulation?"
"## References\n\n[1]E. Nachmani, Y. Beery and D. Burshtein, Learning to Decode Linear Codes Using Deep Learning, IEEE Annual Allerton Conference on Communication, Control, and Computing (Allerton), pp.341-346., 2016. [https://arxiv.org/pdf/1607.04793.pdf](https://arxiv.org/pdf/1607.04793.pdf)\n\n[2] M. Lian, C. Hger, and H. Pfister, What can machine learning teach us about communications? IEEE Information Theory Workshop (ITW), pp.1-5. 2018.\n\n[3] ] M. Pretti, A message passing algorithm with damping, J. Statist. Mech.: Theory Practice, p.11008, Nov.2005.\n\n[4] J.S. Yedidia, W.T. Freeman and Y. Weiss, Constructing free energy approximations and Generalized Belief Propagation algorithms, IEEE Transactions on Information Theory, 2005.\n\n[5] E. Nachmani, E. Marciano, L. Lugosch, W. Gross, D. Burshtein and Y. Beery, Deep learning methods for improved decoding of linear codes, IEEE Journal of Selected Topics in Signal Processing, vol.12, no. 1, pp.119-131, 2018.\n[5] E. Nachmani, E. Marciano, L. Lugosch, W. Gross, D. Burshtein and Y. Beery, Deep learning methods for improved decoding of linear codes, IEEE Journal of Selected Topics in Signal Processing, vol.12, no. 1, pp.119-131, 2018.\n[5] E. Nachmani, E. Marciano, L. Lugosch, W. Gross, D. Burshtein and Y. Beery, Deep learning methods for improved decoding of linear codes, IEEE Journal of Selected Topics in Signal Processing, vol.12, no. 1, pp.119-131, 2018."
"# Introduction to Sionna RT\n\nIn this notebook, you will\n\n- Discover the basic functionalities of Sionnas [ray tracing (RT) module](https://nvlabs.github.io/sionna/api/rt.html)\n- Learn how to compute coverage maps\n- Use ray-traced channels for link-level simulations instead of stochastic channel models"
"## GPU Configuration and Imports\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Colab does currently not support the latest version of ipython.\n# Thus, the preview does not work in Colab. However, whenever possible we\n# strongly recommend to use the scene preview mode.\ntry: # detect if the notebook runs in Colab\n    import google.colab\n    colab_compat = True # deactivate preview\nexcept:\n    colab_compat = False\nresolution = [480,320] # increase for higher quality of renderings\n# Allows to exit cell execution in Jupyter\nclass ExitCell(Exception):\n    def _render_traceback_(self):\n        pass\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n# For more details, see https://www.tensorflow.org/guide/gpu\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\ntf.random.set_seed(1) # Set global random seed for reproducibility\n\n```\n\n```python\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\n# Import Sionna RT components\nfrom sionna.rt import load_scene, Transmitter, Receiver, PlanarArray, Camera\n# For link-level simulations\nfrom sionna.channel import cir_to_ofdm_channel, subcarrier_frequencies, OFDMChannel, ApplyOFDMChannel, CIRDataset\nfrom sionna.nr import PUSCHConfig, PUSCHTransmitter, PUSCHReceiver\nfrom sionna.utils import compute_ber, ebnodb2no, PlotBER\nfrom sionna.ofdm import KBestDetector, LinearDetector\nfrom sionna.mimo import StreamManagement\n\n```"
"## Background Information\n\nRay tracing is a technique to simulate environment-specific and physically accurate channel realizations for a given scene and user position. Please see the [EM Primer](https://nvlabs.github.io/sionna/em_primer.html) for further details on the theoretical background of ray tracing of wireless channels.\n\nSionna RT is a ray tracing extension for radio propagation modeling which is built on top of [Mitsuba 3](https://www.mitsuba-renderer.org/) and [TensorFlow](https://www.tensorflow.org/). Like all of Sionnas components, it is differentiable.\n\nMitsuba 3 is a rendering system for forward and inverse light-transport simulation that makes use of the differentiable just-in-time compiler [Dr.Jit](https://drjit.readthedocs.io/en/latest/). Sionna RT relies on Mitsuba 3 for the rendering and handling of scenes, e.g., its XML-file format, as well as the computation of ray intersections with scene primitives, i.e., triangles forming a mesh. The transformations of the polarized field components at each point of interaction between a ray and a\nscene object, e.g., reflection, are computed in TensorFlow, which is also used to combine the retained paths into (optionally) time-varying channel impulse responses. Thanks to TensorFlows automatic gradient computation, channel impulse responses and functions thereof are differentiable with respect to most parameters of the ray tracing process, including material properties (conductivity, permittivity), antenna patterns, orientations, and positions.\n\nScene files for Mitsuba 3 can be created, edited, and exported with the popular open-source 3D creation suite [Blender](https://www.blender.org/) and the [Mitsuba-Blender add-on](https://github.com/mitsuba-renderer/mitsuba-blender). One can rapdily create scenes from almost any place in the world using [OpenStreetMap](https://www.openstreetmap.org/) and the [Blender-OSM add-on](https://prochitecture.gumroad.com/l/blender-osm). In Sionna, scenes and radio propagation paths can be\neither rendered through the lens of configurable cameras via ray tracing or displayed with an integrated 3D viewer. For more detail on scene creation and rendering, we refer to [Sionnas API documentation](https://nvlabs.github.io/sionna/api/rt.html) and the available [video tutorial](https://youtu.be/7xHLDxUaQ7c)."
"## Loading Scenes\n\nThe Sionna RT module can either load external scene files (in Mitsubas XML file format) or it can load one of the [integrated scenes](https://nvlabs.github.io/sionna/api/rt.html#example-scenes).\n\nIn this example, we load an example scene containing the area around the Frauenkirche in Munich, Germany.\n\n\n```python\n# Load integrated scene\nscene = load_scene(sionna.rt.scene.munich) # Try also sionna.rt.scene.etoile\n\n```\n\n\nTo visualize the scene, we can use the `preview` function which opens an interactive preview of the scene. This only works in Jupyter notebooks.\n\nYou can use the following controls:\n\n- Mouse left: Rotate\n- Scroll wheel: Zoom\n- Mouse right: Move\n\n\nPlease note that the preview does not work in Colab and is therefore deactivated when `colab_compat` is set to True. Further, only one preview instance can be open at the same time.\n\n\n```python\n # Open 3D preview (only works in Jupyter notebook)\nif colab_compat:\n    scene.render(camera=\"scene-cam-0\", num_samples=512);\n    raise ExitCell\nscene.preview()\n\n```\n\n\nIt is often convenient to choose a viewpoint in the 3D preview prior to rendering it as a high-quality image. The next cell uses the preview camera which corresponds to the viewpoint of the current preview image.\n\n\n```python\n# The preview camera can be directly rendered as high-quality image\nif not colab_compat:\n    scene.render(camera=\"preview\", num_samples=512);\nelse:\n    print(\"Function not available in Colab mode.\")\n\n```\n\n\n```python\nFunction not available in Colab mode.\n```\n\n\nOne can also render the image to a file as shown below:\n\n\n```python\nrender_to_file = False # Set to True to render image to file\n# Render scene to file from preview viewpoint\nif render_to_file:\n    scene.render_to_file(camera=\"scene-cam-0\", # Also try camera=\"preview\"\n                         filename=\"scene.png\",\n                         resolution=[650,500])\n\n```\n\n\nInstead of the preview camera, one can also specify dedicated cameras with different positions and `look_at` directions.\n\n\n```python\n# Create new camera with different configuration\nmy_cam = Camera(\"my_cam\", position=[-250,250,150], look_at=[-15,30,28])\nscene.add(my_cam)\n# Render scene with new camera*\nscene.render(\"my_cam\", resolution=resolution, num_samples=512); # Increase num_samples to increase image quality\n\n```"
"Note that each [SceneObject](https://nvlabs.github.io/sionna/api/rt.html#scene-objects) (camera, transmitter,) needs a unique name. Thus, running the cells above multiple times will lead to an error if the object name is not changed or the object is not removed from the scene."
"## Ray Tracing for Radio Propagation\n\nWe need to configure transmitters and receivers prior to computing propagation paths between them. All transmitters and all receivers are equipped with the same antenna arrays which are defined by the `scene` properties `scene.tx_array` and `scene.rx_array`, respectively. Antenna arrays are composed of multiple identical antennas. Antennas can have custom or pre-defined patterns and are either single- or dual-polarized. One can add multiple transmitters and receivers to a scene which need\nto have unique names, a position, and orientation which is defined by yaw, pitch, and roll angles.\n\n\n```python\n# Configure antenna array for all transmitters\nscene.tx_array = PlanarArray(num_rows=1,\n                             num_cols=1,\n                             vertical_spacing=0.5,\n                             horizontal_spacing=0.5,\n                             pattern=\"tr38901\",\n                             polarization=\"V\")\n# Configure antenna array for all receivers\nscene.rx_array = PlanarArray(num_rows=1,\n                             num_cols=1,\n                             vertical_spacing=0.5,\n                             horizontal_spacing=0.5,\n                             pattern=\"dipole\",\n                             polarization=\"cross\")\n# Create transmitter\ntx = Transmitter(name=\"tx\",\n                 position=[8.5,21,27])\n# Add transmitter instance to scene\nscene.add(tx)\n# Create a receiver\nrx = Receiver(name=\"rx\",\n              position=[45,90,1.5],\n              orientation=[0,0,0])\n# Add receiver instance to scene\nscene.add(rx)\ntx.look_at(rx) # Transmitter points towards receiver\n\n```\n\n\nEach [SceneObject](https://nvlabs.github.io/sionna/api/rt.html#scene-objects) has an assigned [RadioMaterial](https://nvlabs.github.io/sionna/api/rt.html#radio-materials) that describes the electromagnetic properties of the object whenever it interacts with a ray. This behavior can be frequency-dependent and the ray tracing is done for a specific frequency.\n\nWe now set the carrier frequency of the scene and implicitly update all RadioMaterials.\n\n\n```python\nscene.frequency = 2.14e9 # in Hz; implicitly updates RadioMaterials\nscene.synthetic_array = True # If set to False, ray tracing will be done per antenna element (slower for large arrays)\n\n```\n\n\nThe default scenes have RadioMaterials assigned to each scene object. However, the RadioMaterial of a specific object can be modified and customized by the user."
"```python\n# Select an example object from the scene\nso = scene.get(\"Altes_Rathaus-itu_marble\")\n# Print name of assigned radio material for different frequenies\nfor f in [3.5e9, 2.14e9]: # Print for differrent frequencies\n    scene.frequency = f\n    print(f\"\\nRadioMaterial: {so.radio_material.name} @ {scene.frequency/1e9:.2f}GHz\")\n    print(\"Conductivity:\", so.radio_material.conductivity.numpy())\n    print(\"Relative permittivity:\", so.radio_material.relative_permittivity.numpy())\n    print(\"Complex relative permittivity:\", so.radio_material.complex_relative_permittivity.numpy())\n    print(\"Relative permeability:\", so.radio_material.relative_permeability.numpy())\n    print(\"Scattering coefficient:\", so.radio_material.scattering_coefficient.numpy())\n    print(\"XPD coefficient:\", so.radio_material.xpd_coefficient.numpy())\n\n```\n\n\n```python\n\nRadioMaterial: itu_marble @ 3.50GHz\nConductivity: 0.017550057\nRelative permittivity: 7.074\nComplex relative permittivity: (7.074-0.090132594j)\nRelative permeability: 1.0\nScattering coefficient: 0.0\nXPD coefficient: 0.0\nRadioMaterial: itu_marble @ 2.14GHz\nConductivity: 0.0111273555\nRelative permittivity: 7.074\nComplex relative permittivity: (7.074-0.09346512j)\nRelative permeability: 1.0\nScattering coefficient: 0.0\nXPD coefficient: 0.0\n```\n\n\nLet us run the ray tracing process and compute propagation paths between all transmitters and receivers. The parameter `max_depth` determines the maximum number of interactions between a ray and a scene objects. For example, with a `max_depth` of one, only LoS paths are considered. When the property `scene.synthetic_array` is set to `True`, antenna arrays are explicitly modeled by finding paths between any pair of transmitting and receiving antennas in the scene. Otherwise, arrays are\nrepresented by a single antenna located in the center of the array. Phase shifts related to the relative antenna positions will then be applied based on a plane-wave assumption when the channel impulse responses are computed.\n\n\n```python\n# Compute propagation paths\npaths = scene.compute_paths(max_depth=5,\n                            num_samples=1e6)  # Number of rays shot into directions defined\n                                              # by a Fibonacci sphere , too few rays can\n                                              # lead to missing paths\n# Visualize paths in the 3D preview\nif colab_compat:\n    scene.render(\"my_cam\", paths=paths, show_devices=True, show_paths=True, resolution=resolution);\n    raise ExitCell\nscene.preview(paths, show_devices=True, show_paths=True) # Use the mouse to focus on the visualized paths\n\n```"
"*Remark*: only one preview instance can be opened at the same time. Please check the previous preview if no output appears.\n\nThe [Paths](https://nvlabs.github.io/sionna/api/rt.html#paths) object contains all paths that have been found between transmitters and receivers. In principle, the existence of each path is determininistic for a given position and environment. Please note that due to the stochastic nature of the *shoot-and-bounce* algorithm, different runs of the `compute_paths` function can lead to different paths that are found. Most importantly, diffusely reflected or scattered paths are obtained through\nrandom sampling of directions after each interaction with a scene object. You can seet TensorFlows random seed to a specific value before executing `compute_paths` to ensure reproducibility.\n\nThe Paths object contains detailed information about every found path and allows us to generated channel impulse responses and apply Doppler shifts for the simulation of time evolution.\n\nLet us now inspect some of the available properties:\n\n\n```python\n# Show the coordinates of the starting points of all rays.\n# These coincide with the location of the transmitters.\nprint(\"Source coordinates: \", paths.sources.numpy())\nprint(\"Transmitter coordinates: \", list(scene.transmitters.values())[0].position.numpy())\n# Show the coordinates of the endpoints of all rays.\n# These coincide with the location of the receivers.\nprint(\"Target coordinates: \",paths.targets.numpy())\nprint(\"Receiver coordinates: \",list(scene.receivers.values())[0].position.numpy())\n# Show the types of all paths:\n# 0 - LoS, 1 - Reflected, 2 - Diffracted, 3 - Scattered\n# Note that Diffraction and scattering are turned off by default.\nprint(\"Path types: \", paths.types.numpy())\n\n```\n\n\n```python\nSource coordinates:  [[ 8.5 21.  27. ]]\nTransmitter coordinates:  [ 8.5 21.  27. ]\nTarget coordinates:  [[45.  90.   1.5]]\nReceiver coordinates:  [45.  90.   1.5]\nPath types:  [[0 1 1 1 1 1 1 1 1 1 1 1 1]]\n```\n\n\nWe can see from the list of path types, that there are 14 paths in total. One LoS and 13 reflected paths."
"```python\n# We can now access for every path the channel coefficient, the propagation delay,\n# as well as the angles of departure and arrival, respectively (zenith and azimuth).\n# Let us inspect a specific path in detail\npath_idx = 4 # Try out other values in the range [0, 13]\n# For a detailed overview of the dimensions of all properties, have a look at the API documentation\nprint(f\"\\n--- Detailed results for path {path_idx} ---\")\nprint(f\"Channel coefficient: {paths.a[0,0,0,0,0,path_idx, 0].numpy()}\")\nprint(f\"Propagation delay: {paths.tau[0,0,0,path_idx].numpy()*1e6:.5f} us\")\nprint(f\"Zenith angle of departure: {paths.theta_t[0,0,0,path_idx]:.4f} rad\")\nprint(f\"Azimuth angle of departure: {paths.phi_t[0,0,0,path_idx]:.4f} rad\")\nprint(f\"Zenith angle of arrival: {paths.theta_r[0,0,0,path_idx]:.4f} rad\")\nprint(f\"Azimuth angle of arrival: {paths.phi_r[0,0,0,path_idx]:.4f} rad\")\n\n```\n\n\n```python\n\n--- Detailed results for path 4 ---\nChannel coefficient: (4.429778527992312e-06+1.574603736287372e-08j)\nPropagation delay: 0.95107 us\nZenith angle of departure: 1.6485 rad\nAzimuth angle of departure: 0.9691 rad\nZenith angle of arrival: 1.6485 rad\nAzimuth angle of arrival: 0.1625 rad\n```"
"## From Paths to Channel Impulse Responses\n\nOnce paths are computed, they can be transformed into channel impulse responses (CIRs). The class method [apply_doppler](https://nvlabs.github.io/sionna/api/rt.html#Paths.apply_doppler) can simulate time evolution of the CIR based on arbitrary velocity vectors of all transmitters and receivers for a desired sampling frequency and number of time steps. The class method [cir](https://nvlabs.github.io/sionna/api/rt.html#Paths.cir) generates the channel impulse responses which can be used by\nother components for link-level simulations in either time or frequency domains. The method also allows you to only consider certain types of paths, e.g., line-of-sight, reflections, etc.\n\n\n```python\n# Default parameters in the PUSCHConfig\nsubcarrier_spacing = 15e3\nfft_size = 48\n\n```\n\n```python\n# Print shape of channel coefficients before the application of Doppler shifts\n# The last dimension corresponds to the number of time steps which defaults to one\n# as there is no mobility\nprint(\"Shape of `a` before applying Doppler shifts: \", paths.a.shape)\n# Apply Doppler shifts\npaths.apply_doppler(sampling_frequency=subcarrier_spacing, # Set to 15e3 Hz\n                    num_time_steps=14, # Number of OFDM symbols\n                    tx_velocities=[3.,0,0], # We can set additional tx speeds\n                    rx_velocities=[0,7.,0]) # Or rx speeds\nprint(\"Shape of `a` after applying Doppler shifts: \", paths.a.shape)\na, tau = paths.cir()\nprint(\"Shape of tau: \", tau.shape)\n\n```\n\n\n```python\nShape of `a` before applying Doppler shifts:  (1, 1, 2, 1, 1, 13, 1)\nShape of `a` after applying Doppler shifts:  (1, 1, 2, 1, 1, 13, 14)\nShape of tau:  (1, 1, 1, 13)\n```\n\n\nLet us have a look at the channel impulse response for the 14 incoming paths from the simulation above.\n\n\n```python\nt = tau[0,0,0,:]/1e-9 # Scale to ns\na_abs = np.abs(a)[0,0,0,0,0,:,0]\na_max = np.max(a_abs)\n# Add dummy entry at start/end for nicer figure\nt = np.concatenate([(0.,), t, (np.max(t)*1.1,)])\na_abs = np.concatenate([(np.nan,), a_abs, (np.nan,)])\n# And plot the CIR\nplt.figure()\nplt.title(\"Channel impulse response realization\")\nplt.stem(t, a_abs)\nplt.xlim([0, np.max(t)])\nplt.ylim([-2e-6, a_max*1.1])\nplt.xlabel(r\"$\\tau$ [ns]\")\nplt.ylabel(r\"$|a|$\");\n\n```"
"Note that the delay of the first arriving path is normalized to zero. This behavior can be changed using the Paths call property `normalize_delays`. For link-level simulations, it is recommended to work with normalized delays, unless perfect synchronization is explicitly desired.\n\n\n```python\n# Disable normalization of delays\npaths.normalize_delays = False\n# Get only the LoS path\n_, tau = paths.cir(los=True, reflection=False)\nprint(\"Delay of first path without normalization: \", np.squeeze(tau))\npaths.normalize_delays = True\n_, tau = paths.cir(los=True, reflection=False)\nprint(\"Delay of first path with normalization: \", np.squeeze(tau))\n\n```\n\n\n```python\nDelay of first path without normalization:  2.739189e-07\nDelay of first path with normalization:  0.0\n```\n\n\nThe CIRs can now be loaded either in the time-domain or frequency-domain channel models, respectively. Please see [cir_to_ofdm_channel](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.cir_to_ofdm_channel) and [cir_to_time_channel](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.cir_to_time_channel) for further details.\n\n\n```python\n# Compute frequencies of subcarriers and center around carrier frequency\nfrequencies = subcarrier_frequencies(fft_size, subcarrier_spacing)\n# Compute the frequency response of the channel at frequencies.\nh_freq = cir_to_ofdm_channel(frequencies,\n                             a,\n                             tau,\n                             normalize=True) # Non-normalized includes path-loss\n# Verify that the channel power is normalized\nh_avg_power = tf.reduce_mean(tf.abs(h_freq)**2).numpy()\nprint(\"Shape of h_freq: \", h_freq.shape)\nprint(\"Average power h_freq: \", h_avg_power) # Channel is normalized\n\n```\n\n\n```python\nShape of h_freq:  (1, 1, 2, 1, 1, 14, 48)\nAverage power h_freq:  1.0000001\n```\n\n\nThe frequency responses `h_freq` are now ready to be processed by the [ApplyOFDMChannel](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.ApplyOFDMChannel) Layer.\n\n\n```python\n# Placeholder for tx signal of shape\n# [batch size, num_tx, num_tx_ant, num_ofdm_symbols, fft_size]\nx = tf.zeros([h_freq.shape.as_list()[i] for i in [0,3,4,5,6]], tf.complex64)\nno = 0.1 # noise variance\n# Init channel layer\nchannel = ApplyOFDMChannel(add_awgn=True)\n# Apply channel\ny = channel([x, h_freq, no])\n# [batch size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size]\nprint(y.shape)\n\n```"
"## BER Evaluation\n\nWe now initialize a transmitter and receiver from the [5G NR PUSCH Tutorial](https://nvlabs.github.io/sionna/examples/5G_NR_PUSCH.html) notebook. These components could be replaced by your own transceiver implementations. Then we simulate PUSCH transmissions over the ray-traced CIRs that we generated in the previous cells.\n\n\n```python\n# Init pusch_transmitter\npusch_config = PUSCHConfig()\n# Instantiate a PUSCHTransmitter from the PUSCHConfig\npusch_transmitter = PUSCHTransmitter(pusch_config)\n# Create a PUSCHReceiver using the PUSCHTransmitter\npusch_receiver = PUSCHReceiver(pusch_transmitter)\n\n```\n\n```python\n# Simulate transmissions over the\nbatch_size = 100 # h_freq is broadcast, i.e., same CIR for all samples but different AWGN realizations\nebno_db = 2. # SNR in dB\nno = ebnodb2no(ebno_db,\n               pusch_transmitter._num_bits_per_symbol,\n               pusch_transmitter._target_coderate,\n               pusch_transmitter.resource_grid)\nx, b = pusch_transmitter(batch_size) # Generate transmit signal and info bits\ny = channel([x, h_freq, no]) # Simulate channel output\nb_hat = pusch_receiver([y, no]) # Recover the info bits\n# Compute BER\nprint(f\"BER: {compute_ber(b, b_hat).numpy():.5f}\")\n\n```\n\n\n```python\nBER: 0.07575\n```\n\n\n**Remark** Contrary to other Sionna components, ray tracing does not have a dedicated batch dimension. However, multiple transmitter and receivers can be simulated in parallel, which effectively equals a batch-dimension.\n\nNote that simulating multiple receivers in the ray tracer comes at little additional overhead. However, the complexity increases significantly for multiple transmitters as an individual ray tracing step is required for each transmitter. As the total number of rays is fixed, an increased number of transmitter requires also an increased number of rays in the `compute_paths` step for the same overall precision."
"## Runtime vs Depth\n\nWe will now investigate the complexity of the ray tracing algorithm for different values of `max_depth`, i.e., for a different number of bounces of the rays.\n\n\n```python\nmax_depths = 10 # evaluate performance up to 10 reflections\ndepths = range(1,max_depths+1)\nts = []\npl_avg = []\nfor d in depths:\n    # save start time\n    t = time.time()\n    # run the ray tracer\n    paths = scene.compute_paths(max_depth=d)\n    # and measure the required time interval\n    ts.append(time.time()-t)\n\n```\n\n```python\n# and plot results\nplt.figure()\nplt.plot(depths, ts, color=\"b\");\nplt.xlabel(\"Max. depth\")\nplt.ylabel(\"Runtime (s)\", color=\"b\")\nplt.grid(which=\"both\")\nplt.xlim([1, max_depths]);\n\n```\n\n\nAs can be seen, the computational complexity increases significantly with the number of ray interactions. Note that the code above does not account for scattering or diffraction. Adding these phenomea adds additional complexity as can be seen below:\n\n\n```python\nt = time.time()\npaths = scene.compute_paths(max_depth=3, diffraction=False)\nprint(\"Time without diffraction and scattering:\" , time.time()-t)\nt = time.time()\npaths = scene.compute_paths(max_depth=3, diffraction=True)\nprint(\"Time with diffraction:\" , time.time()-t)\nt = time.time()\npaths = scene.compute_paths(max_depth=3, scattering=True)\nprint(\"Time with scattering:\" , time.time()-t)\n\n```\n\n\n```python\nTime without diffraction and scattering: 2.456580400466919\nTime with diffraction: 2.614542245864868\nTime with scattering: 3.055100917816162\n```\n\n\nAlthough we have simulated scattering in the last example above, the scattered paths do not carry any energy as none of the materials in the scene has a positive scattering coefficient. You can learn more about scattering and diffraction in the dedicated [tutorial notebooks](https://nvlabs.github.io/sionna/tutorials.html#ray-tracing)."
"## Coverage Map\n\nSionna RT can be also used to simulate coverage maps for a given environment. We now put a new transmitter on top of the Frauenkirche and simulate a large-scale coverage map.\n\n\n```python\n# Remove old transmitter and add new one\nscene.remove(\"tx\")\ntx = Transmitter(name=\"tx\",\n                 position=[-210,73,105], # top of Frauenkirche\n                 orientation=[0,0,0])\nscene.add(tx)\n# We could have alternatively modified the properties position and orientation of the existing transmitter\n#scene.get(\"tx\").position = [-210,73,105]\n#scene.get(\"tx\").orientation = [0,0,0]\n\n```\n\n\nLets have a look at the new setup. The receiver can be ignored for the coverage map simulation.\n\n\n```python\n # Open 3D preview (only works in Jupyter notebook)\nif colab_compat:\n    scene.render(camera=\"scene-cam-0\", num_samples=512, resolution=resolution);\n    raise ExitCell\nscene.preview()\n\n```\n\n\n```python\ncm = scene.coverage_map(max_depth=5,\n                        diffraction=True, # Disable to see the effects of diffraction\n                        cm_cell_size=(5., 5.), # Grid size of coverage map cells in m\n                        combining_vec=None,\n                        precoding_vec=None,\n                        num_samples=int(20e6)) # Reduce if your hardware does not have enough memory\n\n```\n\n\nOnce simulated, the coverage map object can be directly visualized with the `preview` or `render` function.\n\n\n```python\n# Create new camera\ntx_pos = scene.transmitters[\"tx\"].position.numpy()\nbird_pos = tx_pos.copy()\nbird_pos[-1] = 1000 # Set height of coverage map to 1000m above tx\nbird_pos[-2]-= 0.01 # Slightly move the camera for correct orientation\n# Create new camera\nbird_cam = Camera(\"birds_view\", position=bird_pos, look_at=tx_pos)\nscene.add(bird_cam)\nif colab_compat:\n    scene.render(camera=\"birds_view\", coverage_map=cm, num_samples=512, resolution=resolution);\n    raise ExitCell\n# Open 3D preview (only works in Jupyter notebook)\nscene.preview(coverage_map=cm)\n\n```\n\n\nAlternatively, a 2D visualization of the coverage map can be shown.\n\n\n```python\ncm.show(tx=0); # If multiple transmitters exist, tx selects for which transmitter the cm is shown\n\n```"
"Note that it can happen in rare cases that diffracted rays arrive inside or behind buildings through paths which should not exists. This is not a bug in Sionnas ray tracing algorithm but rather an artefact of the way how scenes are created which can lead to the false detection of diffraction edges."
"## Site-specifc Link-Level Simulations\n\nWe will now use Sionna RT for site-specific link-level simulations. For this, we evaluate the BER performance for a MU-MIMO 5G NR system in the uplink direction based on ray traced CIRs for random user positions.\n\nWe use the 5G NR PUSCH transmitter and receiver from the [5G NR PUSCH Tutorial](https://nvlabs.github.io/sionna/examples/5G_NR_PUSCH.html) notebook. Note that also the systems from the [MIMO OFDM Transmissions over the CDL Channel Model](https://nvlabs.github.io/sionna/examples/MIMO_OFDM_Transmissions_over_CDL.html) or the [Neural Receiver for OFDM SIMO Systems](https://nvlabs.github.io/sionna/examples/Neural_Receiver.html) tutorials could be used instead.\n\nThere are different ways to implement uplink scenarios in Sionna RT. In this example, we configure the basestation as transmitter and the user equipments (UEs) as receivers which simplifies the ray tracing. Due to channel reciprocity, one can *reverse* the direction of the ray traced channels afterwards. For the ray tracer itself, the direction (uplink/downlink) does not change the simulated paths.\n\n*Note*: Running the cells below can take several hours of compute time.\n\n\n```python\n# System parameters\nsubcarrier_spacing = 30e3\nnum_time_steps = 14 # Total number of ofdm symbols per slot\nnum_tx = 4 # Number of users\nnum_rx = 1 # Only one receiver considered\nnum_tx_ant = 4 # Each user has 4 antennas\nnum_rx_ant = 16 # The receiver is equipped with 16 antennas\n# batch_size for CIR generation\nbatch_size_cir = 1000\n\n```\n\n\nLet us add a new transmitter that acts as basestation. We will later use channel reciprocity to simulate the uplink direction.\n\n\n```python\n# Remove old tx from scene\nscene.remove(\"tx\")\nscene.synthetic_array = True # Emulate multiple antennas to reduce ray tracing complexity\n# Transmitter (=basestation) has an antenna pattern from 3GPP 38.901\nscene.tx_array = PlanarArray(num_rows=1,\n                             num_cols=int(num_rx_ant/2), # We want to transmitter to be equiped with the 16 rx antennas\n                             vertical_spacing=0.5,\n                             horizontal_spacing=0.5,\n                             pattern=\"tr38901\",\n                             polarization=\"cross\")\n# Create transmitter\ntx = Transmitter(name=\"tx\",\n                 position=[8.5,21,27],\n                 look_at=[45,90,1.5]) # optional, defines view direction\nscene.add(tx)\n\n```"
"We now need to update the coverage map for the new transmitter.\n\n\n```python\nmax_depth = 5 # Defines max number of ray interactions\n# Update coverage_map\ncm = scene.coverage_map(max_depth=max_depth,\n                        diffraction=True,\n                        cm_cell_size=(1., 1.),\n                        combining_vec=None,\n                        precoding_vec=None,\n                        num_samples=int(10e6))\n\n```\n\n\nThe function `sample_positions` allows sampling of random user positions from a coverage map. It ensures that only positions are sampled that have a path gain of at least `min_gain_dB` dB and at most `max_gain_dB` dB, i.e., ignores positions without connection to the transmitter. Further, one can set the distance `min_dist` and `max_dist` to sample only points with a certain distance away from the transmitter.\n\n\n```python\nmin_gain_db = -130 # in dB; ignore any position with less than -130 dB path gain\nmax_gain_db = 0 # in dB; ignore strong paths\n# sample points in a 5-400m radius around the receiver\nmin_dist = 5 # in m\nmax_dist = 400 # in m\n#sample batch_size random user positions from coverage map\nue_pos = cm.sample_positions(batch_size=batch_size_cir,\n                             min_gain_db=min_gain_db,\n                             max_gain_db=max_gain_db,\n                             min_dist=min_dist,\n                             max_dist=max_dist)\n\n```\n\n\nWe now add new receivers (=UEs) at random position.\n\n*Remark*: This is an example for 5G NR PUSCH (uplink direction), we will reverse the direction of the channel for later BER simulations.\n\n\n```python\n# Remove old receivers from scene\nscene.remove(\"rx\")\nfor i in range(batch_size_cir):\n    scene.remove(f\"rx-{i}\")\n# Configure antenna array for all receivers (=UEs)\nscene.rx_array = PlanarArray(num_rows=1,\n                             num_cols=int(num_tx_ant/2), # Each receiver is equipped with 4 tx antennas (uplink)\n                             vertical_spacing=0.5,\n                             horizontal_spacing=0.5,\n                             pattern=\"iso\", # UE orientation is random\n                             polarization=\"cross\")\n# Create batch_size receivers\nfor i in range(batch_size_cir):\n    rx = Receiver(name=f\"rx-{i}\",\n                  position=ue_pos[i], # Random position sampled from coverage map\n                  )\n    scene.add(rx)\n# And visualize the scene\nif colab_compat:\n    scene.render(\"birds_view\", show_devices=True, resolution=resolution);\n    raise ExitCell\nscene.preview(show_devices=True, coverage_map=cm)\n\n```"
"Each dot represents a random receiver position drawn from the random sampling function of the coverage map. This allows to efficiently sample batches of random channel realizations even in complex scenarios.\n\nWe can now simulate the CIRs for many different random positions.\n\n*Remark*: Running the cells below can take some time depending on the requested number of CIRs.\n\n\n```python\ntarget_num_cirs = 5000 # Defines how many different CIRS are generated.\n# Remark: some path are removed if no path was found for this position\nmax_depth = 5\nmin_gain_db = -130 # in dB / ignore any position with less than -130 dB path gain\nmax_gain_db = 0 # in dB / ignore any position with more than 0 dB path gain\n# Sample points within a 10-400m radius around the transmitter\nmin_dist = 10 # in m\nmax_dist = 400 # in m\n# Placeholder to gather channel impulse reponses\na = None\ntau = None\n# Each simulation returns batch_size_cir results\nnum_runs = int(np.ceil(target_num_cirs/batch_size_cir))\nfor idx in range(num_runs):\n    print(f\"Progress: {idx+1}/{num_runs}\", end=\"\\r\")\n    # Sample random user positions\n    ue_pos = cm.sample_positions(\n                        batch_size=batch_size_cir,\n                        min_gain_db=min_gain_db,\n                        max_gain_db=max_gain_db,\n                        min_dist=min_dist,\n                        max_dist=max_dist)\n    # Update all receiver positions\n    for idx in range(batch_size_cir):\n        scene.receivers[f\"rx-{idx}\"].position = ue_pos[idx]\n    # Simulate CIR\n    paths = scene.compute_paths(\n                    max_depth=max_depth,\n                    diffraction=True,\n                    num_samples=1e6) # shared between all tx in a scene\n    # Transform paths into channel impulse responses\n    paths.reverse_direction = True # Convert to uplink direction\n    paths.apply_doppler(sampling_frequency=subcarrier_spacing,\n                        num_time_steps=14,\n                        tx_velocities=[0.,0.,0],\n                        rx_velocities=[3.,3.,0])\n    # We fix here the maximum number of paths to 75 which ensures\n    # that we can simply concatenate different channel impulse reponses\n    a_, tau_ = paths.cir(num_paths=75)\n    del paths # Free memory\n    if a is None:\n        a = a_.numpy()\n        tau = tau_.numpy()\n    else:\n        # Concatenate along the num_tx dimension\n        a = np.concatenate([a, a_], axis=3)\n        tau = np.concatenate([tau, tau_], axis=2)\ndel cm # Free memory\n# Exchange the num_tx and batchsize dimensions\na = np.transpose(a, [3, 1, 2, 0, 4, 5, 6])\ntau = np.transpose(tau, [2, 1, 0, 3])\n# Remove CIRs that have no active link (i.e., a is all-zero)\np_link = np.sum(np.abs(a)**2, axis=(1,2,3,4,5,6))\na = a[p_link>0.,...]\ntau = tau[p_link>0.,...]\nprint(\"Shape of a:\", a.shape)\nprint(\"Shape of tau: \", tau.shape)\n\n```"
"```python\nShape of a: (4858, 1, 16, 1, 4, 75, 14)\nShape of tau:  (4858, 1, 1, 75)\n```\n\n\nNote that transmitter and receiver have been reversed, i.e., the transmitter now denotes the UE (with 4 antennas each) and the receiver is the basestation (with 16 antennas).\n\n*Remark*: We have removed all positions where the resulting CIR was zero, i.e., no path between transmitter and receiver was found. This comes from the fact that the `sample_position` function samples from the quantized coverage map and randomizes the position within the cell. It can happen that for this random position no connection between transmitter and receiver can be found.\n\nLet us now initialize a `data_generator` that samples random UEs from the dataset and *yields* the previously simulated CIRs.\n\n\n```python\nclass CIRGenerator:\n    \"\"\"Creates a generator from a given dataset of channel impulse responses.\n    The generator samples ``num_tx`` different transmitters from the given path\n    coefficients `a` and path delays `tau` and stacks the CIRs into a single tensor.\n    Note that the generator internally samples ``num_tx`` random transmitters\n    from the dataset. For this, the inputs ``a`` and ``tau`` must be given for\n    a single transmitter (i.e., ``num_tx`` =1) which will then be stacked\n    internally.\n    Parameters\n    ----------\n    a : [batch size, num_rx, num_rx_ant, 1, num_tx_ant, num_paths, num_time_steps], complex\n        Path coefficients per transmitter.\n    tau : [batch size, num_rx, 1, num_paths], float\n        Path delays [s] per transmitter.\n    num_tx : int\n        Number of transmitters\n    Output\n    -------\n    a : [batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_paths, num_time_steps], tf.complex\n        Path coefficients\n    tau : [batch size, num_rx, num_tx, num_paths], tf.float\n        Path delays [s]\n    \"\"\"\n    def __init__(self,\n                 a,\n                 tau,\n                 num_tx):\n        # Copy to tensorflow\n        self._a = tf.constant(a, tf.complex64)\n        self._tau = tf.constant(tau, tf.float32)\n        self._dataset_size = self._a.shape[0]\n        self._num_tx = num_tx\n    def __call__(self):\n        # Generator implements an infinite loop that yields new random samples\n        while True:\n            # Sample 4 random users and stack them together\n            idx,_,_ = tf.random.uniform_candidate_sampler(\n                            tf.expand_dims(tf.range(self._dataset_size, dtype=tf.int64), axis=0),\n                            num_true=self._dataset_size,\n                            num_sampled=self._num_tx,\n                            unique=True,\n                            range_max=self._dataset_size)\n            a = tf.gather(self._a, idx)\n            tau = tf.gather(self._tau, idx)\n            # Transpose to remove batch dimension\n            a = tf.transpose(a, (3,1,2,0,4,5,6))\n            tau = tf.transpose(tau, (2,1,0,3))\n            # And remove batch-dimension\n            a = tf.squeeze(a, axis=0)\n            tau = tf.squeeze(tau, axis=0)\n            yield a, tau\n\n```"
"We use Sionnas built-in [CIRDataset](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.CIRDataset) to initialize a channel model that can be directly used in Sionnas [OFDMChannel](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.OFDMChannel) layer.\n\n\n```python\nbatch_size = 20 # Must be the same for the BER simulations as CIRDataset returns fixed batch_size\n# Init CIR generator\ncir_generator = CIRGenerator(a,\n                             tau,\n                             num_tx)\n# Initialises a channel model that can be directly used by OFDMChannel layer\nchannel_model = CIRDataset(cir_generator,\n                           batch_size,\n                           num_rx,\n                           num_rx_ant,\n                           num_tx,\n                           num_tx_ant,\n                           75,\n                           num_time_steps)\n# Delete to free memory\ndel a, tau\n\n```\n\n```python\n# We need to enable sionna.config.xla_compat before we can use\n# tf.function with jit_compile=True.\n# See https://nvlabs.github.io/sionna/api/config.html#sionna.Config.xla_compat\nsionna.config.xla_compat=False # not supported in CIRDataset\nclass Model(tf.keras.Model):\n    \"\"\"Simulate PUSCH transmissions over a 3GPP 38.901 model.\n    This model runs BER simulations for a multi-user MIMO uplink channel\n    compliant with the 5G NR PUSCH specifications.\n    You can pick different scenarios, i.e., channel models, perfect or\n    estimated CSI, as well as different MIMO detectors (LMMSE or KBest).\n    Parameters\n    ----------\n    channel_model : :class:`~sionna.channel.ChannelModel` object\n        An instance of a :class:`~sionna.channel.ChannelModel` object, such as\n        :class:`~sionna.channel.RayleighBlockFading` or\n        :class:`~sionna.channel.tr38901.UMi` or\n        :class:`~sionna.channel.CIRDataset`.\n    perfect_csi : bool\n        Determines if perfect CSI is assumed or if the CSI is estimated\n    detector : str, one of [\"lmmse\", \"kbest\"]\n        MIMO detector to be used. Note that each detector has additional\n        parameters that can be configured in the source code of the _init_ call.\n    Input\n    -----\n    batch_size : int\n        Number of simultaneously simulated slots\n    ebno_db : float\n        Signal-to-noise-ratio\n    Output\n    ------\n    b : [batch_size, num_tx, tb_size], tf.float\n        Transmitted information bits\n    b_hat : [batch_size, num_tx, tb_size], tf.float\n        Decoded information bits\n    \"\"\"\n    def __init__(self,\n                 channel_model,\n                 perfect_csi, # bool\n                 detector,    # \"lmmse\", \"kbest\"\n                ):\n        super().__init__()\n        self._channel_model = channel_model\n        self._perfect_csi = perfect_csi\n        # System configuration\n        self._num_prb = 16\n        self._mcs_index = 14\n        self._num_layers = 1\n        self._mcs_table = 1\n        self._domain = \"freq\"\n        # Below parameters must equal the Path2CIR parameters\n        self._num_tx_ant = 4\n        self._num_tx = 4\n        self._subcarrier_spacing = 30e3 # must be the same as used for Path2CIR\n        # PUSCHConfig for the first transmitter\n        pusch_config = PUSCHConfig()\n        pusch_config.carrier.subcarrier_spacing = self._subcarrier_spacing/1000\n        pusch_config.carrier.n_size_grid = self._num_prb\n        pusch_config.num_antenna_ports = self._num_tx_ant\n        pusch_config.num_layers = self._num_layers\n        pusch_config.precoding = \"codebook\"\n        pusch_config.tpmi = 1\n        pusch_config.dmrs.dmrs_port_set = list(range(self._num_layers))\n        pusch_config.dmrs.config_type = 1\n        pusch_config.dmrs.length = 1\n        pusch_config.dmrs.additional_position = 1\n        pusch_config.dmrs.num_cdm_groups_without_data = 2\n        pusch_config.tb.mcs_index = self._mcs_index\n        pusch_config.tb.mcs_table = self._mcs_table\n        # Create PUSCHConfigs for the other transmitters by cloning of the first PUSCHConfig\n        # and modifying the used DMRS ports.\n        pusch_configs = [pusch_config]\n        for i in range(1, self._num_tx):\n            pc = pusch_config.clone()\n            pc.dmrs.dmrs_port_set = list(range(i*self._num_layers, (i+1)*self._num_layers))\n            pusch_configs.append(pc)\n        # Create PUSCHTransmitter\n        self._pusch_transmitter = PUSCHTransmitter(pusch_configs, output_domain=self._domain)\n        # Create PUSCHReceiver\n        rx_tx_association = np.ones([1, self._num_tx], bool)\n        stream_management = StreamManagement(rx_tx_association,\n                                             self._num_layers)\n        assert detector in[\"lmmse\", \"kbest\"], \"Unsupported MIMO detector\"\n        if detector==\"lmmse\":\n            detector = LinearDetector(equalizer=\"lmmse\",\n                                      output=\"bit\",\n                                      demapping_method=\"maxlog\",\n                                      resource_grid=self._pusch_transmitter.resource_grid,\n                                      stream_management=stream_management,\n                                      constellation_type=\"qam\",\n                                      num_bits_per_symbol=pusch_config.tb.num_bits_per_symbol)\n        elif detector==\"kbest\":\n            detector = KBestDetector(output=\"bit\",\n                                     num_streams=self._num_tx*self._num_layers,\n                                     k=64,\n                                     resource_grid=self._pusch_transmitter.resource_grid,\n                                     stream_management=stream_management,\n                                     constellation_type=\"qam\",\n                                     num_bits_per_symbol=pusch_config.tb.num_bits_per_symbol)\n        if self._perfect_csi:\n            self._pusch_receiver = PUSCHReceiver(self._pusch_transmitter,\n                                                 mimo_detector=detector,\n                                                 input_domain=self._domain,\n                                                 channel_estimator=\"perfect\")\n        else:\n            self._pusch_receiver = PUSCHReceiver(self._pusch_transmitter,\n                                                 mimo_detector=detector,\n                                                 input_domain=self._domain)\n\n        # Configure the actual channel\n        self._channel = OFDMChannel(\n                            self._channel_model,\n                            self._pusch_transmitter.resource_grid,\n                            normalize_channel=True,\n                            return_channel=True)\n    # XLA currently not supported by the CIRDataset function\n    @tf.function(jit_compile=False)\n    def call(self, batch_size, ebno_db):\n        x, b = self._pusch_transmitter(batch_size)\n        no = ebnodb2no(ebno_db,\n                       self._pusch_transmitter._num_bits_per_symbol,\n                       pusch_transmitter._target_coderate,\n                       pusch_transmitter.resource_grid)\n        y, h = self._channel([x, no])\n        if self._perfect_csi:\n            b_hat = self._pusch_receiver([y, h, no])\n        else:\n            b_hat = self._pusch_receiver([y, no])\n        return b, b_hat\n\n```"
"We now initialize the end-to-end model with the `CIRDataset`.\n\n\n```python\nebno_db = 10.\ne2e_model = Model(channel_model,\n                  perfect_csi=False, # bool\n                  detector=\"lmmse\")  # \"lmmse\", \"kbest\"\n# We can draw samples from the end-2-end link-level simulations\nb, b_hat = e2e_model(batch_size, ebno_db)\n\n```\n\n\nAnd lets run the final evaluation for different system configurations.\n\n\n```python\nebno_db = np.arange(-3, 18, 2) # sim SNR range\nber_plot = PlotBER(f\"Site-Specific MU-MIMO 5G NR PUSCH\")\nfor detector in [\"lmmse\", \"kbest\"]:\n    for perf_csi in [True, False]:\n        e2e_model = Model(channel_model,\n                          perfect_csi=perf_csi,\n                          detector=detector)\n        # define legend\n        csi = \"Perf. CSI\" if perf_csi else \"Imperf. CSI\"\n        det = \"K-Best\" if detector==\"kbest\" else \"LMMSE\"\n        l = det + \" \" + csi\n        ber_plot.simulate(\n                    e2e_model,\n                    ebno_dbs=ebno_db, # SNR to simulate\n                    legend=l, # legend string for plotting\n                    max_mc_iter=500,\n                    num_target_block_errors=2000,\n                    batch_size=batch_size, # batch-size per Monte Carlo run\n                    soft_estimates=False, # the model returns hard-estimates\n                    early_stop=True,\n                    show_fig=False,\n                    add_bler=True,\n                    forward_keyboard_interrupt=True);\n\n```\n\n\n```python\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -3.0 | 1.3426e-01 | 9.7500e-01 |     1394056 |    10383360 |         2028 |        2080 |        14.4 |reached target block errors\n     -1.0 | 6.0569e-02 | 5.4375e-01 |     1112682 |    18370560 |         2001 |        3680 |         8.0 |reached target block errors\n      1.0 | 3.0802e-02 | 2.6605e-01 |     1168609 |    37939200 |         2022 |        7600 |        16.3 |reached target block errors\n      3.0 | 1.8333e-02 | 1.4970e-01 |     1222718 |    66693120 |         2000 |       13360 |        28.5 |reached target block errors\n      5.0 | 9.8484e-03 | 8.5119e-02 |     1156321 |   117411840 |         2002 |       23520 |        50.2 |reached target block errors\n      7.0 | 5.7053e-03 | 4.9250e-02 |     1139238 |   199680000 |         1970 |       40000 |        85.2 |reached max iter\n      9.0 | 3.3868e-03 | 2.9075e-02 |      676280 |   199680000 |         1163 |       40000 |        85.3 |reached max iter\n     11.0 | 1.6629e-03 | 1.4825e-02 |      332046 |   199680000 |          593 |       40000 |        85.4 |reached max iter\n     13.0 | 1.0874e-03 | 9.6750e-03 |      217127 |   199680000 |          387 |       40000 |        85.2 |reached max iter\n     15.0 | 5.7423e-04 | 4.8000e-03 |      114662 |   199680000 |          192 |       40000 |        85.1 |reached max iter\n     17.0 | 4.3051e-04 | 3.1000e-03 |       85964 |   199680000 |          124 |       40000 |        85.2 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -3.0 | 2.2992e-01 | 1.0000e+00 |     2295491 |     9984000 |         2000 |        2000 |        14.7 |reached target block errors\n     -1.0 | 1.8111e-01 | 9.9904e-01 |     1880529 |    10383360 |         2078 |        2080 |         4.5 |reached target block errors\n      1.0 | 1.2673e-01 | 9.6346e-01 |     1315935 |    10383360 |         2004 |        2080 |         4.5 |reached target block errors\n      3.0 | 6.2428e-02 | 5.0075e-01 |     1246554 |    19968000 |         2003 |        4000 |         8.7 |reached target block errors\n      5.0 | 3.8155e-02 | 2.9390e-01 |     1310429 |    34344960 |         2022 |        6880 |        14.9 |reached target block errors\n      7.0 | 2.3349e-02 | 1.7764e-01 |     1324110 |    56709120 |         2018 |       11360 |        24.6 |reached target block errors\n      9.0 | 1.4020e-02 | 1.0570e-01 |     1326994 |    94648320 |         2004 |       18960 |        40.9 |reached target block errors\n     11.0 | 8.1793e-03 | 6.2562e-02 |     1306587 |   159744000 |         2002 |       32000 |        69.1 |reached target block errors\n     13.0 | 5.3070e-03 | 4.2200e-02 |     1059697 |   199680000 |         1688 |       40000 |        86.3 |reached max iter\n     15.0 | 3.7709e-03 | 2.9325e-02 |      752975 |   199680000 |         1173 |       40000 |        86.5 |reached max iter\n     17.0 | 2.5822e-03 | 2.0975e-02 |      515618 |   199680000 |          839 |       40000 |        86.4 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -3.0 | 1.4514e-01 | 9.9856e-01 |     1507056 |    10383360 |         2077 |        2080 |        32.2 |reached target block errors\n     -1.0 | 7.4307e-02 | 8.8664e-01 |      860583 |    11581440 |         2057 |        2320 |        23.0 |reached target block errors\n      1.0 | 3.3615e-02 | 3.0241e-01 |     1114221 |    33146880 |         2008 |        6640 |        65.7 |reached target block errors\n      3.0 | 1.5859e-02 | 1.3012e-01 |     1222379 |    77076480 |         2009 |       15440 |       153.0 |reached target block errors\n      5.0 | 6.7793e-03 | 6.0628e-02 |     1120861 |   165335040 |         2008 |       33120 |       328.7 |reached target block errors\n      7.0 | 2.2633e-03 | 2.0250e-02 |      451928 |   199680000 |          810 |       40000 |       398.1 |reached max iter\n      9.0 | 6.0958e-04 | 5.2750e-03 |      121721 |   199680000 |          211 |       40000 |       397.8 |reached max iter\n     11.0 | 2.9266e-04 | 2.0500e-03 |       58438 |   199680000 |           82 |       40000 |       397.2 |reached max iter\n     13.0 | 1.8539e-04 | 1.2000e-03 |       37019 |   199680000 |           48 |       40000 |       396.9 |reached max iter\n     15.0 | 9.1491e-05 | 5.5000e-04 |       18269 |   199680000 |           22 |       40000 |       397.1 |reached max iter\n     17.0 | 5.7602e-05 | 3.7500e-04 |       11502 |   199680000 |           15 |       40000 |       398.1 |reached max iter\nEbNo [dB] |        BER |       BLER |  bit errors |    num bits | block errors |  num blocks | runtime [s] |    status\n---------------------------------------------------------------------------------------------------------------------------------------\n     -3.0 | 2.4055e-01 | 1.0000e+00 |     2401681 |     9984000 |         2000 |        2000 |        31.1 |reached target block errors\n     -1.0 | 1.9379e-01 | 1.0000e+00 |     1934840 |     9984000 |         2000 |        2000 |        20.3 |reached target block errors\n      1.0 | 1.3773e-01 | 9.8846e-01 |     1430079 |    10383360 |         2056 |        2080 |        21.1 |reached target block errors\n      3.0 | 7.0248e-02 | 6.6875e-01 |     1066068 |    15175680 |         2033 |        3040 |        30.9 |reached target block errors\n      5.0 | 3.8589e-02 | 3.0196e-01 |     1279094 |    33146880 |         2005 |        6640 |        67.4 |reached target block errors\n      7.0 | 1.9754e-02 | 1.5022e-01 |     1325339 |    67092480 |         2019 |       13440 |       136.5 |reached target block errors\n      9.0 | 1.0694e-02 | 8.3696e-02 |     1276994 |   119408640 |         2002 |       23920 |       242.5 |reached target block errors\n     11.0 | 5.5038e-03 | 4.2000e-02 |     1099001 |   199680000 |         1680 |       40000 |       405.3 |reached max iter\n     13.0 | 3.0494e-03 | 2.3975e-02 |      608913 |   199680000 |          959 |       40000 |       405.1 |reached max iter\n     15.0 | 2.3187e-03 | 1.8325e-02 |      462991 |   199680000 |          733 |       40000 |       405.3 |reached max iter\n     17.0 | 1.8833e-03 | 1.4850e-02 |      376057 |   199680000 |          594 |       40000 |       404.9 |reached max iter\n```"
"## Conclusion and Outlook\n\nIn this notebook, you have learned how to use the Sionna RT module. We have seen how paths can be found in complex environments such as in the Munich scene. In a second step, we have calculated the effective CIRs from the paths and used them for link-level simulations.\n\nThere is one key feature of Sionna RT that was not discussed in this notebook: Automatic gradient computation. Like most components of Sionna, the ray tracer is differentiable with respect to most system parameters, such as radio materials, transmitter and receiver orientations, array geometries, positions, etc. This enables a whole new line of research which is discussed in the <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/made_with_sionna.html#sionna-rt-differentiable-ray-tracing-for-radio-propagation-modeling\">Sionna RT paper and the related\nnotebooks</a>.\n\nHopefully you have enjoyed this tutorial on Sionnas RT module!\n\nPlease have a look at the [API documentation](https://nvlabs.github.io/sionna/api/sionna.html) of the various components or the other available [tutorials](https://nvlabs.github.io/sionna/tutorials.html) to learn more.\nPlease have a look at the [API documentation](https://nvlabs.github.io/sionna/api/sionna.html) of the various components or the other available [tutorials](https://nvlabs.github.io/sionna/tutorials.html) to learn more.\nPlease have a look at the [API documentation](https://nvlabs.github.io/sionna/api/sionna.html) of the various components or the other available [tutorials](https://nvlabs.github.io/sionna/tutorials.html) to learn more."
"# Mobility in Sionna RT\n\nThis notebook explains different ways in which the effects of mobility can be simulated with Sionnas [ray tracing (RT) module](https://nvlabs.github.io/sionna/api/rt.html). In particular, you will\n\n- Use the `position` and `orientation` properties to move scene objects\n- Understand the `velocity` property of scene objects and their impact on the Doppler shift\n- Learn how to use the `apply_dopper` method of a `Paths` object"
"## Background Information\n\nThere are two ways in which we can simulate the impact of movement of scene objects on the channel impulse response. The first consists in moving the desired objects in small steps along a trajectory and recomputing the propagation paths for each step. While this approach is the most accurate, it comes at the cost of high computational complexity. As we will see later in this notebook, this approach is fortunately not necessary when the lengths of the considered trajectories are small, i.e., not\nmore than a few wavelengths. In this case, we can compute the time evolution of the channel impulse response using the second approach which is based on the experienced Doppler shifts of all propagation paths. It is very fast and leads to very accurate predictions in many cases.\n\nIn order to compute the Doppler shift for a specific path as shown in the figure below, Sionna RT relies on the [velocity vectors](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.SceneObject.velocity) of the scene objects.\n\n\nWhile traveling from the transmitter to the receiver, the path undergoes $n$ scattering processes, such as reflection, diffuse scattering, or diffraction. The object on which lies the $i$th scattering point has the velocity vector $\\mathbf{v}_i$ and the outgoing ray direction at this point is denoted $\\hat{\\mathbf{k}}_i$. The first and last point correspond to the transmitter and receiver, respectively.\n\nThe Doppler shift $f_\\Delta$ for this path can be computed as (see the [documentation](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.Paths.apply_doppler) of `Paths.apply_doppler()`)\n\n\\begin{align}\nf_\\Delta = \\frac{1}{\\lambda}\\left[\\mathbf{v}_{0}^\\mathsf{T}\\hat{\\mathbf{k}}_0 - \\mathbf{v}_{n+1}^\\mathsf{T}\\hat{\\mathbf{k}}_n + \\sum_{i=1}^n \\mathbf{v}_{i}^\\mathsf{T}\\left(\\hat{\\mathbf{k}}_i-\\hat{\\mathbf{k}}_{i-1} \\right) \\right] \\qquad \\text{[Hz]}\n\\end{align}\n\nwhere $\\lambda$ is the wavelength, and then be used to compute the time evolution of the path coefficient `Paths.a` as\n\n\\begin{align}\na(t) = a e^{j2\\pi f_\\Delta t}.\n\\end{align}"
"## GPU Configuration and Imports\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Colab does currently not support the latest version of ipython.\n# Thus, the preview does not work in Colab. However, whenever possible we\n# strongly recommend to use the scene preview mode.\ntry: # detect if the notebook runs in Colab\n    import google.colab\n    colab_compat = True # deactivate preview\nexcept:\n    colab_compat = False\nresolution = [480,320] # increase for higher quality of renderings\n# Allows to exit cell execution in Jupyter\nclass ExitCell(Exception):\n    def _render_traceback_(self):\n        pass\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n# For more details, see https://www.tensorflow.org/guide/gpu\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\ntf.random.set_seed(1) # Set global random seed for reproducibility\n```\n\n```python\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sionna.rt import load_scene, PlanarArray, Transmitter, Receiver, Camera\nfrom sionna.rt.utils import r_hat\nfrom sionna.ofdm import ResourceGrid\nfrom sionna.channel.utils import subcarrier_frequencies, cir_to_ofdm_channel\nfrom sionna.constants import SPEED_OF_LIGHT\n```"
"## Controlling Position and Orientation of Scene Objects\n\nEvery object in a scene has a `position` and `orientation` property that can be inspected and modified. To see this, let us load a scene consisting of a simple street canyon and a few cars.\n\n\n```python\nscene = load_scene(sionna.rt.scene.simple_street_canyon_with_cars)\nscene.add(Camera(\"cam\", position=[50,0,130], look_at=[10,0,0]))\nif colab_compat:\n    scene.render(camera=\"cam\", num_samples=512);\n    raise ExitCell\nscene.preview()\n```\n\n\nThe list of all scene objects can be accessed as follows:\n\n\n```python\nscene.objects\n```\n\n```python\n{'building_1': <sionna.rt.scene_object.SceneObject at 0x7f10cd1182e0>,\n 'building_2': <sionna.rt.scene_object.SceneObject at 0x7f10f2196fb0>,\n 'building_3': <sionna.rt.scene_object.SceneObject at 0x7f10f21962c0>,\n 'building_4': <sionna.rt.scene_object.SceneObject at 0x7f10f2197e20>,\n 'building_5': <sionna.rt.scene_object.SceneObject at 0x7f10f2197e50>,\n 'building_6': <sionna.rt.scene_object.SceneObject at 0x7f10f2197f40>,\n 'car_1': <sionna.rt.scene_object.SceneObject at 0x7f10f2197f70>,\n 'car_2': <sionna.rt.scene_object.SceneObject at 0x7f10f2197fa0>,\n 'car_3': <sionna.rt.scene_object.SceneObject at 0x7f10f2197fd0>,\n 'car_4': <sionna.rt.scene_object.SceneObject at 0x7f10f2197c10>,\n 'car_5': <sionna.rt.scene_object.SceneObject at 0x7f10f2197a60>,\n 'car_6': <sionna.rt.scene_object.SceneObject at 0x7f10f2197b20>,\n 'car_7': <sionna.rt.scene_object.SceneObject at 0x7f10f21979d0>,\n 'car_8': <sionna.rt.scene_object.SceneObject at 0x7f10f2195c90>,\n 'floor': <sionna.rt.scene_object.SceneObject at 0x7f10f2197a30>}\n```"
"Let us now inspect the position and orientation of one of the cars:\n\n\n```python\ncar_2 = scene.get(\"car_2\")\nprint(\"Position: \", car_2.position.numpy())\nprint(\"Orientation: \", car_2.orientation.numpy())\n```\n\n\n```python\nPosition:  [25.         5.5999994  0.7500001]\nOrientation:  [0. 0. 0.]\n```\n\n\nThe position of an object corresponds to the center of its axis-aligned bounding box. By default, the orientation of every scene object is `[0,0,0]`. We can now change the position and orientation of the car as follows:\n\n\n```python\n# Move the car 10m along the y-axis\ncar_2.position += [0, 10, 0]\n# And rotate it by 90 degree around the z-axis\ncar_2.orientation = [np.pi/2, 0, 0]\nif colab_compat:\n    scene.render(camera=\"cam\", num_samples=512);\n    raise ExitCell\nscene.preview(); # You do not need to open a new preview, the preview above will update\n```\n\n\nNext, we will visualize coverage maps for different positions of the cars in the scene, assuming that one of the cars is equipped with a transmit antenna:\n\n\n```python\nscene = load_scene(sionna.rt.scene.simple_street_canyon_with_cars)\nscene.add(Camera(\"cam\", position=[50,0,130], look_at=[10,0,0]))\n# Configure a transmitter that is located at the front of \"car_2\"\nscene.add(Transmitter(\"tx\", position=[22.7, 5.6, 0.75], orientation=[np.pi,0,0]))\nscene.tx_array = PlanarArray(1,1,0.5,0.5,\"tr38901\",\"V\")\nscene.rx_array = scene.tx_array\n# Move cars along straight lines for a couple of steps\ndisplacement_vec = [10, 0, 0]\nnum_displacements = 2\nfor _ in range(num_displacements+1):\n    # Compute and render a coverage map at 0.5m above the ground\n    cm = scene.coverage_map(num_samples=10e6,\n                            max_depth=5,\n                            diffraction=True,\n                            cm_center=[0,0,0.5],\n                            cm_orientation=[0,0,0],\n                            cm_size=[186,121],\n                            cm_cell_size=[2,2])\n    scene.render(\"cam\", coverage_map=cm)\n    # Move TX to next position\n    scene.get(\"tx\").position -= displacement_vec\n    # Move cars driving in -x direction\n    for j in range(1,6):\n        scene.get(f\"car_{j}\").position -= displacement_vec\n    # Move cars driving in x direction\n    for j in range(6,9):\n        scene.get(f\"car_{j}\").position += displacement_vec\n```"
"## Time Evolution of Channels Via Doppler Shift\n\nIn the previous section, we have seen how the position and orientation of objects in a scene can be modified. However, if we want to model the evolution of channels over very short time horizons, this approach becomes impractical. An alternative, consists in assigning to all moving objects a velocity vector $\\mathbf{v}_i\\in\\mathbb{R}^3$ based on which path-wise Doppler shifts can be computed. Let us now load a simple scene with a single reflector and modify its velocity.\n\n\n```python\n# Load scene with a single reflector\nscene = load_scene(sionna.rt.scene.simple_reflector)\n# Inspect the velocity of this object\nprint(\"Velocity vector: \", scene.get(\"reflector\").velocity.numpy())\n# Update velocity vector\nscene.get(\"reflector\").velocity = [0, 0, -20]\nprint(\"Velocity vector after update: \", scene.get(\"reflector\").velocity.numpy())\n```\n\n\n```python\nVelocity vector:  [0. 0. 0.]\nVelocity vector after update:  [  0.   0. -20.]\n```\n\n\nNext, we will add a transmitter and receiver to the scene and compute the propagation paths:\n\n\n```python\n# Configure arrays for all transmitters and receivers in the scene\nscene.tx_array = PlanarArray(1,1,0.5,0.5,\"iso\",\"V\")\nscene.rx_array = scene.tx_array\n# Add a transmitter and a receiver\nscene.add(Transmitter(\"tx\", [-25,0.1,50]))\nscene.add(Receiver(\"rx\",    [ 25,0.1,50]))\n# Compute paths\npaths = scene.compute_paths(max_depth=1)\npaths.normalize_delays = False # Do not normalize the delays such that the first path arrives at tau=0\n# Visualize the scene and propagation paths\nif colab_compat:\n    scene.add(Camera(\"cam\", position=[0, 100, 50], look_at=[0,0,30]))\n    scene.render(paths=paths, camera=\"cam\", num_samples=512);\n    raise ExitCell\nscene.preview(paths=paths)\n```\n\n\nEvery path has a property `Paths.doppler` that corresponds to the aggregated Doppler shift due to the movement of objects it intersects. This property does not account for the additional Doppler shifts caused by possible movements of the transmitter and receiver."
"```python\nprint(\"Path type (0=LoS, 1=Specular reflection): \", paths.types.numpy())\nprint(\"Doppler shifts (Hz): \", paths.doppler.numpy())\n```\n\n\n```python\nPath type (0=LoS, 1=Specular reflection):  [[0 1]]\nDoppler shifts (Hz):  [[[[   0.      -417.68832]]]]\n```"
"### Example: Delay-Doppler Spectrum\n\nWe will now use the Doppler shifts to compute a time-varying channel impulse response and estimate its Delay-Doppler spectrum. To this end, we assume that 1024 subsequent symbols of an OFDM system with 1024 subcarriers can be observed, assuming a subcarrier spacing of 30kHz. This will define the following resolutions in the delay and Doppler domains:\n\n\n```python\nrg = ResourceGrid(num_ofdm_symbols=1024,\n                  fft_size=1024,\n                  subcarrier_spacing=30e3)\ndelay_resolution = rg.ofdm_symbol_duration/rg.fft_size\nprint(\"Delay   resolution (ns): \", int(delay_resolution/1e-9))\ndoppler_resolution = rg.subcarrier_spacing/rg.num_ofdm_symbols\nprint(\"Doppler resolution (Hz): \", int(doppler_resolution))\n```\n\n\n```python\nDelay   resolution (ns):  32\nDoppler resolution (Hz):  29\n```\n\n\nIn addition to the velocity of the reflector, we also assume that the transmitter is moving. Its velocity vector will be provided during the call of the `apply_doppler()` function.\n\n\n```python\n# Compute time evolution of the channel impulse response\ntx_velocity = [30,0,0]\npaths.apply_doppler(sampling_frequency=1/rg.ofdm_symbol_duration,\n                    num_time_steps=rg.num_ofdm_symbols,\n                    tx_velocities=tx_velocity)\n\n### Compute the Delay-Doppler spectrum\n# Determine subcarrier frequencies\nfrequencies = subcarrier_frequencies(rg.fft_size, rg.subcarrier_spacing)\n# Squeeze useless dimensions\n# [num_time_steps, fft_size]\nh = tf.squeeze(cir_to_ofdm_channel(frequencies, *paths.cir(), normalize=True))\n# Apply an FFTshift to bring subcarriers in the\n# correct order for an IFFT\nh = np.fft.fftshift(h, axes=1)\n# Apply IFFT to subcarrier dimension to\n# convert frequency to delay domain\nh_delay = np.fft.ifft(h, axis=1)/np.sqrt(rg.fft_size)\n# Apply FFT to time-step dimension to\n# convert time to Doppler domain\nh_delay_doppler = np.fft.fft(h_delay, axis=0)/np.sqrt(rg.fft_size)\n# Apply FFTShift to bring Doppler dimension in the correct\n# order for visualization\nh_delay_doppler = np.fft.fftshift(h_delay_doppler, axes=0)\n# Compute meshgrid for visualization of the Delay-Doppler spectrum\ndoppler_bins = np.arange(-rg.num_ofdm_symbols/2*doppler_resolution,\n                          rg.num_ofdm_symbols/2*doppler_resolution,\n                         doppler_resolution)\ndelay_bins = np.arange(0,\n                       rg.fft_size*delay_resolution,\n                       delay_resolution) / 1e-9\nx, y = np.meshgrid(delay_bins, doppler_bins)\n# Visualize Delay-Doppler spectrum\nfig = plt.figure(figsize=(8, 10))\nax = fig.add_subplot(111, projection='3d')\n# We only visualize the relevant part of the spectrum\noffset = 20\nx_start = int(rg.fft_size/2)-offset\nx_end = int(rg.fft_size/2)+offset\ny_start = 0\ny_end = offset\nx_grid = x[x_start:x_end,y_start:y_end]\ny_grid = y[x_start:x_end,y_start:y_end]\nz_grid = np.abs(h_delay_doppler[x_start:x_end,y_start:y_end])\nsurf = ax.plot_surface(x_grid,\n                       y_grid,\n                       z_grid,\n                       cmap='viridis', edgecolor='none')\nax.set_xlabel('Delay (ns)')\nax.set_ylabel('Doppler (Hz)')\nax.set_zlabel('Magnitude');\nax.zaxis.labelpad=2\nax.view_init(elev=53, azim=-32)\nax.set_title(\"Delay-Doppler Spectrum\");\n```"
"As expected, we can observe two peaks in the Delay-Doppler spectrum above. The first at a delay of around 160ns, and the second at a delay of approximately 370ns. The respective Doppler shifts are around 350Hz and -260Hz.\n\nNext, we will compute the exact Doppler shifts based on the equation provided in the [Background Information](https://nvlabs.github.io/sionna/examples/Sionna_Ray_Tracing_Mobility.html#Background-Information) that should match the peaks in the Delay-Doppler spectrum.\n\n\n```python\n# Compute outgoing directions for the LoS and reflected path\nk_t_los = r_hat(paths.theta_t[0,0,0,0], paths.phi_t[0,0,0,0])\nk_t_ref = r_hat(paths.theta_t[0,0,0,1], paths.phi_t[0,0,0,1])\n# Compute the Doppler shifts due to movement of the transmitter\ndoppler_tx_los = np.sum(k_t_los*tx_velocity)/scene.wavelength\ndoppler_tx_ref = np.sum(k_t_ref*tx_velocity)/scene.wavelength\n# Compute the overall Doppler shifts\ndoppler_los = doppler_tx_los + paths.doppler[0,0,0,0]\ndoppler_ref = doppler_tx_ref + paths.doppler[0,0,0,1]\nprint(\"Delay - LoS Path (ns) :\", paths.tau[0,0,0,0].numpy()/1e-9)\nprint(\"Doppler - LoS Path (Hz) :\", doppler_los.numpy())\nprint(\"Delay - Reflected Path (ns) :\", paths.tau[0,0,0,1].numpy()/1e-9)\nprint(\"Doppler - Reflected Path (Hz) :\", doppler_ref.numpy())\n```\n\n\n```python\nDelay - LoS Path (ns) : 166.78205838616122\nDoppler - LoS Path (Hz) : 350.2423\nDelay - Reflected Path (ns) : 372.93600030352536\nDoppler - Reflected Path (Hz) : -261.05524\n```"
"## Comparison of Doppler- vs Position-based Time Evolution\n\nWe will now compare a time-varying channel frequency impulse response generated by the application of Doppler shifts against another one obtained by physically moving objects in a scene and retracing the paths.\n\nThe same scene as in the first section will be used where a transmitter is placed on a moving car. However, we now also place a receiver on another car and assume that all cars in the scene are moving along a linear trajectory.\n\n\n```python\nscene = load_scene(sionna.rt.scene.simple_street_canyon_with_cars)\nscene.add(Camera(\"cam\", position=[50,0,130], look_at=[10,0,0]))\n# Parameters for ray tracing\nmax_depth = 3\ndiffraction = True\n# TX and RX have directional antennas\nscene.tx_array = PlanarArray(1,1,0.5,0.5,\"tr38901\",\"V\")\nscene.rx_array = scene.tx_array\n# TX and RX are installed at the front of two different cars.\n# The directive antennas ensure that paths reaching an antenna from the back are close to zero.\nscene.add(Transmitter(\"tx\", position=[22.7, 5.6, 0.75], orientation=[np.pi,0,0]))\nscene.add(Receiver(\"rx\", position=[-27.8,-4.9, 0.75]))\n# Configure an OFDM resource grid\nrg = ResourceGrid(num_ofdm_symbols=128,\n                  fft_size=1024,\n                  subcarrier_spacing=30e3)\nfrequencies = subcarrier_frequencies(rg.fft_size, rg.subcarrier_spacing)\n# Define a velocity vector and the corresponding displacement over the duration\n# of one OFDM symbol\nvelocity_vec = np.array([10,0,0])\ndisplacement_vec = velocity_vec*rg.ofdm_symbol_duration\n# Assign velocity vector to cars driving in -x direction\nfor j in range(1,6):\n    scene.get(f\"car_{j}\").velocity = -velocity_vec\n# Assign velocity vector to cars driving in x direction\nfor j in range(6,9):\n    scene.get(f\"car_{j}\").velocity = velocity_vec\n# Compute paths and apply Doppler shift for time evolution\npaths = scene.compute_paths(max_depth=max_depth, diffraction=diffraction)\npaths.normalize_delays = False\npaths.apply_doppler(sampling_frequency=1/rg.ofdm_symbol_duration,\n                    num_time_steps=rg.num_ofdm_symbols,\n                    tx_velocities=-velocity_vec,\n                    rx_velocities=velocity_vec)\n# Compute the corresponding channel frequency responses\nh_dop = tf.squeeze(cir_to_ofdm_channel(frequencies, *paths.cir()))\n# Visualize the scene and propagation paths\nif colab_compat:\n    scene.render(paths=paths, camera=\"cam\", num_samples=512);\n    raise ExitCell\nscene.preview(paths=paths)\n```"
"In the next cell, we compute a sequence of channel frequency responses by moving all cars as well as the transmitter and receiver in the scene. After each step, propagation paths are traced and the corresponding channel frequency response is computed.\n\n\n```python\npaths = scene.compute_paths(max_depth=max_depth, diffraction=diffraction)\npaths.normalize_delays = False\n# Reshape to [1, num_subcarriers]\nh_sim = tf.reshape(cir_to_ofdm_channel(frequencies, *paths.cir()), [1, -1])\nfor i in range(rg.num_ofdm_symbols-1):\n    # Move TX and RX to next position\n    scene.get(\"tx\").position -= displacement_vec\n    scene.get(\"rx\").position += displacement_vec\n    # Move cars driving in -x direction to the next position\n    for j in range(1,6):\n        scene.get(f\"car_{j}\").position -= displacement_vec\n    # Move cars driving in +x direction to the next position\n    for j in range(6,9):\n        scene.get(f\"car_{j}\").position += displacement_vec\n    # Compute channel frequency response\n    paths = scene.compute_paths(max_depth=max_depth, diffraction=diffraction)\n    paths.normalize_delays = False\n    h = tf.reshape(cir_to_ofdm_channel(frequencies, *paths.cir()), [1, -1])\n    # Concatenate along the time dimensions\n    h_sim = tf.concat([h_sim, h], axis=0)\n```\n\n\nNext, we visualize the the time evolution of a few subcarriers as well as some snapshots of the full channel frequency response.\n\n\n```python\nsubcarriers = np.arange(0, 1024, 256)\ntimesteps =  np.arange(0, 128, 32)\nfig, axs = plt.subplots(2, 4, figsize=(18, 7))\nfor i,j in enumerate(subcarriers):\n    axs[0,i].plot(np.arange(rg.num_ofdm_symbols), np.abs(h_sim[:,j]))\n    axs[0,i].plot(np.arange(rg.num_ofdm_symbols), np.abs(h_dop[:,j]), \"--\")\n    axs[0,i].set_xlabel(\"Timestep\")\n    axs[0,i].set_ylabel(r\"$|h(f,t)|$\")\n    axs[0,i].set_title(f\"Subcarrier {j}\")\n    axs[0,i].legend([\"Movement\", \"Doppler\"])\n\nfor i,j in enumerate(timesteps):\n    axs[1,i].plot(np.arange(rg.fft_size), np.abs(h_sim[j,:]))\n    axs[1,i].plot(np.arange(rg.fft_size), np.abs(h_dop[j,:]), \"--\")\n    axs[1,i].set_xlabel(\"Subcarrier\")\n    axs[1,i].set_ylabel(r\"$|h(f,t)|$\")\n    axs[1,i].set_title(f\"Timestep {j}\")\n    axs[1,i].legend([\"Movement\", \"Doppler\"])\nplt.tight_layout()\nplt.show()\n```"
"From the figures above, we can see that there is until time step 80 no noticeable difference between the Doppler-based channel evolution and the one based on physically moving objects. At time step 80, some paths (diss-)appear and the Doppler-based time-evolution becomes less accurate."
"## Summary\n\nWe have discussed two different ways to simulate mobility in Sionna RT. One can either move objects in a scene and recompute paths or compute the time evolution of channels synthetically based on the Doppler shifts that are obtained from velocity vectors of the scene objects.\n\nThe former approach is computationally intensive but accurate while the latter is much faster but only accurate over short time spans during which the scene objects have moved very short distances.\n\nBoth approaches can be combined to simulate mobility over longer periods of time.\n\nWe hope you enjoyed our dive into the simulation of mobility with Sionna RT. You may also want to explore our other [tutorials](https://nvlabs.github.io/sionna/tutorials.html#ray-tracing).We hope you enjoyed our dive into the simulation of mobility with Sionna RT. You may also want to explore our other [tutorials](https://nvlabs.github.io/sionna/tutorials.html#ray-tracing).We hope you enjoyed our dive into the simulation of mobility with Sionna RT. You may also want to explore our other [tutorials](https://nvlabs.github.io/sionna/tutorials.html#ray-tracing).We hope you enjoyed our dive into the simulation of mobility with Sionna RT. You may also want to explore our other [tutorials](https://nvlabs.github.io/sionna/tutorials.html#ray-tracing)."
"# Tutorial on Diffraction\n\nIn this notebook, you will\n\n- Learn what diffraction is and why it is important\n- Make various ray tracing experiments to validate some theoretical results\n- Familiarize yourself with the Sionna RT API\n- Visualize the impact of diffraction on channel impulse responses and coverage maps"
"## GPU Configuration and Imports\n\n\n```python\nimport os\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Colab does currently not support the latest version of ipython.\n# Thus, the preview does not work in Colab. However, whenever possible we\n# strongly recommend to use the scene preview mode.\ntry: # detect if the notebook runs in Colab\n    import google.colab\n    colab_compat = True # deactivate preview\nexcept:\n    colab_compat = False\nresolution = [480,320] # increase for higher quality of renderings\n# Allows to exit cell execution in Jupyter\nclass ExitCell(Exception):\n    def _render_traceback_(self):\n        pass\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n# For more details, see https://www.tensorflow.org/guide/gpu\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\ntf.random.set_seed(1) # Set global random seed for reproducibility\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport sys\nfrom sionna.rt import load_scene, PlanarArray, Transmitter, Receiver, RadioMaterial, Camera\nfrom sionna.rt.utils import r_hat\nfrom sionna.constants import PI, SPEED_OF_LIGHT\nfrom sionna.utils import expand_to_rank\n```"
"## Background Information\n\n\nLets consider an infinitely long wedge as shown in the figure above. To better visualize this, think of an endless slice of pie. The edge vector is pointed straight out of your screen and the wedge has an opening angle of $n\\pi$, where $n$ is a real number between 1 and 2.\n\nThe wedge has two faces, the 0- and the n-face. They are labeled this way to indicate from which surface the angle $\\phi'\\in[0,n]$ of an incoming locally planar electromagnetic wave is measured. Both faces are made from possibly different materials, each with their own unique properties. These properties are represented by a term known as complex relative permittivity, denoted by $\\eta_0$ and $\\eta_n$, respectively. Without diving too deep into the specifics, permittivity\nmeasures how a material reacts to an applied electric field.\n\nWe can define three distinct regions in this figure: Region $I$, in which the incident field as well as the reflected field from the 0-face are present, Region $II$, in which the reflected field vanishes, and Region $III$, in which the incident field is shadowed by the wedge. The three regions are separated by the reflection shadow boundary (RSB) and the incident shadow boundary (ISB). The former is determined by the angle of specular reflection $\\pi-\\phi'$, while the\nlatter is simply the prolongation of the direction of the incoming wave through the edge, i.e., $\\pi+\\phi'$.\n\nUsing geometrical optics (GO) alone, the electromagnetic field would abruptly change at each boundary as the reflected and incident field components suddenly disappear. As this is physically not plausible, the geometrical theory of diffraction (GTD) [1], as developed by Joseph B. Keller in the 1960s, introduces a so-called diffracted field which ensures that the total field is continuous. The diffracted field is hence especially important in the transition regions between the different regions\nand then rapidly decays to zero. Most importantly, without diffraction, there would be no field beyond the ISB in Region $III$.\n\nDiffraction is hence a very important phenomenon which enables wireless coverage behind buildings at positions without a line-of-sight of strong reflected path. As you will see later in this tutorial, the diffracted field is generally much weaker than the incident or reflected field. Moreover, the higher the frequency, the faster the diffracted field decays when moving away from the RSB and ISB.\n\n\nAccording to the GTD, when a ray hits a point on the edge, its energy gets spread over a continuum of rays lying on the Keller cone. All rays on this cone make equal angles with the edge of diffraction at the point of diffraction, i.e., $\\beta_0'=\\beta_0$. One can think of this phenomenon as an extension of the law of reflection at planar surfaces. The figures above illustrates this concept.\n\nThe GTD was later extended to the uniform theory of diffraction (UTD) [2,3] which overcomes some of its shortcomings.\n\nWe will explore in this notebook these effects in detail and also validate the UTD implementation in Sionna RT as a by-product.\n\n**Wedge vs Edge**\n\nFirst, it is important to know the difference between a *wedge* and an *edge*, and why we distinguish between them.\n\nSionna defines a *wedge* as the line segment between two primitives, i.e., the common segment of two triangles. For example, a cubic building would have 12 wedges.\n\nFor primitives that have one or more line segments that are not shared with another primitive, Sionna refers to such line segments as *edges*. See [sionna.rt.scene.floor_wall](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.scene.floor_wall) for an example scene.\n\nBy default, Sionna does not simulate diffraction on edges (`edge_diffraction=False`), to avoid problems such as diffraction on the exterior edges of the ground surface (modelled as a rectangular plane)."
"## Experiments with a Simple Wedge\n\nWe start by loading a pre-made scene from Sionna RT that contains a simple wedge:\n\n\n```python\nscene = load_scene(sionna.rt.scene.simple_wedge)\n# Create new camera with different configuration\nmy_cam = Camera(\"my_cam\", position=[10,-100,100], look_at=[10,0,0])\nscene.add(my_cam)\n# Render scene\nscene.render(my_cam);\n# You can also preview the scene with the following command\n# scene.preview()\n```\n\n\nThe wedge has an opening angle of $\\frac{3}{2}\\pi=270^\\circ$, i.e., $n=1.5$. The 0-face is aligned with the x axis and the n-face aligned with the negative y axis.\n\nFor the following experiments, we will configure the wedge to be made of metal, an almost perfect conductor, and set the frequency to 1GHz.\n\n\n```python\nscene.frequency = 1e9 # 1GHz\nscene.objects[\"wedge\"].radio_material = \"itu_metal\" # Almost perfect reflector\n```\n\n\nWith our scene being set-up, we now need to configure a transmitter and place multiple receivers to measure the field. We assume that the transmitter and all receivers have a single vertically polarized isotropic antenna.\n\n\n```python\n# Configure the antenna arrays used by the transmitters and receivers\nscene.tx_array = PlanarArray(num_rows=1,\n                             num_cols=1,\n                             vertical_spacing=0.5,\n                             horizontal_spacing=0.5,\n                             pattern=\"iso\",\n                             polarization=\"V\")\nscene.rx_array = scene.tx_array\n```\n\n```python\n# Transmitter\ntx_angle = 30/180*PI # Angle phi from the 0-face\ntx_dist = 50 # Distance from the edge\ntx_pos = 50*r_hat(PI/2, tx_angle)\nref_boundary = (PI - tx_angle)/PI*180\nlos_boundary = (PI + tx_angle)/PI*180\nscene.add(Transmitter(name=\"tx\",\n                      position=tx_pos,\n                      orientation=[0,0,0]))\n# Receivers\n# We place num_rx receivers uniformly spaced on the segment of a circle around the wedge\nnum_rx = 1000 # Number of receivers\nrx_dist = 5 # Distance from the edge\nphi = tf.linspace(1e-2, 3/2*PI-1e-2, num=num_rx)\ntheta = PI/2*tf.ones_like(phi)\nrx_pos = rx_dist*r_hat(theta, phi)\nfor i, pos in enumerate(rx_pos):\n    scene.add(Receiver(name=f\"rx-{i}\",\n                       position=pos,\n                       orientation=[0,0,0]))\n```"
"```python\n# Render scene\nmy_cam.position = [-30,100,100]\nmy_cam.look_at([10,0,0])\nscene.render(my_cam);\n```\n\n\nIn the above figure, the blue ball is the transmitter and the green circle corresponds to 1000 receivers uniformly distributed over a segment of a circle around the edge.\n\nNext, we compute the channel impulse response between the transmitter and all of the receivers. We deactivate scattering in this notebook as it would require a prohibitive amount of memory with such a large number of receivers.\n\n\n```python\n# Compute paths between the transmitter and all receivers\npaths = scene.compute_paths(num_samples=1e6,\n                            los=True,\n                            reflection=True,\n                            diffraction=True,\n                            scattering=False)\n# Obtain channel impulse responses\n# We squeeze irrelevant dimensions\n# [num_rx, max_num_paths]\na, tau = [np.squeeze(t) for t in paths.cir()]\n```\n\n```python\ndef compute_gain(a, tau):\n        \"\"\"Compute $|H(f)|^2 at f = 0 where H(f) is the baseband channel frequency response\"\"\"\n        a = tf.squeeze(a, axis=-1)\n        h_f_2 = tf.math.abs(tf.reduce_sum(a, axis=-1))**2\n        h_f_2 = tf.where(h_f_2==0, 1e-24, h_f_2)\n        g_db = 10*np.log10(h_f_2)\n        return tf.squeeze(g_db)\n```\n\n\nLets have a look at the channel impulse response of one of the receivers:\n\n\n```python\nn = 400\nplt.figure()\nplt.stem(tau[n]/1e-9, 10*np.log10(np.abs(a[n])**2))\nplt.title(f\"Angle of receiver $\\phi: {int(phi[n]/PI*180)}^\\circ$\");\nplt.xlabel(\"Delay (ns)\");\nplt.ylabel(\"$|a|^2$ (dB)\");\n```\n\n\nFor an angle of around 108 degrees, the receiver is located within Region I, where all propagation effects should be visible. As expected, we can observe three path: line-of-sight, reflected, and diffracted. While the first two have roughly the same strength (as metal is an almost perfect reflector), the diffracted path has significantly lower energy.\n\nNext, let us compute the channel frequency response $H(f)$ as the sum of all paths multiplied with their complex phase factors:\n\n$$\nH(f) = \\sum_{i=1}^N a_i e^{-j2\\pi\\tau_i f}\n$$"
"```python\nh_f_tot = np.sum(a, axis=-1)\n```\n\n\nWe can now visualize the path gain $|H(f)|^2$ for all receivers, i.e., as a function of the angle $\\phi$:\n\n\n```python\nfig = plt.figure()\nplt.plot(phi/PI*180, 20*np.log10(np.abs(h_f_tot)))\nplt.xlabel(\"Diffraction angle $\\phi$ (deg)\");\nplt.ylabel(r\"Path gain $|H(f)|^2$ (dB)\");\nplt.ylim([-100, -59]);\nplt.xlim([0, phi[-1]/PI*180]);\n```\n\n\nThe most important observation from the figure above is that $H(f)$ remains continous over the entire range of $\\phi$, especially at the RSB and ISB boundaries at around $\\phi=150^\\circ$ and $\\phi=209^\\circ$, respectively.\n\nTo get some more insight, the convenience function in the next cell, computes and visualizes the different components of $H(f)$ by their type.\n\n\n```python\ndef plot(frequency, material):\n    \"\"\"Plots the path gain $|H(f)|^2 versus $phi$ for a given\n       frequency and RadioMaterial of the wedge.\n    \"\"\"\n    # Set carrier frequency and material of the wedge\n    # You can see a list of available materials by executing\n    # scene.radio_materials\n    scene.frequency = frequency\n    scene.objects[\"wedge\"].radio_material = material\n    # Recompute paths with the updated material and frequency\n    paths = scene.compute_paths(num_samples=1e6,\n                                los=True,\n                                reflection=True,\n                                diffraction=True,\n                                scattering=False)\n    def compute_gain(a, tau):\n        \"\"\"Compute $|H(f)|^2 are f = 0 where H(f) is the baseband channel frequency response\"\"\"\n        a = tf.squeeze(a, axis=-1)\n        h_f_2 = tf.math.abs(tf.reduce_sum(a, axis=-1))**2\n        h_f_2 = tf.where(h_f_2==0, 1e-24, h_f_2)\n        g_db = 10*np.log10(h_f_2)\n        return tf.squeeze(g_db)\n    # Compute gain for all path types\n    g_tot_db = compute_gain(*paths.cir())\n    g_los_db = compute_gain(*paths.cir(reflection=False, diffraction=False, scattering=False))\n    g_ref_db = compute_gain(*paths.cir(los=False, diffraction=False, scattering=False))\n    g_dif_db = compute_gain(*paths.cir(los=False, reflection=False, scattering=False))\n    # Make a nice plot\n    fig = plt.figure()\n    phi_deg = phi/PI*180\n    ymax = np.max(g_tot_db)+5\n    ymin = ymax - 45\n    plt.plot(phi_deg, g_tot_db)\n    plt.plot(phi_deg, g_los_db)\n    plt.plot(phi_deg, g_ref_db)\n    plt.plot(phi_deg, g_dif_db)\n    plt.ylim([ymin, ymax])\n    plt.xlim([phi_deg[0], phi_deg[-1]]);\n    plt.legend([\"Total\", \"LoS\", \"Reflected\", \"Diffracted\"], loc=\"lower left\")\n    plt.xlabel(\"Diffraction angle $\\phi$ (deg)\")\n    plt.ylabel(\"Path gain $|H(f)|^2$ (dB)\")\n    ax = fig.axes[0]\n    ax.axvline(x=ref_boundary, ymin=0, ymax=1, color=\"black\", linestyle=\"--\")\n    ax.axvline(x=los_boundary, ymin=0, ymax=1, color=\"black\", linestyle=\"--\")\n    ax.text(ref_boundary-10,ymin+5,'RSB',rotation=90,va='top')\n    ax.text(los_boundary-10,ymin+5,'ISB',rotation=90,va='top')\n    ax.text(ref_boundary/2,ymax-2.5,'Region I', ha='center', va='center',\n            bbox=dict(facecolor='none', edgecolor='black', pad=4.0))\n    ax.text(los_boundary-(los_boundary-ref_boundary)/2,ymax-2.5,'Region II', ha='center', va='center',\n            bbox=dict(facecolor='none', edgecolor='black', pad=4.0))\n    ax.text(phi_deg[-1]-(phi_deg[-1]-los_boundary)/2,ymax-2.5,'Region III', ha='center', va='center',\n            bbox=dict(facecolor='none', edgecolor='black', pad=4.0))\n    plt.title('$f={}$ GHz (\"{}\")'.format(frequency/1e9, material))\n    plt.tight_layout()\n    return fig\n```"
"```python\nplot(1e9, \"itu_metal\");\n```\n\n\nThe figure above shows the path gain for the total field as well as that for the different path types. In Region $I$, the line-of-sight and reflected paths dominate the total field. While their contributions are almost constant over the range of $\\phi\\in[0,150^\\circ]$, their combined field exhibits large fluctutations due to constructive and destructive interference. As we approach the RSB, the diffracted field increases to ensure continuity at $\\phi=150^\\circ$, where the\nreflected field immediately drops to zero. A similar observation can be made close to the ISB, where the incident (or line-of-sight) component suddenly vanishes. In Region $III$, the only field contribution comes from the diffracted field.\n\nLet us now have a look at what happens when we change the frequency to $10\\,$GHz.\n\n\n```python\nplot(10e9, \"itu_metal\");\n```\n\n\nThe first observation we can make is that the overall path gain has dropped by around $20\\,$dB. This is expected as it is proportional to the square of the wavelength $\\lambda$.\n\nThe second noticeable difference is that the path gain fluctuates far more rapidly. This is simply due to the shorter wavelength.\n\nThe third observation we can make is that the diffracted field decays far more radpily when moving away from the boundaries as compared to a frequency of $1\\,$GHz. Thus, diffraction is less important at high frequencies.\n\nWe can verify that the same trends continue by plotting the result for a frequency of $100\\,$GHz, which is the upper limit for which the ITU Metal material is defined (see the [Sionna RT Documentation](https://nvlabs.github.io/sionna/api/rt.html#radio-materials)).\n\n\n```python\nplot(100e9, \"itu_metal\");\n```\n\n\nIt is also interesting to change the material of the wedge. The preconfigured materials in Sionna RT can be inspected with the following command:\n\n\n```python\nlist(scene.radio_materials.keys())\n```\n\n```python\n['vacuum',\n 'itu_concrete',\n 'itu_brick',\n 'itu_plasterboard',\n 'itu_wood',\n 'itu_glass',\n 'itu_ceiling_board',\n 'itu_chipboard',\n 'itu_plywood',\n 'itu_marble',\n 'itu_floorboard',\n 'itu_metal',\n 'itu_very_dry_ground',\n 'itu_medium_dry_ground',\n 'itu_wet_ground']\n```"
"Lets see what happens when we change the material of the wedge to wood and the frequency back to $1\\,$GHz.\n\n\n```python\nplot(1e9, \"itu_wood\");\n```\n\n\nWe immediately notice that wood is a bad reflector since the strength of the reflected path has dropped by $10\\,$dB compared to the metal. Thanks to the heuristic extension of the diffracted field equations in [2] to non-perfect conductors in [4] (which are implemented in Sionna RT), the total field remains continuous.\n\nYou might now want to try different materials and frequencies for yourself."
"## Coverage Maps with Diffraction\n\nSo far, we have obtained a solid microscopic understanding of the effect of scattering. Let us now turn to the macroscopic effects that can be nicely observed through coverage maps.\n\nA coverage map describes the average received power from a specific transmitter at every point on a plane. The effects of fast fading, i.e., constructive/destructive interference between different paths, are averaged out by summing the squared amplitudes of all paths. As we cannot compute coverage maps with infinitely fine resolution, they are approximated by small rectangular tiles for which average values are computed. For a detailed explanation, have a look at the <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/api/rt.html#coverage-map\">API\nDocumentation</a>.\n\nLet us now load a slightly more interesting scene containing a couple of rectangular buildings and add a transmitter. Note that we do not need to add any receivers to compute a coverage map.\n\n\n```python\nscene = load_scene(sionna.rt.scene.simple_street_canyon)\n# Set the carrier frequency to 1GHz\nscene.frequency = 1e9\nscene.tx_array = PlanarArray(num_rows=1,\n                             num_cols=1,\n                             vertical_spacing=0.5,\n                             horizontal_spacing=0.5,\n                             pattern=\"iso\",\n                             polarization=\"V\")\nscene.rx_array = scene.tx_array\nscene.add(Transmitter(name=\"tx\",\n                      position=[-33,11,32],\n                      orientation=[0,0,0]))\n# Render the scene from one of its cameras\n# The blue dot represents the transmitter\nscene.render('scene-cam-1');\n```\n\n\nComputing a coverage map is as simple as running the following command:\n\n\n```python\ncm = scene.coverage_map(cm_cell_size=[1,1], num_samples=10e6)\n```\n\n\nWe can visualizes the coverage map in the scene as follows:\n\n\n```python\n# Add a camera looking at the scene from the top\nmy_cam = Camera(\"my_cam\", position=[10,0,300], look_at=[0,0,0])\nmy_cam.look_at([0,0,0])\nscene.add(my_cam)\n# Render scene with the new camera and overlay the coverage map\nscene.render(my_cam, coverage_map=cm);\n```\n\n\nFrom the figure above, we can see that many regions behind buildings do not receive any signal. The reason for this is that diffraction is by default deactivated. Let us now generate a new coverage map with diffraction enabled:"
"```python\ncm_diff = scene.coverage_map(cm_cell_size=[1,1], num_samples=10e6, diffraction=True)\nscene.render(my_cam, coverage_map=cm_diff);\n```\n\n\nAs expected from our experiements above, there is not a single point in the scene that is left blank. In some areas, however, the signal is still very weak and will not enable any form of communication.\n\nLets do the same experiments at a higher carrier frequency (30 GHz):\n\n\n```python\nscene = load_scene(sionna.rt.scene.simple_street_canyon)\nscene.frequency = 30e9\nscene.tx_array = PlanarArray(num_rows=1,\n                             num_cols=1,\n                             vertical_spacing=0.5,\n                             horizontal_spacing=0.5,\n                             pattern=\"iso\",\n                             polarization=\"V\")\nscene.rx_array = scene.tx_array\nscene.add(Transmitter(name=\"tx\",\n                      position=[-33,11,32],\n                      orientation=[0,0,0]))\nscene.add(my_cam)\ncm = scene.coverage_map(cm_cell_size=[1,1], num_samples=10e6)\ncm_diff = scene.coverage_map(cm_cell_size=[1,1], num_samples=10e6, diffraction=True)\nscene.render(my_cam, coverage_map=cm);\nscene.render(my_cam, coverage_map=cm_diff);\n```\n\n\nWhile the 1 GHz and 30 GHz carrier frequency coverage maps appear similar, key differences exist. The dynamic range for 30 GHz has grown by around 16dB due to the reduced diffracted field in deep shadow areas, such as behind buildings. The diffracted field at this frequency is considerably smaller compared to the incident field than it is at 1 GHz, leading to a significant increase in dynamic range.\n\nIn conclusion, diffraction plays a vital role in maintaining the consistency of the electric field across both reflection and incident shadow boundaries. It generates diffracted rays that form a Keller cone around an edge. As we move away from these boundaries, the diffracted field diminishes rapidly. Importantly, the contributions of the diffracted field become less significant as the carrier frequency increases.\n\nWe hope you enjoyed our dive into diffraction with this Sionna RT tutorial. We really encourage you to get hands-on, conduct your own experiments and deepen your understanding of ray tracing. Theres always more to learn, so do explore our other [tutorials](https://nvlabs.github.io/sionna/tutorials.html) as well."
"## References\n\n[1] J.B. Keller, [Geometrical Theory of Diffraction](https://opg.optica.org/josa/abstract.cfm?uri=josa-52-2-116), Journal of the Optical Society of America, vol.52, no. 2, Feb.1962.\n\n[2] R.G. Kouyoumjian, [A uniform geometrical theory of diffraction for an edge in a perfectly conducting surface](https://ieeexplore.ieee.org/abstract/document/1451581/authors#authors), Proc. of the IEEE, vol.62, no. 11, Nov.1974.\n\n[3] D.A. McNamara, C.W.I. Pistorius, J.A.G. Malherbe, [Introduction to the Uniform Geometrical Theory of Diffraction](https://us.artechhouse.com/Introduction-to-the-Uniform-Geometrical-Theory-of-Diffraction-P288.aspx), Artech House, 1990.\n\n[4] R. Luebbers, [Finite conductivity uniform GTD versus knife edge diffraction in prediction of propagation path loss](https://ieeexplore.ieee.org/abstract/document/1143189), IEEE Trans. Antennas and Propagation, vol.32, no. 1, Jan.1984.[4] R. Luebbers, [Finite conductivity uniform GTD versus knife edge diffraction in prediction of propagation path loss](https://ieeexplore.ieee.org/abstract/document/1143189), IEEE Trans. Antennas and Propagation, vol.32, no. 1, Jan.1984.[4] R. Luebbers, [Finite conductivity uniform GTD versus knife edge diffraction in prediction of propagation path loss](https://ieeexplore.ieee.org/abstract/document/1143189), IEEE Trans. Antennas and Propagation, vol.32, no. 1, Jan.1984.[4] R. Luebbers, [Finite conductivity uniform GTD versus knife edge diffraction in prediction of propagation path loss](https://ieeexplore.ieee.org/abstract/document/1143189), IEEE Trans. Antennas and Propagation, vol.32, no. 1, Jan.1984."
"# Tutorial on Scattering\n\nIn this notebook, you will\n\n- Learn what scattering is and why it is important\n- Make various ray tracing experiments to validate some theoretical results\n- Familiarize yourself with the Sionna RT API\n- Visualize the impact of scattering on channel impulse responses and coverage maps"
"## GPU Configuration and Imports\n\n\n```python\nimport os # Configure which GPU\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n# Colab does currently not support the latest version of ipython.\n# Thus, the preview does not work in Colab. However, whenever possible we\n# strongly recommend to use the scene preview mode.\ntry: # detect if the notebook runs in Colab\n    import google.colab\n    colab_compat = True # deactivate preview\nexcept:\n    colab_compat = False\nresolution = [480,320] # increase for higher quality of renderings\n# Allows to exit cell execution in Jupyter\nclass ExitCell(Exception):\n    def _render_traceback_(self):\n        pass\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n# Configure the notebook to use only a single GPU and allocate only as much memory as needed\n# For more details, see https://www.tensorflow.org/guide/gpu\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n# Avoid warnings from TensorFlow\ntf.get_logger().setLevel('ERROR')\ntf.random.set_seed(1) # Set global random seed for reproducibility\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport sys\nfrom sionna.channel import cir_to_time_channel\nfrom sionna.rt import load_scene, PlanarArray, Transmitter, Receiver, RadioMaterial, Camera, LambertianPattern, DirectivePattern, BackscatteringPattern\nfrom sionna.rt.utils import r_hat\nfrom sionna.constants import PI, SPEED_OF_LIGHT\nfrom sionna.utils import expand_to_rank\n```"
"## Scattering Basics\n\n\nWhen an electromagnetic wave impinges on a surface, one part of the energy gets reflected while the other part gets refracted, i.e., it propagates into the surface. We distinguish between two types of reflection, specular and diffuse. The latter type is also called diffuse scattering. When a rays hits a diffuse reflection surface, it is not reflected into a single (specular) direction but rather scattered toward many different directions.\n\nOne way to think about scattering is that every infinitesimally small surface element $dA$ (as shown in the figure above) reradiates a part of the energy impinging on it. It essentially behaves like a point source that radiates electromagnetic waves into the hemisphere defined by the surface normal [1]. Similar to the far-field of an antenna which is determined by the antenna pattern, the scattered field is determined by the scattering pattern of the surface element, denoted\n$f_\\text{s}(\\hat{\\mathbf{k}}_\\text{i}, \\hat{\\mathbf{k}}_\\text{s})$, where $\\hat{\\mathbf{k}}_\\text{i}$ and $\\hat{\\mathbf{k}}_\\text{s}$ are the incomning and scattered directions, respectively. In other words, the scattered field can be stronger in certain directions than others.\n\nThe most important difference between diffuse and specular reflections for ray tracing is that an incoming ray essentially spawns infinitely many scattered rays while there is only a single specular path. In order to computed the scattered field at a particular position, one needs to integrate the scattered field over the entire surface.\n\nLet us have a look at some common scattering patterns that are implemented in Sionna:\n\n\n```python\nLambertianPattern().visualize();\n```\n\n\n```python\nDirectivePattern(alpha_r=10).visualize(); # The stronger alpha_r, the more the pattern\n                                          # is concentrated around the specular direction.\n```\n\n\nIn order to develop a feeling for the difference between specular and diffuse reflections, let us load a very simple scene with a single quadratic reflector and place a transmitter and receiver.\n\n\n```python\nscene = load_scene(sionna.rt.scene.simple_reflector)\n# Configure the transmitter and receiver arrays\nscene.tx_array = PlanarArray(num_rows=1,\n                             num_cols=1,\n                             vertical_spacing=0.5,\n                             horizontal_spacing=0.5,\n                             pattern=\"iso\",\n                             polarization=\"V\")\nscene.rx_array = scene.tx_array\n# Add a transmitter and receiver with equal distance from the center of the surface\n# at an angle of 45 degrees.\ndist = 5\nd = dist/np.sqrt(2)\nscene.add(Transmitter(name=\"tx\", position=[-d,0,d]))\nscene.add(Receiver(name=\"rx\", position=[d,0,d]))\n# Add a camera for visualization\nscene.add(Camera(\"my_cam\", position=[0, -30, 20], look_at=[0,0,3]))\n# Open 3D preview (only works in Jupyter notebook)\nif colab_compat:\n    scene.render(\"my_cam\");\n    raise ExitCell\nscene.preview()\n```"
"Next, let us compute the specularly reflected path:\n\n\n```python\npaths = scene.compute_paths(los=False, reflection=True)\n# Open 3D preview (only works in Jupyter notebook)\nif colab_compat:\n    scene.render(\"my_cam\", paths=paths);\n    raise ExitCell\nscene.preview(paths=paths)\n```\n\n\nAs expected from geometrical optics (GO), the specular path goes through the center of the reflector and has indentical incomning and outgoing angles with the surface normal.\n\nWe can compute the scattered paths in a similar way:\n\n\n```python\npaths = scene.compute_paths(los=False, reflection=False, scattering=True, scat_keep_prob=1.0)\n# Open 3D preview (only works in Jupyter notebook)\nif colab_compat:\n    scene.render(\"my_cam\", paths=paths);\n    raise ExitCell\nscene.preview(paths=paths)\n```\n\n\n```python\nprint(f\"There are {tf.size(paths.a).numpy()} scattered paths\")\n```\n\n\n```python\nThere are 2247 scattered paths\n```\n\n\nWe can see that there is a very large number paths. Actually, any ray that hits the surface will be scattered toward the receiver. Thus, the more rays we shoot, the more scattered paths there are. You can see this through the following experiment:\n\n\n```python\npaths = scene.compute_paths(num_samples=2e6, los=False, reflection=False, scattering=True, scat_keep_prob=1.0)\nprint(f\"There are {tf.size(paths.a).numpy()} scattered paths.\")\npaths = scene.compute_paths(num_samples=10e6, los=False, reflection=False, scattering=True, scat_keep_prob=1.0)\nprint(f\"There are {tf.size(paths.a).numpy()} scattered paths.\")\n```\n\n\n```python\nThere are 4400 scattered paths.\nThere are 22572 scattered paths.\n```\n\n\nThe number of rays hitting the surface is proportional to the total number of rays shot and the squared distance between the transmitter and the surface. However, the total received energy across the surface is constant as the transmitted energy is equally divided between all rays.\n\nIf you closely inspect the code in the above cells, you might have noticed the keyword argument `scat_keep_prob`. This determines the fraction of scattered paths that will be randomly dropped in the ray tracing process. The importance of the remaining paths is increased proportionally. Setting this argument to small values prevents obtaining channel impulse responses with an excessive number of scattered paths."
"```python\npaths = scene.compute_paths(num_samples=10e6, los=False, reflection=False, scattering=True, scat_keep_prob=0.001)\nprint(f\"There are {tf.size(paths.a).numpy()} scattered paths.\")\n```\n\n\n```python\nThere are 16 scattered paths.\n```\n\n\nIn our example scene, each ray hitting the surfaces spawns exactly one new ray which connects to the receiver. Each ray has a random phase and energy that is determined by the scattering pattern and the so-called scattering coefficient $S\\in[0,1]$. The squared scattering coefficient $S^2$ determines which portion of the totally reflected energy (specular and diffuse combined) is diffusely reflected. For details on the precise modeling of the scattered field, we refer to the <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/em_primer.html#scattering\">EM\nPrimer</a>.\n\nBy default, all materials in Sionna have a scattering coefficient equal to zero. For this reason, we would expect that all of the scattered paths carry zero energy. Lets verify that this is indeed the case:\n\n\n```python\nprint(\"All scattered paths have zero energy:\", np.all(np.abs(paths.a)==0))\n```\n\n\n```python\nAll scattered paths have zero energy: True\n```\n\n\nLet us change the scattering coefficient of the radio material used by the reflector and run the path computations again:\n\n\n```python\nscene.get(\"reflector\").radio_material.scattering_coefficient = 0.5\npaths = scene.compute_paths(num_samples=1e6, los=False, reflection=False, scattering=True)\nprint(\"All scattered paths have positive energy:\", np.all(np.abs(paths.a)>0))\n```\n\n\n```python\nAll scattered paths have positive energy: True\n```"
"## Scattering Patterns\n\nIn order to study the impact of the scattering pattern, lets replace the perfectly diffuse Lambertian pattern (which all radio materials have by default) by the [DirectivePattern](https://nvlabs.github.io/sionna/api/rt.html#sionna.rt.DirectivePattern). The larger the integer parameter $\\alpha_r$, the more the scattered field is focused around the direction of the specular reflection.\n\n\n```python\nscattering_pattern = DirectivePattern(1)\nscene.get(\"reflector\").radio_material.scattering_pattern = scattering_pattern\nalpha_rs = np.array([1,2,3,5,10,30,50,100], np.int32)\nreceived_powers = np.zeros_like(alpha_rs, np.float32)\nfor i, alpha_r in enumerate(alpha_rs):\n    scattering_pattern.alpha_r = alpha_r\n    paths = scene.compute_paths(num_samples=1e6, los=False, reflection=False, scattering=True, scat_keep_prob=1.0)\n    received_powers[i] = 10*np.log10(tf.reduce_sum(tf.abs(paths.a)**2))\nplt.figure()\nplt.plot(alpha_rs, received_powers)\nplt.xlabel(r\"$\\alpha_r$\")\nplt.ylabel(\"Received power (dB)\");\nplt.title(\"Impact of the Directivity of the Scattering Pattern\");\n```\n\n\nWe can indeed observe that the received energy increases with $\\alpha_r$. This is because the scattered paths are almost parallel to the specular path directions in this scene. If we move the receiver away from the specular direction, this effect should be reversed.\n\n\n```python\n# Move the receiver closer to the surface, i.e., away from the specular angle theta=45deg\nscene.get(\"rx\").position = [d, 0, 1]\nreceived_powers = np.zeros_like(alpha_rs, np.float32)\nfor i, alpha_r in enumerate(alpha_rs):\n    scattering_pattern.alpha_r = alpha_r\n    paths = scene.compute_paths(num_samples=1e6, los=False, reflection=False, scattering=True, scat_keep_prob=1.0)\n    received_powers[i] = 10*np.log10(tf.reduce_sum(tf.abs(paths.a)**2))\nplt.figure()\nplt.plot(alpha_rs, received_powers)\nplt.xlabel(r\"$\\alpha_r$\")\nplt.ylabel(\"Received power (dB)\");\nplt.title(\"Impact of the Directivity of the Scattering Pattern\");\n```"
"## Validation Against the Far-Wall Approximation\n\nIf the scattering surface is small compared to the distance from its center to the transmitter and receiver, respectively, it can be approximated by a single scattering source that reradiates parts of the energy it has captured by the entire surface $A$. In other words, the scattered field is well approximated by a single ray originating from the barycenter of the surface [2]. The reason for this behavior is that the scattering angle is almost constant for any point on the surface. As\ndescribed in the [EM Primer](https://nvlabs.github.io/sionna/em_primer.html#scattering), the received power of the scattered path can be computed as\n\n$$\nP_r = \\left(\\frac{\\lambda S \\Gamma}{4\\pi r_i r_s}\\right)^2 f_\\text{s}(\\hat{\\mathbf{k}}_\\text{i}, \\hat{\\mathbf{k}}_\\text{s}) \\cos(\\theta_i) A\n$$\n\nwhich simplifies for a perfect reflector ($\\Gamma=1$) with Lambertian scattering pattern and unit surface area to\n\n$$\nP_r = \\left(\\frac{\\lambda S}{4\\pi r_i r_s}\\right)^2 \\frac{\\cos(\\theta_i)\\cos(\\theta_s)}{\\pi}\n$$\n\nwhere $r_i$ and $r_s$ are the distances between the surface center and the transmitter and receiver, respectively.\n\nWe have constructed our scene such that $r_i=r_s$ and $\\theta_i=\\theta_s=\\pi/4$, so that $\\cos(\\theta_i)=1/\\sqrt{2}$. Thus,\n\n$$\nP_r = \\left(\\frac{\\lambda S}{4\\pi r_i^2 }\\right)^2 \\frac{1}{2\\pi}\n$$\n\nLets validate for which distances $r_i$ this approximation holds.\n\n\n```python\ns = 0.7 # Scattering coefficient\n# Configure the radio material\nscene.get(\"reflector\").radio_material.scattering_pattern = LambertianPattern()\nscene.get(\"reflector\").radio_material.scattering_coefficient = s\n# Set the carrier frequency\nscene.frequency = 3.5e9\nwavelength = scene.wavelength\nr_is = np.array([0.1, 1, 2, 5, 10], np.float32) # Varying distances\nreceived_powers = np.zeros_like(r_is, np.float32)\ntheo_powers = np.zeros_like(received_powers)\nfor i, r_i in enumerate(r_is):\n    # Update the positions of TX and RX\n    d = r_i/np.sqrt(2)\n    scene.get(\"tx\").position = [-d, 0, d]\n    scene.get(\"rx\").position = [d, 0, d]\n    paths = scene.compute_paths(num_samples=1e6, los=False, reflection=False, scattering=True, scat_keep_prob=1.0)\n    received_powers[i] = 10*np.log10(tf.reduce_sum(tf.abs(paths.a)**2))\n    # Compute theoretically received power using the far-wall approximation\n    theo_powers[i] = 10*np.log10((wavelength*s/(4*np.pi*r_i**2))**2/(2*np.pi))\nplt.figure()\nplt.plot(r_is, received_powers)\nplt.plot(r_is, theo_powers, \"--\")\nplt.title(\"Validation of the Scattered Field Power\")\nplt.xlabel(r\"$r_i$ (m)\")\nplt.ylabel(\"Received power (dB)\");\nplt.legend([\"Ray tracing\", \"\\\"Far\\\"-wall approximation\"]);\n```"
"We can observe an almost perfect match between the results for ray-tracing and the far-wall approximation from a distance of $2\\,$m on. For smaller distances, there is a significant (but expected) difference. In general, none of both approaches is valid for very short propagation distances."
"## Coverage Maps With Scattering\n\nBy now, you have a gained a solid understanding of scattering from a single surface. Let us now make things a bit more interesting by looking at a complex scene with many scattering surfaces. This can be nicely observed with the help of coverage maps.\n\nA coverage map describes the average received power from a specific transmitter at every point on a plane. The effects of fast fading, i.e., constructive/destructive interference between different paths, are averaged out by summing the squared amplitudes of all paths. As we cannot compute coverage maps with infinitely fine resolution, they are approximated by small rectangular tiles for which average values are computed. For a detailed explanation, have a look at the <a class=\"reference external\" href=\"https://nvlabs.github.io/sionna/api/rt.html#coverage-map\">API\nDocumentation</a>.\n\nLet us now load a slightly more interesting scene containing a couple of rectangular buildings and add a transmitter. Note that we do not need to add any receivers to compute a coverage map (we will add one though as we need it later).\n\n\n```python\nscene = load_scene(sionna.rt.scene.simple_street_canyon)\nscene.frequency = 30e9\nscene.tx_array = PlanarArray(num_rows=1,\n                             num_cols=1,\n                             vertical_spacing=0.5,\n                             horizontal_spacing=0.5,\n                             pattern=\"iso\",\n                             polarization=\"V\")\nscene.rx_array = scene.tx_array\nscene.add(Transmitter(name=\"tx\",\n                      position=[-33,11,32],\n                      orientation=[0,0,0]))\n# We add a receiver for later path computations\nscene.add(Receiver(name=\"rx\",\n                      position=[27,-13,1.5],\n                      orientation=[0,0,0]))\nmy_cam = Camera(\"my_cam\", position=[10,0,300], look_at=[0,0,0])\nmy_cam.look_at([0,0,0])\nscene.add(my_cam)\n```\n\n\nComputing and visualizing a coverage map is as simple as running the following commands:\n\n\n```python\ncm = scene.coverage_map(cm_cell_size=[1,1], num_samples=20e6, max_depth=5)\nscene.render(my_cam, coverage_map=cm, cm_vmin=-200, cm_vmax=-90);\n```\n\n\nBy default, coverage maps are only computed for line-of-sight and specular reflections. The parameter `cm_cell_size` determines the resolution of the coverage map. However, the finer the resolution, the more rays (i.e., `num_samples`) must be shot. We can see from the above figure, that there are various regions which have no coverage as they cannot be reached by purely reflected paths.\n\nLets now enable diffuse reflections and see what happens."
"```python\n# Configure radio materials for scattering\n# By default the scattering coefficient is set to zero\nfor rm in scene.radio_materials.values():\n    rm.scattering_coefficient = 1/np.sqrt(3) # Try different values in [0,1]\n    rm.scattering_pattern = DirectivePattern(alpha_r=10) # Play around with different values of alpha_r\ncm_scat = scene.coverage_map(cm_cell_size=[1,1], num_samples=20e6, max_depth=5, scattering=True)\nscene.render(my_cam, coverage_map=cm_scat, cm_vmin=-200, cm_vmax=-90);\n```\n\n\nThanks to scattering, most regions in the scene have some coverage. However, the scattered field is weak compared to that of the LoS and reflected paths. Also note that the peak signal strength has slightly decreased. This is because the scattering coefficient takes away some of the specularly reflected energy."
"## Impact on Channel Impulse Response\n\nAs a last experiment in our tutorial on scattering, let us have a look at the discrete baseband-equivalent channel impulse responses we obtain with and without scattering. To this end, we will compute the channel impulse response of the single receiver we have configured for the current scene, and then transform it into the complex baseband representation using the convenience function [cir_to_time_channel](https://nvlabs.github.io/sionna/api/channel.wireless.html#cir-to-time-channel).\n\n\n```python\n# Change the scattering coefficient of all radio materials\nfor rm in scene.radio_materials.values():\n    rm.scattering_coefficient = 1/np.sqrt(3)\nbandwidth=200e6 # bandwidth of the receiver (= sampling frequency)\nplt.figure()\ntf.random.set_seed(20)\npaths = scene.compute_paths(max_depth=5,\n                            num_samples=20e6,\n                            scattering=True)\n# Compute time channel without scattering\nh = np.squeeze(cir_to_time_channel(bandwidth, *paths.cir(scattering=False), 0, 100, normalize=True))\ntau = np.arange(h.shape[0])/bandwidth*1e9\nplt.plot(tau, 20*np.log10(np.abs(h)));\n# Compute time channel with scattering\nh = np.squeeze(cir_to_time_channel(bandwidth, *paths.cir(), 0, 100, normalize=True))\nplt.plot(tau, 20*np.log10(np.abs(h)), \"--\");\nplt.xlabel(r\"Delay $\\tau$ (ns)\")\nplt.ylabel(r\"$|h|^2$ (dB)\");\nplt.title(\"Comparison of Channel Impulse Responses\")\nplt.legend([\"No Scattering\", \"With Scattering\"]);\n```\n\n\nThe discrete channel impulse response looks similar for small values of $\\tau$, where the field is dominated by strong LOS and reflected paths. However, in the middle and tail, there are differences of a few dB which can have a significant impact on the link-level performance."
"## Summary\n\nIn conclusion, scattering plays an important role for radio propagation modelling. In particular, the higher the carrier frequency, the rougher most surfaces appear compared to the wavelength. Thus, at THz-frequencies diffuse reflections might become the dominating form of radio wave propgation (apart from LoS).\n\nWe hope you enjoyed our dive into scattering with this Sionna RT tutorial. Please try out some experiments yourself and improve your grasp of ray tracing. Theres more to discover, so so dont forget to check out our other [tutorials](https://nvlabs.github.io/sionna/tutorials.html), too."
"## References\n\n[1] Vittorio Degli-Esposti et al., [Measurement and modelling of scattering from buildings](https://ieeexplore.ieee.org/abstract/document/4052607), IEEE Trans. Antennas Propag., vol.55, no. 1, pp.143-153, Jan.2007.\n\n[2] Vittorio Degli-Esposti et al., [An advanced field prediction model including diffuse scattering](https://ieeexplore.ieee.org/abstract/document/1310631), IEEE Trans. Antennas Propag., vol.52, no. 7, pp.1717-1728, Jul.2004.[2] Vittorio Degli-Esposti et al., [An advanced field prediction model including diffuse scattering](https://ieeexplore.ieee.org/abstract/document/1310631), IEEE Trans. Antennas Propag., vol.52, no. 7, pp.1717-1728, Jul.2004.[2] Vittorio Degli-Esposti et al., [An advanced field prediction model including diffuse scattering](https://ieeexplore.ieee.org/abstract/document/1310631), IEEE Trans. Antennas Propag., vol.52, no. 7, pp.1717-1728, Jul.2004.[2] Vittorio Degli-Esposti et al., [An advanced field prediction model including diffuse scattering](https://ieeexplore.ieee.org/abstract/document/1310631), IEEE Trans. Antennas Propag., vol.52, no. 7, pp.1717-1728, Jul.2004."

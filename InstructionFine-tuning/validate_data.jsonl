{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain how to import the necessary modules for using the Sionna package in Python."}, {"role": "assistant", "content": "To import the necessary modules for using the Sionna package in Python, you can use the following code:\n\n```python\n# Import Sionna\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n\n# Load the required Sionna components\nfrom sionna.mapping import Constellation, Mapper, Demapper\nfrom sionna.fec.polar import PolarEncoder, Polar5GEncoder, PolarSCLDecoder, Polar5GDecoder, PolarSCDecoder\nfrom sionna.fec.ldpc import LDPC5GEncoder, LDPC5GDecoder\nfrom sionna.fec.polar.utils import generate_5g_ranking, generate_rm_code\nfrom sionna.fec.conv import ConvEncoder, ViterbiDecoder, BCJRDecoder\nfrom sionna.fec.turbo import TurboEncoder, TurboDecoder\nfrom sionna.fec.linear import OSDecoder\nfrom sionna.utils import BinarySource, ebnodb2no\nfrom sionna.utils.metrics import  count_block_errors\nfrom sionna.channel import AWGN\nfrom sionna.utils.plotting import PlotBER\n```\n\nThis code first tries to import the Sionna package. If it is not installed, it installs it using pip and then imports it. After that, it imports the necessary components from the Sionna package."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain how to import necessary modules and packages for using Sionna."}, {"role": "assistant", "content": "To use Sionna, you need to import the necessary modules and packages. Here's how you can do it:\n\n1. Import the necessary modules:\n\n```python\nimport os\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport time\n```\n\n2. Set the environment variables for GPU configuration:\n\n```python\ngpu_num = 0 # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n```\n\n3. Check if the notebook is running in Google Colab:\n\n```python\ntry: \n    import google.colab\n    colab_compat = True \nexcept:\n    colab_compat = False\n```\n\n4. Import Sionna. If it's not installed, install it using pip:\n\n```python\ntry:\n    import sionna\nexcept ImportError as e:\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\n5. Configure the notebook to use only a single GPU and allocate only as much memory as needed:\n\n```python\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n```\n\n6. Set the global random seed for reproducibility:\n\n```python\ntf.random.set_seed(1)\n```\n\n7. Import Sionna RT components and other necessary modules for link-level simulations:\n\n```python\nfrom sionna.rt import load_scene, Transmitter, Receiver, PlanarArray, Camera\nfrom sionna.channel import cir_to_ofdm_channel, subcarrier_frequencies, OFDMChannel, ApplyOFDMChannel, CIRDataset\nfrom sionna.nr import PUSCHConfig, PUSCHTransmitter, PUSCHReceiver\nfrom sionna.utils import compute_ber, ebnodb2no, PlotBER\nfrom sionna.ofdm import KBestDetector, LinearDetector\nfrom sionna.mimo import StreamManagement\n```\n\nPlease note that the exact modules and packages you need to import may vary depending on your specific use case."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the details of BCJRDecoder, such as the default parameters, the link of the source code of BCJRDecoder."}, {"role": "assistant", "content": "Here is the definition of BCJRDecoder: sionna.fec.conv.BCJRDecoder(encoder=None, gen_poly=None, rate=1 / 2, constraint_length=3, rsc=False, terminate=False, hard_out=True, algorithm='map', output_dtype=tf.float32, **kwargs).  \nAnd here is the link of the source code, [BCJRDecoder](https://nvlabs.github.io/sionna/_modules/sionna/fec/conv/decoding.html#BCJRDecoder).  \n  "}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain how to compute the Doppler shift for a specific path in Sionna."}, {"role": "assistant", "content": "To compute the Doppler shift for a specific path in Sionna, you need to follow these steps:\n\n1. Load the scene and configure the objects: You need to load the scene where the Doppler shift will be computed. This scene should include the objects that will be moving. Each object in the scene has a `position` and `orientation` property that can be inspected and modified.\n\n2. Assign velocity vectors: Assign a velocity vector to all moving objects in the scene. This velocity vector will be used to compute the Doppler shift.\n\n3. Compute the propagation paths: Add a transmitter and a receiver to the scene and compute the propagation paths using the `compute_paths` method.\n\n4. Apply the Doppler shift: Every path has a property `Paths.doppler` that corresponds to the aggregated Doppler shift due to the movement of objects it intersects. This property does not account for the additional Doppler shifts caused by possible movements of the transmitter and receiver. To compute the time evolution of the channel impulse response, use the `apply_doppler` method of a `Paths` object.\n\nThe Doppler shift for a specific path can be computed using the following formula:\n\n    f_\u0394 = 1/\u03bb [v_0^T k_0 - v_{n+1}^T k_n + \u03a3_{i=1}^n v_i^T (k_i - k_{i-1})]\n\nwhere \u03bb is the wavelength, v_i is the velocity vector of the i-th object, and k_i is the outgoing ray direction at the i-th scattering point. The first and last point correspond to the transmitter and receiver, respectively.\n\nPlease note that the above steps are a general guide. The exact implementation may vary depending on the specific requirements of your simulation."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain how to simulate a transmission in Sionna, including defining the number of bits per symbol, code rate, binary source, encoder, mapper, resource grid mapper, frequency domain channel, LS channel estimator, LMMSE equalizer, demapper, and decoder."}, {"role": "assistant", "content": "To simulate a transmission in Sionna, follow these steps:\n\n1. **Define the number of bits per symbol and code rate**: This is done by setting the variables `NUM_BITS_PER_SYMBOL` and `CODERATE`. For example, for QPSK modulation and a code rate of 0.5, you would set `NUM_BITS_PER_SYMBOL = 2` and `CODERATE = 0.5`.\n\n2. **Define the binary source**: This is done by creating an instance of the `BinarySource` class from the `sn.utils` module. This will generate batches of information bits.\n\n3. **Define the encoder**: This is done by creating an instance of the `LDPC5GEncoder` class from the `sn.fec.ldpc` module. This will map information bits to coded bits.\n\n4. **Define the mapper**: This is done by creating an instance of the `Mapper` class from the `sn.mapping` module. This will map blocks of information bits to constellation symbols.\n\n5. **Define the resource grid mapper**: This is done by creating an instance of the `ResourceGridMapper` class from the `sn.ofdm` module. This will map symbols onto an OFDM resource grid.\n\n6. **Define the frequency domain channel**: This is done by creating an instance of the `OFDMChannel` class from the `sn.channel` module. This will simulate the channel in the frequency domain and take care of sampling channel impulse responses, computing the frequency responses, and applying the channel transfer function to the channel inputs (including AWGN).\n\n7. **Define the LS channel estimator**: This is done by creating an instance of the `LSChannelEstimator` class from the `sn.ofdm` module. This will provide channel estimates and error variances.\n\n8. **Define the LMMSE equalizer**: This is done by creating an instance of the `LMMSEEqualizer` class from the `sn.ofdm` module. This will provide soft symbols together with noise variance estimates.\n\n9. **Define the demapper**: This is done by creating an instance of the `Demapper` class from the `sn.mapping` module. This will produce LLR for all coded bits.\n\n10. **Define the decoder**: This is done by creating an instance of the `LDPC5GDecoder` class from the `sn.fec.ldpc` module. This will provide hard-decisions on the information bits.\n\nAfter defining all these components, you can simulate the transmission by calling these components in the correct order and passing the appropriate inputs to each component. The output of one component should be the input to the next component in the transmission chain."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Define the channel frequency response and how it is calculated."}, {"role": "assistant", "content": "The channel frequency response is a measure of how a system, in this case a communication channel, modifies the input signal in terms of its frequency components. It describes the behavior of the system for each frequency component of the input signal. \n\nThe channel frequency response is calculated by taking the Fourier transform of the channel impulse response. The channel impulse response is a function that describes the response of the system to an impulse input signal. By taking the Fourier transform of this function, we obtain a function of frequency that describes how the system modifies the amplitude and phase of each frequency component of the input signal.\n\nIn the context provided, the channel impulse response is mentioned but the channel frequency response is not explicitly defined or calculated. However, it can be inferred that the channel frequency response would be an important concept in the context of wireless propagation modelling, as it would provide information about how the channel modifies the frequency components of the transmitted signal."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Provide instructions on defining frozen bit positions and codeword length for creating an instance of the PolarSCDecoder."}, {"role": "assistant", "content": "To create an instance of the `PolarSCDecoder` from the Sionna Polar code module, you need to define the positions of the frozen bits and the length of the codeword. The frozen bits are the positions in the codeword which are set to a known value (typically 0) as per the Polar coding scheme, and the remaining non-frozen positions are used for the actual information bits. The `PolarSCDecoder` class requires you to specify where these frozen bits are located.\n\nHere are the steps to define the frozen bit positions (frozen_pos) and the codeword length (n) for a `PolarSCDecoder`:\n\n1. Determine the number of information bits (k) and the codeword length (n). The number of frozen bits will be n - k.\n\n2. Generate the positions of the frozen bits. You can use the function `generate_5g_ranking(k, n)` provided by the Sionna library to obtain the frozen bit positions for a 5G Polar code. This function will output both the frozen positions (`frozen_pos`) and the information positions (`info_pos`), but for the decoder, you will need only `frozen_pos`.\n\n3. Import the `generate_5g_ranking` function:\n   ```python\n   from sionna.fec.polar.utils import generate_5g_ranking\n   ```\n\n4. Call the `generate_5g_ranking` function with your specified values of k and n:\n   ```python\n   k = # your number of information bits\n   n = # your codeword length\n\n   frozen_pos, info_pos = generate_5g_ranking(k, n)\n   ```\n\n5. Create an instance of the `PolarSCDecoder` by passing `frozen_pos` and `n` as arguments:\n   ```python\n   from sionna.fec.polar.decoding import PolarSCDecoder\n\n   sc_decoder = PolarSCDecoder(frozen_pos=frozen_pos, n=n)\n   ```\n   \nEnsure that n is a power of 2 and that both k and n are within the supported range of the library (and satisfy any other constraints for Polar codes). The `generate_5g_ranking` function performs checks on the input values, and it will raise an error if these conditions are not met.\n\nLastly, note that the `PolarSCDecoder` assumes by default that the frozen bits are set to 0. If you require a different behaviour (e.g., frozen bits being set to 1), you may need to adjust the provided context accordingly, although this may not be supported directly through the Sionna API and may entail a deeper customization of the decoder's implementation."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain how to access the source code of a class in Sionna."}, {"role": "assistant", "content": "To access the source code of a class in Sionna, you can use the double question mark (??) operator in Python. This operator is used to display the source code of a function or a class. Here is an example of how you can do it:\n\n```python\n# Import Sionna\nimport sionna as sn\n\n# Access the source code of a class, for example, the Mapper class\nsn.mapping.Mapper??\n```\n\nThis will display the source code of the Mapper class in the output. You can replace `Mapper` with the name of any other class you want to inspect.\n\nPlease note that this method works in interactive Python environments like Jupyter notebooks or IPython shells. If you're using a different environment, you might need to use other methods to access the source code."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the definition of ResourceGridMapper, such as the default parameters, the link of the source code and explanation."}, {"role": "assistant", "content": "Here is the definition of ResourceGridMapper: sionna.ofdm.ResourceGridMapper(resource_grid, dtype=tf.complex64, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/resource_grid.html#ResourceGridMapper)\n\nsource code:\n```python\nclass ResourceGridMapper(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"ResourceGridMapper(resource_grid, dtype=tf.complex64, **kwargs)\n\n    Maps a tensor of modulated data symbols to a ResourceGrid.\n\n    This layer takes as input a tensor of modulated data symbols\n    and maps them together with pilot symbols onto an\n    OFDM :class:`~sionna.ofdm.ResourceGrid`. The output can be\n    converted to a time-domain signal with the\n    :class:`~sionna.ofdm.Modulator` or further processed in the\n    frequency domain.\n\n    Parameters\n    ----------\n    resource_grid : ResourceGrid\n        An instance of :class:`~sionna.ofdm.ResourceGrid`.\n\n    dtype : tf.Dtype\n        Datatype for internal calculations and the output dtype.\n        Defaults to `tf.complex64`.\n\n    Input\n    -----\n    : [batch_size, num_tx, num_streams_per_tx, num_data_symbols], tf.complex\n        The modulated data symbols to be mapped onto the resource grid.\n\n    Output\n    ------\n    : [batch_size, num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size], tf.complex\n        The full OFDM resource grid in the frequency domain.\n    \"\"\"\n    def __init__(self, resource_grid, dtype=tf.complex64, **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        self._resource_grid = resource_grid\n\n    def build(self, input_shape): # pylint: disable=unused-argument\n        \"\"\"Precompute a tensor of shape\n        [num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size]\n        which is prefilled with pilots and stores indices\n        to scatter data symbols.\n        \"\"\"\n        self._rg_type = self._resource_grid.build_type_grid()\n        self._pilot_ind = tf.where(self._rg_type==1)\n        self._data_ind = tf.where(self._rg_type==0)\n\n    def call(self, inputs):\n        # Map pilots on empty resource grid\n        pilots = flatten_last_dims(self._resource_grid.pilot_pattern.pilots, 3)\n        template = tf.scatter_nd(self._pilot_ind,\n                                 pilots,\n                                 self._rg_type.shape)\n        template = tf.expand_dims(template, -1)\n\n        # Broadcast the resource grid template to batch_size\n        batch_size = tf.shape(inputs)[0]\n        new_shape = tf.concat([tf.shape(template)[:-1], [batch_size]], 0)\n        template = tf.broadcast_to(template, new_shape)\n\n        # Flatten the inputs and put batch_dim last for scatter update\n        inputs = tf.transpose(flatten_last_dims(inputs, 3))\n        rg = tf.tensor_scatter_nd_update(template, self._data_ind, inputs)\n        rg = tf.transpose(rg, [4, 0, 1, 2, 3])\n\n        return rg\n```"}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the details of function relocate_uts, such as the input and output of the class instance ,the link of source code and source itself."}, {"role": "assistant", "content": "Here is the detailed information of relocate_uts:   \n[sionna.channel.relocate_uts(ut_loc, sector_id, cell_loc)](https://nvlabs.github.io/sionna/_modules/sionna/channel/utils.html#relocate_uts)\n\nRelocate the UTs by rotating them into the sector with index sector_id and transposing them to the cell centered on cell_loc.\n\nsector_id gives the index of the sector to which the UTs are rotated to. The picture below shows how the three sectors of a cell are indexed. Like this [pic](https://nvlabs.github.io/sionna/_images/panel_array_sector_id.png)  \n  \nIf sector_id is a scalar, then all UTs are relocated to the same sector indexed by sector_id. If sector_id is a tensor, it should be broadcastable with [batch_size, num_ut], and give the sector in which each UT or batch example is relocated to.\n\nWhen calling the function, ut_loc gives the locations of the UTs to relocate, which are all assumed to be in sector with index 0, and in the cell centered on the origin (0,0).  \n  \n**Input**\n\n- `ut_loc` ([batch_size, num_ut, 2], tf.float): UTs locations in the X-Y plane.\n- `sector_id` (Tensor broadcastable with [batch_size, num_ut], int): Indexes of the sector to which to relocate the UTs.\n- `cell_loc` (Tensor broadcastable with [batch_size, num_ut], tf.float): Center of the cell to which to transpose the UTs.\n\n**Output**\n\n- `ut_loc` ([batch_size, num_ut, 2], tf.float): Relocated UTs locations in the X-Y plane.\n\nsource code:\n```python\ndef relocate_uts(ut_loc, sector_id, cell_loc):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Relocate the UTs by rotating them into the sector with index ``sector_id``\n    and transposing them to the cell centered on ``cell_loc``.\n\n    ``sector_id`` gives the index of the sector to which the UTs are\n    rotated to. The picture below shows how the three sectors of a cell are\n    indexed.\n\n    .. figure:: ../figures/panel_array_sector_id.png\n        :align: center\n        :scale: 30%\n\n        Indexing of sectors\n\n    If ``sector_id`` is a scalar, then all UTs are relocated to the same\n    sector indexed by ``sector_id``.\n    If ``sector_id`` is a tensor, it should be broadcastable with\n    [``batch_size``, ``num_ut``], and give the sector in which each UT or\n    batch example is relocated to.\n\n    When calling the function, ``ut_loc`` gives the locations of the UTs to\n    relocate, which are all assumed to be in sector with index 0, and in the\n    cell centered on the origin (0,0).\n\n    Input\n    --------\n    ut_loc : [batch_size, num_ut, 2], tf.float\n        UTs locations in the X-Y plan\n\n    sector_id : Tensor broadcastable with [batch_size, num_ut], int\n        Indexes of the sector to which to relocate the UTs\n\n    cell_loc : Tensor broadcastable with [batch_size, num_ut], tf.float\n        Center of the cell to which to transpose the UTs\n\n    Output\n    ------\n    ut_loc : [batch_size, num_ut, 2], tf.float\n        Relocated UTs locations in the X-Y plan\n    \"\"\"\n\n    # Expand the rank of sector_id such that is is broadcastable with\n    # (batch size, num_ut)\n    sector_id = tf.cast(sector_id, ut_loc.dtype)\n    sector_id = expand_to_rank(sector_id, 2, 0)\n\n    # Expant\n    cell_loc = tf.cast(cell_loc, ut_loc.dtype)\n    cell_loc = expand_to_rank(cell_loc, tf.rank(ut_loc), 0)\n\n    # Rotation matrix tensor, broadcastable with [batch size, num uts, 2, 2]\n    rotation_angle = sector_id*2.*PI/3.0\n    rotation_matrix = tf.stack([tf.math.cos(rotation_angle),\n                                -tf.math.sin(rotation_angle),\n                                tf.math.sin(rotation_angle),\n                                tf.math.cos(rotation_angle)],\n                               axis=-1)\n    rotation_matrix = tf.reshape(rotation_matrix,\n                                 tf.concat([tf.shape(rotation_angle),\n                                            [2,2]], axis=-1))\n    rotation_matrix = tf.cast(rotation_matrix, ut_loc.dtype)\n\n    # Applying the rotation matrix\n    ut_loc = tf.expand_dims(ut_loc, axis=-1)\n    ut_loc_rotated = tf.squeeze(rotation_matrix@ut_loc, axis=-1)\n\n    # Translate to the BS location\n    ut_loc_rotated_translated = ut_loc_rotated + cell_loc\n\n    return ut_loc_rotated_translated\n```"}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain how to simulate the effects of mobility with Sionna's ray tracing module."}, {"role": "assistant", "content": "To simulate the effects of mobility with Sionna's ray tracing module, you can follow these steps:\n\n1. **Controlling Position and Orientation of Scene Objects**: Every object in a scene has a `position` and `orientation` property that can be inspected and modified. You can change the position and orientation of the object as per your requirements. For example, you can move a car 10m along the y-axis and rotate it by 90 degrees around the z-axis.\n\n2. **Time Evolution of Channels Via Doppler Shift**: You can simulate the impact of movement of scene objects on the channel impulse response by assigning to all moving objects a velocity vector based on which path-wise Doppler shifts can be computed. You can then add a transmitter and receiver to the scene and compute the propagation paths. Every path has a property `Paths.doppler` that corresponds to the aggregated Doppler shift due to the movement of objects it intersects.\n\n3. **Example: Delay-Doppler Spectrum**: You can use the Doppler shifts to compute a time-varying channel impulse response and estimate its Delay-Doppler spectrum. You can compute the time evolution of the channel impulse response and then compute the Delay-Doppler spectrum.\n\n4. **Comparison of Doppler- vs Position-based Time Evolution**: You can compare a time-varying channel frequency impulse response generated by the application of Doppler shifts against another one obtained by physically moving objects in a scene and retracing the paths. You can compute a sequence of channel frequency responses by moving all cars as well as the transmitter and receiver in the scene. After each step, propagation paths are traced and the corresponding channel frequency response is computed.\n\nRemember, the approach of moving objects in a scene and recomputing paths is computationally intensive but accurate while the approach of computing the time evolution of channels synthetically based on the Doppler shifts is much faster but only accurate over short time spans during which the scene objects have moved very short distances. Both approaches can be combined to simulate mobility over longer periods of time."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain how to define the system parameters for the simulation as a dictionary using the Sionna Python package."}, {"role": "assistant", "content": "To define the system parameters for the simulation as a dictionary using the Sionna Python package, you can follow these steps:\n\n1. First, you need to import the necessary libraries. In this case, you would need to import the Sionna package.\n\n```python\nimport sionna\n```\n\n2. Next, define your system parameters as key-value pairs in a Python dictionary. Each key represents a parameter name, and the corresponding value represents the parameter's value. \n\nFor example, you might have a dictionary like this:\n\n```python\nsys_params = {\n    \"carrier_frequency\" : 3.5e9,\n    \"delay_spread\" : 100e-9,\n    \"min_speed\" : 3,\n    \"max_speed\" : 3,\n    \"tdl_model\" : \"A\",\n    \"fft_size\" : 256,\n    \"subcarrier_spacing\" : 30e3,\n    \"num_ofdm_symbols\" : 14,\n    \"cyclic_prefix_length\" : 16,\n    \"pilot_ofdm_symbol_indices\" : [2, 11],\n    \"coderate\" : 0.5,\n    \"num_bits_per_symbol\" : 4,\n    \"demapping_method\" : \"app\",\n    \"cn_type\" : \"boxplus\",\n    \"bp_iter\" : 20\n}\n```\n\n3. You can then use these parameters in your simulation by accessing the values in the dictionary using the appropriate keys. \n\nFor example, if you want to use the 'carrier_frequency' parameter in your simulation, you can access it like this:\n\n```python\ncarrier_frequency = sys_params[\"carrier_frequency\"]\n```\n\nRemember that the keys in the dictionary must match exactly with the parameter names used in the Sionna package. If they don't match, you will get a KeyError."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the definition of class GenerateFlatFadingChannel, such as the default parameters, the link of the source code and explanation."}, {"role": "assistant", "content": "Here is the definition of GenerateFlatFadingChannel: sionna.channel.GenerateFlatFadingChannel(num_tx_ant, num_rx_ant, spatial_corr=None, dtype=tf.complex64, **kwargs)  \n  \n[source code:](https://nvlabs.github.io/sionna/_modules/sionna/channel/flat_fading_channel.html#GenerateFlatFadingChannel)\n```python\nclass GenerateFlatFadingChannel():\n    # pylint: disable=line-too-long\n    r\"\"\"Generates tensors of flat-fading channel realizations.\n\n    This class generates batches of random flat-fading channel matrices.\n    A spatial correlation can be applied.\n\n    Parameters\n    ----------\n    num_tx_ant : int\n        Number of transmit antennas.\n\n    num_rx_ant : int\n        Number of receive antennas.\n\n    spatial_corr : SpatialCorrelation, None\n        An instance of :class:`~sionna.channel.SpatialCorrelation` or `None`.\n        Defaults to `None`.\n\n    dtype : tf.complex64, tf.complex128\n        The dtype of the output. Defaults to `tf.complex64`.\n\n    Input\n    -----\n    batch_size : int\n        The batch size, i.e., the number of channel matrices to generate.\n\n    Output\n    ------\n    h : [batch_size, num_rx_ant, num_tx_ant], ``dtype``\n        Batch of random flat fading channel matrices.\n\n    \"\"\"\n    def __init__(self, num_tx_ant, num_rx_ant, spatial_corr=None, dtype=tf.complex64, **kwargs):\n        super().__init__(**kwargs)\n        self._num_tx_ant = num_tx_ant\n        self._num_rx_ant = num_rx_ant\n        self._dtype = dtype\n        self.spatial_corr = spatial_corr\n\n    @property\n    def spatial_corr(self):\n        \"\"\"The :class:`~sionna.channel.SpatialCorrelation` to be used.\"\"\"\n        return self._spatial_corr\n\n    @spatial_corr.setter\n    def spatial_corr(self, value):\n        self._spatial_corr = value\n\n    def __call__(self, batch_size):\n        # Generate standard complex Gaussian matrices\n        shape = [batch_size, self._num_rx_ant, self._num_tx_ant]\n        h = complex_normal(shape, dtype=self._dtype)\n\n        # Apply spatial correlation\n        if self.spatial_corr is not None:\n            h = self.spatial_corr(h)\n\n        return h\n```      \n  "}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Describe how to set up the end-to-end model using the Sionna Python package."}, {"role": "assistant", "content": "To set up the end-to-end model using the Sionna Python package, follow these steps:\n\n1. Install the Sionna package if it's not already installed. You can do this using pip: `pip install sionna`.\n\n2. Import the necessary packages and modules. This includes `os`, `numpy`, `tensorflow`, `matplotlib.pyplot`, and of course, `sionna`.\n\n3. Set the environment variables for CUDA_VISIBLE_DEVICES and TF_CPP_MIN_LOG_LEVEL.\n\n4. Create an instance of the Sionna class.\n\n5. Define your system parameters as a dictionary. This includes parameters for the channel, OFDM, code & modulation, etc.\n\n6. Initialize the end-to-end model with the system parameters.\n\n7. Call the model to simulate the BER for the given simulation parameters.\n\n8. Run some throughput tests in eager, graph, and graph with XLA modes.\n\n9. Perform Bit-Error Rate (BER) Monte-Carlo Simulations.\n\n10. Plot the results using the built-in plotting function in Sionna.\n\nRemember to handle exceptions and errors appropriately, especially when importing the Sionna package and when calling the model. Also, ensure that the system parameters are correctly set according to your specific requirements."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the details of function zero_forcing_precoder, such as the input and output of the class instance ,the link of source code and source itself."}, {"role": "assistant", "content": "Here is the detailed information of zero_forcing_precoder:   \n\n[sionna.mimo.zero_forcing_precoder(x, h, return_precoding_matrix=False)])(https://nvlabs.github.io/sionna/_modules/sionna/mimo/precoding.html#zero_forcing_precoder)\n\nZero-Forcing (ZF) Precoder\n\nThis function implements ZF precoding for a MIMO link, assuming the following model: $\\mathbf{y} = \\mathbf{H}\\mathbf{G}\\mathbf{x} + \\mathbf{n}$ where $\\mathbf{y}\\in\\mathbb{C}^K$ is the received signal vector, $\\mathbf{H}\\in\\mathbb{C}^{K\\times M}$ is the known channel matrix, $\\mathbf{G}\\in\\mathbb{C}^{M\\times K}$ is the precoding matrix, $\\mathbf{x}\\in\\mathbb{C}^K$ is the symbol vector to be precoded, and $\\mathbf{n}\\in\\mathbb{C}^K$ is a noise vector. It is assumed that $K\\le M$.\n\nThe precoding matrix $\\mathbf{G}$ is defined as (Eq. 4.37) [Emil Bj\u00f6rnson, Jakob Hoydis and Luca Sanguinetti (2017), \u201cMassive MIMO Networks: Spectral, Energy, and Hardware Efficiency\u201d, Foundations and Trends in Signal Processing: Vol. 11, No. 3-4, pp 154\u2013655.] :\n$\\mathbf{G} = \\mathbf{V}\\mathbf{D}$\nwhere\n$\\begin{split}\\mathbf{V} &= \\mathbf{H}^{\\mathsf{H}}\\left(\\mathbf{H} \\mathbf{H}^{\\mathsf{H}}\\right)^{-1}\\\\\n\\mathbf{D} &= \\mathop{\\text{diag}}\\left( \\lVert \\mathbf{v}_{k} \\rVert_2^{-1}, k=0,\\dots,K-1 \\right).\\end{split}$\n\nThis ensures that each stream is precoded with a unit-norm vector, i.e., $\\mathop{\\text{tr}}\\left(\\mathbf{G}\\mathbf{G}^{\\mathsf{H}}\\right)=K$. The function returns the precoded vector $\\mathbf{G}\\mathbf{x}$ .\n\n**Input**\n\n- `x` ([..., K], tf.complex): 1+D tensor containing the symbol vectors to be precoded.\n- `h` ([..., K, M], tf.complex): 2+D tensor containing the channel matrices.\n- `return_precoding_matrices` (bool): Indicates if the precoding matrices should be returned. Defaults to False.\n\n**Output**\n\n- `x_precoded` ([..., M], tf.complex): Tensor of the same shape and dtype as `x` except the last dimension changes from K to M. It contains the precoded symbol vectors.\n- `g` ([..., M, K], tf.complex): 2+D tensor containing the precoding matrices. This tensor is only returned if `return_precoding_matrices` is True.\n\n**Note:** If you want to use this function in Graph mode with XLA, i.e., within a function that is decorated with @tf.function(jit_compile=True), you must set sionna.Config.xla_compat=true. See xla_compat.\n\nsource code:\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\"\"\"Classes and functions related to MIMO transmit precoding\"\"\"\n\nimport tensorflow as tf\nfrom sionna.utils import matrix_inv\n\ndef zero_forcing_precoder(x, h, return_precoding_matrix=False):\n    # pylint: disable=line-too-long\n    r\"\"\"Zero-Forcing (ZF) Precoder\n\n    This function implements ZF precoding for a MIMO link, assuming the\n    following model:\n\n    .. math::\n\n        \\mathbf{y} = \\mathbf{H}\\mathbf{G}\\mathbf{x} + \\mathbf{n}\n\n    where :math:`\\mathbf{y}\\in\\mathbb{C}^K` is the received signal vector,\n    :math:`\\mathbf{H}\\in\\mathbb{C}^{K\\times M}` is the known channel matrix,\n    :math:`\\mathbf{G}\\in\\mathbb{C}^{M\\times K}` is the precoding matrix,\n    :math:`\\mathbf{x}\\in\\mathbb{C}^K` is the symbol vector to be precoded,\n    and :math:`\\mathbf{n}\\in\\mathbb{C}^K` is a noise vector. It is assumed that\n    :math:`K\\le M`.\n\n    The precoding matrix :math:`\\mathbf{G}` is defined as (Eq. 4.37) [BHS2017]_ :\n\n    .. math::\n\n        \\mathbf{G} = \\mathbf{V}\\mathbf{D}\n\n    where\n\n    .. math::\n\n        \\mathbf{V} &= \\mathbf{H}^{\\mathsf{H}}\\left(\\mathbf{H} \\mathbf{H}^{\\mathsf{H}}\\right)^{-1}\\\\\n        \\mathbf{D} &= \\mathop{\\text{diag}}\\left( \\lVert \\mathbf{v}_{k} \\rVert_2^{-1}, k=0,\\dots,K-1 \\right).\n\n    This ensures that each stream is precoded with a unit-norm vector,\n    i.e., :math:`\\mathop{\\text{tr}}\\left(\\mathbf{G}\\mathbf{G}^{\\mathsf{H}}\\right)=K`.\n    The function returns the precoded vector :math:`\\mathbf{G}\\mathbf{x}`.\n\n    Input\n    -----\n    x : [...,K], tf.complex\n        1+D tensor containing the symbol vectors to be precoded.\n\n    h : [...,K,M], tf.complex\n        2+D tensor containing the channel matrices\n\n    return_precoding_matrices : bool\n        Indicates if the precoding matrices should be returned or not.\n        Defaults to False.\n\n    Output\n    -------\n    x_precoded : [...,M], tf.complex\n        Tensor of the same shape and dtype as ``x`` apart from the last\n        dimensions that has changed from `K` to `M`. It contains the\n        precoded symbol vectors.\n\n    g : [...,M,K], tf.complex\n        2+D tensor containing the precoding matrices. It is only returned\n        if ``return_precoding_matrices=True``.\n\n    Note\n    ----\n    If you want to use this function in Graph mode with XLA, i.e., within\n    a function that is decorated with ``@tf.function(jit_compile=True)``,\n    you must set ``sionna.Config.xla_compat=true``.\n    See :py:attr:`~sionna.Config.xla_compat`.\n    \"\"\"\n\n    # Compute pseudo inverse for precoding\n    g = tf.matmul(h, h, adjoint_b=True)\n    g = tf.matmul(h, matrix_inv(g), adjoint_a=True)\n\n    # Normalize each column to unit power\n    norm = tf.sqrt(tf.reduce_sum(tf.abs(g)**2, axis=-2, keepdims=True))\n    g = g/tf.cast(norm, g.dtype)\n\n    # Expand last dim of `x` for precoding\n    x_precoded = tf.expand_dims(x, -1)\n\n    # Precode\n    x_precoded = tf.squeeze(tf.matmul(g, x_precoded), -1)\n\n    if return_precoding_matrix:\n        return (x_precoded, g)\n    else:\n        return x_precoded\n```"}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Describe the impact of the number of rays shot on the number of scattered paths."}, {"role": "assistant", "content": "The number of rays shot in a scattering experiment directly impacts the number of scattered paths. Essentially, any ray that hits a surface will be scattered towards the receiver. Therefore, the more rays that are shot, the more scattered paths there will be. For instance, in the given context, when the number of rays shot was increased from 2 million to 10 million, the number of scattered paths increased from 4400 to 22572. However, it's important to note that while the number of rays hitting the surface increases with the total number of rays shot, the total received energy across the surface remains constant as the transmitted energy is equally divided between all rays."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain the function of the \"call_inverse\" function in \"RowColumnInterleaver\"."}, {"role": "assistant", "content": "The \"call_inverse\" function in the \"RowColumnInterleaver\" class is a deinterleaver function that corresponds to the call() function. It takes as input a 2+D tensor of arbitrary shape and arbitrary dtype, which must have at least a rank of two. The output of the function is also a 2+D tensor, with the same shape and dtype as the input.\n\nIn other words, the \"call_inverse\" function serves to revert the tensor permutations made by the call() function in the \"RowColumnInterleaver\" class. If the call() function was used to interleave (or rearrange) the elements of a tensor, the \"call_inverse\" function can be used to deinterleave, or restore the original order of the elements in the tensor."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "List the assumptions made when using the 'TimeChannel' class."}, {"role": "assistant", "content": "The text does not provide enough information about any assumptions made when using the 'TimeChannel' class."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the details of function j_fun_tf, such as the input parameters and return output, the link of the source code and source code itself."}, {"role": "assistant", "content": "Here is the detailed information of j_fun_tf: [sionna.fec.utils.j_fun_tf(mu, verify_inputs=True)](https://nvlabs.github.io/sionna/_modules/sionna/fec/utils.html#j_fun_tf)  \n  \nCalculates the J-function in Tensorflow.\n\nThe so-called J-function relates mutual information to the mean of Gaussian distributed LLRs (cf. Gaussian approximation). We use the approximation as proposed in [F. Brannstrom, L. K. Rasmussen, and A. J. Grant, \u201cConvergence analysis and optimal scheduling for multiple concatenated codes,\u201d IEEE Trans. Inform. Theory, vol. 51, no. 9, pp. 3354\u20133364, 2005.] which can be written as $J(\\mu) \\approx \\left( 1- 2^{H_\\text{1}(2\\mu)^{H_\\text{2}}}\\right)^{H_\\text{2}}$ with denoting the mean value of the LLR distribution and $H_\\text{1}=0.3073$, $H_\\text{2}=0.8935$ and $H_\\text{3}=1.1064$.  \n  \n\nInput\n        mu (tf.float32) \u2013 Tensor of arbitrary shape.\n        verify_inputs (bool) \u2013 A boolean defaults to True. If True, mu is clipped internally to be numerical stable.\n\nOutput\n    tf.float32 \u2013 Tensor of same shape and dtype as mu.\n\nRaises\n    InvalidArgumentError \u2013 If mu is negative.  \n  \nsource code:  \n```python\ndef j_fun_tf(mu, verify_inputs=True):\n     # pylint: disable=line-too-long\n    r\"\"\"Calculates the `J-function` in Tensorflow.\n\n    The so-called `J-function` relates mutual information to the mean of\n    Gaussian distributed LLRs (cf. Gaussian approximation). We use the\n    approximation as proposed in [Brannstrom]_ which can be written as\n\n    .. math::\n\n        J(\\mu) \\approx \\left( 1- 2^{H_\\text{1}(2\\mu)^{H_\\text{2}}}\\right)^{H_\\text{2}}\n\n    with :math:`\\mu` denoting the mean value of the LLR distribution and\n    :math:`H_\\text{1}=0.3073`, :math:`H_\\text{2}=0.8935` and\n    :math:`H_\\text{3}=1.1064`.\n\n    Input\n    -----\n        mu : tf.float32\n            Tensor of arbitrary shape.\n\n        verify_inputs : bool\n            A boolean defaults to True. If True, ``mu`` is clipped internally\n            to be numerical stable.\n\n    Output\n    ------\n        : tf.float32\n            Tensor of same shape and dtype as ``mu``.\n\n    Raises\n    ------\n        InvalidArgumentError\n            If ``mu`` is negative.\n    \"\"\"\n    assert isinstance(verify_inputs, bool), \"verify_inputs must be bool.\"\n    if verify_inputs:\n        # input must be positive for numerical stability\n        mu = tf.maximum(mu, 1e-10)\n    else:\n        tf.debugging.assert_greater_equal(mu, 0., \"mu must be positive.\")\n\n    h1 = 0.3073\n    h2 = 0.8935\n    h3 = 1.1064\n    mi = (1-2**(-h1*(2*mu)**h2))**h3\n    return mi\n```  \n  "}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Understand and provide clear instructions for implementing Antenna and AntennaArray classes in Sionna."}, {"role": "assistant", "content": "class Antenna:\n\nTo implement the Antenna class in Sionna, we need to provide the parameters for polarization, polarization_type, antenna_pattern,carrier_frequency and data type. The parameters num_rows_per_panel, num_cols_per_panel, polarization, polarization_type, antenna_pattern, carrier_frequency are compulsory to define. \n\nLet's look at how we can create an instance of this class:\n\n```python\nantenna = sionna.channel.tr38901.Antenna(polarization = 'single',\n                                         polarization_type = 'V', \n                                         antenna_pattern = 'omni',\n                                         carrier_frequency = 3.5e9)\n```\nThis creates a single antenna following the 3GPP TR 38.901 specification which has a single vertically polarized omni pattern and operates at a carrier frequency of 3.5 GHz.\n\n\nclass AntennaArray:\n\nFor the AntennaArray class, we need parameters num_rows, num_cols, polarization, polarization_type, antenna_pattern, carrier_frequency, and dtype to create an instance of the class.\n\nHere's how we instantiate the AntennaArray class:\n\n```python\nantenna_array = sionna.channel.tr38901.AntennaArray(num_rows=1, \n                                                    num_cols=1,\n                                                    polarization='single', \n                                                    polarization_type='V',\n                                                    antenna_pattern='omni',\n                                                    carrier_frequency=3.5e9)\n```\n\nThis creates an array of antennas in Sionna with 1 row and 1 column, a single polarization type 'V' (vertical), an 'omni' antenna pattern, and a carrier frequency of 3.5 GHz.\n\nIt's also important to note that in real-world situations, these properties may be updated or modified based on the requirements of the wireless system being modeled.\n\nNote: The antenna model and antenna array model are special cases in Sionna and you can achieve more complex antenna models by using PanelArray class. So, you should choose the class according to your use case. Use Antenna or AntennaArray for simpler models with single or multiple antennas, and PanelArray for more complex antenna models."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the definition of OFDMDetector, such as the default parameters, the link of the source code and explanation."}, {"role": "assistant", "content": "Here is the definition of OFDMDetector: sionna.ofdm.OFDMDetector(detector, output, resource_grid, stream_management, dtype=tf.complex64, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/detection.html#OFDMDetector)  \n\n```python\nclass OFDMDetector(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"OFDMDetector(detector, output, resource_grid, stream_management, dtype=tf.complex64, **kwargs)\n\n    Layer that wraps a MIMO detector for use with the OFDM waveform.\n\n    The parameter ``detector`` is a callable (e.g., a function) that\n    implements a MIMO detection algorithm for arbitrary batch dimensions.\n\n    This class pre-processes the received resource grid ``y`` and channel\n    estimate ``h_hat``, and computes for each receiver the\n    noise-plus-interference covariance matrix according to the OFDM and stream\n    configuration provided by the ``resource_grid`` and\n    ``stream_management``, which also accounts for the channel\n    estimation error variance ``err_var``. These quantities serve as input to the detection\n    algorithm that is implemented by ``detector``.\n    Both detection of symbols or bits with either soft- or hard-decisions are supported.\n\n    Note\n    -----\n    The callable ``detector`` must take as input a tuple :math:`(\\mathbf{y}, \\mathbf{h}, \\mathbf{s})` such that:\n\n    * **y** ([...,num_rx_ant], tf.complex) -- 1+D tensor containing the received signals.\n    * **h** ([...,num_rx_ant,num_streams_per_rx], tf.complex) -- 2+D tensor containing the channel matrices.\n    * **s** ([...,num_rx_ant,num_rx_ant], tf.complex) -- 2+D tensor containing the noise-plus-interference covariance matrices.\n\n    It must generate one of following outputs depending on the value of ``output``:\n\n    * **b_hat** ([..., num_streams_per_rx, num_bits_per_symbol], tf.float) -- LLRs or hard-decisions for every bit of every stream, if ``output`` equals `\"bit\"`.\n    * **x_hat** ([..., num_streams_per_rx, num_points], tf.float) or ([..., num_streams_per_rx], tf.int) -- Logits or hard-decisions for constellation symbols for every stream, if ``output`` equals `\"symbol\"`. Hard-decisions correspond to the symbol indices.\n\n    Parameters\n    ----------\n    detector : Callable\n        Callable object (e.g., a function) that implements a MIMO detection\n        algorithm for arbitrary batch dimensions. Either one of the existing detectors, e.g.,\n        :class:`~sionna.mimo.LinearDetector`, :class:`~sionna.mimo.MaximumLikelihoodDetector`, or\n        :class:`~sionna.mimo.KBestDetector` can be used, or a custom detector\n        callable provided that has the same input/output specification.\n\n    output : One of [\"bit\", \"symbol\"], str\n        Type of output, either bits or symbols\n\n    resource_grid : ResourceGrid\n        Instance of :class:`~sionna.ofdm.ResourceGrid`\n\n    stream_management : StreamManagement\n        Instance of :class:`~sionna.mimo.StreamManagement`\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n        The dtype of `y`. Defaults to tf.complex64.\n        The output dtype is the corresponding real dtype (tf.float32 or tf.float64).\n\n    Input\n    ------\n    (y, h_hat, err_var, no) :\n        Tuple:\n\n    y : [batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex\n        Received OFDM resource grid after cyclic prefix removal and FFT\n\n    h_hat : [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex\n        Channel estimates for all streams from all transmitters\n\n    err_var : [Broadcastable to shape of ``h_hat``], tf.float\n        Variance of the channel estimation error\n\n    no : [batch_size, num_rx, num_rx_ant] (or only the first n dims), tf.float\n        Variance of the AWGN\n\n    Output\n    ------\n    One of:\n\n    : [batch_size, num_tx, num_streams, num_data_symbols*num_bits_per_symbol], tf.float\n        LLRs or hard-decisions for every bit of every stream, if ``output`` equals `\"bit\"`\n\n    : [batch_size, num_tx, num_streams, num_data_symbols, num_points], tf.float or [batch_size, num_tx, num_streams, num_data_symbols], tf.int\n        Logits or hard-decisions for constellation symbols for every stream, if ``output`` equals `\"symbol\"`.\n        Hard-decisions correspond to the symbol indices.\n    \"\"\"\n    def __init__(self,\n                 detector,\n                 output,\n                 resource_grid,\n                 stream_management,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n        self._detector = detector\n        self._resource_grid = resource_grid\n        self._stream_management = stream_management\n        self._removed_nulled_scs = RemoveNulledSubcarriers(self._resource_grid)\n        self._output = output\n\n        # Precompute indices to extract data symbols\n        mask = resource_grid.pilot_pattern.mask\n        num_data_symbols = resource_grid.pilot_pattern.num_data_symbols\n        data_ind = tf.argsort(flatten_last_dims(mask), direction=\"ASCENDING\")\n        self._data_ind = data_ind[...,:num_data_symbols]\n\n    def _preprocess_inputs(self, y, h_hat, err_var, no):\n        \"\"\"Pro-process the received signal and compute the\n        noise-plus-interference covariance matrix\"\"\"\n\n        # Remove nulled subcarriers from y (guards, dc). New shape:\n        # [batch_size, num_rx, num_rx_ant, ...\n        #  ..., num_ofdm_symbols, num_effective_subcarriers]\n        y_eff = self._removed_nulled_scs(y)\n\n        ####################################################\n        ### Prepare the observation y for MIMO detection ###\n        ####################################################\n        # Transpose y_eff to put num_rx_ant last. New shape:\n        # [batch_size, num_rx, num_ofdm_symbols,...\n        #  ..., num_effective_subcarriers, num_rx_ant]\n        y_dt = tf.transpose(y_eff, [0, 1, 3, 4, 2])\n        y_dt = tf.cast(y_dt, self._dtype)\n\n        # Transpose y_eff to put num_rx_ant last. New shape:\n        # [batch_size, num_rx, num_ofdm_symbols,...\n        #  ..., num_effective_subcarriers, num_rx_ant]\n        y_dt = tf.transpose(y_eff, [0, 1, 3, 4, 2])\n        y_dt = tf.cast(y_dt, self._dtype)\n\n        ##############################################\n        ### Prepare the err_var for MIMO detection ###\n        ##############################################\n        # New shape is:\n        # [batch_size, num_rx, num_ofdm_symbols,...\n        #  ..., num_effective_subcarriers, num_rx_ant, num_tx*num_streams]\n        err_var_dt = tf.broadcast_to(err_var, tf.shape(h_hat))\n        err_var_dt = tf.transpose(err_var_dt, [0, 1, 5, 6, 2, 3, 4])\n        err_var_dt = flatten_last_dims(err_var_dt, 2)\n        err_var_dt = tf.cast(err_var_dt, self._dtype)\n\n        ###############################\n        ### Construct MIMO channels ###\n        ###############################\n\n        # Reshape h_hat for the construction of desired/interfering channels:\n        # [num_rx, num_tx, num_streams_per_tx, batch_size, num_rx_ant, ,...\n        #  ..., num_ofdm_symbols, num_effective_subcarriers]\n        perm = [1, 3, 4, 0, 2, 5, 6]\n        h_dt = tf.transpose(h_hat, perm)\n\n        # Flatten first tthree dimensions:\n        # [num_rx*num_tx*num_streams_per_tx, batch_size, num_rx_ant, ...\n        #  ..., num_ofdm_symbols, num_effective_subcarriers]\n        h_dt = flatten_dims(h_dt, 3, 0)\n\n        # Gather desired and undesired channels\n        ind_desired = self._stream_management.detection_desired_ind\n        ind_undesired = self._stream_management.detection_undesired_ind\n        h_dt_desired = tf.gather(h_dt, ind_desired, axis=0)\n        h_dt_undesired = tf.gather(h_dt, ind_undesired, axis=0)\n\n        # Split first dimension to separate RX and TX:\n        # [num_rx, num_streams_per_rx, batch_size, num_rx_ant, ...\n        #  ..., num_ofdm_symbols, num_effective_subcarriers]\n        h_dt_desired = split_dim(h_dt_desired,\n                                 [self._stream_management.num_rx,\n                                  self._stream_management.num_streams_per_rx],\n                                 0)\n        h_dt_undesired = split_dim(h_dt_undesired,\n                                   [self._stream_management.num_rx, -1], 0)\n\n        # Permutate dims to\n        # [batch_size, num_rx, num_ofdm_symbols, num_effective_subcarriers,..\n        #  ..., num_rx_ant, num_streams_per_rx(num_Interfering_streams_per_rx)]\n        perm = [2, 0, 4, 5, 3, 1]\n        h_dt_desired = tf.transpose(h_dt_desired, perm)\n        h_dt_desired = tf.cast(h_dt_desired, self._dtype)\n        h_dt_undesired = tf.transpose(h_dt_undesired, perm)\n\n        ##################################\n        ### Prepare the noise variance ###\n        ##################################\n        # no is first broadcast to [batch_size, num_rx, num_rx_ant]\n        # then the rank is expanded to that of y\n        # then it is transposed like y to the final shape\n        # [batch_size, num_rx, num_ofdm_symbols,...\n        #  ..., num_effective_subcarriers, num_rx_ant]\n        no_dt = expand_to_rank(no, 3, -1)\n        no_dt = tf.broadcast_to(no_dt, tf.shape(y)[:3])\n        no_dt = expand_to_rank(no_dt, tf.rank(y), -1)\n        no_dt = tf.transpose(no_dt, [0,1,3,4,2])\n        no_dt = tf.cast(no_dt, self._dtype)\n\n        ##################################################\n        ### Compute the interference covariance matrix ###\n        ##################################################\n        # Covariance of undesired transmitters\n        s_inf = tf.matmul(h_dt_undesired, h_dt_undesired, adjoint_b=True)\n\n        #Thermal noise\n        s_no = tf.linalg.diag(no_dt)\n\n        # Channel estimation errors\n        # As we have only error variance information for each element,\n        # we simply sum them across transmitters and build a\n        # diagonal covariance matrix from this\n        s_csi = tf.linalg.diag(tf.reduce_sum(err_var_dt, -1))\n\n        # Final covariance matrix\n        s = s_inf + s_no + s_csi\n        s = tf.cast(s, self._dtype)\n\n        return y_dt, h_dt_desired, s\n\n    def _extract_datasymbols(self, z):\n        \"\"\"Extract data symbols for all detected TX\"\"\"\n\n        # If output is symbols with hard decision, the rank is 5 and not 6 as\n        # for other cases. The tensor rank is therefore expanded with one extra\n        # dimension, which is removed later.\n        rank_extanded = len(z.shape) < 6\n        z = expand_to_rank(z, 6, -1)\n\n        # Transpose tensor to shape\n        # [num_rx, num_streams_per_rx, num_ofdm_symbols,\n        #    num_effective_subcarriers, num_bits_per_symbol or num_points,\n        #       batch_size]\n        z = tf.transpose(z, [1, 4, 2, 3, 5, 0])\n\n        # Merge num_rx amd num_streams_per_rx\n        # [num_rx * num_streams_per_rx, num_ofdm_symbols,\n        #    num_effective_subcarriers, num_bits_per_symbol or num_points,\n        #   batch_size]\n        z = flatten_dims(z, 2, 0)\n\n        # Put first dimension into the right ordering\n        stream_ind = self._stream_management.stream_ind\n        z = tf.gather(z, stream_ind, axis=0)\n\n        # Reshape first dimensions to [num_tx, num_streams] so that\n        # we can compare to the way the streams were created.\n        # [num_tx, num_streams, num_ofdm_symbols, num_effective_subcarriers,\n        #     num_bits_per_symbol or num_points, batch_size]\n        num_streams = self._stream_management.num_streams_per_tx\n        num_tx = self._stream_management.num_tx\n        z = split_dim(z, [num_tx, num_streams], 0)\n\n        # Flatten resource grid dimensions\n        # [num_tx, num_streams, num_ofdm_symbols*num_effective_subcarrier,\n        #    num_bits_per_symbol or num_points, batch_size]\n        z = flatten_dims(z, 2, 2)\n\n        # Gather data symbols\n        # [num_tx, num_streams, num_data_symbols,\n        #    num_bits_per_symbol or num_points, batch_size]\n        z = tf.gather(z, self._data_ind, batch_dims=2, axis=2)\n\n        # Put batch_dim first\n        # [batch_size, num_tx, num_streams,\n        #     num_data_symbols, num_bits_per_symbol or num_points]\n        z = tf.transpose(z, [4, 0, 1, 2, 3])\n\n        # Reshape LLRs to\n        # [batch_size, num_tx, num_streams,\n        #     n = num_data_symbols*num_bits_per_symbol]\n        # if output is LLRs on bits\n        if self._output == 'bit':\n            z = flatten_dims(z, 2, 3)\n        # Remove dummy dimension if output is symbols with hard decision\n        if rank_extanded:\n            z = tf.squeeze(z, axis=-1)\n\n        return z\n\n    def call(self, inputs):\n        y, h_hat, err_var, no = inputs\n        # y has shape:\n        # [batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size]\n\n        # h_hat has shape:\n        # [batch_size, num_rx, num_rx_ant, num_tx, num_streams,...\n        #  ..., num_ofdm_symbols, num_effective_subcarriers]\n\n        # err_var has a shape that is broadcastable to h_hat\n\n        # no has shape [batch_size, num_rx, num_rx_ant]\n        # or just the first n dimensions of this\n\n        ################################\n        ### Pre-process the inputs\n        ################################\n        y_dt, h_dt_desired, s = self._preprocess_inputs(y, h_hat, err_var, no)\n\n        #################################\n        ### Detection\n        #################################\n        z = self._detector([y_dt, h_dt_desired, s])\n\n        ##############################################\n        ### Extract data symbols for all detected TX\n        ##############################################\n        z = self._extract_datasymbols(z)\n\n        return z\n```"}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the definition of sionna.utils.plotting.PlotBER in Sionna, such as the default parameters, the link of the source code and explanation."}, {"role": "assistant", "content": "Here is the definition of sionna.utils.plotting.PlotBER: sionna.utils.plotting.PlotBER(title='Bit/Block Error Rate')\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/utils/plotting.html#PlotBER)  \n\nsource code:\n```python\nclass PlotBER():\n    \"\"\"Provides a plotting object to simulate and store BER/BLER curves.\n\n    Parameters\n    ----------\n    title: str\n        A string defining the title of the figure. Defaults to\n        `\"Bit/Block Error Rate\"`.\n\n    Input\n    -----\n    snr_db: float\n        Python array (or list of Python arrays) of additional SNR values to be\n        plotted.\n\n    ber: float\n        Python array (or list of Python arrays) of additional BERs\n        corresponding to ``snr_db``.\n\n    legend: str\n        String (or list of strings) of legends entries.\n\n    is_bler: bool\n        A boolean (or list of booleans) defaults to False.\n        If True, ``ber`` will be interpreted as BLER.\n\n    show_ber: bool\n        A boolean defaults to True. If True, BER curves will be plotted.\n\n    show_bler: bool\n        A boolean defaults to True. If True, BLER curves will be plotted.\n\n    xlim: tuple of floats\n        Defaults to None. A tuple of two floats defining x-axis limits.\n\n    ylim: tuple of floats\n        Defaults to None. A tuple of two floats defining y-axis limits.\n\n    save_fig: bool\n        A boolean defaults to False. If True, the figure\n        is saved as file.\n\n    path: str\n        A string defining where to save the figure (if ``save_fig``\n        is True).\n    \"\"\"\n\n    def __init__(self, title=\"Bit/Block Error Rate\"):\n\n        assert isinstance(title, str), \"title must be str.\"\n        self._title = title\n\n        # init lists\n        self._bers = []\n        self._snrs = []\n        self._legends = []\n        self._is_bler = []\n\n    # pylint: disable=W0102\n    def __call__(self,\n                 snr_db=[],\n                 ber=[],\n                 legend=[],\n                 is_bler=[],\n                 show_ber=True,\n                 show_bler=True,\n                 xlim=None,\n                 ylim=None,\n                 save_fig=False,\n                 path=\"\"):\n        \"\"\"Plot BER curves.\n\n        \"\"\"\n\n        assert isinstance(path, str), \"path must be str.\"\n        assert isinstance(save_fig, bool), \"save_fig must be bool.\"\n\n        # broadcast snr if ber is list\n        if isinstance(ber, list):\n            if not isinstance(snr_db, list):\n                snr_db = [snr_db]*len(ber)\n\n        if not isinstance(snr_db, list):\n            snrs = self._snrs + [snr_db]\n        else:\n            snrs = self._snrs + snr_db\n        if not isinstance(ber, list):\n            bers = self._bers + [ber]\n        else:\n            bers = self._bers + ber\n        if not isinstance(legend, list):\n            legends = self._legends + [legend]\n        else:\n            legends = self._legends + legend\n        if not isinstance(is_bler, list):\n            is_bler = self._is_bler + [is_bler]\n        else:\n            is_bler = self._is_bler + is_bler\n\n        # deactivate BER/BLER\n        if len(is_bler)>0: # ignore if object is empty\n            if show_ber is False:\n                snrs = list(compress(snrs, is_bler))\n                bers = list(compress(bers, is_bler))\n                legends = list(compress(legends, is_bler))\n                is_bler = list(compress(is_bler, is_bler))\n\n            if show_bler is False:\n                snrs = list(compress(snrs, np.invert(is_bler)))\n                bers = list(compress(bers, np.invert(is_bler)))\n                legends = list(compress(legends, np.invert(is_bler)))\n                is_bler = list(compress(is_bler, np.invert(is_bler)))\n\n        # set ylabel\n        ylabel = \"BER / BLER\"\n        if np.all(is_bler): # only BLERs to plot\n            ylabel = \"BLER\"\n        if not np.any(is_bler): # only BERs to plot\n            ylabel = \"BER\"\n\n        # and plot the results\n        plot_ber(snr_db=snrs,\n                 ber=bers,\n                 legend=legends,\n                 is_bler=is_bler,\n                 title=self._title,\n                 ylabel=ylabel,\n                 xlim=xlim,\n                 ylim=ylim,\n                 save_fig=save_fig,\n                 path=path)\n\n    ####public methods\n    @property\n    def title(self):\n        \"\"\"Title of the plot.\"\"\"\n        return self._title\n\n    @title.setter\n    def title(self, title):\n        \"\"\"Set title of the plot.\"\"\"\n        assert isinstance(title, str), \"title must be string\"\n        self._title = title\n\n    @property\n    def ber(self):\n        \"\"\"List containing all stored BER curves.\"\"\"\n        return self._bers\n\n    @property\n    def snr(self):\n        \"\"\"List containing all stored SNR curves.\"\"\"\n        return self._snrs\n\n    @property\n    def legend(self):\n        \"\"\"List containing all stored legend entries curves.\"\"\"\n        return self._legends\n\n    @property\n    def is_bler(self):\n        \"\"\"List of booleans indicating if ber shall be interpreted as BLER.\"\"\"\n        return self._is_bler\n\n    def simulate(self,\n                 mc_fun,\n                 ebno_dbs,\n                 batch_size,\n                 max_mc_iter,\n                 legend=\"\",\n                 add_ber=True,\n                 add_bler=False,\n                 soft_estimates=False,\n                 num_target_bit_errors=None,\n                 num_target_block_errors=None,\n                 target_ber=None,\n                 target_bler=None,\n                 early_stop=True,\n                 graph_mode=None,\n                 distribute=None,\n                 add_results=True,\n                 forward_keyboard_interrupt=True,\n                 show_fig=True,\n                 verbose=True):\n        # pylint: disable=line-too-long\n        r\"\"\"Simulate BER/BLER curves for given Keras model and saves the results.\n\n        Internally calls :class:`sionna.utils.sim_ber`.\n\n        Input\n        -----\n        mc_fun:\n            Callable that yields the transmitted bits `b` and the\n            receiver's estimate `b_hat` for a given ``batch_size`` and\n            ``ebno_db``. If ``soft_estimates`` is True, b_hat is interpreted as\n            logit.\n\n        ebno_dbs: ndarray of floats\n            SNR points to be evaluated.\n\n        batch_size: tf.int32\n            Batch-size for evaluation.\n\n        max_mc_iter: int\n            Max. number of Monte-Carlo iterations per SNR point.\n\n        legend: str\n            Name to appear in legend.\n\n        add_ber: bool\n            Defaults to True. Indicate if BER should be added to plot.\n\n        add_bler: bool\n            Defaults to False. Indicate if BLER should be added\n            to plot.\n\n        soft_estimates: bool\n            A boolean, defaults to False. If True, ``b_hat``\n            is interpreted as logit and additional hard-decision is applied\n            internally.\n\n        num_target_bit_errors: int\n            Target number of bit errors per SNR point until the simulation\n            stops.\n\n        num_target_block_errors: int\n            Target number of block errors per SNR point until the simulation\n            stops.\n\n        target_ber: tf.float32\n            Defaults to `None`. The simulation stops after the first SNR point\n            which achieves a lower bit error rate as specified by\n            ``target_ber``. This requires ``early_stop`` to be `True`.\n\n        target_bler: tf.float32\n            Defaults to `None`. The simulation stops after the first SNR point\n            which achieves a lower block error rate as specified by\n            ``target_bler``.  This requires ``early_stop`` to be `True`.\n\n        early_stop: bool\n            A boolean defaults to True. If True, the simulation stops after the\n            first error-free SNR point (i.e., no error occurred after\n            ``max_mc_iter`` Monte-Carlo iterations).\n\n        graph_mode: One of [\"graph\", \"xla\"], str\n            A string describing the execution mode of ``mc_fun``.\n            Defaults to `None`. In this case, ``mc_fun`` is executed as is.\n\n        distribute: `None` (default) | \"all\" | list of indices | `tf.distribute.strategy`\n            Distributes simulation on multiple parallel devices. If `None`,\n            multi-device simulations are deactivated. If \"all\", the workload\n            will be automatically distributed across all available GPUs via the\n            `tf.distribute.MirroredStrategy`.\n            If an explicit list of indices is provided, only the GPUs with the\n            given indices will be used. Alternatively, a custom\n            `tf.distribute.strategy` can be provided. Note that the same\n            `batch_size` will be used for all GPUs in parallel, but the number\n            of Monte-Carlo iterations ``max_mc_iter`` will be scaled by the\n            number of devices such that the same number of total samples is\n            simulated. However, all stopping conditions are still in-place\n            which can cause slight differences in the total number of simulated\n            samples.\n\n        add_results: bool\n            Defaults to True. If True, the simulation results will be appended\n            to the internal list of results.\n\n        show_fig: bool\n            Defaults to True. If True, a BER figure will be plotted.\n\n        verbose: bool\n            A boolean defaults to True. If True, the current progress will be\n            printed.\n\n        forward_keyboard_interrupt: bool\n            A boolean defaults to True. If False, `KeyboardInterrupts` will be\n            catched internally and not forwarded (e.g., will not stop outer\n            loops). If False, the simulation ends and returns the intermediate\n            simulation results.\n\n        Output\n        ------\n        (ber, bler):\n            Tuple:\n\n        ber: float\n            The simulated bit-error rate.\n\n        bler: float\n            The simulated block-error rate.\n        \"\"\"\n\n        ber, bler = sim_ber(\n                        mc_fun,\n                        ebno_dbs,\n                        batch_size,\n                        soft_estimates=soft_estimates,\n                        max_mc_iter=max_mc_iter,\n                        num_target_bit_errors=num_target_bit_errors,\n                        num_target_block_errors=num_target_block_errors,\n                        target_ber=target_ber,\n                        target_bler=target_bler,\n                        early_stop=early_stop,\n                        graph_mode=graph_mode,\n                        distribute=distribute,\n                        verbose=verbose,\n                        forward_keyboard_interrupt=forward_keyboard_interrupt)\n\n        if add_ber:\n            self._bers += [ber]\n            self._snrs +=  [ebno_dbs]\n            self._legends += [legend]\n            self._is_bler += [False]\n\n        if add_bler:\n            self._bers += [bler]\n            self._snrs +=  [ebno_dbs]\n            self._legends += [legend + \" (BLER)\"]\n            self._is_bler += [True]\n\n        if show_fig:\n            self()\n\n        # remove current curve if add_results=False\n        if add_results is False:\n            if add_bler:\n                self.remove(-1)\n            if add_ber:\n                self.remove(-1)\n\n        return ber, bler\n\n\n    def add(self, ebno_db, ber, is_bler=False, legend=\"\"):\n        \"\"\"Add static reference curves.\n\n        Input\n        -----\n        ebno_db: float\n            Python array or list of floats defining the SNR points.\n\n        ber: float\n            Python array or list of floats defining the BER corresponding\n            to each SNR point.\n\n        is_bler: bool\n            A boolean defaults to False. If True, ``ber`` is interpreted as\n            BLER.\n\n        legend: str\n            A string defining the text of the legend entry.\n        \"\"\"\n\n        assert (len(ebno_db)==len(ber)), \\\n            \"ebno_db and ber must have same number of elements.\"\n\n        assert isinstance(legend, str), \"legend must be str.\"\n        assert isinstance(is_bler, bool), \"is_bler must be bool.\"\n\n        # concatenate curves\n        self._bers += [ber]\n        self._snrs +=  [ebno_db]\n        self._legends += [legend]\n        self._is_bler += [is_bler]\n\n    def reset(self):\n        \"\"\"Remove all internal data.\"\"\"\n        self._bers = []\n        self._snrs = []\n        self._legends = []\n        self._is_bler = []\n\n    def remove(self, idx=-1):\n        \"\"\"Remove curve with index ``idx``.\n\n        Input\n        ------\n        idx: int\n            An integer defining the index of the dataset that should\n            be removed. Negative indexing is possible.\n        \"\"\"\n\n        assert isinstance(idx, int), \"id must be int.\"\n\n        del self._bers[idx]\n        del self._snrs[idx]\n        del self._legends[idx]\n        del self._is_bler[idx]\n```"}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Describe how to instantiate different versions of the model and use the PlotBer class for easy Monte-Carlo simulations."}, {"role": "assistant", "content": "To instantiate different versions of the model and use the PlotBer class for easy Monte-Carlo simulations, follow these steps:\n\n1. First, import the necessary modules and classes from Sionna, TensorFlow, and other required libraries. This includes the `BinarySource`, `QAMSource`, `ebnodb2no`, `compute_ser`, `compute_ber`, `PlotBER` from `sionna.utils`, `FlatFadingChannel`, `KroneckerModel` from `sionna.channel`, `exp_corr_mat` from `sionna.channel.utils`, `lmmse_equalizer` from `sionna.mimo`, `SymbolDemapper`, `Mapper`, `Demapper` from `sionna.mapping`, `LDPC5GEncoder`, `LDPC5GDecoder` from `sionna.fec.ldpc.encoding` and `sionna.fec.ldpc.decoding`.\n\n2. Define a Keras model class, for example, `Model`, that includes the necessary components for the simulation. This includes the binary source, encoder, mapper, demapper, decoder, and the channel. The `call` method of the model should include the process of generating binary source, encoding, mapping, transmitting over the channel, equalizing, demapping, and decoding.\n\n3. Instantiate the model with or without spatial correlation. For example, you can create an instance of the model without spatial correlation as `model1 = Model()`. If you want to add spatial correlation, you can create correlation matrices and add them to the Kronecker model. Then, instantiate the model with this spatial correlation as `model2 = Model(KroneckerModel(r_tx, r_rx))`.\n\n4. Use the `PlotBer` class for easy Monte-Carlo simulations. First, create an instance of the `PlotBer` class as `ber_plot = PlotBER()`. Then, use the `simulate` method of this instance to run the simulation with the model, for example, `ber_plot.simulate(model1, np.arange(-2.5, 0.25, 0.25), batch_size=4096, max_mc_iter=1000, num_target_block_errors=100, legend=\"Uncorrelated\", show_fig=False)`.\n\nRemember to set `sionna.config.xla_compat=True` before executing the model to speed up the simulations."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the definition of MMSEPICDetector, such as the default parameters, the link of the source code and explanation."}, {"role": "assistant", "content": "Here is the definition of MMSEPICDetector: sionna.mimo.MMSEPICDetector(output, demapping_method='maxlog', num_iter=1, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/mimo/detection.html#MMSEPICDetector)  \n\nsource code:\n```python\nclass MMSEPICDetector(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"MMSEPICDetector(output, demapping_method=\"maxlog\", num_iter=1, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)\n\n    Minimum mean square error (MMSE) with parallel interference cancellation (PIC) detector\n\n    This layer implements the MMSE PIC detector, as proposed in [CST2011]_.\n    For ``num_iter``>1, this implementation performs MMSE PIC self-iterations.\n    MMSE PIC self-iterations can be understood as a concatenation of MMSE PIC\n    detectors from [CST2011]_, which forward intrinsic LLRs to the next\n    self-iteration.\n\n    Compared to [CST2011]_, this implementation also accepts priors on the\n    constellation symbols as an alternative to priors on the bits.\n\n    This layer assumes the following channel model:\n\n    .. math::\n        \\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n\n    where :math:`\\mathbf{y}\\in\\mathbb{C}^M` is the received signal vector,\n    :math:`\\mathbf{x}\\in\\mathcal{C}^S` is the vector of transmitted symbols which\n    are uniformly and independently drawn from the constellation :math:`\\mathcal{C}`,\n    :math:`\\mathbf{H}\\in\\mathbb{C}^{M\\times S}` is the known channel matrix,\n    and :math:`\\mathbf{n}\\in\\mathbb{C}^M` is a complex Gaussian noise vector.\n    It is assumed that :math:`\\mathbb{E}\\left[\\mathbf{n}\\right]=\\mathbf{0}` and\n    :math:`\\mathbb{E}\\left[\\mathbf{n}\\mathbf{n}^{\\mathsf{H}}\\right]=\\mathbf{S}`,\n    where :math:`\\mathbf{S}` has full rank.\n\n    The algorithm starts by computing the soft symbols\n    :math:`\\bar{x}_s=\\mathbb{E}\\left[ x_s \\right]` and\n    variances :math:`v_s=\\mathbb{E}\\left[ |e_s|^2\\right]` from the priors,\n    where :math:`e_s = x_s - \\bar{x}_s`, for all :math:`s=1,\\dots,S`.\n\n    Next, for each stream, the interference caused by all other streams is cancelled\n    from the observation :math:`\\mathbf{y}`, leading to\n\n    .. math::\n        \\hat{\\mathbf{y}}_s = \\mathbf{y} - \\sum_{j\\neq s} \\mathbf{h}_j x_j = \\mathbf{h}_s x_s + \\tilde{\\mathbf{n}}_s,\\quad s=1,\\dots,S\n\n    where :math:`\\tilde{\\mathbf{n}}_s=\\sum_{j\\neq s} \\mathbf{h}_j e_j + \\mathbf{n}`.\n\n    Then, a linear MMSE filter :math:`\\mathbf{w}_s` is computed to reduce the resdiual noise\n    for each observation :math:`\\hat{\\mathbf{y}}_s`, which is given as\n\n    .. math::\n        \\mathbf{w}_s = \\mathbf{h}_s^{\\mathsf{H}}\\left( \\mathbf{H} \\mathbf{D}_s\\mathbf{H}^{\\mathsf{H}} +\\mathbf{S} \\right)^{-1}\n\n    where :math:`\\mathbf{D}_s \\in \\mathbb{C}^{S\\times S}` is diagonal with entries\n\n    .. math::\n        \\left[\\mathbf{D}_s\\right]_{i,i} = \\begin{cases}\n                                            v_i & i\\neq s \\\\\n                                            1 & i=s.\n                                          \\end{cases}\n\n    The filtered observations\n\n    .. math::\n        \\tilde{z}_s = \\mathbf{w}_s^{\\mathsf{H}} \\hat{\\mathbf{y}}_s = \\tilde{\\mu}_s x_s + \\mathbf{w}_s^{\\mathsf{H}}\\tilde{\\mathbf{n}}_s\n\n    where :math:`\\tilde{\\mu}_s=\\mathbf{w}_s^{\\mathsf{H}} \\mathbf{h}_s`, are then demapped to either symbol logits or LLRs, assuming that the remaining noise is Gaussian with variance\n\n    .. math::\n        \\nu_s^2 = \\mathop{\\text{Var}}\\left[\\tilde{z}_s\\right] = \\mathbf{w}_s^{\\mathsf{H}} \\left(\\sum_{j\\neq s} \\mathbf{h}_j \\mathbf{h}_j^{\\mathsf{H}} v_j +\\mathbf{S} \\right)\\mathbf{w}_s.\n\n    The resulting soft-symbols can then be used for the next self-iteration of the algorithm.\n\n    Note that this algorithm can be substantially simplified as described in [CST2011]_ to avoid\n    the computation of different matrix inverses for each stream. This is the version which is\n    implemented.\n\n    Parameters\n    -----------\n    output : One of [\"bit\", \"symbol\"], str\n        The type of output, either LLRs on bits or logits on constellation\n        symbols.\n\n    demapping_method : One of [\"app\", \"maxlog\"], str\n        The demapping method used.\n        Defaults to \"maxlog\".\n\n    num_iter : int\n        Number of MMSE PIC iterations.\n        Defaults to 1.\n\n    constellation_type : One of [\"qam\", \"pam\", \"custom\"], str\n        For \"custom\", an instance of :class:`~sionna.mapping.Constellation`\n        must be provided.\n\n    num_bits_per_symbol : int\n        The number of bits per constellation symbol, e.g., 4 for QAM16.\n        Only required for ``constellation_type`` in [\"qam\", \"pam\"].\n\n    constellation : Constellation\n        An instance of :class:`~sionna.mapping.Constellation` or `None`.\n        In the latter case, ``constellation_type``\n        and ``num_bits_per_symbol`` must be provided.\n\n    hard_out : bool\n        If `True`, the detector computes hard-decided bit values or\n        constellation point indices instead of soft-values.\n        Defaults to `False`.\n\n    dtype : One of [tf.complex64, tf.complex128] tf.DType (dtype)\n        The dtype of ``y``. Defaults to tf.complex64.\n        The output dtype is the corresponding real dtype\n        (tf.float32 or tf.float64).\n\n    Input\n    -----\n    (y, h, prior, s) :\n        Tuple:\n\n    y : [...,M], tf.complex\n        1+D tensor containing the received signals\n\n    h : [...,M,S], tf.complex\n        2+D tensor containing the channel matrices\n\n    prior : [...,S,num_bits_per_symbol] or [...,S,num_points], tf.float\n        Prior of the transmitted signals.\n        If ``output`` equals \"bit\", then LLRs of the transmitted bits are expected.\n        If ``output`` equals \"symbol\", then logits of the transmitted constellation points are expected.\n\n    s : [...,M,M], tf.complex\n        2+D tensor containing the noise covariance matrices\n\n    Output\n    ------\n    One of:\n\n    : [...,S,num_bits_per_symbol], tf.float\n        LLRs or hard-decisions for every bit of every stream, if ``output`` equals `\"bit\"`\n\n    : [...,S,2**num_bits_per_symbol], tf.float or [...,S], tf.int\n       Logits or hard-decisions for constellation symbols for every stream, if ``output`` equals `\"symbol\"`\n\n    Note\n    ----\n    For numerical stability, we do not recommend to use this function in Graph\n    mode with XLA, i.e., within a function that is decorated with\n    ``@tf.function(jit_compile=True)``.\n    However, it is possible to do so by setting\n    ``sionna.Config.xla_compat=true``.\n    See :py:attr:`~sionna.Config.xla_compat`.\n    \"\"\"\n    def __init__(self,\n                 output,\n                 demapping_method=\"maxlog\",\n                 num_iter=1,\n                 constellation_type=None,\n                 num_bits_per_symbol=None,\n                 constellation=None,\n                 hard_out=False,\n                 dtype=tf.complex64,\n                 **kwargs):\n        super().__init__(dtype=dtype, **kwargs)\n\n        assert isinstance(num_iter, int), \"num_iter must be an integer\"\n        assert output in (\"bit\", \"symbol\"), \"Unknown output\"\n        assert demapping_method in (\"app\", \"maxlog\"), \"Unknown demapping method\"\n\n        assert dtype in [tf.complex64, tf.complex128], \\\n            \"dtype must be tf.complex64 or tf.complex128\"\n\n        self._num_iter = num_iter\n        self._output = output\n        self._epsilon = 1e-4\n        self._realdtype = dtype.real_dtype\n        self._demapping_method = demapping_method\n        self._hard_out = hard_out\n\n        # Create constellation object\n        self._constellation = Constellation.create_or_check_constellation(\n            constellation_type,\n            num_bits_per_symbol,\n            constellation,\n            dtype=dtype)\n\n        # Soft symbol mapping\n        self._llr_2_symbol_logits = LLRs2SymbolLogits(\n                                        self._constellation.num_bits_per_symbol,\n                                        dtype=self._realdtype)\n\n        if self._output == \"symbol\":\n            self._llr_2_symbol_logits_output = LLRs2SymbolLogits(\n                                    self._constellation.num_bits_per_symbol,\n                                    dtype=self._realdtype,\n                                    hard_out=hard_out)\n            self._symbol_logits_2_llrs = SymbolLogits2LLRs(\n                method=demapping_method,\n                num_bits_per_symbol=self._constellation.num_bits_per_symbol)\n        self._symbol_logits_2_moments = SymbolLogits2Moments(\n                                            constellation=self._constellation,\n                                            dtype=self._realdtype)\n\n        # soft output demapping\n        self._bit_demapper = DemapperWithPrior(\n                                            demapping_method=demapping_method,\n                                            constellation=self._constellation,\n                                            dtype=dtype)\n\n\n    def call(self, inputs):\n        y, h, prior, s = inputs\n        # y is unwhitened receive signal\n        #   [..., M]\n        # h the channel estimate\n        #   [..., M, K]\n        # prior is either the soft input LLRs\n        #   [..., K, num_bits_per_symbol] or symbol logits [..., K, Q]\n        # s the noise covariance matrix\n        #   [..., M, M]\n\n        ## Preprocessing\n        # Whiten channel\n        # y : [..., M]\n        # s : [..., M, M]\n        y, h = whiten_channel(y, h, s, return_s=False)  # pylint: disable=unbalanced-tuple-unpacking\n\n        # matched filtering of y\n        # [..., K, 1]\n        y_mf = insert_dims(tf.linalg.matvec(h, y, adjoint_a=True),\n                            num_dims=1, axis=-1)\n\n        ## Step 1: compute Gramm matrix\n        # [..., K, K]\n        g = tf.matmul(h, h, adjoint_a=True)\n\n        # For XLA compatibility, this implementation performs the MIMO\n        # equalization in the real-valued domain\n        # [..., 2M, 2K]\n        hr = complex2real_matrix(h)\n        # [..., 2K, 2K]\n        gr = tf.matmul(hr, hr, adjoint_a=True)\n\n        # Compute a priori LLRs\n        if self._output == \"symbol\":\n            llr_a = self._symbol_logits_2_llrs(prior)\n        else:\n            llr_a = prior\n        # llr_a is [..., K, num_bits_per_symbol]\n        llr_shape = tf.shape(llr_a)\n\n        def mmse_pic_self_iteration(llr_d, llr_a, it):\n            # MMSE PIC takes in a priori LLRs\n            llr_a = llr_d\n\n            # Step 2: compute soft symbol estimates and variances\n            # x_hat, var_x : [..., K]\n            x_logits = self._llr_2_symbol_logits(llr_a)\n            x_hat, var_x = self._symbol_logits_2_moments(x_logits)\n\n            # Step 3: perform parallel interference cancellation\n            # H^H y_hat_i = y_mf - sum_j!=i gj x_hat_j = y + g_i x_hat_i\n            #               - sum_j g_j x_hat_j\n            # [..., K, K]\n            y_mf_pic = y_mf + g * insert_dims(x_hat, num_dims=1, axis=-2) \\\n                - tf.linalg.matmul(g, insert_dims(x_hat, num_dims=1, axis=-1))\n\n            # Step 4: compute A^-1 matrix\n            # Calculate MMSE Filter (efficiently)\n            # W^H = A^-1 H^H\n            # A = H^H H \\Lambda + N_0 I_Mt\n            # \\Lambda_ii is a diagonal matrix with \\Lambda_ii = E_i = error_var\n\n            # Stack error variances and make it real\n            # Note: Imaginary part is zero\n            var_x = tf.cast(tf.concat([var_x, var_x], axis=-1),\n                            dtype=self._realdtype)\n            var_x_row_vec = insert_dims(var_x, num_dims=1, axis=-2)\n            # [..., 2K, 2K]\n            a = gr * var_x_row_vec\n\n            i = expand_to_rank(tf.eye(tf.shape(a)[-1], dtype=a.dtype),\n                                tf.rank(a), 0)\n            a = a + i\n\n            # a is non-hermitian! that's why we can't use sn.utils.matrix_inv\n            # XLA can't invert complex matrices, that's why we work with the\n            # real valued domain\n            a_inv = tf.linalg.inv(a)\n\n            # Step 5: compute unbiased MMSE filter and outputs, calculate A\\H^H\n\n            # Calculate bias mu_i = diag(A^-1 H^H H) = diag(A^-1 G)\n            # Diagonal elements of matrix matrix multiplication simplified\n            # to sum and dot-product\n            # [..., 2K]\n            mu = tf.reduce_sum(a_inv * tf.linalg.matrix_transpose(gr), axis=-1)\n\n            # Make y_mf_pic columns real (after transposition,\n            # the last dimension corresponds to vectors)\n            # [..., K, 2K]\n            y_mf_pic_trans = tf.linalg.matrix_transpose(y_mf_pic)\n            y_mf_pic_trans = complex2real_vector(y_mf_pic_trans)\n            # stack them such that y_mf_pic_trans has shape [..., 2K, 2K]\n            y_mf_pic_trans = tf.concat([y_mf_pic_trans, y_mf_pic_trans],\n                                        axis=-2)\n\n            # Efficient parallel equalization after PIC\n            # z_i = i'th row of a_inv * y_MF_PIC_i\n            # boils down to tf.reduce_sum(a_inv * y_mf_pic_trans, axis=-1)\n            # divide by mu_i for unbiasedness\n            # [..., K]\n            x_hat = real2complex_vector(tf.reduce_sum(a_inv * y_mf_pic_trans,\n                                    axis=-1) / tf.cast(mu, dtype=a_inv.dtype))\n\n            # Compute post equalization signal error estimate:\n            # rho_i = mu_i / (1 - var_x_i * mu_i)\n            # 1 - var_x_i * mu_i can become numerically 0, or even slightly\n            # smaller than zero due to limited numerical precision\n            # [..., 2K]\n            var_x = tf.divide(mu, tf.maximum(1 - var_x * mu, self._epsilon))\n            # real variances map to the same complex valued variances in this\n            # model\n            var_x, _ = tf.split(var_x, 2, -1)\n\n            no_eff = 1. / var_x\n\n            # Step 6: LLR demapping (extrinsic LLRs)\n            # [..., K, num_bits_per_symbols]\n            llr_d = tf.reshape(self._bit_demapper([x_hat, llr_a, no_eff]),\n                                llr_shape)\n\n            return llr_d, llr_a, it\n\n        # Stopping condition (required for tf.while_loop)\n        def dec_stop(llr_d, llr_a, it):  # pylint: disable=W0613\n            return tf.less(it, self._num_iter)\n\n        # start decoding iterations\n        it = tf.constant(0)\n        null_prior = tf.zeros(llr_shape, dtype=self._realdtype)\n        llr_d, llr_a, _ = tf.while_loop(dec_stop,\n                                    mmse_pic_self_iteration,\n                                    (llr_a, null_prior, it),\n                                    parallel_iterations=1,\n                                    maximum_iterations=self._num_iter)\n        llr_e = llr_d - llr_a\n        if self._output == \"symbol\":\n            # convert back to symbols if requested.\n             # output symbol logits computed on extrinsic LLRs\n            out = self._llr_2_symbol_logits_output(llr_e)\n        else:\n            # output extrinsic LLRs\n            out = llr_e\n            if self._hard_out:\n                out = hard_decisions(out)\n\n        return out\n```"}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain how to perform efficient implementation of modulo 2 operation for integer inputs using the \"int_mod_2\" method in the Sionna package."}, {"role": "assistant", "content": "The helper function \"int_mod_2\" in the Sionna package allows a modular 2 operation to be performed on an integer input efficiently.\n\nTo use the \"int_mod_2\" function in the Sionna package, you need to import the Sionna package's functions first. Here's how you might write your Python implementation:\n\n```python\nimport tensorflow as tf\nfrom sionna.fec.utils import int_mod_2\n\n# Example integer tensor\nx = tf.constant([1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=tf.int32)\n\n# Run the function\nresult = int_mod_2(x)\n\n# Print the result\nprint(result)\n```\nNote that the int_mod_2 function returns the result of the integer input tensor modulo 2. This operation computes the remainder of the division of the integer by 2. This can be particularly useful in computer science for determining if numbers are odd or even, as even numbers have a remainder of 0 when divided by 2, and odd numbers have a remainder of 1.\n\nKeep in mind that the function expects the input be an integer or it implicitly casts to int, hence it is strongly recommended that the input be integers to avoid unexpected results."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Describe the concept of chromatic dispersion (CD) and how it is implemented in the Sionna package."}, {"role": "assistant", "content": "Chromatic dispersion (CD) is a phenomenon in optical fibers where different wavelengths of light travel at different speeds, causing the signal to spread out over time. This can lead to signal degradation, especially over long distances. \n\nIn the context provided, CD is implemented in the Sionna package through the Split-Step Fourier Method (SSFM). The SSFM is used to simulate the transmission of a single Gaussian impulse over a lumped amplification channel model consisting of multiple fiber spans and optical amplifiers. \n\nThe impact of CD is parameterized by the group velocity dispersion (GVD) parameter, denoted as \u03b22 in the context. A typical value of \u03b22=-21.67 ps\u00b2/km is used in the notebook. \n\nIn the Sionna package, CD is enabled by setting the 'with_dispersion' parameter to True when instantiating the SSFM layer. The 'beta_2' parameter is also set to represent the GVD parameter. \n\nHere is a snippet of the code that configures the channel with CD:\n\n```python\nspan_cd = sionna.channel.optical.SSFM(\n            alpha=alpha,\n            beta_2=beta_2,\n            f_c=f_c,\n            length=length_sp,\n            sample_duration=dt,\n            with_amplification=False,\n            with_attenuation=True,\n            with_dispersion=True,\n            with_nonlinearity=False,\n            dtype=dtype,\n            t_norm=t_norm)\n```\n\nIn this configuration, only CD is considered and other impairments like noise from the previous section are disabled for a better understanding of CD."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Describe how to simulate the CIRs for many different random positions in Sionna RT."}, {"role": "assistant", "content": "To simulate the Channel Impulse Responses (CIRs) for many different random positions in Sionna RT, you can follow these steps:\n\n1. Import the necessary modules and set up the environment:\n\n```python\nimport os\nimport tensorflow as tf\nimport numpy as np\nimport time\nfrom sionna.rt import load_scene, Transmitter, Receiver, PlanarArray, Camera\nfrom sionna.channel import cir_to_ofdm_channel, subcarrier_frequencies, OFDMChannel, ApplyOFDMChannel, CIRDataset\nfrom sionna.nr import PUSCHConfig, PUSCHTransmitter, PUSCHReceiver\nfrom sionna.utils import compute_ber, ebnodb2no, PlotBER\nfrom sionna.ofdm import KBestDetector, LinearDetector\nfrom sionna.mimo import StreamManagement\n```\n\n2. Load the scene:\n\n```python\nscene = load_scene(sionna.rt.scene.munich)\n```\n\n3. Configure the antenna array for all transmitters and receivers:\n\n```python\nscene.tx_array = PlanarArray(num_rows=1, num_cols=1, vertical_spacing=0.5, horizontal_spacing=0.5, pattern=\"tr38901\", polarization=\"V\")\nscene.rx_array = PlanarArray(num_rows=1, num_cols=1, vertical_spacing=0.5, horizontal_spacing=0.5, pattern=\"dipole\", polarization=\"cross\")\n```\n\n4. Create and add a transmitter and receiver to the scene:\n\n```python\ntx = Transmitter(name=\"tx\", position=[8.5,21,27])\nscene.add(tx)\nrx = Receiver(name=\"rx\", position=[45,90,1.5], orientation=[0,0,0])\nscene.add(rx)\n```\n\n5. Set the carrier frequency of the scene:\n\n```python\nscene.frequency = 2.14e9\n```\n\n6. Compute propagation paths:\n\n```python\npaths = scene.compute_paths(max_depth=5, num_samples=1e6)\n```\n\n7. Transform the paths into channel impulse responses:\n\n```python\npaths.apply_doppler(sampling_frequency=subcarrier_spacing, num_time_steps=14, tx_velocities=[3.,0,0], rx_velocities=[0,7.,0])\na, tau = paths.cir()\n```\n\n8. Compute the frequency response of the channel:\n\n```python\nfrequencies = subcarrier_frequencies(fft_size, subcarrier_spacing)\nh_freq = cir_to_ofdm_channel(frequencies, a, tau, normalize=True)\n```\n\n9. Now you can use the frequency responses `h_freq` for link-level simulations.\n\nRemember to adjust the parameters according to your specific needs."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Discuss the \"RandomInterleaver\" class including its parameters: \"seed\", \"keep_batch_constant\", \"inverse\", \"keep_state\", \"axis\"."}, {"role": "assistant", "content": "The `RandomInterleaver` class is a part of the interleaving module that permutes tensors in a pseudo-random manner. This class can be used as a layer in a Keras model. Here are the main parameters associated with this class:\n\n1. `seed`: This is an integer value that serves as the defining seed for the random sequence when the `keep_state` option is set to True. It helps for reproducibility of the permutation. If `keep_state` is False, a new random seed is generated for each call, unless an explicit seed is provided.\n\n2. `keep_batch_constant`: This boolean parameter, which defaults to True, determines if each sample in the batch uses the same permutation or not. If set to False, unique permutations are generated for each batch sample, which could be slower.\n\n3. `inverse`: Another boolean parameter defaulting to False. When set to True, the inverse permutation is performed.\n\n4. `keep_state`: This parameter also defaults to True. When True, the permutation remains fixed for mulitple calls and is defined by the `seed` attribute. If False, a new permutation is generated for each call unless an explicit seed is provided through the call function.\n\n5. `axis`: This integer value defaults to -1. It determines the dimension that should be interleaved. The first dimension (axis=0) is not allowed.\n\nHere is an example of how to set up an instance of the `RandomInterleaver` in Python:\n\n```python\nfrom sionna.fec.interleaving import RandomInterleaver\nfrom sionna.fec.interleaving import Deinterleaver\n# set-up system\ninterleaver = RandomInterleaver(seed=1234,\n                                keep_batch_constant=False,\n                                axis=-1) \ndeinterleaver = Deinterleaver(interleaver=interleaver)\n```\n\nWhen using this implementation, it's important to remember that the interleaver is stateless, which means the internal seed cannot be updated during runtime and does not change after the initialization. This is designed to simplify distributed graph execution. If required, an explicit random seed can be passed as an additional input when calling the interleaver/deinterleaver pair. And note, this is not the 5G interleaver sequence."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Describe how to define a resource grid and an OFDM channel generator for sampling the channel in the frequency domain."}, {"role": "assistant", "content": "To define a resource grid and an OFDM channel generator for sampling the channel in the frequency domain, you can use the following steps:\n\n1. Define the resource grid: The resource grid is defined using the `ResourceGrid` class from the `sionna.ofdm` module. You need to specify the number of OFDM symbols and the FFT size, which is the number of subcarriers in the OFDM symbol. You also need to specify the subcarrier spacing.\n\n```python\nfrom sionna.ofdm import ResourceGrid\n\nrg = ResourceGrid(num_ofdm_symbols=NUM_OFDM_SYMBOLS,\n                  fft_size=FFT_SIZE,\n                  subcarrier_spacing=SUBCARRIER_SPACING)\n```\n\n2. Define the OFDM channel generator: The OFDM channel generator is defined using the `GenerateOFDMChannel` class from the `sionna.channel` module. You need to specify the channel model and the resource grid.\n\n```python\nfrom sionna.channel import GenerateOFDMChannel\n\nchannel_sampler = GenerateOFDMChannel(CHANNEL_MODEL, rg)\n```\n\nIn the above code, `CHANNEL_MODEL` is the channel model, `NUM_OFDM_SYMBOLS` is the number of OFDM symbols, `FFT_SIZE` is the FFT size, and `SUBCARRIER_SPACING` is the subcarrier spacing. These parameters should be defined based on your specific requirements.\n\nPlease note that the above code snippets are based on the Sionna library, and you need to import the necessary modules and classes before using them."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Define the symbols used in the document related to Sionna including; $T_\\\\text{norm}$, $L_\\\\text{norm}$, $W$, $\\\\alpha$, $\\\\beta_2$, $f_\\\\mathrm{c}$, $\\\\gamma$, $\\\\ell$, $h$, $N_\\mathrm{SSFM}$, $n_\\\\mathrm{sp}$, $\\\\Delta_t$, $\\\\Delta_z$, $G$, $F$, $\\\\rho_\\\\text{ASE}$, $P$, $\\\\hat{D}$, $\\\\hat{N}$ and $f_\\\\textrm{sim}$."}, {"role": "assistant", "content": "The symbols defined in the document related to the optical channel model Sionna include:\n\n1. $T_{\\text{norm}}$: This symbol is the time normalization for the SSFM in seconds.\n\n2. $L_{\\text{norm}}$: This denotes the distance normalization for the SSFM in meters.\n\n3. $W$: This symbol refers to the bandwidth.\n\n4. $\\alpha$: This is the attenuation coefficient in units of $1/L_{\\text{norm}}$.\n\n5. $\\beta_2$: This denotes the group velocity dispersion coefficient in units of $T_{\\text{norm}}^2/L_{\\text{norm}}$.\n\n6. $f_{\\mathrm{c}}$: This is the carrier frequency in Hertz.\n\n7. $\\gamma$: This symbol is the nonlinearity coefficient in units of $1/L_{\\text{norm}}/\\text{W}$.\n\n8. $\\ell$: This is the fiber length in units of $L_{\\text{norm}}$.\n\n9. $h$: This symbol denotes the Planck constant.\n\n10. $N_{\\mathrm{SSFM}}$: This is the number of SSFM simulation steps.\n\n11. $n_{\\mathrm{sp}}$ : This symbol represents the spontaneous emission factor of Raman amplification.\n\n12. $\\Delta_t$:  This is the normalized simulation time step in $T_{\\text{norm}}$.\n\n13. $\\Delta_z$: This represents the normalized simulation step size in $L_{\\text{norm}}$.\n\n14. $G$: This symbol represents the amplifier gain.\n\n15. $F$: This denotes the noise figure of an amplifier.\n\n16. $\\rho_{\\text{ASE}}$: It symbolizes the noise spectral density.\n\n17. $P$: This symbol represents the signal power.\n\n18. $\\hat{D}$: This is the linear SSFM operator.\n\n19. $\\hat{N}$: This is the non-linear SSFM operator.\n\n20. $f_{\\text{sim}}$: This symbol represents the simulation bandwidth."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain how to use a filter to pulse shape a sequence of QAM symbols."}, {"role": "assistant", "content": "To use a filter to pulse shape a sequence of QAM symbols, follow these steps:\n\n1. **Create a Root-Raised-Cosine Filter**: This filter is used for pulse shaping. You can create it using the `RootRaisedCosineFilter` function from the `sionna.signal` module. You need to specify the roll-off factor, the filter span in symbols, and the oversampling factor.\n\n```python\nbeta = 0.22 # Roll-off factor\nspan_in_symbols = 32 # Filter span in symbols\nsamples_per_symbol = 4 # Number of samples per symbol, i.e., the oversampling factor\nrrcf = RootRaisedCosineFilter(span_in_symbols, samples_per_symbol, beta)\n```\n\n2. **Generate a Batch of QAM Symbol Sequences**: Use the `QAMSource` function from the `sionna.utils` module to generate a batch of QAM symbol sequences. \n\n```python\nnum_bits_per_symbol = 4 # The modulation order of the QAM constellation, i.e., 16QAM\nqam = QAMSource(num_bits_per_symbol) # Layer to generate batches of QAM symbols\nbatch_size = 128\nnum_symbols = 1000\nx = qam([batch_size, num_symbols])\n```\n\n3. **Upsample the QAM Symbol Sequence**: Upsampling is the process of inserting zeros after every QAM symbol to increase the sampling rate. Use the `Upsampling` function from the `sionna.signal` module for this.\n\n```python\nus = Upsampling(samples_per_symbol) # Create instance of the Upsampling layer\nx_us = us(x) # Upsample the QAM symbol sequence\n```\n\n4. **Apply the Filter to the Upsampled Sequence**: Now, you can apply the root-raised-cosine filter to the upsampled sequence.\n\n```python\nx_rrcf = rrcf(x_us) # Filter the upsampled sequence\n```\n\n5. **Recover the QAM Symbols**: To recover the QAM symbols from this waveform, apply a matched filter (the same filter in this case) and downsample the result. Use the `Downsampling` function from the `sionna.signal` module for this.\n\n```python\nx_mf = rrcf(x_rrcf) # Apply the matched filter\nds = Downsampling(samples_per_symbol, rrcf.length-1, num_symbols) # Instantiate a downsampling layer\nx_hat = ds(x_mf) # Recover the transmitted symbol sequence\n```\n\nRemember to import the necessary modules and functions before starting."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the details of TurboEncoder, such as the default parameters, the link of the source code of TurboEncoder and explanation."}, {"role": "assistant", "content": "Here is the definition of TurboEncoder: sionna.fec.turbo.TurboEncoder(gen_poly=None, constraint_length=3, rate=1 / 3, terminate=False, interleaver_type='3GPP', output_dtype=tf.float32, **kwargs).  \n  \nThe link of the source code: [TurboEncoder](https://nvlabs.github.io/sionna/_modules/sionna/fec/turbo/encoding.html#TurboEncoder)  \n  \nThe source code of TurboEncoder is as follows:\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\"\"\"Layer for Turbo Code Encoding.\"\"\"\n\nimport math\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Layer\nfrom sionna.fec import interleaving\nfrom sionna.fec.utils import bin2int_tf, int2bin_tf\nfrom sionna.fec.conv.encoding import ConvEncoder\nfrom sionna.fec.conv.utils import Trellis\nfrom sionna.fec.turbo.utils import polynomial_selector, puncture_pattern, TurboTermination\n\nclass TurboEncoder(Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"TurboEncoder(gen_poly=None, constraint_length=3, rate=1/3, terminate=False, interleaver_type='3GPP', output_dtype=tf.float32, **kwargs)\n\n    Performs encoding of information bits to a Turbo code codeword [Berrou]_.\n    Implements the standard Turbo code framework [Berrou]_: Two identical\n    rate-1/2 convolutional encoders :class:`~sionna.fec.conv.encoding.ConvEncoder`\n    are combined to produce a rate-1/3 Turbo code. Further,\n    puncturing to attain a rate-1/2 Turbo code is supported.\n\n    The class inherits from the Keras layer class and can be used as layer in a\n    Keras model.\n\n    Parameters\n    ----------\n    gen_poly: tuple\n        Tuple of strings with each string being a 0,1 sequence. If\n        `None`, ``constraint_length`` must be provided.\n\n    constraint_length: int\n        Valid values are between 3 and 6 inclusive. Only required if\n        ``gen_poly`` is `None`.\n\n    rate: float\n        Valid values are 1/3 and 1/2. Note that ``rate`` here denotes\n        the `design` rate of the Turbo code. If ``terminate`` is `True`, a\n        small rate-loss occurs.\n\n    terminate: boolean\n        Underlying convolutional encoders are terminated to all zero state\n        if `True`. If terminated, the true rate of the code is slightly lower\n        than ``rate``.\n\n    interleaver_type: str\n        Valid values are `\"3GPP\"` or `\"random\"`. Determines the choice of\n        the interleaver to interleave the message bits before input to the\n        second convolutional encoder. If `\"3GPP\"`, the Turbo code interleaver\n        from the 3GPP LTE standard [3GPPTS36212_Turbo]_ is used. If `\"random\"`,\n        a random interleaver is used.\n\n    output_dtype: tf.DType\n        Defaults to `tf.float32`. Defines the output datatype of the layer.\n\n    Input\n    -----\n    inputs : [...,k], tf.float32\n        2+D tensor of information bits where `k` is the information length\n\n    Output\n    ------\n    : `[...,k/rate]`, tf.float32\n        2+D tensor where `rate` is provided as input\n        parameter. The output is the encoded codeword for the input\n        information tensor. When ``terminate`` is `True`, the effective rate\n        of the Turbo code is slightly less than ``rate``.\n\n    Note\n    ----\n        Various notations are used in literature to represent the generator\n        polynomials for convolutional codes. For simplicity\n        :class:`~sionna.fec.turbo.encoding.TurboEncoder` only\n        accepts the binary format, i.e., `10011`, for the ``gen_poly`` argument\n        which corresponds to the polynomial :math:`1 + D^3 + D^4`.\n\n        Note that Turbo codes require the underlying convolutional encoders\n        to be recursive systematic encoders. Only then the channel output\n        from the systematic part of the first encoder can be used to decode\n        the second encoder.\n\n        Also note that ``constraint_length`` and ``memory`` are two different\n        terms often used to denote the strength of the convolutional code. In\n        this sub-package we use ``constraint_length``. For example, the polynomial\n        `10011` has a ``constraint_length`` of 5, however its ``memory`` is\n        only 4.\n\n        When ``terminate`` is `True`, the true rate of the Turbo code is\n        slightly lower than ``rate``. It can be computed as\n        :math:`\\frac{k}{\\frac{k}{r}+\\frac{4\\mu}{3r}}` where `r` denotes\n        ``rate`` and :math:`\\mu` is the ``constraint_length`` - 1. For example, in\n        3GPP, ``constraint_length`` = 4, ``terminate`` = `True`, for\n        ``rate`` = 1/3, true rate is equal to  :math:`\\frac{k}{3k+12}` .\n    \"\"\"\n\n    def __init__(self,\n                 gen_poly=None,\n                 constraint_length=3,\n                 rate=1/3,\n                 terminate=False,\n                 interleaver_type='3GPP',\n                 output_dtype=tf.float32,\n                 **kwargs):\n\n        super().__init__(**kwargs)\n\n        if gen_poly is not None:\n            assert all(isinstance(poly, str) for poly in gen_poly), \\\n                \"Each element of gen_poly must be a string.\"\n            assert all(len(poly)==len(gen_poly[0]) for poly in gen_poly), \\\n                \"Each polynomial must be of same length.\"\n            assert all(all(\n                char in ['0','1'] for char in poly) for poly in gen_poly),\\\n                \"Each Polynomial must be a string of 0/1 s.\"\n            assert len(gen_poly)==2, \\\n                \"Generator polynomials need to be of Rate-1/2 \"\n            self._gen_poly = gen_poly\n        else:\n            valid_constraint_length = (3, 4, 5, 6)\n            assert constraint_length in valid_constraint_length, \\\n                \"Constraint length must be between 3 and 6.\"\n            self._gen_poly = polynomial_selector(constraint_length)\n\n        valid_rates = (1/2, 1/3)\n        assert rate in valid_rates, \"Invalid coderate.\"\n        assert isinstance(terminate, bool), \"terminate must be bool.\"\n        assert interleaver_type in ('3GPP', 'random'),\\\n                                            \"Invalid interleaver_type.\"\n\n        self._coderate_desired = rate\n        self._coderate = self._coderate_desired\n        self._terminate = terminate\n        self._interleaver_type = interleaver_type\n        self.output_dtype = output_dtype\n        # Underlying convolutional encoders to be rsc or not\n        rsc = True\n\n        self._coderate_conv = 1/len(self.gen_poly)\n        self._punct_pattern = puncture_pattern(rate, self._coderate_conv)\n\n        self._trellis = Trellis(self.gen_poly, rsc=rsc)\n        self._mu = self.trellis._mu\n\n        # conv_n denotes number of output bits for conv_k input bits.\n        self._conv_k = self._trellis.conv_k\n        self._conv_n = self._trellis.conv_n\n\n        self._ni = 2**self._conv_k\n        self._no  = 2**self._conv_n\n        self._ns = self._trellis.ns\n\n        self._k = None\n        self._n = None\n\n        if self.terminate:\n            self.turbo_term = TurboTermination(self._mu+1, conv_n=self._conv_n)\n\n        if self._interleaver_type == '3GPP':\n            self.internal_interleaver = interleaving.Turbo3GPPInterleaver()\n        else:\n            self.internal_interleaver = interleaving.RandomInterleaver(\n                                                    keep_batch_constant=True,\n                                                    keep_state=True,\n                                                    axis=-1)\n\n        if self.punct_pattern is not None:\n            self.punct_idx = tf.where(self.punct_pattern)\n\n        self.convencoder = ConvEncoder(gen_poly=self._gen_poly,\n                                       rsc=rsc,\n                                       terminate=self._terminate)\n\n    #########################################\n    # Public methods and properties\n    #########################################\n\n    @property\n    def gen_poly(self):\n        \"\"\"Generator polynomial used by the encoder\"\"\"\n        return self._gen_poly\n\n    @property\n    def constraint_length(self):\n        \"\"\"Constraint length of the encoder\"\"\"\n        return self._mu + 1\n\n    @property\n    def coderate(self):\n        \"\"\"Rate of the code used in the encoder\"\"\"\n        if self.terminate and self._k is None:\n            print(\"Note that, due to termination, the true coderate is lower \"\\\n                  \"than the returned design rate. \"\\\n                  \"The exact true rate is dependent on the value of k and \"\\\n                  \"hence cannot be computed before the first call().\")\n        elif self.terminate and self._k is not None:\n            term_factor = 1+math.ceil(4*self._mu/3)/self._k\n            self._coderate = self._coderate_desired/term_factor\n        return self._coderate\n\n    @property\n    def trellis(self):\n        \"\"\"Trellis object used during encoding\"\"\"\n        return self._trellis\n\n    @property\n    def terminate(self):\n        \"\"\"Indicates if the convolutional encoders are terminated\"\"\"\n        return self._terminate\n\n    @property\n    def punct_pattern(self):\n        \"\"\"Puncturing pattern for the Turbo codeword\"\"\"\n        return self._punct_pattern\n\n    @property\n    def k(self):\n        \"\"\"Number of information bits per codeword\"\"\"\n        if self._k is None:\n            print(\"Note: The value of k cannot be computed before the first \" \\\n                  \"call().\")\n        return self._k\n\n    @property\n    def n(self):\n        \"\"\"Number of codeword bits\"\"\"\n        if self._n is None:\n            print(\"Note: The value of n cannot be computed before the first \" \\\n                  \"call().\")\n        return self._n\n\n    def _conv_enc(self, info_vec, terminate):\n        \"\"\"\n        This method encodes the information tensor info_vec using the\n        underlying convolutional encoder. Returns the encoded codeword tensor\n        array ta, and the tensor array containing termination bits ta_term.\n        If the terminate variable is False, ta_term is array of length 0.\n        \"\"\"\n        msg = tf.cast(info_vec, tf.int32)\n\n        msg_reshaped = tf.reshape(msg, [-1, self._k])\n        term_syms = int(self._mu) if terminate else 0\n\n        prev_st = tf.zeros([tf.shape(msg_reshaped)[0]], tf.int32)\n        ta = tf.TensorArray(tf.int32, size=self.num_syms, dynamic_size=False)\n\n        idx_offset = range(0, self._conv_k)\n        for idx in tf.range(0, self._k, self._conv_k):\n            msg_bits_idx = tf.gather(msg_reshaped,\n                                     idx + idx_offset,\n                                     axis=-1)\n\n            #msg_bits_idx = tf.experimental.numpy.take_along_axis(msg_reshaped)\n\n            msg_idx = bin2int_tf(msg_bits_idx)\n\n            indices = tf.stack([prev_st, msg_idx], -1)\n            new_st = tf.gather_nd(self._trellis.to_nodes, indices=indices)\n\n            idx_syms = tf.gather_nd(self._trellis.op_mat,\n                                    tf.stack([prev_st, new_st], -1))\n            idx_bits = int2bin_tf(idx_syms, self._conv_n)\n            ta = ta.write(idx//self._conv_k, idx_bits)\n            prev_st = new_st\n\n        ta_term = tf.TensorArray(tf.int32, size=term_syms, dynamic_size=False)\n        # Termination\n        if terminate:\n            fb_poly = tf.constant([int(x) for x in self.gen_poly[0][1:]])\n            fb_poly_tiled = tf.tile(\n                tf.expand_dims(fb_poly,0),[tf.shape(prev_st)[0],1])\n            for idx in tf.range(0, term_syms, self._conv_k):\n                prev_st_bits = int2bin_tf(prev_st, self._mu)\n                msg_idx = tf.math.reduce_sum(\n                                    tf.multiply(fb_poly_tiled, prev_st_bits),-1)\n                msg_idx = tf.squeeze(int2bin_tf(msg_idx,1),-1)\n\n                indices = tf.stack([prev_st, msg_idx], -1)\n                new_st = tf.gather_nd(self._trellis.to_nodes, indices=indices)\n                idx_syms = tf.gather_nd(self._trellis.op_mat,\n                                        tf.stack([prev_st, new_st], -1))\n                idx_bits = int2bin_tf(idx_syms, self._conv_n)\n                ta_term = ta_term.write(idx//self._conv_k, idx_bits)\n                prev_st = new_st\n\n        return ta, ta_term\n\n    def _puncture_cw(self, cw):\n        \"\"\"\n        Given the codeword ``cw``, this method punctures ``cw`` using the\n        puncturing pattern defined in self.punct_pattern. A simple tile\n        operation of self.punct_pattern followed by tf.boolean_mask(cw, mask_)\n        works. However this fails in XLA mode as the dimension of the above\n        operation is unknown.\n\n        Hence, idx is obtained from `tf.where(self.punct_pattern)` during\n        initialization. This way the dimension of idx is known during graph\n        creation. Then during the call(), idx is tiled followed by row offset\n        addition to idx (the indices tensor) will achieve the same result as\n        applying a tiled boolean_mask.\n        \"\"\"\n        # cw shape: (bs, n, 3)- transpose to (n, 3, bs)\n        cw = tf.transpose(cw, perm=[1, 2, 0])\n        cw_n = cw.get_shape()[0]\n\n        punct_period = self.punct_pattern.shape[0]\n        mask_reps = cw_n//punct_period\n        idx = tf.tile(self.punct_idx, [mask_reps, 1])\n\n        idx_per_period = self.punct_idx.shape[0]\n        idx_per_time = idx_per_period/punct_period\n\n        # When tiling punct_pattern doesn't cover cw, delta_times > 0\n        delta_times  = cw_n - (mask_reps * punct_period)\n        delta_idx_rows = int(delta_times*idx_per_time)\n\n        time_offset = punct_period * tf.range(mask_reps)[None,:]\n        row_idx = tf.transpose(tf.tile(time_offset,[idx_per_period,1]))\n        row_idx = tf.reshape(row_idx, (-1, 1))\n\n        total_indices = mask_reps*idx_per_period + delta_idx_rows\n        col_idx = tf.zeros((total_indices,1), tf.int32)\n\n        if delta_times > 0:\n            idx = tf.concat([idx, self.punct_idx[:delta_idx_rows]], axis=0)\n            # Additional index row offsets if delta_times > 0\n            time_n = punct_period*mask_reps\n            row_idx_delta = tf.tile(\n                                tf.range(time_n, time_n+delta_times)[None, :],\n                                [delta_idx_rows, 1])\n            row_idx = tf.concat([row_idx, row_idx_delta], axis=0)\n\n        idx_offset = tf.cast(tf.concat([row_idx, col_idx], axis=1), tf.int64)\n        idx = tf.add(idx, idx_offset)\n\n        cw = tf.gather_nd(cw, idx)\n        cw = tf.transpose(cw)\n        return cw\n\n    #########################\n    # Keras layer functions\n    #########################\n\n    def build(self, input_shape):\n        \"\"\"Build layer and check dimensions.\n\n        Args:\n            input_shape: shape of input tensor (...,k).\n        \"\"\"\n        self._k = input_shape[-1]\n        self._n = int(self._k/self._coderate_desired)\n        if self._interleaver_type == '3GPP':\n            assert self._k <= 6144, '3GPP Turbo Codes define Interleavers only\\\n            upto frame lengths of 6144'\n\n        # Num. of encoding periods/state transitions.\n        # Not equal to _k if_conv_k>1.\n        self.num_syms = int(self._k//self._conv_k)\n\n    def call(self, inputs):\n        \"\"\"Turbo code encoding function.\n        Args:\n            inputs (tf.float32): Information tensor of shape `[...,k]`.\n\n        Returns:\n            `tf.float32`: Encoded codeword tensor of shape `[...,n]`.\n        \"\"\"\n        tf.debugging.assert_greater(tf.rank(inputs), 1)\n\n        if inputs.shape[-1] != self._k:\n            self.build(inputs.shape)\n\n        if self._terminate:\n            num_term_bits_ = int(\n                self.turbo_term.get_num_term_syms()/self._coderate_conv)\n            num_term_bits_punct = int(\n                num_term_bits_*self._coderate_conv/self._coderate_desired)\n        else:\n            num_term_bits_ = 0\n            num_term_bits_punct = 0\n\n        output_shape = inputs.get_shape().as_list()\n        output_shape[0] = -1\n        output_shape[-1] = self._n + num_term_bits_punct\n\n        preterm_n = int(self._k/self._coderate_conv)\n        msg = tf.cast(tf.reshape(inputs, [-1, self._k]), tf.int32)\n        msg2 = self.internal_interleaver(msg)\n\n        cw1_ = self.convencoder(msg)\n        cw2_ = self.convencoder(msg2)\n\n        cw1, term1 = cw1_[:, :preterm_n], cw1_[:, preterm_n:]\n        cw2, term2 = cw2_[:, :preterm_n], cw2_[:, preterm_n:]\n\n        # Gather parity stream from 2nd enc\n        par_idx = tf.range(1, preterm_n, delta=self._conv_n)\n        cw2_par = tf.gather(cw2, indices=par_idx, axis=-1)\n\n        cw1 = tf.reshape(cw1,(-1, self._k, self._conv_n))\n        cw2_par = tf.reshape(cw2_par, (-1, self._k, 1))\n\n        # Concatenate 2nd enc parity to _conv_n streams from first encoder\n        cw = tf.concat([cw1, cw2_par], axis=-1)\n\n        if self.terminate:\n            term_syms_turbo = self.turbo_term.termbits_conv2turbo(term1, term2)\n            term_syms_turbo = tf.reshape(\n                term_syms_turbo, (-1, num_term_bits_//2, 3))\n            cw = tf.concat([cw, term_syms_turbo], axis=-2)\n\n        if self.punct_pattern is not None:\n            cw = self._puncture_cw(cw)\n\n        cw = tf.cast(cw, self.output_dtype)\n        cw_reshaped = tf.reshape(cw, output_shape)\n        return cw_reshaped\n```\n  "}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the definition of LMMSEInterpolator, such as the default parameters, the link of the source code and explanation."}, {"role": "assistant", "content": "Here is the definition of LMMSEInterpolator: sionna.ofdm.LMMSEInterpolator(pilot_pattern, cov_mat_time, cov_mat_freq, cov_mat_space=None, order='t-f')\n  \n[sionna.ofdm.LMMSEInterpolator(pilot_pattern, cov_mat_time, cov_mat_freq, cov_mat_space=None, order='t-f')](https://nvlabs.github.io/sionna/_modules/sionna/channel/channel_model.html#ChannelModel)  \n\nsource code:\n```python\nclass LMMSEInterpolator(BaseChannelInterpolator):\n    # pylint: disable=line-too-long\n    r\"\"\"LMMSEInterpolator(pilot_pattern, cov_mat_time, cov_mat_freq, cov_mat_space=None, order='t-f')\n\n    LMMSE interpolation on a resource grid with optional spatial smoothing.\n\n    This class computes for each element of an OFDM resource grid\n    a channel estimate and error variance\n    through linear minimum mean square error (LMMSE) interpolation/smoothing.\n    It is assumed that the measurements were taken at the nonzero positions\n    of a :class:`~sionna.ofdm.PilotPattern`.\n\n    Depending on the value of ``order``, the interpolation is carried out\n    accross time (t), i.e., OFDM symbols, frequency (f), i.e., subcarriers,\n    and optionally space (s), i.e., receive antennas, in any desired order.\n\n    For simplicity, we describe the underlying algorithm assuming that interpolation\n    across the sub-carriers is performed first, followed by interpolation across\n    OFDM symbols, and finally by spatial smoothing across receive\n    antennas.\n    The algorithm is similar if interpolation and/or smoothing are performed in\n    a different order.\n    For clarity, antenna indices are omitted when describing frequency and time\n    interpolation, as the same process is applied to all the antennas.\n\n    The input ``h_hat`` is first reshaped to a resource grid\n    :math:`\\hat{\\mathbf{H}} \\in \\mathbb{C}^{N \\times M}`, by scattering the channel\n    estimates at pilot locations according to the ``pilot_pattern``. :math:`N`\n    denotes the number of OFDM symbols and :math:`M` the number of sub-carriers.\n\n    The first pass consists in interpolating across the sub-carriers:\n\n    .. math::\n        \\hat{\\mathbf{h}}_n^{(1)} = \\mathbf{A}_n \\hat{\\mathbf{h}}_n\n\n    where :math:`1 \\leq n \\leq N` is the OFDM symbol index and :math:`\\hat{\\mathbf{h}}_n` is\n    the :math:`n^{\\text{th}}` (transposed) row of :math:`\\hat{\\mathbf{H}}`.\n    :math:`\\mathbf{A}_n` is the :math:`M \\times M` matrix such that:\n\n    .. math::\n        \\mathbf{A}_n = \\bar{\\mathbf{A}}_n \\mathbf{\\Pi}_n^\\intercal\n\n    where\n\n    .. math::\n        \\bar{\\mathbf{A}}_n = \\underset{\\mathbf{Z} \\in \\mathbb{C}^{M \\times K_n}}{\\text{argmin}} \\left\\lVert \\mathbf{Z}\\left( \\mathbf{\\Pi}_n^\\intercal \\mathbf{R^{(f)}} \\mathbf{\\Pi}_n + \\mathbf{\\Sigma}_n \\right) - \\mathbf{R^{(f)}} \\mathbf{\\Pi}_n \\right\\rVert_{\\text{F}}^2\n\n    and :math:`\\mathbf{R^{(f)}}` is the :math:`M \\times M` channel frequency covariance matrix,\n    :math:`\\mathbf{\\Pi}_n` the :math:`M \\times K_n` matrix that spreads :math:`K_n`\n    values to a vector of size :math:`M` according to the ``pilot_pattern`` for the :math:`n^{\\text{th}}` OFDM symbol,\n    and :math:`\\mathbf{\\Sigma}_n \\in \\mathbb{R}^{K_n \\times K_n}` is the channel estimation error covariance built from\n    ``err_var`` and assumed to be diagonal.\n    Computation of :math:`\\bar{\\mathbf{A}}_n` is done using an algorithm based on complete orthogonal decomposition.\n    This is done to avoid matrix inversion for badly conditioned covariance matrices.\n\n    The channel estimation error variances after the first interpolation pass are computed as\n\n    .. math::\n        \\mathbf{\\Sigma}^{(1)}_n = \\text{diag} \\left( \\mathbf{R^{(f)}} - \\mathbf{A}_n \\mathbf{\\Xi}_n \\mathbf{R^{(f)}} \\right)\n\n    where :math:`\\mathbf{\\Xi}_n` is the diagonal matrix of size :math:`M \\times M` that zeros the\n    columns corresponding to sub-carriers not carrying any pilots.\n    Note that interpolation is not performed for OFDM symbols which do not carry pilots.\n\n    **Remark**: The interpolation matrix differs across OFDM symbols as different\n    OFDM symbols may carry pilots on different sub-carriers and/or have different\n    estimation error variances.\n\n    Scaling of the estimates is then performed to ensure that their\n    variances match the ones expected by the next interpolation step, and the error variances are updated accordingly:\n\n    .. math::\n        \\begin{align}\n            \\left[\\hat{\\mathbf{h}}_n^{(2)}\\right]_m &= s_{n,m} \\left[\\hat{\\mathbf{h}}_n^{(1)}\\right]_m\\\\\n            \\left[\\mathbf{\\Sigma}^{(2)}_n\\right]_{m,m}  &= s_{n,m}\\left( s_{n,m}-1 \\right) \\left[\\hat{\\mathbf{\\Sigma}}^{(1)}_n\\right]_{m,m} + \\left( 1 - s_{n,m} \\right) \\left[\\mathbf{R^{(f)}}\\right]_{m,m} + s_{n,m} \\left[\\mathbf{\\Sigma}^{(1)}_n\\right]_{m,m}\n        \\end{align}\n\n    where the scaling factor :math:`s_{n,m}` is such that:\n\n\n    .. math::\n        \\mathbb{E} \\left\\{ \\left\\lvert s_{n,m} \\left[\\hat{\\mathbf{h}}_n^{(1)}\\right]_m \\right\\rvert^2 \\right\\} = \\left[\\mathbf{R^{(f)}}\\right]_{m,m} +  \\mathbb{E} \\left\\{ \\left\\lvert s_{n,m} \\left[\\hat{\\mathbf{h}}^{(1)}_n\\right]_m - \\left[\\mathbf{h}_n\\right]_m \\right\\rvert^2 \\right\\}\n\n    which leads to:\n\n    .. math::\n        \\begin{align}\n            s_{n,m} &= \\frac{2 \\left[\\mathbf{R^{(f)}}\\right]_{m,m}}{\\left[\\mathbf{R^{(f)}}\\right]_{m,m} - \\left[\\mathbf{\\Sigma}^{(1)}_n\\right]_{m,m} + \\left[\\hat{\\mathbf{\\Sigma}}^{(1)}_n\\right]_{m,m}}\\\\\n            \\hat{\\mathbf{\\Sigma}}^{(1)}_n &= \\mathbf{A}_n \\mathbf{R^{(f)}} \\mathbf{A}_n^{\\mathrm{H}}.\n        \\end{align}\n\n    The second pass consists in interpolating across the OFDM symbols:\n\n    .. math::\n        \\hat{\\mathbf{h}}_m^{(3)} = \\mathbf{B}_m \\tilde{\\mathbf{h}}^{(2)}_m\n\n    where :math:`1 \\leq m \\leq M` is the sub-carrier index and :math:`\\tilde{\\mathbf{h}}^{(2)}_m` is\n    the :math:`m^{\\text{th}}` column of\n\n    .. math::\n        \\hat{\\mathbf{H}}^{(2)} = \\begin{bmatrix}\n                                    {\\hat{\\mathbf{h}}_1^{(2)}}^\\intercal\\\\\n                                    \\vdots\\\\\n                                    {\\hat{\\mathbf{h}}_N^{(2)}}^\\intercal\n                                 \\end{bmatrix}\n\n    and :math:`\\mathbf{B}_m` is the :math:`N \\times N` interpolation LMMSE matrix:\n\n    .. math::\n        \\mathbf{B}_m = \\bar{\\mathbf{B}}_m \\tilde{\\mathbf{\\Pi}}_m^\\intercal\n\n    where\n\n    .. math::\n        \\bar{\\mathbf{B}}_m = \\underset{\\mathbf{Z} \\in \\mathbb{C}^{N \\times L_m}}{\\text{argmin}} \\left\\lVert \\mathbf{Z} \\left( \\tilde{\\mathbf{\\Pi}}_m^\\intercal \\mathbf{R^{(t)}}\\tilde{\\mathbf{\\Pi}}_m + \\tilde{\\mathbf{\\Sigma}}^{(2)}_m \\right) -  \\mathbf{R^{(t)}}\\tilde{\\mathbf{\\Pi}}_m \\right\\rVert_{\\text{F}}^2\n\n    where :math:`\\mathbf{R^{(t)}}` is the :math:`N \\times N` channel time covariance matrix,\n    :math:`\\tilde{\\mathbf{\\Pi}}_m` the :math:`N \\times L_m` matrix that spreads :math:`L_m`\n    values to a vector of size :math:`N` according to the ``pilot_pattern`` for the :math:`m^{\\text{th}}` sub-carrier,\n    and :math:`\\tilde{\\mathbf{\\Sigma}}^{(2)}_m \\in \\mathbb{R}^{L_m \\times L_m}` is the diagonal matrix of channel estimation error variances\n    built by gathering the error variances from (:math:`\\mathbf{\\Sigma}^{(2)}_1,\\dots,\\mathbf{\\Sigma}^{(2)}_N`) corresponding\n    to resource elements carried by the :math:`m^{\\text{th}}` sub-carrier.\n    Computation of :math:`\\bar{\\mathbf{B}}_m` is done using an algorithm based on complete orthogonal decomposition.\n    This is done to avoid matrix inversion for badly conditioned covariance matrices.\n\n    The resulting channel estimate for the resource grid is\n\n    .. math::\n        \\hat{\\mathbf{H}}^{(3)} = \\left[ \\hat{\\mathbf{h}}_1^{(3)} \\dots \\hat{\\mathbf{h}}_M^{(3)} \\right]\n\n    The resulting channel estimation error variances are the diagonal coefficients of the matrices\n\n    .. math::\n        \\mathbf{\\Sigma}^{(3)}_m = \\mathbf{R^{(t)}} - \\mathbf{B}_m \\tilde{\\mathbf{\\Xi}}_m \\mathbf{R^{(t)}}, 1 \\leq m \\leq M\n\n    where :math:`\\tilde{\\mathbf{\\Xi}}_m` is the diagonal matrix of size :math:`N \\times N` that zeros the\n    columns corresponding to OFDM symbols not carrying any pilots.\n\n    **Remark**: The interpolation matrix differs across sub-carriers as different\n    sub-carriers may have different estimation error variances computed by the first\n    pass.\n    However, all sub-carriers carry at least one channel estimate as a result of\n    the first pass, ensuring that a channel estimate is computed for all the resource\n    elements after the second pass.\n\n    **Remark:** LMMSE interpolation requires knowledge of the time and frequency\n    covariance matrices of the channel. The notebook `OFDM MIMO Channel Estimation and Detection <../examples/OFDM_MIMO_Detection.ipynb>`_ shows how to estimate\n    such matrices for arbitrary channel models.\n    Moreover, the functions :func:`~sionna.ofdm.tdl_time_cov_mat`\n    and :func:`~sionna.ofdm.tdl_freq_cov_mat` compute the expected time and frequency\n    covariance matrices, respectively, for the :class:`~sionna.channel.tr38901.TDL` channel models.\n\n    Scaling of the estimates is then performed to ensure that their\n    variances match the ones expected by the next smoothing step, and the\n    error variances are updated accordingly:\n\n    .. math::\n        \\begin{align}\n            \\left[\\hat{\\mathbf{h}}_m^{(4)}\\right]_n &= \\gamma_{m,n} \\left[\\hat{\\mathbf{h}}_m^{(3)}\\right]_n\\\\\n            \\left[\\mathbf{\\Sigma}^{(4)}_m\\right]_{n,n}  &= \\gamma_{m,n}\\left( \\gamma_{m,n}-1 \\right) \\left[\\hat{\\mathbf{\\Sigma}}^{(3)}_m\\right]_{n,n} + \\left( 1 - \\gamma_{m,n} \\right) \\left[\\mathbf{R^{(t)}}\\right]_{n,n} + \\gamma_{m,n} \\left[\\mathbf{\\Sigma}^{(3)}_n\\right]_{m,m}\n        \\end{align}\n\n    where:\n\n    .. math::\n        \\begin{align}\n            \\gamma_{m,n} &= \\frac{2 \\left[\\mathbf{R^{(t)}}\\right]_{n,n}}{\\left[\\mathbf{R^{(t)}}\\right]_{n,n} - \\left[\\mathbf{\\Sigma}^{(3)}_m\\right]_{n,n} + \\left[\\hat{\\mathbf{\\Sigma}}^{(3)}_n\\right]_{m,m}}\\\\\n            \\hat{\\mathbf{\\Sigma}}^{(3)}_m &= \\mathbf{B}_m \\mathbf{R^{(t)}} \\mathbf{B}_m^{\\mathrm{H}}\n        \\end{align}\n\n    Finally, a spatial smoothing step is applied to every resource element carrying\n    a channel estimate.\n    For clarity, we drop the resource element indexing :math:`(n,m)`.\n    We denote by :math:`L` the number of receive antennas, and by\n    :math:`\\mathbf{R^{(s)}}\\in\\mathbb{C}^{L \\times L}` the spatial covariance matrix.\n\n    LMMSE spatial smoothing consists in the following computations:\n\n    .. math::\n        \\hat{\\mathbf{h}}^{(5)} = \\mathbf{C} \\hat{\\mathbf{h}}^{(4)}\n\n    where\n\n    .. math::\n        \\mathbf{C} = \\mathbf{R^{(s)}} \\left( \\mathbf{R^{(s)}} + \\mathbf{\\Sigma}^{(4)} \\right)^{-1}.\n\n    The estimation error variances are the digonal coefficients of\n\n    .. math::\n        \\mathbf{\\Sigma}^{(5)} = \\mathbf{R^{(s)}} - \\mathbf{C}\\mathbf{R^{(s)}}\n\n    The smoothed channel estimate :math:`\\hat{\\mathbf{h}}^{(5)}` and corresponding\n    error variances :math:`\\text{diag}\\left( \\mathbf{\\Sigma}^{(5)} \\right)` are\n    returned for every resource element :math:`(m,n)`.\n\n    **Remark:** No scaling is performed after the last interpolation or smoothing\n    step.\n\n    **Remark:** All passes assume that the estimation error covariance matrix\n    (:math:`\\mathbf{\\Sigma}`, :math:`\\tilde{\\mathbf{\\Sigma}}^{(2)}`, or :math:`\\tilde{\\mathbf{\\Sigma}}^{(4)}`) is diagonal, which\n    may not be accurate. When this assumption does not hold, this interpolator is only\n    an approximation of LMMSE interpolation.\n\n    **Remark:** The order in which frequency interpolation, temporal\n    interpolation, and, optionally, spatial smoothing are applied, is controlled using the\n    ``order`` parameter.\n\n    Note\n    ----\n    This layer does not support graph mode with XLA.\n\n    Parameters\n    ----------\n    pilot_pattern : PilotPattern\n        An instance of :class:`~sionna.ofdm.PilotPattern`\n\n    cov_mat_time : [num_ofdm_symbols, num_ofdm_symbols], tf.complex\n        Time covariance matrix of the channel\n\n    cov_mat_freq : [fft_size, fft_size], tf.complex\n        Frequency covariance matrix of the channel\n\n    cov_time_space : [num_rx_ant, num_rx_ant], tf.complex\n        Spatial covariance matrix of the channel.\n        Defaults to `None`.\n        Only required if spatial smoothing is requested (see ``order``).\n\n    order : str\n        Order in which to perform interpolation and optional smoothing.\n        For example, ``\"t-f-s\"`` means that interpolation across the OFDM symbols\n        is performed first (``\"t\"``: time), followed by interpolation across the\n        sub-carriers (``\"f\"``: frequency), and finally smoothing across the\n        receive antennas (``\"s\"``: space).\n        Similarly, ``\"f-t\"`` means interpolation across the sub-carriers followed\n        by interpolation across the OFDM symbols and no spatial smoothing.\n        The spatial covariance matrix (``cov_time_space``) is only required when\n        spatial smoothing is requested.\n        Time and frequency interpolation are not optional to ensure that a channel\n        estimate is computed for all resource elements.\n\n    Input\n    -----\n    h_hat : [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_pilot_symbols], tf.complex\n        Channel estimates for the pilot-carrying resource elements\n\n    err_var : [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_pilot_symbols], tf.complex\n        Channel estimation error variances for the pilot-carrying resource elements\n\n    Output\n    ------\n    h_hat : [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size], tf.complex\n        Channel estimates accross the entire resource grid for all\n        transmitters and streams\n\n    err_var : Same shape as ``h_hat``, tf.float\n        Channel estimation error variances accross the entire resource grid\n        for all transmitters and streams\n    \"\"\"\n\n    def __init__(self, pilot_pattern, cov_mat_time, cov_mat_freq,\n                    cov_mat_space=None, order='t-f'):\n\n        # Check the specified order\n        order = order.split('-')\n        assert 2 <= len(order) <= 3, \"Invalid order for interpolation.\"\n        spatial_smoothing = False\n        freq_smoothing = False\n        time_smoothing = False\n        for o in order:\n            assert o in ('s', 'f', 't'), f\"Uknown dimension {o}\"\n            if o == 's':\n                assert not spatial_smoothing,\\\n                    \"Spatial smoothing can be specified at most once\"\n                spatial_smoothing = True\n            elif o == 't':\n                assert not time_smoothing,\\\n                    \"Temporal interpolation can be specified once only\"\n                time_smoothing = True\n            elif o == 'f':\n                assert not freq_smoothing,\\\n                    \"Frequency interpolation can be specified once only\"\n                freq_smoothing = True\n        if spatial_smoothing:\n            assert cov_mat_space is not None,\\\n                \"A spatial covariance matrix is required for spatial smoothing\"\n        assert freq_smoothing, \"Frequency interpolation is required\"\n        assert time_smoothing, \"Time interpolation is required\"\n\n        self._order = order\n        self._num_ofdm_symbols = pilot_pattern.num_ofdm_symbols\n        self._num_effective_subcarriers =pilot_pattern.num_effective_subcarriers\n\n        # Build pilot masks for every stream\n        pilot_mask = self._build_pilot_mask(pilot_pattern)\n\n        # Build indices for mapping channel estimates and\n        # error variances that are given as input to a\n        # resource grid\n        num_pilots = pilot_pattern.pilots.shape[2]\n        inputs_to_rg_indices = self._build_inputs2rg_indices(pilot_mask,\n                                                             num_pilots)\n        self._inputs_to_rg_indices = tf.cast(inputs_to_rg_indices, tf.int32)\n\n        # 1D interpolator according to requested order\n        # Interpolation is always performed along the inner dimension.\n        interpolators = []\n        # Masks for masking error variances that were not updated\n        err_var_masks = []\n        for i, o in enumerate(order):\n            # Is it the last one?\n            last_step = i == len(order)-1\n            # Frequency\n            if o == \"f\":\n                interpolator = LMMSEInterpolator1D(pilot_mask, cov_mat_freq,\n                                                        last_step=last_step)\n                pilot_mask = self._update_pilot_mask_interp(pilot_mask)\n                err_var_mask = tf.cast(pilot_mask == 1,\n                                        cov_mat_freq.dtype.real_dtype)\n            # Time\n            elif o == 't':\n                pilot_mask = tf.transpose(pilot_mask, [0, 1, 3, 2])\n                interpolator = LMMSEInterpolator1D(pilot_mask, cov_mat_time,\n                                                        last_step=last_step)\n                pilot_mask = self._update_pilot_mask_interp(pilot_mask)\n                pilot_mask = tf.transpose(pilot_mask, [0, 1, 3, 2])\n                err_var_mask = tf.cast(pilot_mask == 1,\n                                            cov_mat_freq.dtype.real_dtype)\n            # Space\n            elif o == 's':\n                interpolator = SpatialChannelFilter(cov_mat_space,\n                                                    last_step=last_step)\n                err_var_mask = tf.cast(pilot_mask == 1,\n                                            cov_mat_freq.dtype.real_dtype)\n            interpolators.append(interpolator)\n            err_var_masks.append(err_var_mask)\n        self._interpolators = interpolators\n        self._err_var_masks = err_var_masks\n\n    def _build_pilot_mask(self, pilot_pattern):\n        \"\"\"\n        Build for every transmitter and stream a pilot mask indicating\n        which REs are allocated to pilots, data, or not used.\n        # 0 -> Data\n        # 1 -> Pilot\n        # 2 -> Not used\n        \"\"\"\n\n        mask = pilot_pattern.mask\n        pilots = pilot_pattern.pilots\n        num_tx = mask.shape[0]\n        num_streams_per_tx = mask.shape[1]\n        num_ofdm_symbols = mask.shape[2]\n        num_effective_subcarriers = mask.shape[3]\n\n        pilot_mask = np.zeros([num_tx, num_streams_per_tx, num_ofdm_symbols,\n                                num_effective_subcarriers], int)\n        for tx,st in itertools.product( range(num_tx),\n                                        range(num_streams_per_tx)):\n            pil_index = 0\n            for sb,sc in itertools.product( range(num_ofdm_symbols),\n                                            range(num_effective_subcarriers)):\n                if mask[tx,st,sb,sc] == 1:\n                    if np.abs(pilots[tx,st,pil_index]) > 0.0:\n                        pilot_mask[tx,st,sb,sc] = 1\n                    else:\n                        pilot_mask[tx,st,sb,sc] = 2\n                    pil_index += 1\n\n        return pilot_mask\n\n    def _build_inputs2rg_indices(self, pilot_mask, num_pilots):\n        \"\"\"\n        Builds indices for mapping channel estimates and\n        error variances that are given as input to a\n        resource grid\n        \"\"\"\n\n        num_tx = pilot_mask.shape[0]\n        num_streams_per_tx = pilot_mask.shape[1]\n        num_ofdm_symbols = pilot_mask.shape[2]\n        num_effective_subcarriers = pilot_mask.shape[3]\n\n        inputs_to_rg_indices = np.zeros([num_tx, num_streams_per_tx,\n                                         num_pilots, 4], int)\n        for tx,st in itertools.product( range(num_tx),\n                                        range(num_streams_per_tx)):\n            pil_index = 0 # Pilot index for this stream\n            for sb,sc in itertools.product( range(num_ofdm_symbols),\n                                            range(num_effective_subcarriers)):\n                if pilot_mask[tx,st,sb,sc] == 0:\n                    continue\n                if pilot_mask[tx,st,sb,sc] == 1:\n                    inputs_to_rg_indices[tx, st, pil_index] = [tx, st, sb, sc]\n                pil_index += 1\n\n        return inputs_to_rg_indices\n\n    def _update_pilot_mask_interp(self, pilot_mask):\n        \"\"\"\n        Update the pilot mask to label the resource elements for which the\n        channel was interpolated.\n        \"\"\"\n\n        interpolated = np.any(pilot_mask == 1, axis=-1, keepdims=True)\n        pilot_mask = np.where(interpolated, 1, pilot_mask)\n\n        return pilot_mask\n\n    def __call__(self, h_hat, err_var):\n\n        # h_hat : [batch_size, num_rx, num_rx_ant, num_tx,\n        #          num_streams_per_tx, num_pilots]\n        # err_var : [batch_size, num_rx, num_rx_ant, num_tx,\n        #          num_streams_per_tx, num_pilots]\n\n        batch_size = tf.shape(h_hat)[0]\n        num_rx = tf.shape(h_hat)[1]\n        num_rx_ant = tf.shape(h_hat)[2]\n        num_tx = tf.shape(h_hat)[3]\n        num_tx_stream = tf.shape(h_hat)[4]\n        num_ofdm_symbols = self._num_ofdm_symbols\n        num_effective_subcarriers = self._num_effective_subcarriers\n\n        # For some estimator, err_var might not have the same shape\n        # as h_hat\n        err_var = tf.broadcast_to(err_var, tf.shape(h_hat))\n\n        # Mapping the channel estimates and error variances to a resource grid\n        # all : [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx,\n        #           num_ofdm_symbols, num_effective_subcarriers]\n        h_hat = tf.transpose(h_hat, [3, 4, 5, 0, 1, 2])\n        err_var = tf.transpose(err_var, [3, 4, 5, 0, 1, 2])\n        h_hat = tf.scatter_nd(self._inputs_to_rg_indices, h_hat,\n                                            [num_tx, num_tx_stream,\n                                             num_ofdm_symbols,\n                                             num_effective_subcarriers,\n                                             batch_size, num_rx, num_rx_ant])\n        err_var = tf.scatter_nd(self._inputs_to_rg_indices, err_var,\n                                            [num_tx, num_tx_stream,\n                                             num_ofdm_symbols,\n                                             num_effective_subcarriers,\n                                             batch_size, num_rx, num_rx_ant])\n        h_hat = tf.transpose(h_hat, [4, 5, 6, 0, 1, 2, 3])\n        err_var = tf.transpose(err_var, [4, 5, 6, 0, 1, 2, 3])\n\n        # Interpolation\n        # Performed according to the requested order. Transpose are used as\n        # 1D interpolation is performed along the inner axis.\n        items = zip(self._order, self._interpolators, self._err_var_masks)\n        for o,interp,err_var_mask in items:\n            # Frequency\n            if o == 'f':\n                # [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx,\n                #           num_ofdm_symbols, num_effective_subcarriers]\n                h_hat, err_var = interp(h_hat, err_var)\n                err_var_mask = expand_to_rank(err_var_mask, tf.rank(err_var), 0)\n                err_var = err_var*err_var_mask\n            # Time\n            elif o == 't':\n                # [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx,\n                #           num_effective_subcarriers, num_ofdm_symbols]\n                h_hat = tf.transpose(h_hat, [0, 1, 2, 3, 4, 6, 5])\n                err_var = tf.transpose(err_var, [0, 1, 2, 3, 4, 6, 5])\n                h_hat, err_var = interp(h_hat, err_var)\n                # [batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx,\n                #           num_ofdm_symbols, num_effective_subcarriers]\n                h_hat = tf.transpose(h_hat, [0, 1, 2, 3, 4, 6, 5])\n                err_var = tf.transpose(err_var, [0, 1, 2, 3, 4, 6, 5])\n                err_var_mask = expand_to_rank(err_var_mask, tf.rank(err_var), 0)\n                err_var = err_var*err_var_mask\n            # Space\n            elif o == 's':\n                # [batch_size, num_rx, num_tx, num_streams_per_tx,\n                #      num_ofdm_symbols, num_effective_subcarriers, num_rx_ant]\n                h_hat = tf.transpose(h_hat, [0, 1, 3, 4, 5, 6, 2])\n                err_var = tf.transpose(err_var, [0, 1, 3, 4, 5, 6, 2])\n                h_hat, err_var = interp(h_hat, err_var)\n                # [batch_size, num_rx, num_tx, num_streams_per_tx,\n                #      num_ofdm_symbols, num_effective_subcarriers, num_rx_ant]\n                h_hat = tf.transpose(h_hat, [0, 1, 6, 2, 3, 4, 5])\n                err_var = tf.transpose(err_var, [0, 1, 6, 2, 3, 4, 5])\n                err_var_mask = expand_to_rank(err_var_mask, tf.rank(err_var), 0)\n                err_var = err_var*err_var_mask\n\n        return h_hat, err_var\n```"}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain the task of the receiver in Sionna."}, {"role": "assistant", "content": "In Sionna, the task of the receiver is to reconstruct the transmitted bits from the received resource grid of frequency-domain baseband symbols. This is done by solving binary classification problems for each resource element. The receiver uses a state-of-the-art neural receiver that substitutes the channel estimator, equalizer, and demapper. \n\nThe neural receiver is implemented using residual convolutional layers, which are used to process the 2D resource grid that is fed as an input to the neural receiver. Residual (skip) connections are used to avoid gradient vanishing. \n\nThe receiver computes Log-Likelihood Ratios (LLRs) on the coded bits from the received resource grid. The LLRs are then used to compute the binary cross-entropy (BCE) without any additional processing. The BCE is used as the loss function for training the neural receiver. \n\nThe receiver is trained using a training loop of a specified number of iterations. At each iteration, a batch of Signal-to-Noise Ratios (SNRs) is sampled, a forward pass through the end-to-end system is performed, the gradients are computed and applied using the Adam optimizer. After training, the weights of the models are saved in a file for future use. \n\nDuring evaluation, the receiver uses the outer encoder and decoder, and the transmitted information and corresponding LLRs are returned. The performance of the receiver is then benchmarked against other baselines."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the definition of KroneckerModel, such as the default parameters, the link of the source code and explanation."}, {"role": "assistant", "content": "Here is the definition of KroneckerModel: sionna.channel.KroneckerModel(r_tx=None, r_rx=None)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/channel/spatial_correlation.html#KroneckerModel)  \n```python\nclass KroneckerModel(SpatialCorrelation):\n    # pylint: disable=line-too-long\n    r\"\"\"Kronecker model for spatial correlation.\n\n    Given a batch of matrices :math:`\\mathbf{H}\\in\\mathbb{C}^{M\\times K}`,\n    :math:`\\mathbf{R}_\\text{tx}\\in\\mathbb{C}^{K\\times K}`, and\n    :math:`\\mathbf{R}_\\text{rx}\\in\\mathbb{C}^{M\\times M}`, this function\n    will generate the following output:\n\n    .. math::\n\n        \\mathbf{H}_\\text{corr} = \\mathbf{R}^{\\frac12}_\\text{rx} \\mathbf{H} \\mathbf{R}^{\\frac12}_\\text{tx}\n\n    Note that :math:`\\mathbf{R}_\\text{tx}\\in\\mathbb{C}^{K\\times K}` and :math:`\\mathbf{R}_\\text{rx}\\in\\mathbb{C}^{M\\times M}`\n    must be positive semi-definite, such as the ones generated by\n    :meth:`~sionna.channel.exp_corr_mat`.\n\n    Parameters\n    ----------\n    r_tx : [..., K, K], tf.complex\n        Tensor containing the transmit correlation matrices. If\n        the rank of ``r_tx`` is smaller than that of the input ``h``,\n        it will be broadcast.\n\n    r_rx : [..., M, M], tf.complex\n        Tensor containing the receive correlation matrices. If\n        the rank of ``r_rx`` is smaller than that of the input ``h``,\n        it will be broadcast.\n\n    Input\n    -----\n    h : [..., M, K], tf.complex\n        Tensor containing spatially uncorrelated\n        channel coeffficients.\n\n    Output\n    ------\n    h_corr : [..., M, K], tf.complex\n        Tensor containing the spatially\n        correlated channel coefficients.\n    \"\"\"\n    def __init__(self, r_tx=None, r_rx=None):\n        super().__init__()\n        self.r_tx = r_tx\n        self.r_rx = r_rx\n\n    @property\n    def r_tx(self):\n        r\"\"\"Tensor containing the transmit correlation matrices.\n\n        Note\n        ----\n        If you want to set this property in Graph mode with XLA, i.e., within\n        a function that is decorated with ``@tf.function(jit_compile=True)``,\n        you must set ``sionna.Config.xla_compat=true``.\n        See :py:attr:`~sionna.Config.xla_compat`.\n        \"\"\"\n        return self._r_tx\n\n    @r_tx.setter\n    def r_tx(self, value):\n        self._r_tx = value\n        if self._r_tx is not None:\n            self._r_tx_sqrt = matrix_sqrt(value)\n        else:\n            self._r_tx_sqrt = None\n\n    @property\n    def r_rx(self):\n        r\"\"\"Tensor containing the receive correlation matrices.\n\n        Note\n        ----\n        If you want to set this property in Graph mode with XLA, i.e., within\n        a function that is decorated with ``@tf.function(jit_compile=True)``,\n        you must set ``sionna.Config.xla_compat=true``.\n        See :py:attr:`~sionna.Config.xla_compat`.\n        \"\"\"\n        return self._r_rx\n\n    @r_rx.setter\n    def r_rx(self, value):\n        self._r_rx = value\n        if self._r_rx is not None:\n            self._r_rx_sqrt = matrix_sqrt(value)\n        else:\n            self._r_rx_sqrt = None\n\n    def __call__(self, h):\n        if self._r_tx_sqrt is not None:\n            r_tx_sqrt = expand_to_rank(self._r_tx_sqrt, tf.rank(h), 0)\n            h = tf.matmul(h, r_tx_sqrt, adjoint_b=True)\n\n        if self._r_rx_sqrt is not None:\n            r_rx_sqrt = expand_to_rank(self._r_rx_sqrt, tf.rank(h), 0)\n            h = tf.matmul(r_rx_sqrt, h)\n\n        return h\n```  \n  "}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Set up a `ViterbiDecoder` instance compatible with the previously defined convolutional encoder, illustrating using both the `encoder` reference and `gen_poly` parameters for initialization."}, {"role": "assistant", "content": "To set up a `ViterbiDecoder` instance that is compatible with a previously defined `ConvEncoder`, one would typically need to know the specific convolutional code parameters used by the `ConvEncoder`. These parameters include the `gen_poly` (generator polynomials), `rate` (code rate), and `constraint_length`. However, when creating a `ViterbiDecoder`, if we already have an instance of `ConvEncoder`, we can directly pass this instance to the `ViterbiDecoder` without the need to separately specify these parameters.\n\nBelow is an example Python script that illustrates how to initialize a `ViterbiDecoder` using a reference to a `ConvEncoder` instance. Additionally, I'll show how to initialize it using the `gen_poly` parameter for the case where the `ConvEncoder` is not directly referenced.\n\n```python\nfrom sionna.fec.conv import ConvEncoder, ViterbiDecoder\n\n# Initialize the ConvEncoder with specified parameters\n# (This step assumes we have already created the ConvEncoder instance)\n\n# Method 1: Using encoder reference\nencoder = ConvEncoder(gen_poly=['101', '111']) # For illustration purposes\ndecoder_using_encoder_ref = ViterbiDecoder(encoder=encoder)\n\n# Print some properties to confirm successful initialisation\nprint(\"Decoder using encoder reference:\")\nprint(\"Generator Polynomials:\", decoder_using_encoder_ref.gen_poly)\n\n# Method 2: Using gen_poly parameter\n# (This code assumes that gen_poly is known or has been retrieved from the encoder)\ngen_poly = encoder.gen_poly  # Get the generator polynomials from the encoder\ndecoder_using_gen_poly = ViterbiDecoder(gen_poly=gen_poly)\n\n# Print some properties to confirm successful initialisation\nprint(\"\\nDecoder using gen_poly:\")\nprint(\"Generator Polynomials:\", decoder_using_gen_poly.gen_poly)\n\n```\n\nIn the script above, the `ViterbiDecoder` has been initialized in two ways:\n\n1. **Using `encoder` reference**: The `ViterbiDecoder` is directly passed the `encoder` object which is an instance of `ConvEncoder`. All necessary parameters are inferred from the `encoder`.\n\n2. **Using `gen_poly` parameter**: The `ViterbiDecoder` is initialized with the generator polynomials `gen_poly` parameter. This parameter is the same as the one used in the encoder. When initializing the decoder using `gen_poly`, the polynomials must be in the form of a tuple of binary strings, each representing a generator polynomial.\n\nJust to clarify, this Python script assumes that the `ConvEncoder` with generator polynomials '101' and '111' has been previously created and we are referencing that instance. Proper initializations of the `ConvEncoder` or obtaining the generator polynomials (`gen_poly`) from an existing instance would be necessary for this setup. The script also assumes that the appropriate imports are made from Sionna APIs, and other prerequisites such as TensorFlow have been satisfied in the execution environment."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain the significance and definition of a generator matrix and parity-check matrix."}, {"role": "assistant", "content": "A generator matrix and a parity-check matrix are fundamental concepts in coding theory related to linear block codes, which are used extensively in communication and storage systems to detect and correct errors.\n\n**Generator Matrix Definition and Significance:**\nThe generator matrix (often denoted as G) of a linear block code is a matrix used to encode information bits into codeword bits. In mathematical terms, if k is the number of information bits and n is the codeword length, then the generator matrix has dimensions k \u00d7 n. To encode a message, you multiply the binary vector representing the message (of length k) by the generator matrix to produce a codeword (of length n).\n\nThe significance of the generator matrix lies in its ability to map the k-dimensional space of information vectors to the n-dimensional space of codewords while ensuring that the properties of the linear block code, such as minimum distance and error-correcting capability, are maintained. In the code's standard form, the generator matrix typically contains an identity matrix of size k \u00d7 k, which signifies the actual information part, followed by a (k \u00d7 (n-k)) parity matrix.\n\nFor example, in a Sionna API, you might use the `LinearEncoder` class from Sionna's linear FEC (Forward Error Correction) package to encode information bits based on a generator matrix, like so:\n```python\nfrom sionna.fec.linear import LinearEncoder\ngenerator_matrix = #... (some binary matrix of full rank with dimensions [k, n])\nencoder = LinearEncoder(enc_mat=generator_matrix, is_pcm=False)\n# Assume `u` is a tensor of information bits\ncodeword = encoder(u)\n```\n\n**Parity-Check Matrix Definition and Significance:**\nThe parity-check matrix (often denoted as H) of a linear block code is a matrix that allows for the detection of errors in codewords. If n is the codeword length and k is the number of information bits, then the parity-check matrix has dimensions (n-k) \u00d7 n. In a valid codeword, when you multiply the codeword by the transpose of the parity-check matrix, the result is a zero vector (of length n-k).\n\nThe parity-check matrix is crucial for error detection and for some decoding algorithms because it defines the code's properties, such as the code's minimum distance and the error patterns that can be detected. Decoding a received vector often involves operations that are based on the parity-check matrix.\n\nWithin a Sionna implementation, the `OSDecoder` might be used to decode messages based on parity-check matrices or generator matrices. When initiating the OSDecoder with a parity-check matrix, the process would look similar to this:\n```python\nfrom sionna.fec.linear import OSDecoder\nparity_check_matrix = #... (some binary matrix of full rank with dimensions [n-k, n])\ndecoder = OSDecoder(enc_mat=parity_check_matrix, t=4, is_pcm=True)\n# Assume `llr_ch` is a tensor of channel log-likelihood ratios (LLRs)\ndecoded_message = decoder(llr_ch)\n```\n\nThese matrices are closely linked, as a parity-check matrix can be derived from a generator matrix and vice versa, under certain conditions such as full rank. In the context of binary linear block codes provided by the Sionna package, which you have included, you can instantiate the `LinearEncoder` with either a generator matrix or a parity-check matrix (`is_pcm=True`). The encoder object's internal mechanisms will handle the conversion if necessary, ensuring that encoding and decoding operations are performed correctly."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain how to plot the MSE."}, {"role": "assistant", "content": "To plot the Mean Square Error (MSE), you can follow these steps:\n\n1. **Prepare the data**: In the context provided, the MSE is calculated for different methods of channel estimation and interpolation. You need to store these MSE values along with their corresponding labels in a data structure, such as a dictionary or a list.\n\n2. **Import necessary libraries**: You need to import the necessary libraries for plotting. In this case, you would use matplotlib, a popular data visualization library in Python. You can import it with the following line of code:\n\n```python\nimport matplotlib.pyplot as plt\n```\n\n3. **Create the plot**: You can use the `plot` function from matplotlib to create the plot. If your MSE values and their labels are stored in a dictionary, you can loop through the dictionary and plot each set of MSE values with the corresponding label. Here is an example:\n\n```python\nfor label, mse_values in mse_dict.items():\n    plt.plot(snr_dbs, mse_values, label=label)\n```\n\nIn this code, `snr_dbs` is a list of SNR values, `mse_values` is a list of MSE values for a specific method, and `label` is the name of the method.\n\n4. **Customize the plot**: You can customize the plot by adding a title, labels for the x and y axes, a legend, and a grid. Here is an example:\n\n```python\nplt.title(\"MSE for different methods\")\nplt.xlabel(\"SNR (dB)\")\nplt.ylabel(\"MSE\")\nplt.legend()\nplt.grid(True)\n```\n\n5. **Display the plot**: Finally, you can display the plot with the following line of code:\n\n```python\nplt.show()\n```\n\nPlease note that this is a general guide. The actual code might vary depending on how the data is structured and the specific requirements of your plot."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the definition of List2LLRSimple, such as the default parameters, the link of the source code and explanation."}, {"role": "assistant", "content": "Here is the definition of List2LLRSimple: sionna.mimo.List2LLRSimple(num_bits_per_symbol, llr_clip_val=20.0, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/mimo/utils.html#List2LLRSimple)  \n\nsource code:\n```python\nclass List2LLRSimple(Layer, List2LLR):\n    # pylint: disable=line-too-long\n    r\"\"\"List2LLRSimple(num_bits_per_symbol, llr_clip_val=20.0, **kwargs)\n\n    Computes LLRs from a list of candidate vectors (or paths) provided by a MIMO detector.\n\n    The following channel model is assumed:\n\n    .. math::\n        \\bar{\\mathbf{y}} = \\mathbf{R}\\bar{\\mathbf{x}} + \\bar{\\mathbf{n}}\n\n    where :math:`\\bar{\\mathbf{y}}\\in\\mathbb{C}^S` are the channel outputs,\n    :math:`\\mathbf{R}\\in\\mathbb{C}^{S\\times S}` is an upper-triangular matrix,\n    :math:`\\bar{\\mathbf{x}}\\in\\mathbb{C}^S` is the transmitted vector whose entries\n    are uniformly and independently drawn from the constellation :math:`\\mathcal{C}`,\n    and :math:`\\bar{\\mathbf{n}}\\in\\mathbb{C}^S` is white noise\n    with :math:`\\mathbb{E}\\left[\\bar{\\mathbf{n}}\\right]=\\mathbf{0}` and\n    :math:`\\mathbb{E}\\left[\\bar{\\mathbf{n}}\\bar{\\mathbf{n}}^{\\mathsf{H}}\\right]=\\mathbf{I}`.\n\n    It is assumed that a MIMO detector such as :class:`~sionna.mimo.KBestDetector`\n    produces :math:`K` candidate solutions :math:`\\bar{\\mathbf{x}}_k\\in\\mathcal{C}^S`\n    and their associated distance metrics :math:`d_k=\\lVert \\bar{\\mathbf{y}} - \\mathbf{R}\\bar{\\mathbf{x}}_k \\rVert^2`\n    for :math:`k=1,\\dots,K`. This layer can also be used with the real-valued representation of the channel.\n\n    The LLR for the :math:`i\\text{th}` bit of the :math:`k\\text{th}` stream is computed as\n\n    .. math::\n        \\begin{align}\n            LLR(k,i) &= \\log\\left(\\frac{\\Pr(b_{k,i}=1|\\bar{\\mathbf{y}},\\mathbf{R})}{\\Pr(b_{k,i}=0|\\bar{\\mathbf{y}},\\mathbf{R})}\\right)\\\\\n                &\\approx \\min_{j \\in  \\mathcal{C}_{k,i,0}}d_j - \\min_{j \\in  \\mathcal{C}_{k,i,1}}d_j\n        \\end{align}\n\n    where :math:`\\mathcal{C}_{k,i,1}` and :math:`\\mathcal{C}_{k,i,0}` are the set of indices\n    in the list of candidates for which the :math:`i\\text{th}` bit of the :math:`k\\text{th}`\n    stream is equal to 1 and 0, respectively. The LLRs are clipped to :math:`\\pm LLR_\\text{clip}`\n    which can be configured through the parameter ``llr_clip_val``.\n\n    If :math:`\\mathcal{C}_{k,i,0}` is empty, :math:`LLR(k,i)=LLR_\\text{clip}`;\n    if :math:`\\mathcal{C}_{k,i,1}` is empty, :math:`LLR(k,i)=-LLR_\\text{clip}`.\n\n    Parameters\n    ----------\n    num_bits_per_symbol : int\n        Number of bits per constellation symbol\n\n    llr_clip_val : float\n        The absolute values of LLRs are clipped to this value.\n        Defaults to 20.0. Can also be a trainable variable.\n\n    Input\n    -----\n    (y, r, dists, path_inds, path_syms) :\n        Tuple:\n\n    y : [...,M], tf.complex or tf.float\n        Channel outputs of the whitened channel\n\n    r : [...,num_streams, num_streams], same dtype as ``y``\n        Upper triangular channel matrix of the whitened channel\n\n    dists : [...,num_paths], tf.float\n        Distance metric for each path (or candidate)\n\n    path_inds : [...,num_paths,num_streams], tf.int32\n        Symbol indices for every stream of every path (or candidate)\n\n    path_syms : [...,num_path,num_streams], same dtype as ``y``\n        Constellation symbol for every stream of every path (or candidate)\n\n    Output\n    ------\n    llr : [...num_streams,num_bits_per_symbol], tf.float\n        LLRs for all bits of every stream\n    \"\"\"\n    def __init__(self,\n                 num_bits_per_symbol,\n                 llr_clip_val=20.0,\n                 **kwargs):\n        super().__init__(**kwargs)\n\n        # Array composed of binary representations of all symbols indices\n        num_points = 2**num_bits_per_symbol\n        a = np.zeros([num_points, num_bits_per_symbol])\n        for i in range(num_points):\n            a[i, :] = np.array(list(np.binary_repr(i, num_bits_per_symbol)),\n                               dtype=np.int32)\n\n        # Compute symbol indices for which the bits are 0 or 1, e.g.,:\n        # The ith column of c0 provides all symbol indices for which\n        # the ith bit is 0.\n        c0 = np.zeros([int(num_points/2), num_bits_per_symbol])\n        c1 = np.zeros([int(num_points/2), num_bits_per_symbol])\n        for i in range(num_bits_per_symbol):\n            c0[:,i] = np.where(a[:,i]==0)[0]\n            c1[:,i] = np.where(a[:,i]==1)[0]\n\n        # Convert to tensor and add dummy dimensions needed for broadcasting\n        self._c0 = expand_to_rank(tf.constant(c0, tf.int32), 5, 0)\n        self._c1 = expand_to_rank(tf.constant(c1, tf.int32), 5, 0)\n\n        # Assign this absolute value to all LLRs without counter-hypothesis\n        self.llr_clip_val = llr_clip_val\n\n    @property\n    def llr_clip_val(self):\n        return self._llr_clip_val\n\n    @llr_clip_val.setter\n    def llr_clip_val(self, value):\n        self._llr_clip_val = value\n\n    def __call__(self, inputs):\n\n        # dists :     [batch_size, num_paths]\n        # path_inds : [batch_size, num_paths, num_streams]\n        dists, path_inds = inputs[2:4]\n\n        # Scaled by 0.5 to account for the reduced noise power in each complex\n        # dimension if real channel representation is used.\n        if inputs[0].dtype.is_floating:\n            dists = dists/2.0\n\n        # Compute for every symbol in every path which bits are 0 or 1\n        # b0/b1: [batch_size, num_path, num_streams, num_bits_per_symbol]\n        # The reduce_any op is forced to run in XLA mode to be able to\n        # work with very large tensors. There seems to an int32 indexing issue\n        # for all TF reduce CUDA kernels.\n        path_inds = insert_dims(path_inds, 2, axis=-1)\n        b0 = tf.equal(path_inds, self._c0)\n        b1 = tf.equal(path_inds, self._c1)\n        b0 = tf.function(tf.reduce_any, jit_compile=True)(b0, axis=-2)\n        b1 = tf.function(tf.reduce_any, jit_compile=True)(b1, axis=-2)\n\n        # Compute distances for all bits in all paths, set distance to inf\n        # if the bit does not have the correct value\n        dists = expand_to_rank(dists, tf.rank(b0), axis=-1)\n        d0 = tf.where(b0, dists, tf.constant(np.inf, dists.dtype))\n        d1 = tf.where(b1, dists, tf.constant(np.inf, dists.dtype))\n\n        # Compute minimum distance for each bit in each stream\n        # l0/l1: [batch_size, num_streams, num_bits_per_symbol]\n        l0 = tf.reduce_min(d0, axis=1)\n        l1 = tf.reduce_min(d1, axis=1)\n\n        # Compute LLRs\n        llr = l0-l1\n\n        #  Clip LLRs\n        llr = tf.clip_by_value(llr, -self.llr_clip_val, self.llr_clip_val)\n\n        return llr\n```"}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Understand and implement the creation of a ResourceGrid in the sionna.ofdm module. This includes importing the necessary classes, initializing parameters such as num_ofdm_symbols, fft_size, subcarrier_spacing, num_tx, num_streams_per_tx, num_guard_carriers and the other parameters enumerated in the documentation. Generate code that visually represents the created ResourceGrid."}, {"role": "assistant", "content": "Sure, here is a Python code snippet that illustrates the creation of a `ResourceGrid` in the `sionna.ofdm` module:\n\n```python\nimport numpy as np\nfrom sionna.ofdm import ResourceGrid\n\n# Initialize parameters\nnum_ofdm_symbols = 14\nfft_size = 64\nsubcarrier_spacing = 30e3\nnum_tx = 1\nnum_streams_per_tx = 1\nnum_guard_carriers = [5, 6]\ndc_null = True\npilot_pattern = \"kronecker\"\npilot_ofdm_symbol_indices = [2, 11]\n# Create an instance of ResourceGrid\nrg = ResourceGrid(num_ofdm_symbols = num_ofdm_symbols,\n                  fft_size = fft_size,\n                  subcarrier_spacing = subcarrier_spacing,\n                  num_tx = num_tx,\n                  num_streams_per_tx = num_streams_per_tx,\n                  num_guard_carriers = num_guard_carriers,\n                  dc_null = dc_null,\n                  pilot_pattern = pilot_pattern,\n                  pilot_ofdm_symbol_indices = pilot_ofdm_symbol_indices)\n\n# Visually represent the ResourceGrid\nrg.show();\n```\nPlease note that the configurations of `ResourceGrid` can be changed based on your requirements. The lines outlined after \"Create an instance of ResourceGrid\" take parameters such as FFT size, number of transmitters, number of streams per transmitter, cyclic prefix length, guard carriers, etc.\n\nLastly, the `show()` function is used to visually represent the resource grid."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain how to use the `Sionna` Python package to implement differentiable ray tracing for radio propagation modeling."}, {"role": "assistant", "content": "To use the Sionna Python package for implementing differentiable ray tracing for radio propagation modeling, follow the steps below:\n\n1. Import the required modules from `sionna` and load the scene:\n\n    ```python\n    import sionna\n    from sionna.rt import load_scene, PlanarArray, Transmitter, Receiver\n    scene = load_scene(sionna.rt.scene.<scene_name>)  # Substitute <scene_name> with the actual scene name\n    ```\n\n2. Configure antenna arrays for transmitters and receivers:\n\n    ```python\n    scene.tx_array = PlanarArray(num_rows=8, num_cols=2, vertical_spacing=0.7, horizontal_spacing=0.5, pattern=\"tr38901\", polarization=\"VH\")\n    scene.rx_array = PlanarArray(num_rows=1, num_cols=1, vertical_spacing=0.5, horizontal_spacing=0.5, pattern=\"dipole\", polarization=\"cross\")\n    ```\n\n3. Create and place your transmitters and receivers within the scene:\n\n    ```python\n    tx = Transmitter(name=\"tx\", position=[8.5,21,27], orientation=[0,0,0])\n    rx = Receiver(name=\"rx\", position=[45,90,1.5], orientation=[0,0,0])\n    scene.add(tx)\n    scene.add(rx)\n    ```\n\n4. Compute propagation paths:\n\n    ```python\n    paths = scene.compute_paths()\n    ```\n   \n5. Visualize paths and/or compute coverage map:\n\n    ```python\n    scene.preview(paths=paths)  # to visualize paths\n    cm = scene.coverage_map(cm_cell_size=[1.,1.], num_samples=1e7)  # to compute coverage map\n    ```\n\nRemember to review the Sionna [documentation](https://nvlabs.github.io/sionna/api/rt.html) for a detailed explanation of each function and its parameters. \n\nAlso note that this is only a basic implementation and there are several advanced features and options in the Sionna package that you can use depending on your specific requirements such as different types of AntennaArrays, multiple Transmitters and Receivers, different scene objects, different methods to visualize (e.g., rendering to file), etc."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Describe how to implement the concept of weighted BP for BCH codes."}, {"role": "assistant", "content": "To implement the concept of weighted Belief Propagation (BP) for BCH codes, follow these steps:\n\n1. Define the trainable model: This model consists of an LDPC BP decoder and a Gaussian LLR source. The multi-loss function is used to average the loss over all iterations, not just the final estimate. This requires calling the BP decoder iteration-wise by setting `num_iter=1` and `stateful=True`. This allows the decoder to perform a single iteration and return its current estimate while also providing the internal messages for the next iteration.\n\n2. Load a parity-check matrix: This matrix is used for the experiment. The same BCH(63,45) code as in [1] is used. The code can be replaced by any parity-check matrix of your choice.\n\n3. Initialize the model: Set the number of decoding iterations and initialize the model.\n\n4. Simulate and store the BER performance before training: This is done using the `PlotBER` class, which provides a convenient way to store the results for later comparison.\n\n5. Train the model: This is done for a fixed number of SGD training iterations. The training loop is very basic and can be improved with early stopping, different hyper-parameters or optimizers, etc.\n\n6. After training, the weights of the decoder have changed. The new BER performance can be compared to the old one.\n\n7. Further experiments can be conducted, such as implementing weighted BP with unique weights per iteration, applying the concept to (scaled) min-sum decoding, replacing the complete CN update by a neural network, verifying the results from all-zero simulations for a real system simulation with explicit encoder and random data, and seeing what happens in combination with higher order modulation.\n\nPlease note that this is a simplified version of the original algorithm consisting of two major simplifications: Only outgoing variable node (VN) messages are weighted and the same shared weights are used for all iterations. This can potentially influence the final performance, however, simplifies the implementation and allows to run the decoder with different number of iterations."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain how to compare the available OFDM channel estimators in Sionna for the considered setup."}, {"role": "assistant", "content": "To compare the available OFDM channel estimators in Sionna for the considered setup, you can follow these steps:\n\n1. **Define the Simulation Parameters**: This includes the OFDM waveform parameters, antennas geometries and patterns, and the 3GPP UMi channel model.\n\n2. **Estimate the Channel Covariance Matrices**: The linear minimum mean square (LMMSE) interpolation method requires knowledge of the time, frequency, and spatial covariance matrices of the channel frequency response. These are estimated using Monte Carlo sampling.\n\n3. **Create the End-to-End Model**: Create a Keras model which uses the interpolation method specified at initialization. It computes the mean square error (MSE) for a specified batch size and signal-to-noise ratio (SNR) in dB.\n\n4. **Evaluate the MSE**: Define a function that estimates the frequency, time, and spatial covariance matrices using Monte Carlo sampling. Then, compute the estimates by executing the function defined. The batch size and number of iterations determine the total number of samples, i.e., number of samples = batch_size x num_iterations, and hence control the tradeoff between the accuracy of the estimates and the time needed for their computation.\n\n5. **Compare the OFDM Estimators**: This section focuses on comparing the available OFDM channel estimators in Sionna for the considered setup. OFDM channel estimation consists of two steps: Channel estimation at pilot-carrying resource elements using least-squares (LS) and Interpolation for data-carrying resource elements. The LMMSE interpolator also features optional spatial smoothing, which requires the spatial covariance matrix.\n\n6. **Evaluate the Performance**: Define a function for evaluating the mean square error (MSE) of a model over a range of SNRs. The batch_size and num_it parameters control the number of samples used to compute the MSE for each SNR value. The higher the number of samples is, the more accurate the MSE estimation is, at the cost of longer compute time.\n\n7. **Plot the Results**: Finally, plot the MSE for each of the considered OFDM channel estimators to visually compare their performance.\n\nRemember to carefully choose the appropriate Sionna APIs and use them as they are provided without any modifications."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the details of PolarBPDecoder, such as the parameters of the class, the input and output of the class instance, the parameters of the class instance, common error, the property of the class instance."}, {"role": "assistant", "content": "Here is the detailed information of PolarBPDecoder:  \nBelief propagation (BP) decoder for Polar codes [E. Arikan, \u201cChannel polarization: A method for constructing capacity-achieving codes for symmetric binary-input memoryless channels,\u201d IEEE Trans. on Information Theory, 2009.] and Polar-like codes based on [E. Arikan, \u201cA Performance Comparison of Polar Codes and Reed-Muller Codes,\u201d IEEE Commun. Lett., vol. 12, no. 6, pp. 447-449, Jun. 2008.] and [G. D. Forney, \u201cCodes on graphs: normal realizations,\u201d IEEE Trans. Inform. Theory, vol. 47, no. 2, pp. 520-548, Feb. 2001.].\n\nThe class inherits from the Keras layer class and can be used as layer in a Keras model.\n\nRemark: The PolarBPDecoder does currently not support XLA.  \n  \nParameters\n\n- `frozen_pos` (ndarray) \u2013 Array of int defining the n-k indices of the frozen positions.\n- `n` (int) \u2013 Defining the codeword length.\n- `num_iter` (int) \u2013 Defining the number of decoder iterations (no early stopping used at the moment).\n- `hard_out` (bool) \u2013 Defaults to True. If True, the decoder provides hard-decided information bits instead of soft-values.\n- `output_dtype` (tf.DType) \u2013 Defaults to tf.float32. Defines the output datatype of the layer (internal precision remains tf.float32).\n\nInput\n\n- `inputs` ([\u2026,n], tf.float32) \u2013 2+D tensor containing the channel logits/llr values.\n\nOutput\n\n- [\u2026,k], tf.float32 \u2013 2+D tensor containing bit-wise soft-estimates (or hard-decided bit-values) of all k information bits.\n\nRaises\n\n- `AssertionError` \u2013 If n is not int.\n- `AssertionError` \u2013 If n is not a power of 2.\n- `AssertionError` \u2013 If the number of elements in frozen_pos is greater than n.\n- `AssertionError` \u2013 If frozen_pos does not consist of int.\n- `AssertionError` \u2013 If hard_out is not bool.\n- `ValueError` \u2013 If output_dtype is not {tf.float16, tf.float32, tf.float64}.\n- `AssertionError` \u2013 If num_iter is not int.\n- `AssertionError` \u2013 If num_iter is not a positive value.\n\n**Note: **This decoder is fully differentiable and, thus, well-suited for gradient descent-based learning tasks such as learned code design [M. Ebada, S. Cammerer, A. Elkelesh and S. ten Brink, \u201cDeep Learning-based Polar Code Design\u201d, Annual Allerton Conference on Communication, Control, and Computing, 2019.].\n\nAs commonly done, we assume frozen bits are set to 0. Please note that - although its practical relevance is only little - setting frozen bits to 1 may result in affine codes instead of linear code as the all-zero codeword is not necessarily part of the code any more.\n  \nProperties\n- `frozen_pos`: Frozen positions for Polar decoding.\n- `hard_out`: Indicates if decoder hard-decides outputs.\n- `info_pos`: Information bit positions for Polar encoding.\n- `k`: Number of information bits.\n- `llr_max`: Maximum LLR value for internal calculations.\n- `n`: Codeword length.\n- `num_iter`: Number of decoding iterations.\n- `output_dtype`: Output dtype of the decoder.  \n  "}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Describe how to plot the BLERs of the neural receiver and the baselines."}, {"role": "assistant", "content": "To plot the Block Error Rates (BLERs) of the neural receiver and the baselines, you can follow these steps:\n\n1. First, you need to evaluate the performance of each system (neural receiver, baseline with perfect CSI, and baseline with LS estimation) over a range of SNR values. This can be done using the `sim_ber` function from the `sionna.utils` module. This function simulates the Bit Error Rate (BER) and Block Error Rate (BLER) for a given model over a range of SNR values. The function returns the BER and BLER for each SNR value.\n\n2. Store the BLER results for each system in a dictionary. The keys of the dictionary should be the names of the systems (e.g., 'neural-receiver', 'baseline-perfect-csi', 'baseline-ls-estimation') and the values should be the BLER results.\n\n3. Once you have the BLER results for each system, you can plot them using the `semilogy` function from the `matplotlib.pyplot` module. This function creates a plot using a base 10 logarithmic scale for the y-axis and a linear scale for the x-axis. The x-values should be the SNR values and the y-values should be the BLER results.\n\nHere is a sample code snippet for the above steps:\n\n```python\nimport matplotlib.pyplot as plt\n\n# Assume ebno_dbs is the range of SNR values and BLER is the dictionary storing the BLER results\nebno_dbs = np.arange(ebno_db_min, ebno_db_max, 0.5)\nBLER = {'neural-receiver': bler_neural, 'baseline-perfect-csi': bler_perfect_csi, 'baseline-ls-estimation': bler_ls_estimation}\n\nplt.figure(figsize=(10,6))\nfor system, bler in BLER.items():\n    plt.semilogy(ebno_dbs, bler, label=system)\nplt.xlabel(r\"$E_b/N_0$ (dB)\")\nplt.ylabel(\"BLER\")\nplt.grid(which=\"both\")\nplt.ylim((1e-4, 1.0))\nplt.legend()\nplt.tight_layout()\nplt.show()\n```\n\nIn this code, `bler_neural`, `bler_perfect_csi`, and `bler_ls_estimation` are the BLER results for the neural receiver, the baseline with perfect CSI, and the baseline with LS estimation, respectively. These results should be obtained from the `sim_ber` function."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Discuss the potential of optimizing IDD with machine learning, specifically deep-unfolding."}, {"role": "assistant", "content": "Iterative Detection and Decoding (IDD) is a scheme that combines multiple components to optimize the performance of MIMO simulations. The IDD MIMO receiver iteratively exchanges soft-information between the data detector and the channel decoder. This process involves the use of a posteriori information (represented by log-likelihood ratios, LLRs) and extrinsic information, which corresponds to the information gain in the a posteriori information relative to the a priori information.\n\nThe potential of optimizing IDD with machine learning, specifically deep-unfolding, has been explored in recent studies. Deep-unfolding applies machine learning to automatically tune hyperparameters of classical algorithms. For instance, the Deep-Unfolded Interleaved Detection and Decoding (DUIDD) method showed performance gains of up to 1.4 dB at the same computational complexity. This method optimizes a scaling of the forwarded decoder state among other quantities.\n\nIn the context provided, IDD was implemented with a non-resetting LDPC decoder, which showed better performance with a low number of decoding iterations. The non-resetting decoder forwards the decoder state (i.e., the check node to variable node messages) from each IDD iteration to the next. This approach was found to converge faster than with resetting decoders. However, a resetting decoder might perform slightly better for a large number of message passing decoding iterations.\n\nIn conclusion, optimizing IDD with machine learning, specifically deep-unfolding, has the potential to significantly improve the performance of MIMO simulations by automatically tuning hyperparameters and optimizing the decoder state."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain how to import the Sionna package and handle import errors."}, {"role": "assistant", "content": "To import the Sionna package in Python, you can use the following code:\n\n```python\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    import os\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\nThis code first attempts to import the Sionna package. If the package is not found (which raises an `ImportError`), it then installs the package using the `os.system` function to run the command `pip install sionna` in the system shell. After the package is installed, it attempts to import it again.\n\nIf there are any errors during the import process, they will be caught by the `except` block and the error message will be stored in the variable `e`. This can be useful for debugging if there are issues with the installation or import process."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the definition and source code of class Turbo3GPPInterleaver."}, {"role": "assistant", "content": "Here is the definition: sionna.fec.interleaving.Turbo3GPPInterleaver(inverse=False, axis=- 1, dtype=tf.float32, **kwargs)  \n  \nHere is the source code of  Turbo3GPPInterleaver:  \n```python\nclass Turbo3GPPInterleaver(Layer):\n    # pylint: disable=line-too-long\n    \"\"\"Turbo3GPPInterleaver(inverse=False, axis=-1, dtype=tf.float32, **kwargs)\n\n    Interleaver as used in the 3GPP Turbo codes [3GPPTS36212_I]_ and, thus,\n    the maximum length is given as 6144 elements (only for the dimension as\n    specific by ``axis``).\n\n    The class inherits from the Keras layer class and can be used as layer in a\n    Keras model.\n\n    Parameters\n    ----------\n        inverse: bool\n            A boolean defaults to False. If True, the inverse permutation is\n            performed.\n\n        axis: int\n            Defaults to `-1`. The dimension that should be interleaved.\n            First dimension (`axis=0`) is not allowed.\n\n        dtype: tf.DType\n            Defaults to `tf.float32`. Defines the datatype for internal\n            calculations and the output dtype.\n\n    Input\n    -----\n        x: tf.DType\n            2+D tensor of arbitrary shape and dtype.\n\n    Output\n    ------\n        : tf.DType\n            2+D tensor of same shape and dtype as the input ``x``.\n\n    Raises\n    ------\n        AssertionError\n            If ``axis`` is not `int`.\n\n        AssertionError\n            If ``axis`` > number of input dimensions.\n\n        AssertionError\n            If ``inverse`` is not bool.\n\n        InvalidArgumentError\n            When rank(``x``)<2.\n\n    Note\n    ----\n        Note that this implementation slightly deviates from the 3GPP\n        standard [3GPPTS36212_I]_ in a sense that zero-padding is introduced\n        for cases when the exact interleaver length is not supported by the\n        standard.\n    \"\"\"\n\n    def __init__(self,\n                 inverse=False,\n                 axis=-1,\n                 dtype=tf.float32,\n                 **kwargs):\n\n        super().__init__(dtype=dtype, **kwargs)\n\n        assert isinstance(axis, int), \"axis must be int.\"\n        assert axis!=0, \"Cannot permute batch dimension.\"\n        self._axis=axis\n        self._keep_state = True # only required for deinterleaver\n        self.frame_size = None\n\n        assert isinstance(inverse, bool), \"inverse must be boolean\"\n        self._inverse = inverse\n\n        # load interleaver patterns as defined in the 3GPP standard\n        self.coeffs_dict = {}\n        source = files(coeffs).joinpath(\"turbo_coeffs.csv\")\n        with as_file(source) as coeffs.csv:\n            csv_reader = np.genfromtxt(coeffs.csv, delimiter=\",\")\n\n            for (line_count, row) in enumerate(csv_reader):\n                if line_count >0: #igonore first line (=header)\n                    self.coeffs_dict[int(row[1])] = (int(row[2]), int(row[3]))\n    #########################################\n    # Public methods and properties\n    #########################################\n\n    @property\n    def axis(self):\n        \"\"\"Axis to be permuted.\"\"\"\n        return self._axis\n\n    def find_s_min(self, frame_size, s_min_stop=0):\n        r\"\"\"Find :math:`S` parameter such that :math:`\\pi(i)-\\pi(j)>S` for all\n        :math:`i-j<S`. This can be used to find optimized interleaver patterns.\n\n        ``s_min_stop`` is an additional stopping condition, i.e., stop if\n        current :math:`S` is already smaller than ``s_min_stop``.\n\n        Please note that this is a Numpy utility function and usually not part\n        of the graph.\n\n        Input\n        -----\n        frame_size: int\n            length of interleaver.\n\n        s_min_stop: int\n            Defaults to 0. Enables early stop if already current\n            s_min<``s_min_stop``.\n\n        Output\n        ------\n        : float\n            The S-parameter for the given ``frame_size``.\n        \"\"\"\n\n        assert isinstance(s_min_stop, int), \"s_min_stop must be int.\"\n        assert isinstance(frame_size, int), \"frame_size must be int.\"\n        assert(frame_size<6145), \"Interleaver not defined for this frame_size.\"\n\n        perm_seq = self._generate_perm_full(frame_size)\n        perm_seq = perm_seq.numpy()\n        s_min = frame_size\n\n        for i in range(len(perm_seq)): # search for all positions in perm_seq\n            for j in range(-s_min,s_min,1): # search dist\n                if j==0: # ignore identity\n                    continue\n                if i+j>=0 and i+j<frame_size:\n                    d = np.abs(perm_seq[i] - perm_seq[i+j])\n                    if d<=np.abs(j):\n                        s_min = np.min([s_min, np.abs(j)])\n                    if d<s_min and np.abs(j)<s_min:\n                        s_min = np.min([s_min, d])\n            # early stop\n            if s_min<=s_min_stop:\n                break\n        return int(s_min)\n\n\n    def call_inverse(self, inputs):\n        \"\"\"Implements deinterleaver function corresponding to call().\n\n        Input\n        -----\n         x: tf.DType\n            2+D tensor of arbitrary shape and dtype.\n\n        Output\n        ------\n        : tf.DType\n            2+D tensor of same shape and dtype as the input ``x``.\n\n        Raises\n        ------\n        InvalidArgumentError\n            When rank(``x``)<2.\n        \"\"\"\n\n        if isinstance(inputs, (tuple, list)):\n            if len(inputs)==1: # if user wants to call with call([x])\n                x = inputs\n            else:\n                raise TypeError(\"inputs cannot have more than 1 entry.\")\n        else:\n            x = inputs\n\n        input_shape = x.shape\n        frame_size = input_shape[self._axis]\n\n        # activate inverse\n        perm_seq = self._generate_perm_full(frame_size, inverse=True)\n        x = tf.gather(x, perm_seq, batch_dims=0, axis=self._axis)\n\n        # set explicitly for keras models\n        x = tf.ensure_shape(x, input_shape)\n        return x\n\n\n    #########################\n    # Utility methods\n    #########################\n\n    def _generate_perm_full(self, frame_size, inverse=False):\n        \"\"\"Generates a random permutation for the interleaver.\n        Args:\n            frame_size (int): The length of the sequence to be permuted.\n\n            batch_size (int): The batch size (=number of independent\n                permutations).\n\n            inverse (bool): Defaults to False. If True, the inverse permutation\n                for the given seed is generated.\n        \"\"\"\n        k = frame_size\n        if k not in self.coeffs_dict:\n            geqk_sizes = sorted([x for x in self.coeffs_dict if x >= k])\n            if len(geqk_sizes)==0:\n                print(\"Input frame size too large for 3GPP Turbo Interleaver.\")\n            else:\n                k = geqk_sizes[0]\n        f1, f2 = self.coeffs_dict[k]\n        perm_seq = [(f1 * i + f2* (i**2))%k for i in range(k)]\n\n        if frame_size < k:\n            perm_seq = [x for x in perm_seq if x < frame_size]\n\n        perm_seq = tf.convert_to_tensor(perm_seq)\n        if inverse:\n            # cast to tf.float32 due to improved sorting performance\n            perm_seq = tf.cast(perm_seq, tf.float32)\n            perm_seq = tf.argsort(perm_seq, axis=-1)\n\n        return perm_seq\n\n    #########################\n    # Keras layer functions\n    #########################\n\n    def build(self, input_shape):\n        \"\"\"Build Keras layer and check consistency of dimensions.\"\"\"\n        if isinstance(input_shape, list):\n            input_shape=input_shape[0]\n\n        assert self.axis < len(input_shape), \"Axis does not match input shape.\"\n        assert len(input_shape) > 1, \"At least two dims are required.\"\n\n        frame_size = input_shape[self._axis]\n        assert(frame_size< 6145), \\\n            \"3GPP Turbo Interleaver is defined for block lengths up to 6144.\"\n\n    def call(self, inputs):\n        \"\"\"Interleaving function.\n\n        This function returns the permuted version of ``inputs``.\n        \"\"\"\n\n        if isinstance(inputs, (tuple, list)):\n            if len(inputs)==1: # if user wants to call with call([x])\n                x = inputs\n            else:\n                raise TypeError(\"inputs cannot have more than 1 entry.\")\n        else:\n            x = inputs\n\n        input_shape = x.shape\n        frame_size = input_shape[self._axis]\n\n        perm_seq = self._generate_perm_full(frame_size, self._inverse)\n        x = tf.gather(x, perm_seq, batch_dims=0, axis=self._axis)\n\n        # set explicitly for keras models\n        x = tf.ensure_shape(x, input_shape)\n        return x\n```\n  "}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Describe the purpose of a binary linear block code in the context of error correction."}, {"role": "assistant", "content": "The purpose of a binary linear block code in the context of error correction is to enable the reliable transmission of data over noisy communication channels. These codes are structured sets of binary sequences, which are used to add redundancy to the information being sent. This redundancy allows the receiver to detect and correct errors that occur during the transmission.\n\nWhen data is encoded using a binary linear block code, it is transformed from k information bits to an n-bit codeword, where n > k. This process introduces n - k redundant bits, which are determined by the specific properties of the code. The parameters k and n define the dimensions of the generator matrix or the parity-check matrix associated with the code.\n\nThe role of the generator matrix is to create the actual codewords, while the parity-check matrix is used to verify if the received codeword contains errors. Using these matrices, the encoder and decoder can validate and correct certain patterns of errors to ensure the integrity of the transmitted data.\n\nIn the provided context, the `LinearEncoder` can be initialized with either a generator or a parity-check matrix, and it encodes the information bits into codewords. To exemplify, the encoder might be set up using the following code snippet from the Sionna APIs:\n\n```python\nfrom sionna.fec.linear import LinearEncoder\n# Initialize encoder with a parity-check or generator matrix (pcm)\nencoder = LinearEncoder(enc_mat=pcm, is_pcm=True)\n```\n\nFor decoding, the `OSDecoder` executes the ordered-statistics decoding algorithm to correct errors in the received codewords. Specifically, it sorts Log-Likelihood Ratios (LLRs) based on reliability, uses the generator matrix in a permuted systematic form, and then searches for the most likely error-free codeword by evaluating various error patterns. This process can be represented by the initialization of the decoder from the Sionna APIs:\n\n```python\nfrom sionna.fec.linear import OSDecoder\n# Initialize decoder with a parity-check matrix or from a specific encoder\ndecoder = OSDecoder(pcm, t=4, is_pcm=True) # where t is the OSD order\n```\n\nor\n\n```python\n# Instantiate from a specific encoder\ndecoder = OSDecoder(encoder=encoder, t=4) # where t is the OSD order\n```\n\nOSD is an approximation of a maximum likelihood decoding algorithm, which gives it the capability to correct errors up to a certain degree depending on the complexity allowed by the selected order `t`.\n\nThe interaction between the encoder and decoder demonstrates how binary linear block codes are pivotal in error correction, enhancing the reliability of data transmission by introducing systematic redundancy and providing mechanisms to detect and correct errors introduced by the communication channel. These operations fall under the broader field of Forward Error Correction (FEC), which is essential for maintaining communication integrity and efficiency."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain the difference between eager mode and graph mode in Sionna."}, {"role": "assistant", "content": "Eager mode and graph mode in Sionna refer to two different ways of executing computations in TensorFlow, which is the underlying framework used by Sionna.\n\nEager mode allows operations to be executed immediately as they are called within Python. This makes it more interactive and easier to debug, as you can access and manipulate the values of tensors directly. It's useful for prototyping and experimenting with new ideas.\n\nOn the other hand, graph mode compiles and optimizes a computation graph before executing operations. This can lead to more efficient execution and is better suited for production environments and large-scale simulations. In graph mode, operations are executed all at once, which can lead to performance improvements, especially on GPUs.\n\nIn the context provided, Sionna models can be developed in eager mode for easy modification of system parameters, and then executed in the faster graph mode for number crunching simulations. There's also mention of XLA acceleration, which is an advanced optimization feature of TensorFlow that can further speed up computations."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain how to configure the channel to perform the true SSFM to simulate the impairments (ASE noise, CD, and Kerr nonlinearity) jointly."}, {"role": "assistant", "content": "To configure the channel to perform the true Split-Step Fourier Method (SSFM) to simulate the impairments (ASE noise, Chromatic Dispersion (CD), and Kerr nonlinearity) jointly, follow these steps:\n\n1. Import the necessary libraries and modules. This includes TensorFlow, numpy, matplotlib, and the Sionna package.\n\n2. Set up the simulation parameters. This includes the simulation time window, number of simulation samples, peak power of the Gaussian pulse, and the temporal scaling of the Gaussian pulse.\n\n3. Define the fiber parameters. This includes the carrier frequency, fiber span length, and fiber attenuation.\n\n4. Define the EDFA parameters. This includes the amplifier gain and the noise figure.\n\n5. Configure the SSFM layer. This includes setting the alpha, beta_2, gamma, carrier frequency, length, sample duration, number of SSFM simulation steps, and enabling the amplification, attenuation, dispersion, and nonlinearity.\n\n6. Configure the EDFA layer. This includes setting the gain, noise figure, carrier frequency, and sample duration.\n\n7. Define the lumped amplification channel function. This function takes the input signal, passes it through the SSFM layer and the EDFA layer for each span of the fiber.\n\n8. Transmit the impulse over the channel. This involves passing the Gaussian impulse through the lumped amplification channel function.\n\n9. Visualize the output. This can be done using matplotlib to plot the transmitted and received signals.\n\nRemember to compile the channel model before its execution by adding the `tf.function` decorator to the lumped amplification channel function. This is because performing the true SSFM to simulate the impairments jointly is computationally complex."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the definition of sionna.signal.Upsampling in Sionna, such as the default parameters, the link of the source code and explanation."}, {"role": "assistant", "content": "Here is the definition of sionna.signal.Upsampling: sionna.signal.Upsampling(samples_per_symbol, axis=- 1, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/signal/upsampling.html#Upsampling)  \n\nsource code:\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\"\"\"Layers implementing upsampling\"\"\"\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Layer\nfrom tensorflow.experimental.numpy import swapaxes\nfrom sionna.utils.tensors import flatten_last_dims\n\nclass Upsampling(Layer):\n    \"\"\"Upsampling(samples_per_symbol, axis=-1, **kwargs)\n\n    Upsamples a tensor along a specified axis by inserting zeros\n    between samples.\n\n    Parameters\n    ----------\n    samples_per_symbol: int\n        The upsampling factor. If ``samples_per_symbol`` is equal to `n`,\n        then the upsampled axis will be `n`-times longer.\n\n    axis: int\n        The dimension to be up-sampled. Must not be the first dimension.\n\n    Input\n    -----\n    x : [...,n,...], tf.DType\n        The tensor to be upsampled. `n` is the size of the `axis` dimension.\n\n    Output\n    ------\n    y : [...,n*samples_per_symbol,...], same dtype as ``x``\n        The upsampled tensor.\n    \"\"\"\n    def __init__(self, samples_per_symbol, axis=-1, **kwargs):\n        super().__init__(**kwargs)\n        self._samples_per_symbol = samples_per_symbol\n        self._axis = axis\n\n    def build(self, input_shape):\n        paddings = []\n        for _ in range(len(input_shape)):\n            paddings.append([0, 0])\n        paddings.append([0, self._samples_per_symbol-1])\n        self._paddings = paddings\n\n    def call(self, inputs):\n        x = swapaxes(inputs, self._axis, -1)\n        x = tf.expand_dims(x, -1)\n        x = tf.pad(x,\n                   self._paddings,\n                   constant_values=tf.cast(0, dtype=x.dtype))\n        x = flatten_last_dims(x, 2)\n        x = swapaxes(x, -1, self._axis)\n        return x\n```"}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the details of class ApplyOFDMChannel, such as the parameters of the class, the input and output of the class instance and the link of source code."}, {"role": "assistant", "content": "Here is the detailed information of ApplyOFDMChannel:   \n  \n[sionna.channel.ApplyOFDMChannel(add_awgn=True, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/channel/apply_ofdm_channel.html#ApplyOFDMChannel)  \n\nApply single-tap channel frequency responses to channel inputs.\n\nThis class inherits from the Keras Layer class and can be used as layer in a Keras model.\n\nFor each OFDM symbol $s$ and subcarrier $n$, the single-tap channel is applied as follows: $y_{s,n} = \\widehat{h}_{s, n} x_{s,n} + w_{s,n}$ where $y_{s,n}$ is the channel output computed by this layer, $\\widehat{h}_{s, n}$ the frequency channel response (h_freq), $x_{s,n}$ the channel input x, and $w_{s,n}$ the additive noise.  \n  \nFor multiple-input multiple-output (MIMO) links, the channel output is computed for each antenna of each receiver and by summing over all the antennas of all transmitters.\n\n**Parameters**\n\n- `add_awgn` (bool): If set to False, no white Gaussian noise is added. Defaults to True.\n- `dtype` (tf.DType): Complex datatype to use for internal processing and output. Defaults to tf.complex64.\n\n**Input**\n\n- `(x, h_freq, no)` or `(x, h_freq)` \u2013 Tuple:\n  - `x` ([batch size, num_tx, num_tx_ant, num_ofdm_symbols, fft_size], tf.complex): Channel inputs\n  - `h_freq` ([batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_ofdm_symbols, fft_size], tf.complex): Channel frequency responses\n  - `no` (Scalar or Tensor, tf.float): Scalar or tensor whose shape can be broadcast to the shape of the channel outputs: [batch size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size]. Only required if `add_awgn` is set to True. The noise power `no` is per complex dimension. If `no` is a scalar, noise of the same variance will be added to the outputs. If `no` is a tensor, it must have a shape that can be broadcast to the shape of the channel outputs. This allows, e.g., adding noise of different variance to each example in a batch. If `no` has a lower rank than the channel outputs, then `no` will be broadcast to the shape of the channel outputs by adding dummy dimensions after the last axis.\n\n**Output**\n\n- `y` ([batch size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex): Channel outputs"}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the definition of CustomFilter in Sionna, such as the default parameters, the link of the source code and explanation."}, {"role": "assistant", "content": "Here is the definition of CustomFilter: sionna.signal.CustomFilter(span_in_symbols=None, samples_per_symbol=None, coefficients=None, window=None, normalize=True, trainable=False, dtype=tf.float32, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/signal/filter.html#CustomFilter)  \n\nsource code:\n```python\nclass CustomFilter(Filter):\n    # pylint: disable=line-too-long\n    r\"\"\"CustomFilter(span_in_symbols=None, samples_per_symbol=None, coefficients=None, window=None, normalize=True, trainable=False, dtype=tf.float32, **kwargs)\n\n    Layer for applying a custom filter of ``length`` K\n    to an input ``x`` of length N.\n\n    The filter length K is equal to the filter span in symbols (``span_in_symbols``)\n    multiplied by the oversampling factor (``samples_per_symbol``).\n    If this product is even, a value of one will be added.\n\n    The filter is applied through discrete convolution.\n\n    An optional windowing function ``window`` can be applied to the filter.\n\n    The `dtype` of the output is `tf.float` if both ``x`` and the filter coefficients have dtype `tf.float`.\n    Otherwise, the dtype of the output is `tf.complex`.\n\n    Three padding modes are available for applying the filter:\n\n    *   \"full\" (default): Returns the convolution at each point of overlap between ``x`` and the filter.\n        The length of the output is N + K - 1. Zero-padding of the input ``x`` is performed to\n        compute the convolution at the borders.\n    *   \"same\": Returns an output of the same length as the input ``x``. The convolution is computed such\n        that the coefficients of the input ``x`` are centered on the coefficient of the filter with index\n        (K-1)/2. Zero-padding of the input signal is performed to compute the convolution at the borders.\n    *   \"valid\": Returns the convolution only at points where ``x`` and the filter completely overlap.\n        The length of the output is N - K + 1.\n\n    Parameters\n    ----------\n    span_in_symbols: int\n        Filter span as measured by the number of symbols.\n        Only needs to be provided if ``coefficients`` is None.\n\n    samples_per_symbol: int\n        Number of samples per symbol, i.e., the oversampling factor.\n        Must always be provided.\n\n    coefficients: [K], tf.float or tf.complex\n        Optional filter coefficients.\n        If set to `None`, then a random filter of K is generated\n        by sampling a Gaussian distribution. Defaults to `None`.\n\n    window: Window or string ([\"hann\", \"hamming\", \"blackman\"])\n        Instance of :class:`~sionna.signal.Window` that is applied to the filter coefficients.\n        Alternatively, a string indicating the window name can be provided. In this case,\n        the chosen window will be instantiated with the default parameters. Custom windows\n        must be provided as instance.\n\n    normalize: bool\n        If `True`, the filter is normalized to have unit power.\n        Defaults to `True`.\n\n    trainable: bool\n        If `True`, the filter coefficients are trainable variables.\n        Defaults to `False`.\n\n    dtype: tf.DType\n        The `dtype` of the filter coefficients.\n        Defaults to `tf.float32`.\n\n    Input\n    -----\n    x : [..., N], tf.complex or tf.float\n        The input to which the filter is applied.\n        The filter is applied along the last dimension.\n\n    padding : string ([\"full\", \"valid\", \"same\"])\n        Padding mode for convolving ``x`` and the filter.\n        Must be one of \"full\", \"valid\", or \"same\". Case insensitive.\n        Defaults to \"full\".\n\n    conjugate : bool\n        If `True`, the complex conjugate of the filter is applied.\n        Defaults to `False`.\n\n    Output\n    ------\n    y : [...,M], tf.complex or tf.float\n        Filtered input.\n        It is `tf.float` only if both ``x`` and the filter are `tf.float`.\n        It is `tf.complex` otherwise.\n        The length M depends on the ``padding``.\n    \"\"\"\n    def __init__(self,\n                 span_in_symbols=None,\n                 samples_per_symbol=None,\n                 coefficients=None,\n                 window=None,\n                 normalize=True,\n                 trainable=False,\n                 dtype=tf.float32,\n                 **kwargs):\n\n        assert samples_per_symbol is not None and samples_per_symbol>0, \\\n        \"samples_per_symbol must be positive\"\n        self._samples_per_symbol = samples_per_symbol\n\n        if coefficients is None:\n            assert span_in_symbols is not None and span_in_symbols>0, \\\n                \"span_in_symbols must be positive\"\n            self._span_in_symbols = span_in_symbols\n\n        if coefficients is not None:\n            l = coefficients.shape[-1]\n            assert l%2==1, \\\n                \"The number of coefficients must be odd\"\n            self._span_in_symbols = l//self._samples_per_symbol\n        else:\n            if dtype.is_complex:\n                h = RandomNormal()([2, self.length], dtype.real_dtype)\n                coefficients = tf.complex(h[0], h[1])\n            else:\n                coefficients = RandomNormal()([self.length], dtype)\n\n        # Coefficients setter initialises coefficients properly\n        self._h = tf.constant(coefficients, dtype)\n\n        super().__init__(self._span_in_symbols,\n                         self._samples_per_symbol,\n                         window=window,\n                         normalize=normalize,\n                         trainable=trainable,\n                         dtype=dtype,\n                         **kwargs)\n\n    @property\n    def _coefficients_source(self):\n        return self._h\n```"}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the details of class MMSEPICDetector, such as the parameters of the class, the input and output of the class instance and the link of source code."}, {"role": "assistant", "content": "Here is the detailed information of MMSEPICDetector:   \n  \n[sionna.mimo.MMSEPICDetector(output, demapping_method='maxlog', num_iter=1, constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/mimo/detection.html#MMSEPICDetector)  \n\nMinimum mean square error (MMSE) with parallel interference cancellation (PIC) detector\n\nThis layer implements the MMSE PIC detector, as proposed in [CST2011]. For num_iter>1, this implementation performs MMSE PIC self-iterations. MMSE PIC self-iterations can be understood as a concatenation of MMSE PIC detectors from [CST2011], which forward intrinsic LLRs to the next self-iteration.\n\nCompared to [CST2011], this implementation also accepts priors on the constellation symbols as an alternative to priors on the bits.\n\nThis layer assumes the following channel model:\n$\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}$\nwhere $\\mathbf{y}\\in\\mathbb{C}^M$ is the received signal vector, $\\mathbf{x}\\in\\mathcal{C}^S$ is the vector of transmitted symbols which are uniformly and independently drawn from the constellation $\\mathcal{C}$, $\\mathbf{H}\\in\\mathbb{C}^{M\\times S}$ is the known channel matrix, and $\\mathbf{n}\\in\\mathbb{C}^M$  is a complex Gaussian noise vector. It is assumed that $\\mathbb{E}\\left[\\mathbf{n}\\right]=\\mathbf{0}$ and $\\mathbb{E}\\left[\\mathbf{n}\\mathbf{n}^{\\mathsf{H}}\\right]=\\mathbf{S}$, where $\\mathbf{S}$ has full rank.\n\nThe algorithm starts by computing the soft symbols $\\bar{x}_s=\\mathbb{E}\\left[ x_s \\right]$ and variances $v_s=\\mathbb{E}\\left[ |e_s|^2\\right]$ from the priors, where $e_s = x_s - \\bar{x}_s$, for all $s=1,\\dots,S$.\n\nNext, for each stream, the interference caused by all other streams is cancelled from the observation $\\mathbf{y}$, leading to\n$\\hat{\\mathbf{y}}_s = \\mathbf{y} - \\sum_{j\\neq s} \\mathbf{h}_j x_j = \\mathbf{h}_s x_s + \\tilde{\\mathbf{n}}_s,\\quad s=1,\\dots,S$\nwhere $\\tilde{\\mathbf{n}}_s=\\sum_{j\\neq s} \\mathbf{h}_j e_j + \\mathbf{n}$\n\nThen, a linear MMSE filter $\\mathbf{w}_s$ is computed to reduce the resdiual noise for each observation $\\hat{\\mathbf{y}}_s$, which is given as $\\mathbf{w}_s = \\mathbf{h}_s^{\\mathsf{H}}\\left( \\mathbf{H} \\mathbf{D}_s\\mathbf{H}^{\\mathsf{H}} +\\mathbf{S} \\right)^{-1}$\nwhere $\\mathbf{D}_s \\in \\mathbb{C}^{S\\times S}$ is diagonal with entries $\\begin{split}\\left[\\mathbf{D}_s\\right]_{i,i} = \\begin{cases}\n                                    v_i & i\\neq s \\\\\n                                    1 & i=s.\n                                  \\end{cases}\\end{split}$\nThe filtered observations $\\tilde{z}_s = \\mathbf{w}_s^{\\mathsf{H}} \\hat{\\mathbf{y}}_s = \\tilde{\\mu}_s x_s + \\mathbf{w}_s^{\\mathsf{H}}\\tilde{\\mathbf{n}}_s$ where $\\tilde{\\mu}_s=\\mathbf{w}_s^{\\mathsf{H}} \\mathbf{h}_s$, are then demapped to either symbol logits or LLRs, assuming that the remaining noise is Gaussian with variance $\\nu_s^2 = \\mathop{\\text{Var}}\\left[\\tilde{z}_s\\right] = \\mathbf{w}_s^{\\mathsf{H}} \\left(\\sum_{j\\neq s} \\mathbf{h}_j \\mathbf{h}_j^{\\mathsf{H}} v_j +\\mathbf{S} \\right)\\mathbf{w}_s.$\n\nThe resulting soft-symbols can then be used for the next self-iteration of the algorithm.\n\nNote that this algorithm can be substantially simplified as described in [C. Studer, S. Fateh, and D. Seethaler, \u201cASIC Implementation of Soft-Input Soft-Output MIMO Detection Using MMSE Parallel Interference Cancellation\u201d, IEEE Journal of Solid-State Circuits, vol. 46, no. 7, pp. 1754\u20131765, July 2011.] to avoid the computation of different matrix inverses for each stream. This is the version which is implemented.\n\n**Parameters**\n\n- `output` (str): Specifies the type of output, either \"bit\" for LLRs on bits or \"symbol\" for logits on constellation symbols.\n- `demapping_method` (str): Demapping method used, options include \"app\" or \"maxlog\". Defaults to \"maxlog\".\n- `num_iter` (int): Number of MMSE PIC iterations. Defaults to 1.\n- `constellation_type` (str): Type of constellation, options are \"qam\", \"pam\", or \"custom\". For \"custom\", an instance of Constellation must be provided.\n- `num_bits_per_symbol` (int): Number of bits per constellation symbol, necessary for \"qam\" and \"pam\" constellation types.\n- `constellation` (Constellation): Instance of Constellation, or None if not using a custom type. If None, both `constellation_type` and `num_bits_per_symbol` must be specified.\n- `hard_out` (bool): If true, computes hard-decided values instead of soft-values. Defaults to False.\n- `dtype` (tf.DType): The data type of `y`. Choices include tf.complex64 or tf.complex128, defaulting to tf.complex64. The output data type is the corresponding real type (tf.float32 or tf.float64).\n\n**Input**\n\n- `(y, h, prior, s)` \u2013 Tuple:\n  - `y` ([..., M], tf.complex): 1+D tensor containing the received signals.\n  - `h` ([..., M, S], tf.complex): 2+D tensor containing the channel matrices.\n  - `prior` ([..., S, num_bits_per_symbol] or [..., S, num_points], tf.float): Prior of the transmitted signals. If output is \"bit\", then LLRs of the transmitted bits are expected; if \"symbol\", then logits of the transmitted constellation points are expected.\n  - `s` ([..., M, M], tf.complex): 2+D tensor containing the noise covariance matrices.\n\n**Output**\n\n- Depending on the `output` setting:\n  - If `output` equals \"bit\":\n    - [..., S, num_bits_per_symbol], tf.float: LLRs or hard-decisions for every bit of every stream.\n  - If `output` equals \"symbol\":\n    - [..., S, 2**num_bits_per_symbol], tf.float or [..., S], tf.int: Logits or hard-decisions for constellation symbols for every stream. Hard-decisions correspond to the symbol indices.\n\n**Note:** For numerical stability, we do not recommend to use this function in Graph mode with XLA, i.e., within a function that is decorated with @tf.function(jit_compile=True). However, it is possible to do so by setting sionna.Config.xla_compat=true. See xla_compat."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain the two algorithms for training the autoencoder implemented in the context."}, {"role": "assistant", "content": "The context describes two algorithms for training an autoencoder in a communication system:\n\n1. Conventional Stochastic Gradient Descent (SGD) with Backpropagation: This algorithm assumes a differentiable channel model and optimizes the end-to-end system by backpropagating the gradients through the channel. The transmitter and receiver are jointly trained using the binary cross entropy (BCE) as the loss function. Training on the BCE is equivalent to maximizing an achievable information rate. The model can be instantiated either for training or evaluation. In the former case, the BCE is returned and no outer code is used to reduce computational complexity. When set for evaluation, an LDPC outer code from 5G NR is applied.\n\n2. Reinforcement Learning (RL)-based Training: This algorithm does not assume a differentiable channel model. It trains the end-to-end system by alternating between conventional training of the receiver and RL-based training of the transmitter. During the RL-based training, known perturbations are applied to the transmitter output to enable estimation of the gradient of the transmitter weights with respect to an approximation of the loss function. After alternating training, an additional step of fine-tuning of the receiver is performed. When the model is set for training, both losses for training the receiver and the transmitter are returned."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Describe how to configure a transmitter with multiple antenna ports and layers, and how to choose different precoding matrices."}, {"role": "assistant", "content": "To configure a transmitter with multiple antenna ports and layers, you can use the Sionna 5G NR module. Here are the steps:\n\n1. Import the necessary modules from Sionna, including `PUSCHConfig`, `PUSCHTransmitter`, and `PUSCHReceiver`.\n\n2. Create a `PUSCHConfig` instance. This configuration includes various parameters such as the carrier, DMRS, and transport block.\n\n3. Set the number of antenna ports and layers in the `PUSCHConfig` instance. For example, you can set `pusch_config.num_antenna_ports = 4` and `pusch_config.num_layers = 2`.\n\n4. Specify the DMRS ports for each layer in the `PUSCHConfig` instance. For example, you can set `pusch_config.dmrs.dmrs_port_set = [0,1]` for the first two layers.\n\n5. If you want to use precoding, set `pusch_config.precoding = \"codebook\"` and specify the transmit precoding matrix identifier (TPMI) with `pusch_config.tpmi = 7`.\n\n6. Instantiate a `PUSCHTransmitter` from the `PUSCHConfig`.\n\n7. If you want to simulate transmissions, you can generate a batch of random transmit signals with `x, b = pusch_transmitter(batch_size)`.\n\nTo choose different precoding matrices, you can change the TPMI in the `PUSCHConfig` instance. The TPMI is an index that specifies a particular precoding matrix from a codebook. For example, you can set `pusch_config.tpmi = 4` to choose a different precoding matrix.\n\nPlease note that the above steps are based on the provided context and may need to be adjusted based on the specific requirements of your application."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the details of SymbolDemapper, such as the parameters of the class, the input and output of the class instance and the link of source code."}, {"role": "assistant", "content": "Here is the detailed information of [sionna.mapping.SymbolDemapper(constellation_type=None, num_bits_per_symbol=None, constellation=None, hard_out=False, with_prior=False, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#SymbolDemapper):  \n  \nComputes normalized log-probabilities (logits) or hard-decisions on symbols for a tensor of received symbols. If the with_prior flag is set, prior knowldge on the transmitted constellation points is assumed to be available. The demapping function is fully differentiable when soft-values are computed.  \n  \n### Parameters\n\n- **constellation_type** (`str`): One of [\"qam\", \"pam\", \"custom\"]. For \"custom\", an instance of `Constellation` must be provided.\n\n- **num_bits_per_symbol** (`int`): The number of bits per constellation symbol, e.g., 4 for QAM16. Required only for `constellation_type` in [\"qam\", \"pam\"].\n\n- **constellation** (`Constellation`): An instance of `Constellation` or None. If None, `constellation_type` and `num_bits_per_symbol` must be provided.\n\n- **hard_out** (`bool`): If True, the demapper provides hard-decided symbols instead of soft values. Defaults to False.\n\n- **with_prior** (`bool`): If True, it is assumed that prior knowledge on the constellation points is available. This prior information is given as log-probabilities (logits) as an additional input to the layer. Defaults to False.\n\n- **dtype** (`tf.complex64`, `tf.complex128`, `tf.DType`): The dtype of `y`. Defaults to `tf.complex64`. The output dtype is the corresponding real dtype (`tf.float32` or `tf.float64`).\n\n### Input\n\n- **y** (`[..., n]`, `tf.complex`): The received symbols.\n\n- **prior** (`[num_points]` or `[..., num_points]`, `tf.float`): Prior for every symbol as log-probabilities (logits). It can be provided either as a tensor of shape `[num_points]` for the entire input batch, or as a tensor that is \"broadcastable\" to `[..., n, num_points]`. Only required if the `with_prior` flag is set.\n\n- **no** (Scalar or `[..., n]`, `tf.float`): The noise variance estimate. It can be provided either as scalar for the entire input batch or as a tensor that is \"broadcastable\" to `y`.\n\n### Output\n\n- **Logits or Hard Decisions** (`[..., n, num_points]` or `[..., n]`, `tf.float`): A tensor of shape `[..., n, num_points]` of logits for every constellation point if `hard_out` is set to False. Otherwise, a tensor of shape `[..., n]` of hard-decisions on the symbols.\n  \n**Note: **The normalized log-probability for the constellation point $c$ is computed according to $\\ln\\left(\\Pr\\left(c \\lvert y,\\mathbf{p}\\right)\\right) = \\ln\\left( \\frac{\\exp\\left(-\\frac{|y-c|^2}{N_0} + p_c \\right)}{\\sum_{c'\\in\\mathcal{C}} \\exp\\left(-\\frac{|y-c'|^2}{N_0} + p_{c'} \\right)} \\right)$ where $\\mathcal{C}$ is the set of constellation points used for modulation, and $\\mathbf{p} = \\left\\{p_c \\lvert c \\in \\mathcal{C}\\right\\}$ the prior information on constellation points given as log-probabilities and which is set to $\\mathbf{0}$ if no prior information on the constellation points is assumed to be available.  \n  "}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain the working and usage of the `trace_paths()` method in the Scene class in the Sionna package."}, {"role": "assistant", "content": "The `trace_paths()` method is part of the `Scene` class in the Sionna package. This method is used to compute the trajectories of propagation paths between antennas of all transmitters and receivers in the current scene.\n\nThe `trace_paths()` method operates by shooting rays and then simulating how they would reflect and refract off objects in the scene, based on the properties of the scene's materials. For each propagation path, the method stores information such as the path's direction, depth (i.e., number of reflections), and a sequence of intersection points.\n\nThe `trace_paths()` function does not compute the electromagnetic fields corresponding to traced paths. It only traces the geometry of paths. The computation of electromagnetic fields can be done with a separate function (`compute_fields()`).\n\nThe `trace_paths()` method accepts several arguments like `max_depth`, `method`, `num_samples`, `los`, `reflection`, `diffraction`, `scattering`, `scat_keep_prob`, `edge_diffraction`, and `check_scene` which can be configured based on the scenario that needs to be simulated. For example, `max_depth` refers to the maximum depth (i.e., number of bounces) allowed for tracing the paths, and `num_samples` refers to the number of rays to be traced in order to generate candidates.\n\nThe output from `trace_paths()` is a tuple consisting of specular paths, diffracted paths, scattered paths, and additional data required to compute the electromagnetic fields for these paths.\n\nHere's a usage example:\n\n```python\ntraced_paths = scene.trace_paths()\n```\n\nIn this example, the `trace_paths()` method is called on the `scene` object to trace the propagation paths. The resulting traced paths can then be used with the `compute_fields()` function to compute the fields for these paths:\n\n```python\npaths = scene.compute_fields(*traced_paths)\n```\n\nPlease note that the working and usage of the `trace_paths()` method might vary based on the Sionna package version, the scene setup and the specific requirements of the ray-tracing simulation."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Describe the \"GaussianPriorSource\" in the Sionna package and its parameters, inputs, and output."}, {"role": "assistant", "content": "The \"GaussianPriorSource\" is a class in the Sionna package that's used to generate 'fake' Log-Likelihood Ratios (LLRs) as if the all-zero codeword was transmitted over a Binary Additive White Gaussian Noise (Bi-AWGN) channel. \n\nParameters:\n- `specified_by_mi`: This is a boolean parameter that defaults to False. If set as true, the second input parameter `no` is interpreted as mutual information instead of noise variance.\n- `dtype`: This defines the datatype for internal calculations and the output. It is set as tf.float32 by default, but it should be one of the following: (tf.float16, tf.bfloat16, tf.float32, tf.float64).\n\nInputs:\n- `output_shape`, `no`: These are passed as a tuple to the GaussianPriorSource. The `output_shape` is an integer tensor or Python array that represents the shape of the desired output tensor. The `no` is a scalar that defines the noise variance or mutual information (if `specified_by_mi` is True) of the corresponding (fake) AWGN channel.\n\nOutput:\n- The GaussianPriorSource returns a 1+D Tensor with a shape as defined by `output_shape` where datatype defaults to tf.float32. This tensor contains the 'fake' Log-Likelihood Ratios (LLRs).\n\nIt's important to note that if `specified_by_mi` is set to True, the `no` input is interpreted as mutual information instead of noise variance.\n\nExceptions:\n- An InvalidArgumentError may occur if the mutual information is not in the range (0,1).\n- An AssertionError may occur if `inputs` is not a list with 2 elements. \n\nPlease ensure these parameters are correctly defined, and the appropriate input is passed while using the GaussianPriorSource in the Sionna package."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Describe the data-flow and design paradigms of Sionna, including its use of batching, preferred datatypes, and its structure into sub-packages."}, {"role": "assistant", "content": "Sionna is a Python library designed for the simulation of communication systems. It is built on top of TensorFlow and follows a few key design principles to ensure efficient data flow:\n\n1. **Batching**: Sionna inherently parallelizes simulations via batching. Each element in the batch dimension is simulated independently, allowing for inter-frame parallelization similar to an outer for-loop in Matlab/NumPy simulations. This means operations can be performed in parallel, enhancing the efficiency of the system.\n\n2. **Preferred Datatypes**: Sionna uses `tf.float32` as the preferred datatype and `tf.complex64` for complex-valued datatypes. This simplifies the re-use of components. For instance, the same scrambling layer can be used for binary inputs and LLR-values. High precision datatypes `tf.float64`/`tf.complex128` are also available when needed.\n\n3. **Eager and Graph Modes**: Models can be developed in eager mode, which allows for simple and fast modification of system parameters. For more intensive simulations, the faster graph mode or even XLA acceleration (experimental) can be used.\n\n4. **Differentiability**: Whenever possible, components are automatically differentiable via auto-grad to simplify the deep learning design flow.\n\n5. **Modular Design**: The code is structured into sub-packages for different tasks such as channel coding, mapping, etc. This enhances the reusability and reliability of the components for a wide range of communication-related applications.\n\nIn terms of design paradigms, Sionna uses the Keras functional API to stack layers and build complex systems. Signal-processing components are implemented as individual Keras layers. This approach simplifies the re-useability and reliability of the components for a wide range of communication-related applications."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Describe the role of Mitsuba 3 and TensorFlow in Sionna RT."}, {"role": "assistant", "content": "In Sionna RT, Mitsuba 3 and TensorFlow play crucial roles in simulating environment-specific and physically accurate channel realizations for a given scene and user position. \n\nMitsuba 3 is a rendering system for forward and inverse light-transport simulation. Sionna RT uses Mitsuba 3 for rendering and handling scenes, such as its XML-file format, as well as the computation of ray intersections with scene primitives, i.e., triangles forming a mesh. \n\nOn the other hand, TensorFlow is used to compute the transformations of the polarized field components at each point of interaction between a ray and a scene object, such as reflection. It is also used to combine the retained paths into (optionally) time-varying channel impulse responses. Thanks to TensorFlow's automatic gradient computation, channel impulse responses and functions thereof are differentiable with respect to most parameters of the ray tracing process, including material properties (conductivity, permittivity), antenna patterns, orientations, and positions. \n\nIn the context of Sionna RT, these tools are used to simulate radio propagation modeling, enabling the computation of coverage maps and the use of ray-traced channels for link-level simulations instead of stochastic channel models."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Detail the methods for computation of propagation `Paths` and `CoverageMap`."}, {"role": "assistant", "content": "The computation of propagation paths and CoverageMap in the Sionna APIs is done primarily through the `Scene` class.\n\nFor propagation paths:\n\n1. First, you need to create a scene using `scene = load_scene(sionna.rt.scene.your_scene)`.\n\n2. Once the scene is created, you can add a transmitter and receiver to it.\n\n```python\n# Configure antenna array for transmitters and receivers\nscene.tx_array = PlanarArray(#your parameters)\nscene.rx_array = PlanarArray(#your parameters)\n\n# Create and add a transmitter\ntx = Transmitter(name=\"tx\", position=[#coordinates], orientation=[#orientation])\nscene.add(tx)\n\n# Similarly, create and add a receiver\nrx = Receiver(name=\"rx\", position=[#coordinates], orientation=[#orientation])\nscene.add(rx)\n```\n\n3. The `compute_paths` method of the `Scene` class is then used to compute the propagation paths. \n\n```python\npaths = scene.compute_paths()\n```\n\n4. The output of this function is an instance of `Paths` which contains information about the propagation paths in the scene.\n\nFor `CoverageMap`:\n\n1. After preparing the scene and adding the transmitter and receiver, the `coverage_map` method of the Scene class can be used.\n\n```python\ncm = scene.coverage_map(cm_cell_size=[1.,1.], num_samples=1e7)\n```\n2. The method `coverage_map` returns an instance of `CoverageMap` for every transmitter in the scene.\n\nIt's important to note that the configuration of transmitters, receivers, the antenna array and other elements of the scene can significantly affect the computed propagation paths and coverage map.\n\nAdditionally, the scene's `preview` method can be used to visualize the calculated paths and coverage map.\n\n```python\n# Open preview showing paths or coverage map\nscene.preview(paths=paths) # For paths\nscene.preview(coverage_map=cm) # For coverage maps\n```\n\nRemember to replace `#your parameters`, `#coordinates` and `#orientation` with the actual parameters required by function calls."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the details of function sionna.utils.log2 in Sionna,  the link of source code and source itself."}, {"role": "assistant", "content": "Here is the detailed information of sionna.utils.log2:   \n\n[sionna.utils.log2(x)](https://nvlabs.github.io/sionna/_modules/sionna/utils/misc.html#log2)\n\nTensorFlow implementation of NumPy\u2019s log2 function.\n\nSimple extension to tf.experimental.numpy.log2 which casts the result to the dtype of the input. For more details see the TensorFlow and NumPy documentation.\n\nsource code:\n```python\ndef log2(x):\n    # pylint: disable=C0301\n    \"\"\"TensorFlow implementation of NumPy's `log2` function.\n\n    Simple extension to `tf.experimental.numpy.log2`\n    which casts the result to the `dtype` of the input.\n    For more details see the `TensorFlow <https://www.tensorflow.org/api_docs/python/tf/experimental/numpy/log2>`_ and `NumPy <https://numpy.org/doc/1.16/reference/generated/numpy.log2.html>`_ documentation.\n    \"\"\"\n    return tf.cast(_log2(x), x.dtype)\n```"}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the definition of PanelArray, such as the default parameters, the link of the source code and explanation."}, {"role": "assistant", "content": "Here is the definition of PanelArray: sionna.channel.tr38901.PanelArray(num_rows_per_panel, num_cols_per_panel, polarization, polarization_type, antenna_pattern, carrier_frequency, num_rows=1, num_cols=1, panel_vertical_spacing=None, panel_horizontal_spacing=None, element_vertical_spacing=None, element_horizontal_spacing=None, dtype=tf.complex64)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/channel/tr38901/antenna.html#PanelArray)  \n```python\nclass PanelArray:\n    # pylint: disable=line-too-long\n    r\"\"\"PanelArray(num_rows_per_panel, num_cols_per_panel, polarization, polarization_type, antenna_pattern, carrier_frequency, num_rows=1, num_cols=1, panel_vertical_spacing=None, panel_horizontal_spacing=None, element_vertical_spacing=None, element_horizontal_spacing=None, dtype=tf.complex64)\n\n    Antenna panel array following the [TR38901]_ specification.\n\n    This class is used to create models of the panel arrays used by the\n    transmitters and receivers and that need to be specified when using the\n    :ref:`CDL <cdl>`, :ref:`UMi <umi>`, :ref:`UMa <uma>`, and :ref:`RMa <rma>`\n    models.\n\n    Example\n    --------\n\n    >>> array = PanelArray(num_rows_per_panel = 4,\n    ...                    num_cols_per_panel = 4,\n    ...                    polarization = 'dual',\n    ...                    polarization_type = 'VH',\n    ...                    antenna_pattern = '38.901',\n    ...                    carrier_frequency = 3.5e9,\n    ...                    num_cols = 2,\n    ...                    panel_horizontal_spacing = 3.)\n    >>> array.show()\n\n    .. image:: ../figures/panel_array.png\n\n    Parameters\n    ----------\n\n    num_rows_per_panel : int\n        Number of rows of elements per panel\n\n    num_cols_per_panel : int\n        Number of columns of elements per panel\n\n    polarization : str\n        Polarization, either \"single\" or \"dual\"\n\n    polarization_type : str\n        Type of polarization. For single polarization, must be \"V\" or \"H\".\n        For dual polarization, must be \"VH\" or \"cross\".\n\n    antenna_pattern : str\n        Element radiation pattern, either \"omni\" or \"38.901\"\n\n    carrier_frequency : float\n        Carrier frequency [Hz]\n\n    num_rows : int\n        Number of rows of panels. Defaults to 1.\n\n    num_cols : int\n        Number of columns of panels. Defaults to 1.\n\n    panel_vertical_spacing : `None` or float\n        Vertical spacing of panels [multiples of wavelength].\n        Must be greater than the panel width.\n        If set to `None` (default value), it is set to the panel width + 0.5.\n\n    panel_horizontal_spacing : `None` or float\n        Horizontal spacing of panels [in multiples of wavelength].\n        Must be greater than the panel height.\n        If set to `None` (default value), it is set to the panel height + 0.5.\n\n    element_vertical_spacing : `None` or float\n        Element vertical spacing [multiple of wavelength].\n        Defaults to 0.5 if set to `None`.\n\n    element_horizontal_spacing : `None` or float\n        Element horizontal spacing [multiple of wavelength].\n        Defaults to 0.5 if set to `None`.\n\n    dtype : Complex tf.DType\n        Defines the datatype for internal calculations and the output\n        dtype. Defaults to `tf.complex64`.\n    \"\"\"\n\n    def __init__(self,  num_rows_per_panel,\n                        num_cols_per_panel,\n                        polarization,\n                        polarization_type,\n                        antenna_pattern,\n                        carrier_frequency,\n                        num_rows=1,\n                        num_cols=1,\n                        panel_vertical_spacing=None,\n                        panel_horizontal_spacing=None,\n                        element_vertical_spacing=None,\n                        element_horizontal_spacing=None,\n                        dtype=tf.complex64):\n\n        assert dtype.is_complex, \"'dtype' must be complex type\"\n\n        assert polarization in ('single', 'dual'), \\\n            \"polarization must be either 'single' or 'dual'\"\n\n        # Setting default values for antenna and panel spacings if not\n        # specified by the user\n        # Default spacing for antenna elements is half a wavelength\n        if element_vertical_spacing is None:\n            element_vertical_spacing = 0.5\n        if element_horizontal_spacing is None:\n            element_horizontal_spacing = 0.5\n        # Default values of panel spacing is the pannel size + 0.5\n        if panel_vertical_spacing is None:\n            panel_vertical_spacing = (num_rows_per_panel-1)\\\n                *element_vertical_spacing+0.5\n        if panel_horizontal_spacing is None:\n            panel_horizontal_spacing = (num_cols_per_panel-1)\\\n                *element_horizontal_spacing+0.5\n\n        # Check that panel spacing is larger than panel dimensions\n        assert panel_horizontal_spacing > (num_cols_per_panel-1)\\\n            *element_horizontal_spacing,\\\n                \"Pannel horizontal spacing must be larger than the panel width\"\n        assert panel_vertical_spacing > (num_rows_per_panel-1)\\\n            *element_vertical_spacing,\\\n            \"Pannel vertical spacing must be larger than panel height\"\n\n        self._num_rows = tf.constant(num_rows, tf.int32)\n        self._num_cols = tf.constant(num_cols, tf.int32)\n        self._num_rows_per_panel = tf.constant(num_rows_per_panel, tf.int32)\n        self._num_cols_per_panel = tf.constant(num_cols_per_panel, tf.int32)\n        self._polarization = polarization\n        self._polarization_type = polarization_type\n        self._panel_vertical_spacing = tf.constant(panel_vertical_spacing,\n                                            dtype.real_dtype)\n        self._panel_horizontal_spacing = tf.constant(panel_horizontal_spacing,\n                                            dtype.real_dtype)\n        self._element_vertical_spacing = tf.constant(element_vertical_spacing,\n                                            dtype.real_dtype)\n        self._element_horizontal_spacing=tf.constant(element_horizontal_spacing,\n                            dtype.real_dtype)\n        self._dtype = dtype\n\n        self._num_panels = tf.constant(num_cols*num_rows, tf.int32)\n\n        p = 1 if polarization == 'single' else 2\n        self._num_panel_ant = tf.constant(  num_cols_per_panel*\n                                            num_rows_per_panel*p,\n                                            tf.int32)\n        # Total number of antenna elements\n        self._num_ant = self._num_panels * self._num_panel_ant\n\n        # Wavelength (m)\n        self._lambda_0 = tf.constant(SPEED_OF_LIGHT / carrier_frequency,\n                                    dtype.real_dtype)\n\n        # Create one antenna element for each polarization direction\n        # polarization must be one of {\"V\", \"H\", \"VH\", \"cross\"}\n        if polarization == 'single':\n            assert polarization_type in [\"V\", \"H\"],\\\n                \"For single polarization, polarization_type must be 'V' or 'H'\"\n            slant_angle = 0 if polarization_type == \"V\" else PI/2\n            self._ant_pol1 = AntennaElement(antenna_pattern, slant_angle,\n                self._dtype)\n        else:\n            assert polarization_type in [\"VH\", \"cross\"],\\\n            \"For dual polarization, polarization_type must be 'VH' or 'cross'\"\n            slant_angle = 0 if polarization_type == \"VH\" else -PI/4\n            self._ant_pol1 = AntennaElement(antenna_pattern, slant_angle,\n                self._dtype)\n            self._ant_pol2 = AntennaElement(antenna_pattern, slant_angle+PI/2,\n                self._dtype)\n\n        # Compose array from panels\n        ant_pos = np.zeros([self._num_ant, 3])\n        panel = AntennaPanel(num_rows_per_panel, num_cols_per_panel,\n            polarization, element_vertical_spacing, element_horizontal_spacing,\n            dtype)\n        pos = panel.ant_pos\n        count = 0\n        num_panel_ant = self._num_panel_ant\n        for j in range(num_cols):\n            for i in range(num_rows):\n                offset = [  0,\n                            j*panel_horizontal_spacing,\n                            -i*panel_vertical_spacing]\n                new_pos = pos + offset\n                ant_pos[count*num_panel_ant:(count+1)*num_panel_ant] = new_pos\n                count += 1\n\n        # Center the entire panel array around the orgin of the y-z plane\n        offset = [  0,\n                    -(num_cols-1)*panel_horizontal_spacing/2,\n                    (num_rows-1)*panel_vertical_spacing/2]\n        ant_pos += offset\n\n        # Scale antenna element positions by the wavelength\n        ant_pos *= self._lambda_0\n        self._ant_pos = tf.constant(ant_pos, dtype.real_dtype)\n\n        # Compute indices of antennas for polarization directions\n        ind = np.arange(0, self._num_ant)\n        ind = np.reshape(ind, [self._num_panels*p, -1])\n        self._ant_ind_pol1 = tf.constant(np.reshape(ind[::p], [-1]), tf.int32)\n        if polarization == 'single':\n            self._ant_ind_pol2 = tf.constant(np.array([]), tf.int32)\n        else:\n            self._ant_ind_pol2 = tf.constant(np.reshape(\n                ind[1:self._num_panels*p:2], [-1]), tf.int32)\n\n        # Get positions of antenna elements for each polarization direction\n        self._ant_pos_pol1 = tf.gather(self._ant_pos, self._ant_ind_pol1,\n                                        axis=0)\n        self._ant_pos_pol2 = tf.gather(self._ant_pos, self._ant_ind_pol2,\n                                        axis=0)\n\n    @property\n    def num_rows(self):\n        \"\"\"Number of rows of panels\"\"\"\n        return self._num_rows\n\n    @property\n    def num_cols(self):\n        \"\"\"Number of columns of panels\"\"\"\n        return self._num_cols\n\n    @property\n    def num_rows_per_panel(self):\n        \"\"\"Number of rows of elements per panel\"\"\"\n        return self._num_rows_per_panel\n\n    @property\n    def num_cols_per_panel(self):\n        \"\"\"Number of columns of elements per panel\"\"\"\n        return self._num_cols_per_panel\n\n    @property\n    def polarization(self):\n        \"\"\"Polarization (\"single\" or \"dual\")\"\"\"\n        return self._polarization\n\n    @property\n    def polarization_type(self):\n        \"\"\"Polarization type. \"V\" or \"H\" for single polarization.\n        \"VH\" or \"cross\" for dual polarization.\"\"\"\n        return self._polarization_type\n\n    @property\n    def panel_vertical_spacing(self):\n        \"\"\"Vertical spacing between the panels [multiple of wavelength]\"\"\"\n        return self._panel_vertical_spacing\n\n    @property\n    def panel_horizontal_spacing(self):\n        \"\"\"Horizontal spacing between the panels [multiple of wavelength]\"\"\"\n        return self._panel_horizontal_spacing\n\n    @property\n    def element_vertical_spacing(self):\n        \"\"\"Vertical spacing between the antenna elements within a panel\n        [multiple of wavelength]\"\"\"\n        return self._element_vertical_spacing\n\n    @property\n    def element_horizontal_spacing(self):\n        \"\"\"Horizontal spacing between the antenna elements within a panel\n        [multiple of wavelength]\"\"\"\n        return self._element_horizontal_spacing\n\n    @property\n    def num_panels(self):\n        \"\"\"Number of panels\"\"\"\n        return self._num_panels\n\n    @property\n    def num_panels_ant(self):\n        \"\"\"Number of antenna elements per panel\"\"\"\n        return self._num_panel_ant\n\n    @property\n    def num_ant(self):\n        \"\"\"Total number of antenna elements\"\"\"\n        return self._num_ant\n\n    @property\n    def ant_pol1(self):\n        \"\"\"Field of an antenna element with the first polarization direction\"\"\"\n        return self._ant_pol1\n\n    @property\n    def ant_pol2(self):\n        \"\"\"Field of an antenna element with the second polarization direction.\n        Only defined with dual polarization.\"\"\"\n        assert self._polarization == 'dual',\\\n            \"This property is not defined with single polarization\"\n        return self._ant_pol2\n\n    @property\n    def ant_pos(self):\n        \"\"\"Positions of the antennas\"\"\"\n        return self._ant_pos\n\n    @property\n    def ant_ind_pol1(self):\n        \"\"\"Indices of antenna elements with the first polarization direction\"\"\"\n        return self._ant_ind_pol1\n\n    @property\n    def ant_ind_pol2(self):\n        \"\"\"Indices of antenna elements with the second polarization direction.\n        Only defined with dual polarization.\"\"\"\n        assert self._polarization == 'dual',\\\n            \"This property is not defined with single polarization\"\n        return self._ant_ind_pol2\n\n    @property\n    def ant_pos_pol1(self):\n        \"\"\"Positions of the antenna elements with the first polarization\n        direction\"\"\"\n        return self._ant_pos_pol1\n\n    @property\n    def ant_pos_pol2(self):\n        \"\"\"Positions of antenna elements with the second polarization direction.\n        Only defined with dual polarization.\"\"\"\n        assert self._polarization == 'dual',\\\n            \"This property is not defined with single polarization\"\n        return self._ant_pos_pol2\n\n    def show(self):\n        \"\"\"Show the panel array geometry\"\"\"\n        if self._polarization == 'single':\n            if self._polarization_type == 'H':\n                marker_p1 = MarkerStyle(\"_\").get_marker()\n            else:\n                marker_p1 = MarkerStyle(\"|\")\n        elif self._polarization == 'dual':\n            if self._polarization_type == 'cross':\n                marker_p1 = (2, 0, -45)\n                marker_p2 = (2, 0, 45)\n            else:\n                marker_p1 = MarkerStyle(\"_\").get_marker()\n                marker_p2 = MarkerStyle(\"|\").get_marker()\n\n        fig = plt.figure()\n        pos_pol1 = self._ant_pos_pol1\n        plt.plot(pos_pol1[:,1], pos_pol1[:,2],\n            marker=marker_p1, markeredgecolor='red',\n            markersize=\"20\", linestyle=\"None\", markeredgewidth=\"2\")\n        for i, p in enumerate(pos_pol1):\n            fig.axes[0].annotate(self._ant_ind_pol1[i].numpy()+1, (p[1], p[2]))\n        if self._polarization == 'dual':\n            pos_pol2 = self._ant_pos_pol2\n            plt.plot(pos_pol2[:,1], pos_pol2[:,2],\n                marker=marker_p2, markeredgecolor='black',\n                markersize=\"20\", linestyle=\"None\", markeredgewidth=\"1\")\n        plt.xlabel(\"y (m)\")\n        plt.ylabel(\"z (m)\")\n        plt.title(\"Panel Array\")\n        plt.legend([\"Polarization 1\", \"Polarization 2\"], loc=\"upper right\")\n\n    def show_element_radiation_pattern(self):\n        \"\"\"Show the radiation field of antenna elements forming the panel\"\"\"\n        self._ant_pol1.show()\n```"}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Define the input parameters of the class \"List2LLR\" including 'y', 'r', 'dists', 'path_inds', 'path_syms', their data types, and explanations."}, {"role": "assistant", "content": "The class \"List2LLR\" in the context has the following input parameters:\n\n- 'y': This is a tensor with data type tf.complex or tf.float. It represents the channel outputs of the whitened channel. Its shape is [,M].\n\n- 'r': This is a tensor with the same data type as 'y'. It represents the upper triangular channel matrix of the whitened channel. Its shape is [,num_streams, num_streams].\n\n- 'dists': This parameter is a tensor having data type tf.float. It represents the distance metric for each path (or candidate). Its shape is [,num_paths].\n\n- 'path_inds': This parameter is a tensor with data type tf.int32. It represents the symbol indices for every stream of every path (or candidate). Its shape is [,num_paths,num_streams].\n\n- 'path_syms': This is a tensor having the same data type as 'y. It represents the constellation symbol for every stream of every path (or candidate). Its shape is [,num_path,num_streams].\n\nThese parameters are packaged in a tuple for the class \"List2LLR\". The class is designed to compute Log-Likelihood Ratios (LLRs) from a list of candidate vectors (or paths) provided by a Multiple-Input Multiple-Output (MIMO) detector."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Describe the end-to-end system implemented in the E2ESystemRLTraining class."}, {"role": "assistant", "content": "The E2ESystemRLTraining class implements an end-to-end communication system that transmits bits modulated using a trainable constellation over an AWGN channel. The receiver uses a neural network-based demapper to compute Log-Likelihood Ratios (LLRs) on the transmitted (coded) bits. \n\nThe class is designed to handle both training and evaluation modes. During training, it alternates between conventional training of the receiver using backpropagation and Stochastic Gradient Descent (SGD), and Reinforcement Learning (RL)-based training of the transmitter. The RL-based training applies known perturbations to the transmitter output to enable estimation of the gradient of the transmitter weights with respect to an approximation of the loss function. \n\nIn evaluation mode, an LDPC outer code from 5G NR is applied, and the Binary Cross Entropy (BCE) is not returned. Instead, the ground truth and reconstructed information bits are returned for Bit Error Rate (BER) or Block Error Rate (BLER) computation.\n\nThe class uses TensorFlow and the Sionna library for implementation. It includes methods for the transmitter (including a binary source and a mapper with a trainable constellation), the AWGN channel, and the receiver (including a neural network-based demapper and an LDPC decoder). \n\nThe class also includes a method for the call operation, which handles the forward pass of the model, including the modulation, channel transmission, demapping, and decoding steps. It also handles the computation of the BCE loss during training and the computation of the LLRs during evaluation."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the details of function sionna.mimo.mf_equalizer(y, h, s), such as the input and output of the class instance ,the link of source code and source itself."}, {"role": "assistant", "content": "Here is the detailed information of sionna.mimo.mf_equalizer(y, h, s):  \n\n[sionna.mimo.mf_equalizer(y, h, s)](https://nvlabs.github.io/sionna/_modules/sionna/mimo/equalization.html#mf_equalizer)\n\nMIMO MF Equalizer\n\nThis function implements matched filter (MF) equalization for a MIMO link, assuming the following model: $\\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}$\nwhere $\\mathbf{y}\\in\\mathbb{C}^M$ is the received signal vector, $\\mathbf{x}\\in\\mathbb{C}^K$ is the vector of transmitted symbols, $\\mathbf{H}\\in\\mathbb{C}^{M\\times K}$ is the known channel matrix, and $\\mathbf{n}\\in\\mathbb{C}^M$ is a noise vector. It is assumed that $\\mathbb{E}\\left[\\mathbf{x}\\right]=\\mathbb{E}\\left[\\mathbf{n}\\right]=\\mathbf{0}$, $\\mathbb{E}\\left[\\mathbf{x}\\mathbf{x}^{\\mathsf{H}}\\right]=\\mathbf{I}_K$ and $\\mathbb{E}\\left[\\mathbf{n}\\mathbf{n}^{\\mathsf{H}}\\right]=\\mathbf{S}$.\n\nThe estimated symbol vector $\\hat{\\mathbf{x}}\\in\\mathbb{C}^K$ is given as (Eq. 4.11) [Emil Bj\u00f6rnson, Jakob Hoydis and Luca Sanguinetti (2017), \u201cMassive MIMO Networks: Spectral, Energy, and Hardware Efficiency\u201d, Foundations and Trends in Signal Processing: Vol. 11, No. 3-4, pp 154\u2013655.]:\n$\\hat{\\mathbf{x}} = \\mathbf{G}\\mathbf{y}$\nwhere \n$\\mathbf{G} = \\mathop{\\text{diag}}\\left(\\mathbf{H}^{\\mathsf{H}}\\mathbf{H}\\right)^{-1}\\mathbf{H}^{\\mathsf{H}}.$\nThis leads to the post-equalized per-symbol model:\n$\\hat{x}_k = x_k + e_k,\\quad k=0,\\dots,K-1$\nwhere the variances $\\sigma^2_k$ of the effective residual noise terms $e_k$ are given by the diagonal elements of the matrix $\\mathbb{E}\\left[\\mathbf{e}\\mathbf{e}^{\\mathsf{H}}\\right]\n= \\left(\\mathbf{I}-\\mathbf{G}\\mathbf{H} \\right)\\left(\\mathbf{I}-\\mathbf{G}\\mathbf{H} \\right)^{\\mathsf{H}} + \\mathbf{G}\\mathbf{S}\\mathbf{G}^{\\mathsf{H}}.$\n\nNote that the scaling by $\\mathop{\\text{diag}}\\left(\\mathbf{H}^{\\mathsf{H}}\\mathbf{H}\\right)^{-1}$ in the definition of $\\mathbf{G}$ is important for the Demapper although it does not change the signal-to-noise ratio.\n\nThe function returns $\\hat{\\mathbf{x}}$ and $\\boldsymbol{\\sigma}^2=\\left[\\sigma^2_0,\\dots, \\sigma^2_{K-1}\\right]^{\\mathsf{T}}$.\n\n**Input**\n\n- `y` ([..., M], tf.complex): 1+D tensor containing the received signals.\n- `h` ([..., M, K], tf.complex): 2+D tensor containing the channel matrices.\n- `s` ([..., M, M], tf.complex): 2+D tensor containing the noise covariance matrices.\n\n**Output**\n\n- `x_hat` ([..., K], tf.complex): 1+D tensor representing the estimated symbol vectors.\n- `no_eff` (tf.float): Tensor of the same shape as `x_hat` containing the effective noise variance estimates.\n\nsource code:\n```python\ndef mf_equalizer(y, h, s):\n    # pylint: disable=line-too-long\n    r\"\"\"MIMO MF Equalizer\n\n    This function implements matched filter (MF) equalization for a\n    MIMO link, assuming the following model:\n\n    .. math::\n\n        \\mathbf{y} = \\mathbf{H}\\mathbf{x} + \\mathbf{n}\n\n    where :math:`\\mathbf{y}\\in\\mathbb{C}^M` is the received signal vector,\n    :math:`\\mathbf{x}\\in\\mathbb{C}^K` is the vector of transmitted symbols,\n    :math:`\\mathbf{H}\\in\\mathbb{C}^{M\\times K}` is the known channel matrix,\n    and :math:`\\mathbf{n}\\in\\mathbb{C}^M` is a noise vector.\n    It is assumed that :math:`\\mathbb{E}\\left[\\mathbf{x}\\right]=\\mathbb{E}\\left[\\mathbf{n}\\right]=\\mathbf{0}`,\n    :math:`\\mathbb{E}\\left[\\mathbf{x}\\mathbf{x}^{\\mathsf{H}}\\right]=\\mathbf{I}_K` and\n    :math:`\\mathbb{E}\\left[\\mathbf{n}\\mathbf{n}^{\\mathsf{H}}\\right]=\\mathbf{S}`.\n\n    The estimated symbol vector :math:`\\hat{\\mathbf{x}}\\in\\mathbb{C}^K` is given as\n    (Eq. 4.11) [BHS2017]_ :\n\n    .. math::\n\n        \\hat{\\mathbf{x}} = \\mathbf{G}\\mathbf{y}\n\n    where\n\n    .. math::\n\n        \\mathbf{G} = \\mathop{\\text{diag}}\\left(\\mathbf{H}^{\\mathsf{H}}\\mathbf{H}\\right)^{-1}\\mathbf{H}^{\\mathsf{H}}.\n\n    This leads to the post-equalized per-symbol model:\n\n    .. math::\n\n        \\hat{x}_k = x_k + e_k,\\quad k=0,\\dots,K-1\n\n    where the variances :math:`\\sigma^2_k` of the effective residual noise\n    terms :math:`e_k` are given by the diagonal elements of the matrix\n\n    .. math::\n\n        \\mathbb{E}\\left[\\mathbf{e}\\mathbf{e}^{\\mathsf{H}}\\right]\n        = \\left(\\mathbf{I}-\\mathbf{G}\\mathbf{H} \\right)\\left(\\mathbf{I}-\\mathbf{G}\\mathbf{H} \\right)^{\\mathsf{H}} + \\mathbf{G}\\mathbf{S}\\mathbf{G}^{\\mathsf{H}}.\n\n    Note that the scaling by :math:`\\mathop{\\text{diag}}\\left(\\mathbf{H}^{\\mathsf{H}}\\mathbf{H}\\right)^{-1}`\n    in the definition of :math:`\\mathbf{G}`\n    is important for the :class:`~sionna.mapping.Demapper` although it does\n    not change the signal-to-noise ratio.\n\n    The function returns :math:`\\hat{\\mathbf{x}}` and\n    :math:`\\boldsymbol{\\sigma}^2=\\left[\\sigma^2_0,\\dots, \\sigma^2_{K-1}\\right]^{\\mathsf{T}}`.\n\n    Input\n    -----\n    y : [...,M], tf.complex\n        1+D tensor containing the received signals.\n\n    h : [...,M,K], tf.complex\n        2+D tensor containing the channel matrices.\n\n    s : [...,M,M], tf.complex\n        2+D tensor containing the noise covariance matrices.\n\n    Output\n    ------\n    x_hat : [...,K], tf.complex\n        1+D tensor representing the estimated symbol vectors.\n\n    no_eff : tf.float\n        Tensor of the same shape as ``x_hat`` containing the effective noise\n        variance estimates.\n    \"\"\"\n\n    # We assume the model:\n    # y = Hx + n, where E[nn']=S.\n    # E[x]=E[n]=0\n    #\n    # The MF estimate of x is given as:\n    # x_hat = Gy\n    # with G=diag(H'H)^-1 H'.\n    #\n    # This leads us to the per-symbol model;\n    #\n    # x_hat_k = x_k + e_k\n    #\n    # The elements of the residual noise vector e have variance:\n    # E[ee'] = (I-GH)(I-GH)' + GSG'\n\n    # Compute G\n    hth = tf.matmul(h, h, adjoint_a=True)\n    d = tf.linalg.diag(tf.cast(1, h.dtype)/tf.linalg.diag_part(hth))\n    g = tf.matmul(d, h, adjoint_b=True)\n\n    # Compute x_hat\n    y = tf.expand_dims(y, -1)\n    x_hat = tf.squeeze(tf.matmul(g, y), axis=-1)\n\n    # Compute residual error variance\n    gsg = tf.matmul(tf.matmul(g, s), g, adjoint_b=True)\n    gh = tf.matmul(g, h)\n    i = expand_to_rank(tf.eye(gsg.shape[-2], dtype=gsg.dtype), tf.rank(gsg), 0)\n\n    no_eff = tf.abs(tf.linalg.diag_part(tf.matmul(i-gh, i-gh, adjoint_b=True) + gsg))\n    return x_hat, no_eff\n```"}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Point out the benefits of using code-specific decoders like ViterbiDecoder or PolarSCLDecoder over OSDecoder for certain code families."}, {"role": "assistant", "content": "Using code-specific decoders like `ViterbiDecoder` for convolutional codes or `PolarSCLDecoder` for Polar codes can present several benefits over a generic decoder like the `OSDecoder`:\n\n1. **Optimized Performance**: Code-specific decoders are designed to leverage the unique structural properties of their respective code families. For example, the `ViterbiDecoder` utilizes the trellis structure of convolutional codes to execute an efficient maximum likelihood decoding. Similarly, the `PolarSCLDecoder` (Successive Cancellation List Decoder) takes advantage of the recursive nature of Polar codes to achieve near-maximum likelihood performance with the use of lists.\n\n2. **Reduced Complexity**: Code-specific decoders typically have lower computational complexity for their intended codes. The `OSDecoder` involves high computational complexity especially as the order `t` increases. Since it must evaluate numerous error patterns (`n choose t`), it becomes less feasible for longer codes. In contrast, `ViterbiDecoder` and `PolarSCLDecoder` often have lower complexity algorithms for equivalent performance.\n\n3. **Better Error Correction Performance**: Due to the optimizations possible with knowledge of the code structure, code-specific decoders can often correct more errors than a generic decoder, particularly at higher signal noise levels. This translates into better bit-error-rate (BER) performance.\n\n4. **Efficient Memory Usage**: Algorithms like Viterbi and Successive Cancellation List decoding are typically more memory efficient than the OSD due to the specific ways in which they process the received bits and maintain internal state.\n\n5. **Faster Processing Time**: A direct consequence of reduced complexity and efficient memory usage is that code-specific decoders can process decodings faster, leading to higher throughput which is critical in real-time communication systems.\n\n6. **Scalability**: Code-specific decoders generally scale better with code length and code rate compared to the `OSDecoder`. This is particularly important when dealing with large block sizes or high rate codes.\n\n7. **Decoding Reliability**: In certain conditions, such as specific channels or code parameters, code-specific decoders can offer more reliable decoding, which is critical for applications requiring high data integrity.\n\nHowever, developers must balance these benefits with the need to correctly implement and deploy the code-specific decoders, as errors in this complex task can negate the benefits. Therefore, while `OSDecoder` can be seen as a universal option that works for any linear block code, harnessing the full potential of specific code families usually requires the implementation of specialized decoding algorithms like the `ViterbiDecoder` and `PolarSCLDecoder`."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the details of SymbolInds2Bits, such as the parameters of the class, the input and output of the class instance and the link of source code."}, {"role": "assistant", "content": "Here is the detailed information of [SymbolInds2Bits](https://nvlabs.github.io/sionna/_modules/sionna/mapping.html#SymbolInds2Bits):  \n\nTransforms symbol indices to their binary representations.\n\nParameters\n        num_bits_per_symbol (int) \u2013 Number of bits per constellation symbol\n\n        dtype (tf.DType) \u2013 Output dtype. Defaults to tf.float32.\n\nInput\n    Tensor, tf.int \u2013 Symbol indices\n\nOutput\n    input.shape + [num_bits_per_symbol], dtype \u2013 Binary representation of symbol indices"}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Describe the impact of scattering on radio propagation modelling."}, {"role": "assistant", "content": "Scattering has a significant impact on radio propagation modelling. When an electromagnetic wave impinges on a surface, part of the energy gets reflected while the other part gets refracted, propagating into the surface. This reflection can be either specular or diffuse, with the latter also known as diffuse scattering. \n\nIn the context of ray tracing, an incoming ray spawns infinitely many scattered rays in the case of diffuse reflections, while there is only a single specular path. This means that to compute the scattered field at a particular position, one needs to integrate the scattered field over the entire surface. \n\nScattering can also affect the number of paths in a scene. For instance, any ray that hits a surface will be scattered toward the receiver, meaning the more rays we shoot, the more scattered paths there are. However, the total received energy across the surface remains constant as the transmitted energy is equally divided between all rays.\n\nScattering also plays a role in coverage maps, which describe the average received power from a specific transmitter at every point on a plane. By enabling diffuse reflections, most regions in a scene can have some coverage, although the scattered field is typically weaker compared to that of the line-of-sight and reflected paths.\n\nFinally, scattering can impact the discrete baseband-equivalent channel impulse responses. While the field is dominated by strong line-of-sight and reflected paths for small values, there can be differences of a few dB in the middle and tail, which can significantly impact the link-level performance. \n\nIn conclusion, scattering plays an important role in radio propagation modelling, particularly at higher carrier frequencies where most surfaces appear rougher compared to the wavelength."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Define what a log-likelihood ratio is and explain how it's used in the context of a `BinarySymmetricChannel`."}, {"role": "assistant", "content": "A log-likelihood ratio (LLR) is a statistical measure used to compare the likelihood of two hypotheses. It is calculated as the logarithm of the ratio of two likelihoods. In the context of this module, log-likelihood ratios are used with discrete channel models that support binary or bipolar inputs. These models can return either discrete values or LLRs. \n\nWhen used in a `BinarySymmetricChannel`, an LLR serves as a measure of the likelihood or confidence of receiving a '1' or a '0' as the output of the channel. Calculated from the bit flipping probability (`pb`), if the channel is set to return LLRs (`return_llrs=True`), it provides the LLR instead of the binary value based on `pb`.\n\nThe LLR is calculated as follows:\n\n    \ud835\udcf5\ud835\udcf5 = log(\ud835\udc5d\ud835\udc4f/(1\u2212\ud835\udc5d\ud835\udc4f)), if y=0,\n    \ud835\udcf5\ud835\udcf5 = log((1\u2212\ud835\udc5d\ud835\udc4f)/\ud835\udc5d\ud835\udc4f), if y=1,\n\nwhere `y` represents the binary output of the channel, and `pb` the bit flipping probability. These LLRs give a measure of how likely it is for a '1' or a '0' to be transmitted given the channel's output and its properties."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "State the conditions that will trigger AssertionError, ValueError and InvalidArgumentError when using the CRCEncoder class function."}, {"role": "assistant", "content": "The CRCEncoder class function from the Sionna API will trigger an:\n\n- AssertionError if the parameter `crc_degree` is not of type string. This means that the class is expecting a string value for the degree of the CRC polynomial to be used.\n\n- ValueError if the requested CRC polynomial is not available. The acceptable CRC polynomial values are listed in the 3GPP TS 38.212 and include CRC24A, CRC24B, CRC24C, CRC16, CRC11, and CRC6.\n\n- InvalidArgumentError when the parameter `inputs` has a rank less than 2. The `inputs` should be a 2+D tensor of arbitrary shape where the last dimension is [,k]. \n\nSimilarly, the CRCDecoder class function will throw an:\n\n- AssertionError if the `crc_encoder` provided is not an instance of the CRCEncoder class\n- InvalidArgumentError when the rank of `x` (the provided inputs) is less than 2. The `inputs` for the `CRCDecoder` should also be 2+D Tensor, but the last `crc_degree` bits should be parity bits."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the definition of ApplyOFDMChannel, such as the default parameters, the link of the source code and explanation."}, {"role": "assistant", "content": "Here is the definition of ApplyOFDMChannel: sionna.channel.ApplyOFDMChannel(add_awgn=True, dtype=tf.complex64, **kwargs)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/channel/apply_ofdm_channel.html#ApplyOFDMChannel)  \nsource code:\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\"\"\"\nLayer for applying OFDM channel: single-tap channel response in the frequency\ndomain\n\"\"\"\n\nimport tensorflow as tf\n\nfrom sionna.utils import expand_to_rank\nfrom .awgn import AWGN\n\nclass ApplyOFDMChannel(tf.keras.layers.Layer):\n    # pylint: disable=line-too-long\n    r\"\"\"ApplyOFDMChannel(add_awgn=True, dtype=tf.complex64, **kwargs)\n\n    Apply single-tap channel frequency responses to channel inputs.\n\n    This class inherits from the Keras `Layer` class and can be used as layer\n    in a Keras model.\n\n    For each OFDM symbol :math:`s` and subcarrier :math:`n`, the single-tap channel\n    is applied as follows:\n\n    .. math::\n        y_{s,n} = \\widehat{h}_{s, n} x_{s,n} + w_{s,n}\n\n    where :math:`y_{s,n}` is the channel output computed by this layer,\n    :math:`\\widehat{h}_{s, n}` the frequency channel response (``h_freq``),\n    :math:`x_{s,n}` the channel input ``x``, and :math:`w_{s,n}` the additive noise.\n\n    For multiple-input multiple-output (MIMO) links, the channel output is computed for each antenna\n    of each receiver and by summing over all the antennas of all transmitters.\n\n    Parameters\n    ----------\n\n    add_awgn : bool\n        If set to `False`, no white Gaussian noise is added.\n        Defaults to `True`.\n\n    dtype : tf.DType\n        Complex datatype to use for internal processing and output. Defaults to\n        `tf.complex64`.\n\n    Input\n    -----\n\n    (x, h_freq, no) or (x, h_freq):\n        Tuple:\n\n    x :  [batch size, num_tx, num_tx_ant, num_ofdm_symbols, fft_size], tf.complex\n        Channel inputs\n\n    h_freq : [batch size, num_rx, num_rx_ant, num_tx, num_tx_ant, num_ofdm_symbols, fft_size], tf.complex\n        Channel frequency responses\n\n    no : Scalar or Tensor, tf.float\n        Scalar or tensor whose shape can be broadcast to the shape of the\n        channel outputs:\n        [batch size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size].\n        Only required if ``add_awgn`` is set to `True`.\n        The noise power ``no`` is per complex dimension. If ``no`` is a\n        scalar, noise of the same variance will be added to the outputs.\n        If ``no`` is a tensor, it must have a shape that can be broadcast to\n        the shape of the channel outputs. This allows, e.g., adding noise of\n        different variance to each example in a batch. If ``no`` has a lower\n        rank than the channel outputs, then ``no`` will be broadcast to the\n        shape of the channel outputs by adding dummy dimensions after the\n        last axis.\n\n    Output\n    -------\n    y : [batch size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex\n        Channel outputs\n    \"\"\"\n\n    def __init__(self, add_awgn=True, dtype=tf.complex64, **kwargs):\n\n        super().__init__(trainable=False, dtype=dtype, **kwargs)\n\n        self._add_awgn = add_awgn\n\n    def build(self, input_shape): #pylint: disable=unused-argument\n\n        if self._add_awgn:\n            self._awgn = AWGN(dtype=self.dtype)\n\n    def call(self, inputs):\n\n        if self._add_awgn:\n            x, h_freq, no = inputs\n        else:\n            x, h_freq = inputs\n\n        # Apply the channel response\n        x = expand_to_rank(x, h_freq.shape.rank, axis=1)\n        y = tf.reduce_sum(tf.reduce_sum(h_freq*x, axis=4), axis=3)\n\n        # Add AWGN if requested\n        if self._add_awgn:\n            y = self._awgn((y, no))\n\n        return y\n```"}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Get to know how to set up and use an instance of the scrambler using `scrambler = Scrambler(seed=1234, binary=True)`."}, {"role": "assistant", "content": "The `Scrambler` in the Sionna library is used for pseudorandomly flipping bits in a binary sequence. To set it up, you have to instantiate it and supply the values of the parameters `seed` and `binary`. `seed` is an explicit seed for the random generator used in scrambling sequences\u2014in this case, we're using 1234. `binary` indicates whether bits should be flipped (if set to True) or if the signs should be flipped (if set to False). \n\nHere's how to set it up:\n\n```python\nfrom sionna.fec.scrambling import Scrambler\n\n# Instantiate the Scrambler\nscrambler = Scrambler(seed=1234, binary=True)\n```\n\nFurthermore, you can use the `Scrambler` as follows:\n\n```python\n# Assume c is a binary sequence we want to scramble\nc_scr = scrambler(c)\n```\n`c_scr` will hold the scrambled bits, and they can be descrambled to reconstruct the original sequence if desired.\n\nHere's how to instantiate and use a descrambler:\n\n```python\nfrom sionna.fec.scrambling import Descrambler\n\n# Instantiate and connect Descrambler with Scrambler\ndescrambler = Descrambler(scrambler=scrambler)\n\n# Descramble to reconstruct the original sequence\nc_descr = descrambler(c_scr)\n```\nIn `c_descr`, we should now have a sequence that's identical to our original `c`.\n\nAlso, note that these bits of code assume that you're using TensorFlow (`tf`)\u2014referenced but not explicitly imported in the context\u2014for generating arrays/tensors."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain how to run the ray tracing process and compute propagation paths for different values of max_depth."}, {"role": "assistant", "content": "To run the ray tracing process and compute propagation paths for different values of max_depth, follow these steps:\n\n1. Import the necessary modules and set up the environment. This includes importing Sionna and TensorFlow, setting up the GPU configuration, and setting the seed for reproducibility.\n\n2. Load the scene you want to use for ray tracing. You can use the `load_scene` function from the Sionna RT module to do this.\n\n3. Configure the antenna array for all transmitters and receivers using the `PlanarArray` class. Set the number of rows and columns, the spacing, the pattern, and the polarization.\n\n4. Create a transmitter and a receiver using the `Transmitter` and `Receiver` classes. Add them to the scene using the `add` method.\n\n5. Set the carrier frequency of the scene and update all RadioMaterials.\n\n6. Run the ray tracing process using the `compute_paths` method of the scene. The `max_depth` parameter determines the maximum number of interactions between a ray and a scene object. For example, with a `max_depth` of one, only line-of-sight paths are considered.\n\n7. Visualize the paths in the 3D preview using the `preview` method of the scene.\n\n8. Transform the paths into channel impulse responses using the `cir` method of the Paths object.\n\n9. If you want to simulate time evolution of the CIR, use the `apply_doppler` method of the Paths object.\n\n10. Finally, you can use the channel impulse responses for link-level simulations.\n\nRemember to adjust the `max_depth` parameter to compute propagation paths for different depths."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the details of PolarSCLDecoder, such as the parameters of the class, the input and output of the class instance, the parameters of the class instance, common error, the property of the class instance."}, {"role": "assistant", "content": "Here is the detailed information:  \nSuccessive cancellation list (SCL) decoder [Ido Tal and Alexander Vardy, \u201cList Decoding of Polar Codes.\u201d IEEE Trans Inf Theory, 2015.] for Polar codes and Polar-like codes.\n\nThe class inherits from the Keras layer class and can be used as layer in a Keras model.  \n  \nParameters\n\n- `frozen_pos` (ndarray) \u2013 Array of int defining the n-k indices of the frozen positions.\n- `n` (int) \u2013 Defining the codeword length.\n- `list_size` (int) \u2013 Defaults to 8. Defines the list size of the decoder.\n- `crc_degree` (str) \u2013 Defining the CRC polynomial to be used. Can be any value from {CRC24A, CRC24B, CRC24C, CRC16, CRC11, CRC6}.\n- `use_hybrid_sc` (bool) \u2013 Defaults to False. If True, SC decoding is applied and only the codewords with invalid CRC are decoded with SCL. This option requires an outer CRC specified via crc_degree. Remark: hybrid_sc does not support XLA optimization, i.e., @tf.function(jit_compile=True).\n- `use_fast_scl` (bool) \u2013 Defaults to True. If True, Tree pruning is used to reduce the decoding complexity. The output is equivalent to the non-pruned version (besides numerical differences).\n- `cpu_only` (bool) \u2013 Defaults to False. If True, tf.py_function embedding is used and the decoder runs on the CPU. This option is usually slower, but also more memory efficient and, in particular, recommended for larger blocklengths. Remark: cpu_only does not support XLA optimization @tf.function(jit_compile=True).\n- `use_scatter` (bool) \u2013 Defaults to False. If True, tf.tensor_scatter_update is used for tensor updates. This option is usually slower, but more memory efficient.\n- `ind_iil_inv` (None or [k+k_crc], int or tf.int) \u2013 Defaults to None. If not None, the sequence is used as inverse input bit interleaver before evaluating the CRC. Remark: this only effects the CRC evaluation but the output sequence is not permuted.\n- `return_crc_status` (bool) \u2013 Defaults to False. If True, the decoder additionally returns the CRC status indicating if a codeword was (most likely) correctly recovered. This is only available if crc_degree is not None.\n- `output_dtype` (tf.DType) \u2013 Defaults to tf.float32. Defines the output datatype of the layer (internal precision remains tf.float32).\n\nInput\n\n- `inputs` ([\u2026,n], tf.float32) \u2013 2+D tensor containing the channel LLR values (as logits).\n\nOutput\n\n- `b_hat` ([\u2026,k], tf.float32) \u2013 2+D tensor containing hard-decided estimations of all k information bits.\n- `crc_status` ([\u2026], tf.bool) \u2013 CRC status indicating if a codeword was (most likely) correctly recovered. This is only returned if return_crc_status is True. Note that false positives are possible.\n\nRaises\n\n- `AssertionError` \u2013 If n is not int.\n- `AssertionError` \u2013 If n is not a power of 2.\n- `AssertionError` \u2013 If the number of elements in frozen_pos is greater than n.\n- `AssertionError` \u2013 If frozen_pos does not consist of int.\n- `AssertionError` \u2013 If list_size is not int.\n- `AssertionError` \u2013 If cpu_only is not bool.\n- `AssertionError` \u2013 If use_scatter is not bool.\n- `AssertionError` \u2013 If use_fast_scl is not bool.\n- `AssertionError` \u2013 If use_hybrid_sc is not bool.\n- `AssertionError` \u2013 If list_size is not a power of 2.\n- `ValueError` \u2013 If output_dtype is not {tf.float16, tf.float32, tf.float64}.\n- `ValueError` \u2013 If inputs is not of shape [\u2026, n] or dtype is not correct.\n- `InvalidArgumentError` \u2013 When rank(inputs)<2.  \n  \n**Note: **    \n[Tal_SCL] -   Ido Tal and Alexander Vardy, \u201cList Decoding of Polar Codes.\u201d IEEE Trans Inf Theory, 2015.  \n[Stimming_LLR] - Alexios Balatsoukas-Stimming, Mani Bastani Parizi, Andreas Burg, \u201cLLR-Based Successive Cancellation List Decoding of Polar Codes.\u201d IEEE Trans Signal Processing, 2015.  \n[Gross_Fast_SCL] - Seyyed Ali Hashemi, Carlo Condo, and Warren J. Gross, \u201cFast and Flexible Successive-cancellation List Decoders for Polar Codes.\u201d IEEE Trans. on Signal Processing, 2017.  \n[Hashemi_SSCL] - Seyyed Ali Hashemi, Carlo Condo, and Warren J. Gross, \u201cSimplified Successive-Cancellation List Decoding of Polar Codes.\u201d IEEE ISIT, 2016.  \n[Cammerer_Hybrid_SCL] - Sebastian Cammerer, Benedikt Leible, Matthias Stahl, Jakob Hoydis, and Stephan ten Brink, \u201cCombining Belief Propagation and Successive Cancellation List Decoding of Polar Codes on a GPU Platform,\u201d IEEE ICASSP, 2017.\n\nThis layer implements the successive cancellation list (SCL) decoder as described in [Tal_SCL] but uses LLR-based message updates [Stimming_LLR]. The implementation follows the notation from [Gross_Fast_SCL], [Hashemi_SSCL]. If option use_fast_scl is active tree pruning is used and tree nodes are combined if possible (see [Hashemi_SSCL] for details).\n\nImplementing SCL decoding as TensorFlow graph is a difficult task that requires several design tradeoffs to match the TF constraints while maintaining a reasonable throughput. Thus, the decoder minimizes the control flow as much as possible, leading to a strong memory occupation (e.g., due to full path duplication after each decision). For longer code lengths, the complexity of the decoding graph becomes large and we recommend to use the CPU_only option that uses an embedded Numpy decoder. Further, this function recursively unrolls the SCL decoding tree, thus, for larger values of n building the decoding graph can become time consuming. Please consider the cpu_only option if building the graph takes to long.\n\nA hybrid SC/SCL decoder as proposed in [Cammerer_Hybrid_SCL] (using SC instead of BP) can be activated with option use_hybrid_sc iff an outer CRC is available. Please note that the results are not exactly SCL performance caused by the false positive rate of the CRC.\n\nAs commonly done, we assume frozen bits are set to 0. Please note that - although its practical relevance is only little - setting frozen bits to 1 may result in affine codes instead of linear code as the all-zero codeword is not necessarily part of the code any more.\n  \nProperties\n- `frozen_pos`: Frozen positions for Polar decoding.\n- `info_pos`: Information bit positions for Polar encoding.\n- `k`: Number of information bits.\n- `k_crc`: Number of CRC bits.\n- `list_size`: List size for SCL decoding.\n- `llr_max`: Maximum LLR value for internal calculations.\n- `n`: Codeword length.\n- `output_dtype`: Output dtype of the decoder.\n  "}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the details of class BinaryErasureChannel, such as the parameters of the class, the input and output of the class instance and the link of source code."}, {"role": "assistant", "content": "Here is the detailed information of BinaryErasureChannel:   \n  \n[sionna.channel.BinaryErasureChannel(return_llrs=False, bipolar_input=False, llr_max=100., dtype=tf.float32, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/channel/discrete_channel.html#BinaryErasureChannel)  \n\nBinary erasure channel (BEC) where a bit is either correctly received or erased.\n\nIn the binary erasure channel, bits are always correctly received or erased with erasure probability $p_\\text{b}$, like this [pic](https://nvlabs.github.io/sionna/_images/BEC_channel.png)\n\nThis layer supports binary inputs ($x \\in \\{0, 1\\}$) and bipolar inputs ($x \\in \\{-1, 1\\}$).\n\nIf activated, the channel directly returns log-likelihood ratios (LLRs) defined as $\\begin{split}\\ell =\n\\begin{cases}\n    -\\infty, \\qquad \\text{if} \\, y=0 \\\\\n    0, \\qquad \\quad \\,\\, \\text{if} \\, y=? \\\\\n    \\infty, \\qquad \\quad \\text{if} \\, y=1 \\\\\n\\end{cases}\\end{split}$\n\nThe erasure probability $p_\\text{b}$ can be either a scalar or a tensor (broadcastable to the shape of the input). This allows different erasure probabilities per bit position.\n\nPlease note that the output of the BEC is ternary. Hereby, -1 indicates an erasure for the binary configuration and 0 for the bipolar mode, respectively.\n\nThis class inherits from the Keras Layer class and can be used as layer in a Keras model.\n\n**Parameters**\n\n- `return_llrs` (bool): Defaults to False. If True, the layer returns log-likelihood ratios (LLRs) instead of binary values based on `pb`.\n- `bipolar_input` (bool): Defaults to False. If True, the expected input is given as $\\{-1, 1\\}$ instead of $\\{0, 1\\}$.\n- `llr_max` (tf.float): Defaults to 100. Defines the clipping value for the LLRs.\n- `dtype` (tf.DType): Defines the datatype for internal calculations and the output dtype. Defaults to tf.float32.\n\n**Input**\n\n- `(x, pb)` \u2013 Tuple:\n  - `x` ([\u2026,n], tf.float32): Input sequence to the channel.\n  - `pb` (tf.float32): Erasure probability. Can be a scalar or of any shape that can be broadcasted to the shape of `x`.\n\n**Output**\n\n- `[\u2026,n]`, tf.float32: Output sequence of the same length as the input `x`. If `return_llrs` is False, the output is ternary where each -1 and each 0 indicate an erasure for the binary and bipolar input, respectively."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Detail how to set up and run the \"FlatFadingChannel\"."}, {"role": "assistant", "content": "To set up and run the FlatFadingChannel, follow the steps below:\n\n1. First, import necessary classes:\n\n    ```python\n    from sionna.channel import FlatFadingChannel, SpatialCorrelation\n    ```\n\n2. To set up FlatFadingChannel, you need to create an instance of the class. You can optionally specify spatial correlation for the channel by creating an instance of SpatialCorrelation, but remember SpatialCorrelation is an abstract class, thus, you may need to create your own subclass that inherits from SpatialCorrelation and implements all its abstract methods. Here is an example where we specify KroneckerModel for spatial correlation:\n   \n   Here is just an example about how to use SpatialCorrelation(): \n   ```python\n   import tensorflow as tf\n\n   class BasicSpatialCorrelation(SpatialCorrelation):\n      def __call__(self, h):\n        # Example implementation that simply scales the coefficients to simulate correlation\n        # In practice, you would replace this with a realistic correlation model\n        scaling_factor = tf.complex(0.5, 0.0)  # Example scaling factor\n        h_corr = scaling_factor * h\n        return h_corr\n\n   # Example usage\n   # Assume h is a tensor of spatially uncorrelated channel coefficients\n   batch_size = 1\n   num_rx = 2\n   num_tx = 2\n   h = tf.complex(\n    tf.random.normal([batch_size, num_rx, num_tx], dtype=tf.float32),\n    tf.random.normal([batch_size, num_rx, num_tx], dtype=tf.float32)\n   )\n\n   # Instantiate and apply your custom spatial correlation model\n   spatial_corr = BasicSpatialCorrelation()\n   h_corr = spatial_corr(h)\n\n   print(\"Original Channel Coefficients:\", h)\n   print(\"Correlated Channel Coefficients:\", h_corr)\n   ```\n   \n    ```python\n    flat_fading_channel = FlatFadingChannel(num_tx_ant=2, num_rx_ant=2, spatial_corr=spatial_corr)\n    ```\n\n    In this example, we set the number of transmit and receive antennas as 2. The spatial correlation model is set to KroneckerModel. You can change these parameters as per your requirements.\n\n3. After setting up, you can generate and apply the FlatFadingChannel. Remember `generate`, `apply` are properties, DO NOT treat them as method:\n\n    ```python\n    h = flat_fading_channel.generate  \n    y = flat_fading_channel.apply\n    ```\n\n    Here `generate` is to call the internal GenerateFlatFadingChannel, `apply` is to call the internal ApplyFlatFadingChannel.\n\nNote: The code snippets provided are for illustration purposes and need to be fit into a context or a larger script that includes necessary earlier steps like importing required libraries, preparing necessary variables and data, error handling, etc."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Elaborate on the 'prune_pcm' parameter in `LDPC5GDecoder` and its impact on decoding efficiency."}, {"role": "assistant", "content": "In the context of the `LDPC5GDecoder` which inherits from `LDPCBPDecoder`, the `prune_pcm` parameter plays a significant role in optimizing the decoding process for 5G NR LDPC codes. The `prune_pcm` parameter is a boolean that defaults to True, and its function is to modify the parity-check matrix (PCM) used in the decoding by removing certain nodes and connections which correspond to punctured variable nodes in the transmitted codeword.\n\nHere's why `prune_pcm` is important:\n\n1. **Puncturing in LDPC Codes**: Puncturing is a process in encoding where certain bits are intentionally omitted or not transmitted to adapt to a specific code rate or channel bandwidth. When decoding, these punctured bits are essentially treated as erasures.\n\n2. **Pruning Parity-Check Matrix**: When `prune_pcm` is set to True, the decoding graph (or the parity-check matrix) ignores the contributions of punctured (degree-1 variable) nodes and the connected check nodes. This is done based on the understanding that punctured bits do not contribute to the decoding process since they are not transmitted.\n\n3. **Decoding Efficiency**: By pruning the parity-check matrix, the LDPC decoder eliminates unnecessary computations associated with the punctured bits, which do not provide any useful information during the belief propagation process. This results in a reduced decoding complexity, improved throughput, and can also lower the memory footprint, which is beneficial in high-performance applications where resources are a constraint.\n\n4. **Decoding Outcome**: The pruning process should not alter the decoding outcome significantly. However, it might cause small numerical differences due to the change in the graph structure used in the iterative belief propagation process. It is noted in the context provided that pruning should yield the same decoding result overall.\n\nIn summary, enabling `prune_pcm` in `LDPC5GDecoder` allows for a more efficient decoding process by simplifying the decoding graph to exclude contributions from punctured bits, resulting in better performance, especially in systems where processing efficiency and memory usage are critical.\n\nHere is a small snippet showing the instantiation of `LDPC5GDecoder` from the Sionna API with the `prune_pcm` parameter:\n\n```python\nfrom sionna.fec.ldpc.encoding import LDPC5GEncoder\nfrom sionna.fec.ldpc.decoding import LDPC5GDecoder\n\nencoder = LDPC5GEncoder(k=100, n=200)\ndecoder = LDPC5GDecoder(encoder=encoder, num_iter=20, return_infobits=True, prune_pcm=True)\n```\n\nThis code demonstrates how to instantiate the `LDPC5GDecoder` with pruning enabled. It should be noted, though, that the actual impact of the `prune_pcm` parameter on the decoding efficiency can depend on the specific implementation details within the Sionna library and should be verified against the latest documentation or by empirical performance testing."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain the LLR-based distance metric used in the OSDecoder and its advantages for higher-order modulation schemes."}, {"role": "assistant", "content": "The OSDecoder, implemented as the `sionna.fec.linear.OSDecoder` class from the Sionna package, utilizes an LLR-based distance metric as an integral part of its ordered-statistics decoding (OSD) algorithm. This LLR-based distance metric was introduced based on the work referenced in the context as [Stimming_LLR_OSD]. The approach is focused on simplifying the handling of higher-order modulation schemes when performing decoding tasks.\n\nThe principle behind an LLR-based distance metric can be understood by considering the basic workings of the OSD algorithm. Here's a summary of how OSD works:\n\n1. Sort log-likelihood ratios (LLRs) according to their reliability. This helps identify the most reliable bits, which are more likely to be correctly received.\n2. Apply the same column permutation to the generator matrix to align with the sorted reliability of LLRs.\n3. Transform the permuted generator matrix into a systematic form.\n4. Hard-decide the k most reliable bits and re-encode them while disregarding the less reliable bits.\n5. Generate possible error patterns up to a specified order 't' in the decoded bits and identify the most likely codeword.\n\nIncorporating an LLR-based distance metric allows the decoder to directly consider the reliability of the received LLRs for each bit. For higher-order modulation schemes, this is particularly advantageous because the LLR values convey more information about the transmitted symbols compared to hard decisions.\n\nThe use of an LLR-based metric can result in the following advantages:\n\n- Improved decoding performance, particularly for complex modulation schemes like those higher than Quadrature Amplitude Modulation (QAM), where symbol distances vary significantly, and consequently, so do LLR magnitudes.\n- Enhanced sensitivity to the soft-decision information conveyed by the demapper, as opposed to strictly binary decision-making methods.\n- Better approximation to maximum likelihood decoding, especially when the order 't' of the OSD is large enough.\n\nThe LLR-based distance metric thus complements the OSD method in handling the inherent challenges posed by higher-order modulation schemes, offering decoding performance that is closer to the optimal maximum likelihood performance.\n\nPlease note that the decoding steps listed do not directly relate to a code snippet, but if you were to instantiate an `OSDecoder` using the Sionna API, your code would look like this:\n\n```python\nimport numpy as np\nfrom sionna.fec.linear import OSDecoder\n\n# Define a parity-check matrix\npcm = np.array([[1, 1, 1, 0, 1, 0, 0],\n                [0, 1, 1, 1, 0, 1, 0],\n                [1, 1, 0, 1, 0, 0, 1]])\n\n# Assuming 'llr_ch' contains channel LLRs\n# For example, let's use a placeholder array\nllr_ch = np.array([-0.9, 1.2, -1.5, 0.8, -1.1, 1.4, -0.7])\n\n# Initialize the decoder with the parity-check matrix and the order of the OSD\ndecoder = OSDecoder(pcm, t=4, is_pcm=True)\n\n# Decode the LLRs\ndecoded_bits = decoder(llr_ch)\n\n# Print the decoded bits\nprint(\"Decoded bits:\", decoded_bits)\n\n```\n\nIn this code, `pcm` represents the parity-check matrix that the decoder is initialized with, `t=4` determines the order of the OSD, and `llr_ch` contains the channel LLRs. The `OSDecoder` then processes the LLR information according to the steps of the OSD algorithm using the LLR-based distance metric."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain how to select a modulation and coding scheme (MCS) in Sionna's API."}, {"role": "assistant", "content": "To select a modulation and coding scheme (MCS) in Sionna's API, you would need to utilize the `TBConfig` and `PUSCHConfig` classes. To do so, you may need a series of steps:\n\n1. First, instantiate a `CarrierConfig` object with the necessary parameters.\n\n```python\ncarrier_config = CarrierConfig(n_cell_id=41, num_slots_per_frame=10)\ncarrier_config.subcarrier_spacing = 30\n```\n2. Then, create a `PUSCHConfig` object, passing in your `CarrierConfig` object (or using default settings). \n\n```python\npusch_config = PUSCHConfig(carrier_config)\n```\n3. Within the `PUSCHConfig` object, you can set properties related to MCS. This includes `mcs_table`, `mcs_index`, `tb`, and more.\n\n```python\npusch_config.tb.mcs_index = 13\npusch_config.tb.mcs_table = 3\n```\n4. You can see more details of the MCS configuration by calling `PUSCHConfig.tb.show()`. \n\n```python\npusch_config.tb.show()\n```\n\nThis setup allows you to adjust the MCS according to your needs.\n\nThe provided context does not contain enough specificity for adjusting the MCS in Sionna's API. Please refer to the official API documentation or examples for more detailed instructions."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain what the qam function does in the sionna mapping."}, {"role": "assistant", "content": "The `qam` function in the `sionna.mapping` module generates a Quadrature Amplitude Modulation (QAM) constellation. It creates a complex-valued vector, where each element is a constellation point of an M-ary QAM constellation. The binary label of the `n`th point is given by the `num_bits_per_symbol` length binary representation of `n`. \n\nThe function requires two arguments:\n- `num_bits_per_symbol`: An integer that represents the number of bits per constellation point. It must be a multiple of two, for example, 2, 4, 6, 8, etc.\n- `normalize`: A boolean value that, if True, normalizes the constellation to have unit power. It defaults to True.\n\nThe function returns a QAM constellation represented as a complex-valued vector of size `[2^(num_bits_per_symbol)]`.\n\nThis function can be used for the generation of QAM constellation points necessary to modulate digital signals in communication systems."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain how to visualize the scene using the preview function."}, {"role": "assistant", "content": "To visualize the scene using the preview function in Sionna, you can follow these steps:\n\n1. Import the necessary modules and set up the environment. This includes importing the Sionna module and setting up the GPU configuration.\n\n```python\nimport os\nimport sionna\nfrom sionna.rt import load_scene\n\ngpu_num = 0\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n```\n\n2. Load the scene that you want to visualize. You can use the `load_scene` function from the Sionna RT module to do this. \n\n```python\nscene = load_scene(sionna.rt.scene.munich)\n```\n\n3. Check if you are running the notebook in Google Colab. The preview function does not work in Colab, so you need to deactivate it if you are using Colab.\n\n```python\ntry:\n    import google.colab\n    colab_compat = True\nexcept:\n    colab_compat = False\n```\n\n4. If you are not using Colab, you can use the `preview` function to visualize the scene. \n\n```python\nif not colab_compat:\n    scene.preview()\n```\n\nThe `preview` function opens an interactive preview of the scene. You can use the mouse to rotate the view, the scroll wheel to zoom in and out, and the right mouse button to move the view.\n\nPlease note that the preview function only works in Jupyter notebooks and is deactivated when `colab_compat` is set to True. Also, only one preview instance can be open at the same time."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Describe how to configure GPU and import necessary modules for Sionna."}, {"role": "assistant", "content": "To configure GPU and import necessary modules for Sionna, follow these steps:\n\n1. Set the GPU number. If you want to use the CPU, set the GPU number to an empty string (\"\").\n```python\nimport os\ngpu_num = 0  # Use \"\" to use the CPU\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = f\"{gpu_num}\"\n```\n\n2. Set the TensorFlow C++ minimum log level to '3' to avoid unnecessary warnings.\n```python\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n```\n\n3. Import the Sionna package. If it's not already installed, install it using pip.\n```python\ntry:\n    import sionna\nexcept ImportError as e:\n    # Install Sionna if package is not already installed\n    os.system(\"pip install sionna\")\n    import sionna\n```\n\n4. Configure the notebook to use only a single GPU and allocate only as much memory as needed. For more details, see https://www.tensorflow.org/guide/gpu.\n```python\nimport tensorflow as tf\ngpus = tf.config.list_physical_devices('GPU')\nif gpus:\n    try:\n        tf.config.experimental.set_memory_growth(gpus[0], True)\n    except RuntimeError as e:\n        print(e)\n```\n\n5. Set the TensorFlow logger level to 'ERROR' to avoid warnings from TensorFlow.\n```python\ntf.get_logger().setLevel('ERROR')\n```\n\n6. Import the necessary modules for your work with Sionna. Here is an example of some modules you might need:\n```python\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport sys\nfrom sionna.utils import BinarySource, QAMSource, ebnodb2no, compute_ser, compute_ber, PlotBER\nfrom sionna.channel import FlatFadingChannel, KroneckerModel\nfrom sionna.channel.utils import exp_corr_mat\nfrom sionna.mimo import lmmse_equalizer\nfrom sionna.mapping import SymbolDemapper, Mapper, Demapper\nfrom sionna.fec.ldpc.encoding import LDPC5GEncoder\nfrom sionna.fec.ldpc.decoding import LDPC5GDecoder\n```\nRemember to replace these modules with the ones you need for your specific task."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain the function of the \"call_inverse\" function in \"Turbo3GPPInterleaver\"."}, {"role": "assistant", "content": "The \"call_inverse\" function in the \"Turbo3GPPInterleaver\" class is a method that implements the deinterleaver functionality corresponding to the call() method. It is essentially used for reversing the process of interleaving.\n\nThe purpose of deinterleaving is to revert the interleaving process and restore the original sequence of data. Why would we want to do this? Interleaving is a common technique used in communication systems for dealing with burst errors. It rearranges the order of data so that consecutive bits of information are less likely to be lost all at once. But once the data is received, you'll want to deinterleave it to restore the original sequence.\n\nThe function takes as input a 2+D tensor of arbitrary shape and data type, and it returns a 2+D tensor of the same shape and data type as the input.\n\nIt's important to note that while interleaving is typically done in the transmitter end in communication systems, the deinterleaving happens on the receiver side. This means that typically the call_inverse function will be used in a different part of the system than the initial interleaving operation was performed.\n\nFirst of all, you need to create an instance of class Turbo3GPPInterleaver:  \n  \n```python\nfrom sionna.fec.interleaving import Turbo3GPPInterleaver  \n  \nturbo3GPPInterleaver = Turbo3GPPInterleaver() \n```\n\nIn Python, you might call this function like this:\n\n```python\nimport tensorflow as tf\nx_interleaved = tf.constant([[0,1,2],[2,1,0]]) #  2+D tensor of arbitrary shape and dtype, choose you own x_interleaved\n\nx_deinterleaved = turbo3GPPInterleaver.call_inverse(x_interleaved)\n```\n\nIn this snippet, `x_interleaved` is the interleaved tensor, and `x_deinterleaved` is the output of the function, which should be the original tensor before interleaving, assuming there were no errors in transmission."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Discuss the functionalities and properties of the TBDecoder class in the Sionna Python package."}, {"role": "assistant", "content": "The TBDecoder class in the Sionna Python package is designed to decode 5G NR transport blocks (TB) based on the specifications defined in TS 38.214. It is constructed using associated transport block encodings and the logic is framed to decode blocks as specified in the technical specification.\n\nSome of the key functionalities of the TBDecoder class include:\n- Decoding: Provided with a sequence of noisy channel observations, the TBDecoder is capable of reconstructing the corresponding transport block of information bits.\n- Iterative functioning: It supports iterative functioning with a set number of iterations for the belief propagation (BP) decoder.\n- Use of check-node processing functions: This class allows for the use of check-node processing functions.\n- Error handling: TBDecoder also incorporates error handling. The decoding process ensures and checks the correctness of the transport block recovery.\n\nThe properties and methods of the TBDecoder class include:\n- Few key properties like 'k' that signifies the number of input bits, 'n' representing the total number of output bits, 'tb_size' shows the number of information bits per TB.\n- TBDecoder uses an internal method `calculate_tb_size` to calculate the transport block size.\n- It has 'encoder' as an essential parameter that needs an associated transport block encoder for the encoding of the signal.\n- 'num_bp_iter' is an important parameter that sets the number of BP decoder iterations.\n- 'cn_type' helps in defining the check node processing function of the LDPC BP decoder.\n- 'output_dtype' parameter is used to set the required data type for internal calculations and for setting the output data type.\n\nLastly, it uses an inheritance model from the Keras layer class which allows it to be used as a layer in a Keras model."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Illustrate encoding information bits using an instance of `LDPC5GEncoder` in a code snippet, and explain the expected input and output formats."}, {"role": "assistant", "content": "To illustrate encoding information bits using an instance of `LDPC5GEncoder` in Python, you would follow a code snippet similar to the one provided in the context. The expected input to the encoder is a 2+D tensor containing the information bits you want to encode, and the expected output is also a 2+D tensor containing the encoded codeword bits.\n\nHere is an example of how to use the `LDPC5GEncoder` from Sionna's LDPC code module to encode information bits:\n\n```python\nimport tensorflow as tf\nfrom sionna.fec.ldpc.encoding import LDPC5GEncoder\n\n# Define the number of information bits (k) and the codeword length (n)\nk = 100  # Number of information bits\nn = 200  # Number of codeword bits\n\n# Create an instance of the LDPC5GEncoder\nencoder = LDPC5GEncoder(k=k, n=n)\n\n# Generate an example batch of information bits\n# The shape [..., k] means you can have any number of dimensions before the last one,\n# which should be of size k. This is typically a 2D tensor.\nbatch_size = 10  # Example batch size\ninfo_bits = tf.random.uniform(shape=[batch_size, k], minval=0, maxval=2, dtype=tf.int32)\ninfo_bits = tf.cast(info_bits, tf.float32)  # Convert to float32 as expected by the encoder\n\n# Encode the information bits\nencoded_bits = encoder(info_bits)\n\n# The shape of encoded_bits tensor now is [batch_size, n], as the encoder\n# changes the last dimension from k (number of information bits) to n (codeword length)\nprint(\"Shape of encoded_bits:\", encoded_bits.shape)\n```\n\nIn this example:\n- `k` is the number of information bits per codeword.\n- `n` is the desired codeword length.\n- `info_bits` is a tensor that contains the information bits to be encoded. The tensor's shape is `[batch_size, k]`, which means there are `batch_size` codewords, each containing `k` information bits.\n- The `LDPC5GEncoder` takes `info_bits` as input and outputs `encoded_bits`, which is a tensor of the encoded codeword bits. After encoding, the shape of the `encoded_bits` tensor is `[batch_size, n]`, where `n` is the codeword length specified when creating the encoder instance.\n\nPlease note that this code snippet assumes that the necessary libraries are installed and that Sionna's LDPC module supports the LDPC5GEncoder class as described. It's also important to ensure the input data tensor only contains binary values (0s and 1s), as LDPC encoding operates on binary data."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the details of class RandomInterleaver, such as the parameters of the class, input and output of the instance, common errors and properties."}, {"role": "assistant", "content": "Here is details of [RandomInterleaver](https://nvlabs.github.io/sionna/_modules/sionna/fec/interleaving.html#RandomInterleaver):  \n  \nRandom interleaver permuting a sequence of input symbols.\n\nThe class inherits from the Keras layer class and can be used as layer in a Keras model.  \n  \n#### Parameters\n- **seed** (`int`): Integer defining the random seed used if the option `keep_state` is `True`.\n- **keep_batch_constant** (`bool`): Defaults to `True`. If set to `True`, each sample in the batch uses the same permutation. Otherwise, unique permutations per batch sample are generated (slower).\n- **inverse** (`bool`): A boolean that defaults to `False`. If `True`, the inverse permutation is performed.\n- **keep_state** (`bool`): A boolean that defaults to `True`. If `True`, the permutation is fixed for multiple calls (defined by the `seed` attribute).\n- **axis** (`int`): Defaults to `-1`. The dimension that should be interleaved. The first dimension (axis=0) is not allowed.\n- **dtype** (`tf.DType`): Defaults to `tf.float32`. Defines the datatype for internal calculations and the output dtype.\n  \n#### Input\n- **(x, seed)**: Either Tuple `(x, seed)` or `x` only (no tuple) if the internal seed should be used:\n    - **x** (`tf.DType`): 2+D tensor of arbitrary shape and dtype.\n    - **seed** (`int`): An integer defining the state of the random number generator. If explicitly given, the global internal seed is replaced by this seed. Can be used to realize random interleaver/deinterleaver pairs (call with the same random seed).\n\n#### Output\n- `tf.DType`: 2+D tensor of the same shape and dtype as the input `x`.\n\n#### Raises\n- **AssertionError**: If `axis` is not an integer.\n- **AssertionError**: If `seed` is not `None` or an integer.\n- **AssertionError**: If `axis` > number of input dimensions.\n- **AssertionError**: If `inverse` is not a boolean.\n- **AssertionError**: If `keep_state` is not a boolean.\n- **AssertionError**: If `keep_batch_constant` is not a boolean.\n- **InvalidArgumentError**: When rank(`x`)<2.\n  \n**Note: **  \nTo permute the batch dimension, expand_dims at axis=0, interleave and remove new dimension.\n\nThe interleaver layer is stateless, i.e., the seed is either random during each call or must be explicitly provided during init/call. This simplifies XLA/graph execution.\n\nThis is NOT the 5G interleaver sequence.\n  \n#### Properties\n- **axis**: Axis to be permuted.\n\n- **keep_state**: Generate new random seed per call.\n\n- **seed**: Seed to generate random sequence.  \n  \n#### Function 1:  \n[call_inverse(inputs)](https://nvlabs.github.io/sionna/_modules/sionna/fec/interleaving.html#RandomInterleaver.call_inverse)  \nImplements deinterleaver function corresponding to call().  \n  \n#### Input\n- **(x, seed)**: Either Tuple `(x, seed)` or `x` only (no tuple) if the internal seed should be used:\n    - **x** (`tf.DType`): 2+D tensor of arbitrary shape and dtype.\n    - **seed** (`int`): An integer defining the state of the random number generator. If explicitly given, the global internal seed is replaced by this seed. Can be used to realize random interleaver/deinterleaver pairs (call with the same random seed).\n\n#### Output\n- `tf.DType`: 2+D tensor of the same shape and dtype as the input `x`.\n\n#### Raises\n- **InvalidArgumentError**: When rank(`x`)<2.\n- **ValueError**: If `keep_state` is `False` and no explicit seed is provided.\n  \n**Note: **In case of inverse interleaving (e.g., at the receiver), keep_state should be True as otherwise a new permutation is generated and the output is not equal to the original sequence. Alternatively, an explicit seed must be provided as function argument.  \n  \nsource code:   \n```python\n    def call_inverse(self, inputs):\n        \"\"\"Implements deinterleaver function corresponding to call().\n\n        Input\n        -----\n            (x, seed):\n                Either Tuple ``(x, seed)`` or ``x`` only (no tuple) if the internal\n                seed should be used:\n\n            x: tf.DType\n                2+D tensor of arbitrary shape and dtype.\n            seed: int\n                An integer defining the state of the random number\n                generator. If explicitly given, the global internal seed is\n                replaced by this seed. Can be used to realize random\n                interleaver/deinterleaver pairs (call with same random seed).\n\n        Output\n        ------\n            : tf.DType\n                2+D tensor of same shape and dtype as the input ``x``.\n\n        Raises\n        ------\n            InvalidArgumentError\n                When rank(``x``)<2.\n\n            ValueError\n                If ``keep_state`` is False and no explicit seed is provided.\n\n        Note\n        ----\n            In case of inverse interleaving (e.g., at the receiver),\n            ``keep_state`` should be True as otherwise a new permutation is\n            generated and the output is not equal to the original sequence.\n            Alternatively, an explicit seed must be provided as function\n            argument.\n        \"\"\"\n\n        if isinstance(inputs, (tuple, list)):\n            if len(inputs)==1: # if user wants to call with call([x])\n                seed = None\n                x = inputs\n            elif len(inputs)==2:\n                x, seed = inputs\n            else:\n                raise TypeError(\"inputs cannot have more than 2 entries.\")\n        else:\n            seed = None\n            x = inputs\n\n        input_shape = x.shape\n        tf.debugging.assert_greater(tf.rank(x), 1)\n\n        # use seed if explicit seed is provided\n        if seed is not None:\n            seed = (tf.constant(1337), tf.cast(seed, tf.int32))\n        elif self._keep_state:\n            # use sequence as defined by seed\n            seed = self._seed\n        else:\n            # This mode is not supported for\n            raise ValueError(\"Deinterleaving not possible for random \" \\\n                \"seeds per call (keep_state=False) without explicitly \" \\\n                \"providing the seed as inputs.\")\n        # select if each sample in batch needs own perm (computational complex!)\n        if self._keep_batch_constant:\n            batch_size = 1\n        else:\n            batch_size = tf.shape(x)[0]\n\n        perm_seq = self._generate_perm_full(seed,\n                                            tf.shape(x)[self._axis],\n                                            batch_size,\n                                            inverse=True) # activate inverse\n\n        if self._keep_batch_constant:\n            # broadcast single sequence over complete batch\n            perm_seq = tf.squeeze(perm_seq, axis=0) # remove batch_dim\n            x = tf.gather(x, perm_seq, batch_dims=0, axis=self._axis)\n        else:\n            x = tf.gather(x, perm_seq, batch_dims=1, axis=self._axis)\n\n        # set explicitly for keras models\n        x = tf.ensure_shape(x, input_shape)\n        return x\n```  \n  \n#### Function 2:  \n[find_s_min(seed, seq_length, s_min_stop=0)](https://nvlabs.github.io/sionna/_modules/sionna/fec/interleaving.html#RandomInterleaver.find_s_min)  \n  \nFind $S$ parameter such that $\\pi(i)-\\pi(j)>S$ for all $i-j<S$. This can be used to find optimized interleaver patterns.  \n  \ns_min_stop is an additional stopping condition, i.e., stop if current $S$ is already smaller than s_min_stop.\n\nPlease note that this is a Numpy utility function and usually not part of the graph.\n  \n#### Input\n- **seed** (`int`): Seed to draw a random permutation that shall be analyzed.\n- **seq_length** (`int`): Length of the permutation sequence to be analyzed.\n- **s_min_stop** (`int`): Defaults to 0. Enables early stop if already current `s_min` < `s_min_stop`.\n\n#### Output\n- `float`: The S-parameter for the given seed.\n  \nsource code:  \n```python\n    def find_s_min(self, seed, seq_length, s_min_stop=0):\n        r\"\"\"Find :math:`S` parameter such that :math:`\\pi(i)-\\pi(j)>S` for all\n        :math:`i-j<S`. This can be used to find optimized interleaver patterns.\n\n        ``s_min_stop`` is an additional stopping condition, i.e., stop if\n        current :math:`S` is already smaller than ``s_min_stop``.\n\n        Please note that this is a Numpy utility function and usually not part\n        of the graph.\n\n        Input\n        -----\n            seed: int\n                seed to draw random permutation that shall be analyzed.\n\n            seq_length: int\n                length of permutation sequence to be analyzed.\n\n            s_min_stop: int\n                Defaults to 0. Enables early stop if already current s_min< ``s_min_stop`` .\n        Output\n        ------\n            : float\n                The S-parameter for the given ``seed``.\n        \"\"\"\n\n        assert isinstance(seed, int), \"seed must be int.\"\n        assert isinstance(seq_length, int), \"seq_length must be int.\"\n        assert isinstance(s_min_stop, int), \"s_min_stop must be int.\"\n\n        seed = (1337, seed)\n        perm_seq = self._generate_perm_full(seed, seq_length, batch_size=1)\n        perm_seq = tf.squeeze(perm_seq, axis=0).numpy()\n        s_min = seq_length\n        for i in range(len(perm_seq)): # search for all positions in perm_seq\n            for j in range(-s_min,s_min,1): # search dist\n                if j==0: # ignore identity\n                    continue\n                if i+j>=0 and i+j<seq_length:\n                    d = np.abs(perm_seq[i] - perm_seq[i+j])\n                    if d<=np.abs(j):\n                        s_min = np.min([s_min, np.abs(j)])\n                    if d<s_min and np.abs(j)<s_min:\n                        s_min = np.min([s_min, d])\n            # early stop\n            if s_min<=s_min_stop:\n                break\n        return int(s_min)\n```"}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain how to load the saved estimates of the time, frequency, and space covariance matrices."}, {"role": "assistant", "content": "To load the saved estimates of the time, frequency, and space covariance matrices, you can use the `numpy.load()` function. Here are the steps:\n\n1. Import the necessary library: `import numpy as np`.\n\n2. Use the `numpy.load()` function to load the saved numpy arrays. You need to provide the file path (or name if the file is in the same directory) as a string argument to the function. For example:\n\n```python\nFREQ_COV_MAT = np.load('freq_cov_mat.npy')\nTIME_COV_MAT = np.load('time_cov_mat.npy')\nSPACE_COV_MAT = np.load('space_cov_mat.npy')\n```\n\nIn this example, 'freq_cov_mat.npy', 'time_cov_mat.npy', and 'space_cov_mat.npy' are the names of the saved numpy files for the frequency, time, and space covariance matrices, respectively. Replace these with the actual names of your files.\n\nAfter running these lines of code, `FREQ_COV_MAT`, `TIME_COV_MAT`, and `SPACE_COV_MAT` will be numpy arrays containing the loaded covariance matrices."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Describe the signal processing pipeline for non-IDD models."}, {"role": "assistant", "content": "The signal processing pipeline for non-Iterative Detection and Decoding (IDD) models involves several steps:\n\n1. **Transmitter**: The transmitter part of the pipeline includes a binary source, an encoder, a mapper, and a resource grid mapper. The binary source generates binary data. This data is then encoded using an LDPC5GEncoder. The encoded data is then mapped to symbols using a Mapper. Finally, the symbols are mapped to a resource grid using a ResourceGridMapper.\n\n2. **Channel**: The channel part of the pipeline includes a channel model and an OFDM channel. The channel model can be either a UMa model or a Rayleigh block fading model. The OFDM channel applies the channel model to the transmitted signal and adds white Gaussian noise.\n\n3. **Receiver**: The receiver part of the pipeline includes a channel estimator, a detector, and a decoder. The channel estimator estimates the channel state information (CSI) from the received signal. The detector then uses this CSI to detect the transmitted symbols. The detected symbols are then decoded using an LDPC5GDecoder to recover the transmitted data.\n\nThe non-IDD models used for comparison include soft-output LMMSE, K-Best, and expectation propagation (EP) detectors, as well as iterative SISO MMSE-PIC detection."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Describe how to apply the \"ApplyFlatFadingChannel\" and its properties."}, {"role": "assistant", "content": "To apply the \"ApplyFlatFadingChannel\" in Sionna's wireless channel models, you first need to create an instance of the ApplyFlatFadingChannel class. This class applies given flat-fading channel matrices to a vector input and optionally adds Additive White Gaussian Noise (AWGN). Here's the basic structure:\n\n```python\nfrom sionna.channel import ApplyFlatFadingChannel\nimport tensorflow as tf\n\napply_channel = ApplyFlatFadingChannel(add_awgn=True, dtype=tf.complex64)\n```\n\nHere, `add_awgn=True` means that the AWGN noise should be added to the output. This is recommended for realistic scenarios. \n\nThen you should be able to apply channel responses to your input data as follows:\n\n```python\nfrom sionna.channel import RayleighBlockFading\nfrom sionna.channel import GenerateOFDMChannel\nfrom sionna.ofdm import ResourceGrid\n\nrayleigh = RayleighBlockFading(num_rx = 1,\n                               num_rx_ant = 32,\n                               num_tx = 4,\n                               num_tx_ant = 2)\n\n# Parameters for ResourceGrid\nnum_ofdm_symbols = 14\nfft_size = 256\nsubcarrier_spacing = 15e3  # 15 kHz, common in LTE & 5G NR\n\n# ResourceGrid instance with specified parameters\nrg = ResourceGrid(\n    num_ofdm_symbols=num_ofdm_symbols,\n    fft_size=fft_size,\n    subcarrier_spacing=subcarrier_spacing\n)\n\ngenerate_channel = GenerateOFDMChannel(channel_model = rayleigh,\n                                       resource_grid = rg)\n # Generate a batch of channel responses\nh = generate_channel(100) \n\n# (x, h, no) \u2013 Tuple:\n# x ([batch_size, num_tx_ant], tf.complex) \u2013 Tensor of transmit vectors.\n# h ([batch_size, num_rx_ant, num_tx_ant], tf.complex) \u2013 Tensor of channel realizations. Will be broadcast to the dimensions of x if needed.\n# no (Scalar or Tensor, tf.float) \u2013 The noise power no is per complex dimension. Only required if add_awgn==True. Will be broadcast to the shape of y. For more details, see AWGN.\n# y ([batch_size, num_rx_ant, num_tx_ant], dtype) \u2013 Channel output.\ny = apply_channel((x, h, no))\n```\n\nHere, `x` is your input data, `h` is your generated channel responses, and `no` is the noise variance. \n\nThe ApplyFlatFadingChannel class also supports chaining operations with other classes and functions via the `apply` property. You can consult [`SpatialCorrelation`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.SpatialCorrelation) for configuring spatial correlation, [`GenerateFlatFadingChannel`](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.GenerateFlatFadingChannel) for generating flat-fading channel realizations, and other useful classes and functions in the context. \n\nNote: The exact usage may vary depending on your specific setup. Always consult the official documentation when in doubt."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the definition of Paths in Sionna, such as the default parameters, the link of the source code and explanation."}, {"role": "assistant", "content": "Here is the definition of CoverageMap: sionna.rt.Paths\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/rt/paths.html#Paths)  \n\nsource code:\n```python\n#\n# SPDX-FileCopyrightText: Copyright (c) 2021-2024 NVIDIA CORPORATION & AFFILIATES. All rights reserved.\n# SPDX-License-Identifier: Apache-2.0\n#\n\"\"\"\nDataclass that stores paths\n\"\"\"\n\nimport tensorflow as tf\nimport os\nimport numpy as np\n\nfrom . import scene as scene_module\nfrom sionna.utils.tensors import expand_to_rank, insert_dims\nfrom sionna.constants import PI\nfrom .utils import dot, r_hat\n\nclass Paths:\n    LOS = 0\n    SPECULAR = 1\n    DIFFRACTED = 2\n    SCATTERED = 3\n\n    def __init__(self,\n                 sources,\n                 targets,\n                 scene,\n                 types=None):\n\n        dtype = scene.dtype\n        num_sources = sources.shape[0]\n        num_targets = targets.shape[0]\n        rdtype = dtype.real_dtype\n\n        self._a = tf.zeros([num_targets, num_sources, 0], dtype)\n        self._tau = tf.zeros([num_targets, num_sources, 0], rdtype)\n        self._theta_t = tf.zeros([num_targets, num_sources, 0], rdtype)\n        self._theta_r = tf.zeros([num_targets, num_sources, 0], rdtype)\n        self._phi_t = tf.zeros([num_targets, num_sources, 0], rdtype)\n        self._phi_r = tf.zeros([num_targets, num_sources, 0], rdtype)\n        self._mask = tf.fill([num_targets, num_sources, 0], False)\n        self._targets_sources_mask = tf.fill([num_targets, num_sources, 0], False)\n        self._vertices = tf.zeros([0, num_targets, num_sources, 0, 3], rdtype)\n        self._objects = tf.fill([0, num_targets, num_sources, 0], -1)\n        self._doppler = tf.zeros([num_targets, num_sources, 0], rdtype)\n        if types is None:\n            self._types = tf.fill([0], -1)\n        else:\n            self._types = types\n\n        self._sources = sources\n        self._targets = targets\n        self._scene = scene\n\n        # Is the direction reversed?\n        self._reverse_direction = False\n        # Normalize paths delays?\n        self._normalize_delays = False\n\n    def to_dict(self):\n        members_names = dir(self)\n        members_objects = [getattr(self, attr) for attr in members_names]\n        data = {attr_name[1:] : attr_obj for (attr_obj, attr_name)\n                in zip(members_objects,members_names)\n                if not callable(attr_obj) and\n                   not isinstance(attr_obj, scene_module.Scene) and\n                   not attr_name.startswith(\"__\") and\n                   attr_name.startswith(\"_\")}\n        return data\n\n    def from_dict(self, data_dict):\n        for attr_name in data_dict:\n            attr_obj = data_dict[attr_name]\n            setattr(self, '_' + attr_name, attr_obj)\n\n    def export(self, filename):\n        vertices = self.vertices\n        objects = self.objects\n        sources = self.sources\n        targets = self.targets\n        mask = self.targets_sources_mask\n\n        # Content of the obj file\n        r = ''\n        offset = 0\n        for rx in range(vertices.shape[1]):\n            tgt = targets[rx].numpy()\n            for tx in range(vertices.shape[2]):\n                src = sources[tx].numpy()\n                for p in range(vertices.shape[3]):\n\n                    # If the path is masked, skip it\n                    if not mask[rx,tx,p]:\n                        continue\n\n                    # Add a comment to describe this path\n                    r += f'# Path {p} from tx {tx} to rx {rx}' + os.linesep\n                    # Vertices and intersected objects\n                    vs = vertices[:,rx,tx,p].numpy()\n                    objs = objects[:,rx,tx,p].numpy()\n\n                    depth = 0\n                    # First vertex is the source\n                    r += f\"v {src[0]:.8f} {src[1]:.8f} {src[2]:.8f}\"+os.linesep\n                    # Add intersection points\n                    for v,o in zip(vs,objs):\n                        # Skip if no intersection\n                        if o == -1:\n                            continue\n                        r += f\"v {v[0]:.8f} {v[1]:.8f} {v[2]:.8f}\" + os.linesep\n                        depth += 1\n                    r += f\"v {tgt[0]:.8f} {tgt[1]:.8f} {tgt[2]:.8f}\"+os.linesep\n\n                    # Add the connections\n                    for i in range(1, depth+2):\n                        v0 = i + offset\n                        v1 = i + offset + 1\n                        r += f\"l {v0} {v1}\" + os.linesep\n\n                    # Prepare for the next path\n                    r += os.linesep\n                    offset += depth+2\n\n        # Save the file\n        # pylint: disable=unspecified-encoding\n        with open(filename, 'w') as f:\n            f.write(r)\n\n    @property\n    def mask(self):\n        return self._mask\n\n    @mask.setter\n    def mask(self, v):\n        self._mask = v\n\n    @property\n    def a(self):\n        return self._a\n\n    @a.setter\n    def a(self, v):\n        self._a = v\n\n    @property\n    def tau(self):\n        return self._tau\n\n    @tau.setter\n    def tau(self, v):\n        self._tau = v\n\n    @property\n    def theta_t(self):\n        return self._theta_t\n\n    @theta_t.setter\n    def theta_t(self, v):\n        self._theta_t = v\n\n    @property\n    def phi_t(self):\n        return self._phi_t\n\n    @phi_t.setter\n    def phi_t(self, v):\n        self._phi_t = v\n\n    @property\n    def theta_r(self):\n        return self._theta_r\n\n    @theta_r.setter\n    def theta_r(self, v):\n        self._theta_r = v\n\n    @property\n    def phi_r(self):\n        return self._phi_r\n\n    @phi_r.setter\n    def phi_r(self, v):\n        self._phi_r = v\n\n    @property\n    def types(self):\n        return self._types\n\n    @types.setter\n    def types(self, v):\n        self._types = v\n\n    @property\n    def sources(self):\n        return self._sources\n\n    @sources.setter\n    def sources(self, v):\n        self._sources = v\n\n    @property\n    def targets(self):\n        return self._targets\n\n    @targets.setter\n    def targets(self, v):\n        self._targets = v\n\n    @property\n    def normalize_delays(self):\n        return self._normalize_delays\n\n    @normalize_delays.setter\n    def normalize_delays(self, v):\n        if v == self._normalize_delays:\n            return\n\n        if ~v and self._normalize_delays:\n            self.tau += self._min_tau\n        else:\n            self.tau -= self._min_tau\n        self.tau = tf.where(self.tau<0, tf.cast(-1, self.tau.dtype) , self.tau)\n        self._normalize_delays = v\n\n    @property\n    def doppler(self):\n        return self._doppler\n\n    @doppler.setter\n    def doppler(self, v):\n        self._doppler = v\n\n    def apply_doppler(self, sampling_frequency, num_time_steps,\n                      tx_velocities=(0.,0.,0.), rx_velocities=(0.,0.,0.)):\n\n        dtype = self._scene.dtype\n        rdtype = dtype.real_dtype\n        zeror = tf.zeros((), rdtype)\n        two_pi = tf.cast(2.*PI, rdtype)\n\n        tx_velocities = tf.cast(tx_velocities, rdtype)\n        tx_velocities = expand_to_rank(tx_velocities, 3, 0)\n        if tx_velocities.shape[2] != 3:\n            raise ValueError(\"Last dimension of `tx_velocities` must equal 3\")\n\n        if rx_velocities is None:\n            rx_velocities = [0.,0.,0.]\n        rx_velocities = tf.cast(rx_velocities, rdtype)\n        rx_velocities = expand_to_rank(rx_velocities, 3, 0)\n        if rx_velocities.shape[2] != 3:\n            raise ValueError(\"Last dimension of `rx_velocities` must equal 3\")\n\n        sampling_frequency = tf.cast(sampling_frequency, rdtype)\n        if sampling_frequency <= 0.0:\n            raise ValueError(\"The sampling frequency must be positive\")\n\n        num_time_steps = tf.cast(num_time_steps, tf.int32)\n        if num_time_steps <= 0:\n            msg = \"The number of time samples must a positive integer\"\n            raise ValueError(msg)\n\n        # Drop previous time step dimension, if any\n        if tf.rank(self.a) == 7:\n            self.a = self.a[...,0]\n\n        # [batch_size, num_rx, num_tx, max_num_paths, 3]\n        # or\n        # [batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths, 3]\n        k_t = r_hat(self.theta_t, self.phi_t)\n        k_r = r_hat(self.theta_r, self.phi_r)\n\n        if self._scene.synthetic_array:\n            # [batch_size, num_rx, 1, num_tx, 1, max_num_paths, 3]\n            k_t = tf.expand_dims(tf.expand_dims(k_t, axis=2), axis=4)\n            # [batch_size, num_rx, 1, num_tx, 1, max_num_paths, 3]\n            k_r = tf.expand_dims(tf.expand_dims(k_r, axis=2), axis=4)\n\n        # Expand rank of the speed vector for broadcasting with k_r\n        # [batch_dim, 1, 1, num_tx, 1, 1, 3]\n        tx_velocities = insert_dims(insert_dims(tx_velocities, 2,1), 2,4)\n        # [batch_dim, num_rx, 1, 1, 1, 1, 3]\n        rx_velocities = insert_dims(rx_velocities, 4, 2)\n\n        # Generate time steps\n        # [num_time_steps]\n        ts = tf.range(num_time_steps, dtype=rdtype)\n        ts = ts / sampling_frequency\n\n        # Compute the Doppler shift\n        # [batch_dim, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths]\n        # or\n        # [batch_dim, num_rx, 1, num_tx, 1, max_num_paths]\n        tx_ds = two_pi*dot(tx_velocities, k_t)/self._scene.wavelength\n        rx_ds = two_pi*dot(rx_velocities, k_r)/self._scene.wavelength\n        ds = tx_ds + rx_ds\n\n        # Add Doppler shifts due to movement of scene objects\n        if self._scene.synthetic_array:\n            # Create dummy dims for tx and rx antennas\n            # [batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths]\n            ds += two_pi*self.doppler[..., tf.newaxis, :, tf.newaxis, :]\n        else:\n            ds += two_pi*self.doppler\n\n        # Expand for the time sample dimension\n        # [batch_dim, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths, 1]\n        # or\n        # [batch_dim, num_rx, 1, num_tx, 1, max_num_paths, 1]\n        ds = tf.expand_dims(ds, axis=-1)\n        # Expand time steps for broadcasting\n        # [1, 1, 1, 1, 1, 1, num_time_steps]\n        ts = expand_to_rank(ts, tf.rank(ds), 0)\n        # [batch_dim, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths,\n        #   num_time_steps]\n        # or\n        # [batch_dim, num_rx, 1, num_tx, 1, max_num_paths, num_time_steps]\n        ds = ds*ts\n        exp_ds = tf.exp(tf.complex(zeror, ds))\n\n        # Apply Doppler shift\n        # Expand with time dimension\n        # [batch_dim, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths, 1]\n        a = tf.expand_dims(self.a, axis=-1)\n\n        # Manual broadcast last dimension\n        a = tf.repeat(a, exp_ds.shape[6], -1)\n\n        a = a*exp_ds\n\n        self.a = a\n\n    @property\n    def reverse_direction(self):\n        return self._reverse_direction\n\n    @reverse_direction.setter\n    def reverse_direction(self, v):\n\n        if v == self._reverse_direction:\n            return\n\n        if tf.rank(self.a) == 6:\n            self.a = tf.transpose(self.a, perm=[0,3,4,1,2,5])\n        else:\n            self.a = tf.transpose(self.a, perm=[0,3,4,1,2,5,6])\n\n        if self._scene.synthetic_array:\n            self.tau = tf.transpose(self.tau, perm=[0,2,1,3])\n            self._min_tau = tf.transpose(self._min_tau, perm=[0,2,1,3])\n            self.theta_t = tf.transpose(self.theta_t, perm=[0,2,1,3])\n            self.phi_t = tf.transpose(self.phi_t, perm=[0,2,1,3])\n            self.theta_r = tf.transpose(self.theta_r, perm=[0,2,1,3])\n            self.phi_r = tf.transpose(self.phi_r, perm=[0,2,1,3])\n            self.doppler = tf.transpose(self.doppler, perm=[0,2,1,3])\n        else:\n            self.tau = tf.transpose(self.tau, perm=[0,3,4,1,2,5])\n            self._min_tau = tf.transpose(self._min_tau, perm=[0,3,4,1,2,5])\n            self.theta_t = tf.transpose(self.theta_t, perm=[0,3,4,1,2,5])\n            self.phi_t = tf.transpose(self.phi_t, perm=[0,3,4,1,2,5])\n            self.theta_r = tf.transpose(self.theta_r, perm=[0,3,4,1,2,5])\n            self.phi_r = tf.transpose(self.phi_r, perm=[0,3,4,1,2,5])\n            self.doppler = tf.transpose(self.doppler, perm=[0,3,4,1,2,5])\n\n        self._reverse_direction = v\n\n    def cir(self,\n            los=True,\n            reflection=True,\n            diffraction=True,\n            scattering=True,\n            num_paths=None):\n        # Select only the desired effects\n        types = self.types[0]\n        # [max_num_paths]\n        selection_mask = tf.fill(tf.shape(types), False)\n        if los:\n            selection_mask = tf.logical_or(selection_mask,\n                                           types == Paths.LOS)\n        if reflection:\n            selection_mask = tf.logical_or(selection_mask,\n                                           types == Paths.SPECULAR)\n        if diffraction:\n            selection_mask = tf.logical_or(selection_mask,\n                                           types == Paths.DIFFRACTED)\n        if scattering:\n            selection_mask = tf.logical_or(selection_mask,\n                                           types == Paths.SCATTERED)\n\n        # Extract selected paths\n        # [batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths,\n        #   num_time_steps]\n        a = tf.gather(self.a, tf.where(selection_mask)[:,0], axis=-2)\n        # [batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths]\n        #   or [batch_size, num_rx, num_tx, max_num_paths]\n        tau = tf.gather(self.tau, tf.where(selection_mask)[:,0], axis=-1)\n\n        # Compute baseband CIR\n        # [batch_size, num_rx, 1/num_rx_ant, num_tx, 1/num_tx_ant,\n        #   max_num_paths, num_time_steps, 1]\n        if self._scene.synthetic_array:\n            tau_ = tf.expand_dims(tau, 2)\n            tau_ = tf.expand_dims(tau_, 4)\n        else:\n            tau_ = tau\n        tau_ = tf.expand_dims(tau_, -1)\n        phase = tf.complex(tf.zeros_like(tau_),\n                           -2*PI*self._scene.frequency*tau_)\n        # Manual repeat along the time step dimension as high-dimensional\n        # brodcast is not possible\n        phase = tf.repeat(phase, a.shape[-1], axis=-1)\n        a = a*tf.exp(phase)\n\n        if num_paths is not None:\n            a, tau = self.pad_or_crop(a, tau, num_paths)\n\n        return a,tau\n\n    #######################################################\n    # Internal methods and properties\n    #######################################################\n\n    @ property\n    def targets_sources_mask(self):\n        return self._targets_sources_mask\n\n    @ targets_sources_mask.setter\n    def targets_sources_mask(self, v):\n        self._targets_sources_mask = v\n\n    @property\n    def vertices(self):\n        return self._vertices\n\n    @vertices.setter\n    def vertices(self, v):\n        self._vertices = v\n\n    @property\n    def objects(self):\n        return self._objects\n\n    @objects.setter\n    def objects(self, v):\n        self._objects = v\n\n    def merge(self, more_paths):\n        dtype = self._scene.dtype\n\n        more_vertices = more_paths.vertices\n        more_objects = more_paths.objects\n        more_types = more_paths.types\n\n        # The paths to merge must have the same number of sources and targets\n        assert more_paths.targets.shape[0] == self.targets.shape[0],\\\n            \"Paths to merge must have same number of targets\"\n        assert more_paths.sources.shape[0] == self.sources.shape[0],\\\n            \"Paths to merge must have same number of targets\"\n\n        # Pad the paths with the lowest depth\n        padding = self.vertices.shape[0] - more_vertices.shape[0]\n        if padding > 0:\n            more_vertices = tf.pad(more_vertices,\n                                   [[0,padding],[0,0],[0,0],[0,0],[0,0]],\n                                   constant_values=tf.zeros((),\n                                                            dtype.real_dtype))\n            more_objects = tf.pad(more_objects,\n                                  [[0,padding],[0,0],[0,0],[0,0]],\n                                  constant_values=-1)\n        elif padding < 0:\n            padding = -padding\n            self.vertices = tf.pad(self.vertices,\n                                   [[0,padding],[0,0],[0,0],[0,0],[0,0]],\n                            constant_values=tf.zeros((), dtype.real_dtype))\n            self.objects = tf.pad(self.objects,\n                                  [[0,padding],[0,0],[0,0],[0,0]],\n                                  constant_values=-1)\n\n        # Merge types\n        if tf.rank(self.types) == 0:\n            merged_types = tf.repeat(self.types, tf.shape(self.vertices)[3])\n        else:\n            merged_types = self.types\n        if tf.rank(more_types) == 0:\n            more_types = tf.repeat(more_types, tf.shape(more_vertices)[3])\n\n        self.types = tf.concat([merged_types, more_types], axis=0)\n\n        # Concatenate all\n        self.a = tf.concat([self.a, more_paths.a], axis=2)\n        self.tau = tf.concat([self.tau, more_paths.tau], axis=2)\n        self.theta_t = tf.concat([self.theta_t, more_paths.theta_t], axis=2)\n        self.phi_t = tf.concat([self.phi_t, more_paths.phi_t], axis=2)\n        self.theta_r = tf.concat([self.theta_r, more_paths.theta_r], axis=2)\n        self.phi_r = tf.concat([self.phi_r, more_paths.phi_r], axis=2)\n        self.mask = tf.concat([self.mask, more_paths.mask], axis=2)\n        self.vertices = tf.concat([self.vertices, more_vertices], axis=3)\n        self.objects = tf.concat([self.objects, more_objects], axis=3)\n        self.doppler = tf.concat([self.doppler, more_paths.doppler], axis=2)\n\n        return self\n\n    def finalize(self):\n        self.set_los_path_type()\n\n        # Add dummy-dimension for batch_size\n        # [1, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths]\n        self.mask = tf.expand_dims(self.mask, axis=0)\n        # [1, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths]\n        self.a = tf.expand_dims(self.a, axis=0)\n        # [1, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths]\n        self.tau = tf.expand_dims(self.tau, axis=0)\n        # [1, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths]\n        self.theta_t = tf.expand_dims(self.theta_t, axis=0)\n        # [1, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths]\n        self.phi_t = tf.expand_dims(self.phi_t, axis=0)\n        # [1, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths]\n        self.theta_r = tf.expand_dims(self.theta_r, axis=0)\n        # [1, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths]\n        self.phi_r = tf.expand_dims(self.phi_r, axis=0)\n        # [1, max_num_paths]\n        self.types = tf.expand_dims(self.types, axis=0)\n        # [1, max_num_paths]\n        self.doppler = tf.expand_dims(self.doppler, axis=0)\n\n        tau = self.tau\n        if tau.shape[-1] == 0: # No paths\n            self._min_tau = tf.zeros_like(tau)\n        else:\n            zero = tf.zeros((), tau.dtype)\n            inf = tf.cast(np.inf, tau.dtype)\n            tau = tf.where(tau < zero, inf, tau)\n            if self._scene.synthetic_array:\n                # [1, num_rx, num_tx, 1]\n                min_tau = tf.reduce_min(tau, axis=3, keepdims=True)\n            else:\n                # [1, num_rx, 1, num_tx, 1, 1]\n                min_tau = tf.reduce_min(tau, axis=(2, 4, 5), keepdims=True)\n            min_tau = tf.where(tf.math.is_inf(min_tau), zero, min_tau)\n            self._min_tau = min_tau\n\n        # Add the time steps dimension\n        # [1, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths, 1]\n        self.a = tf.expand_dims(self.a, axis=-1)\n\n        # Normalize delays\n        self.normalize_delays = True\n\n    def set_los_path_type(self):\n\n        # [max_depth, num_targets, num_sources, num_paths]\n        objects = self.objects\n        # [num_targets, num_sources, num_paths]\n        mask = self.targets_sources_mask\n\n        if objects.shape[3] > 0:\n            # [num_targets, num_sources, num_paths]\n            los_path = tf.reduce_all(objects == -1, axis=0)\n            # [num_targets, num_sources, num_paths]\n            los_path = tf.logical_and(los_path, mask)\n            # [num_paths]\n            los_path = tf.reduce_any(los_path, axis=(0,1))\n            # [[1]]\n            los_path_index = tf.where(los_path)\n            updates = tf.repeat(Paths.LOS, tf.shape(los_path_index)[0], 0)\n            self.types = tf.tensor_scatter_nd_update(self.types,\n                                                        los_path_index,\n                                                        updates)\n\n    def pad_or_crop(self, a, tau, k):\n        max_num_paths = a.shape[-2]\n\n        # Crop\n        if k<max_num_paths:\n            # Compute indices of the k strongest paths\n            # As is independent of the number of time steps,\n            # Therefore, we use only the first one a[...,0].\n            # ind : [batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, k]\n            _, ind = tf.math.top_k(tf.abs(a[...,0]), k=k, sorted=True)\n\n            # Gather the strongest paths\n            # [batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, k, num_time_steps]\n            a = tf.gather(a, ind, batch_dims=5)\n\n            # Gather the corresponding path delays\n            # Synthetic array\n            if tf.rank(tau)==4:\n                # tau : [batch_size, num_rx, num_tx, max_num_paths]\n\n                # Get relevant indices\n                # [batch_size, num_rx, num_tx, k]\n                ind_tau = ind[:,:,0,:,0]\n\n                # [batch_size, num_rx, num_tx, k]\n                tau = tf.gather(tau, ind_tau, batch_dims=3)\n\n            # Non-synthetic array\n            else:\n                # tau: [batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, max_num_paths]\n\n                # [batch_size, num_rx, num_rx_ant, num_tx, num_tx_ant, k]\n                tau = tf.gather(tau, ind, batch_dims=5)\n\n        # Pad\n        elif k>max_num_paths:\n            # Pad paths with zeros\n            pad_size = k-max_num_paths\n\n            # Paddings for the paths gains\n            paddings = tf.constant([[0, 0] if i != 5 else [0, pad_size] for i in range(7)])\n            a = tf.pad(a, paddings=paddings, mode='CONSTANT', constant_values=0)\n\n            # Paddings for the delays (-1 by Sionna convention)\n            paddings = tf.constant([[0, 0] if i != tf.rank(tau)-1 else [0, pad_size] for i in range(tf.rank(tau))])\n            tau = tf.pad(tau, paddings=paddings, mode='CONSTANT', constant_values=-1)\n\n        return a, tau\n```"}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Detail the working and usage of the `add()` method in the Scene class in Sionna package."}, {"role": "assistant", "content": "The `add()` method in the Scene class of the Sionna package is used to add components to a scene. It may add objects such as transmitters (`Transmitter`), receivers (`Receiver`), radio materials (`RadioMaterial`), or cameras (`Camera`).\n\nHere's how you would use it in code:\n\n```python\n# Create a transmitter\ntx = Transmitter(name=\"tx\", position=[8.5,21,27], orientation=[0,0,0])\n\n# Add the transmitter to the scene\nscene.add(tx)\n```\n\nThis method takes as an input parameter an item. The item can be an instance of `Transmitter`, `Receiver`, `RadioMaterial`, or `Camera`. It adds that item to the scene. If an item with the same name as the new item is already part of the scene, an error is raised.\n\nThe `add()` function plays a significant role in setting up a scene for radio propagation simulations or 3D rendering, as it allows users to place transmitters, receivers, radio materials, and cameras within the scene.\n\nNote: Ensure the item's name you want to add does not previously exist in the scene, otherwise, an error will occur. The names for items in the scene should be unique."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain the conditions that will trigger the AssertionError and InvalidArgumentError exceptions when using the CRCDecoder class function."}, {"role": "assistant", "content": "The CRCDecoder class function in Python's Sionna library might raise AssertionError and InvalidArgumentError exceptions under certain conditions. \n\n1. AssertionError: It can be triggered if the `crc_encoder` parameter passed into the CRCDecoder function is not an instance of the `CRCEncoder`. This seems to be meant to ensure that the decoder function is associated with a specific encoder for accurate decoding purposes.\n\n2. InvalidArgumentError: It can occur when the rank of the tensor passed to the `inputs` parameter for the CRCDecoder function is less than 2. The rank of a tensor in this context represents the number of dimensions. This requirement appears to be necessary for the tensor operations within the function to work properly.\n\nThis information about exceptions is based on the context provided and more specific conditions may exist based on the detailed implementation of the CRCDecoder function, which is not fully visible within the given context. This information should be confirmed by looking at the specific implementation details of the CRCDecoder function in the source code."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Discuss the property \"interleaver\" of the Deinterleaver class."}, {"role": "assistant", "content": "The \"interleaver\" property in the Deinterleaver class in Sionna is the associated interleaver instance that the Deinterleaver class reverses or deinterleaves. This property can be either an instance of the `RandomInterleaver` or the `RowColumnInterleaver` class.\n\nThe `Deinterleaver` class in Sionna provides a wrapper of the inverse function of the corresponding interleaver, which is defined by the \"interleaver\" property. This property plays a key role in the functioning of `Deinterleaver` as it's required to undo the specific interleaving logic implemented by the associated `interleaver` instance. The deinterleaving is implemented such that it reconstructs the original order of the data that was permuted by the associated interleaver. This is helpful in cases where the data sequence is expected to be returned to its original order after specific operations or transmissions.\n\nRemember that the associated interleaver must be a valid instance of the Interleaver class, or else it raises an AssertionError. Accessing the \"interleaver\" property simply returns this associated interleaver instance."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the details of class MFEqualizer, such as the parameters of the class, the input and output of the class instance and the link of source code."}, {"role": "assistant", "content": "Here is the detailed information of MFEqualizer:   \n  \n[sionna.ofdm.MFEqualizer(resource_grid, stream_management, dtype=tf.complex64, **kwargs)](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/equalization.html#MFEqualizer)  \n\nMF equalization for OFDM MIMO transmissions.\n\nThis layer computes matched filter (MF) equalization for OFDM MIMO transmissions. The OFDM and stream configuration are provided by a ResourceGrid and StreamManagement instance, respectively. The detection algorithm is the mf_equalizer(). The layer computes soft-symbol estimates together with effective noise variances for all streams which can, e.g., be used by a Demapper to obtain LLRs.\n\n**Parameters**\n\n- `resource_grid` (ResourceGrid): An instance of ResourceGrid.\n- `stream_management` (StreamManagement): An instance of StreamManagement.\n- `dtype` (tf.Dtype): Datatype for internal calculations and the output dtype. Defaults to tf.complex64.\n\n**Input**\n\n- `(y, h_hat, err_var, no)` \u2013 Tuple:\n  - `y` ([batch_size, num_rx, num_rx_ant, num_ofdm_symbols, fft_size], tf.complex): Received OFDM resource grid after cyclic prefix removal and FFT.\n  - `h_hat` ([batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, num_effective_subcarriers], tf.complex): Channel estimates for all streams from all transmitters.\n  - `err_var` ([Broadcastable to shape of h_hat], tf.float): Variance of the channel estimation error.\n  - `no` ([batch_size, num_rx, num_rx_ant] or only the first n dimensions, tf.float): Variance of the AWGN.\n\n**Output**\n\n- `x_hat` ([batch_size, num_tx, num_streams, num_data_symbols], tf.complex): Estimated symbols.\n- `no_eff` ([batch_size, num_tx, num_streams, num_data_symbols], tf.float): Effective noise variance for each estimated symbol.\n\n**Note:** If you want to use this layer in Graph mode with XLA, i.e., within a function that is decorated with @tf.function(jit_compile=True), you must set sionna.Config.xla_compat=true. See xla_compat."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the definition of DirectivePattern in Sionna, such as the default parameters, the link of the source code and explanation."}, {"role": "assistant", "content": "Here is the definition of DirectivePattern: sionna.rt.DirectivePattern(alpha_r, dtype=tf.complex64)\n  \n[source code](https://nvlabs.github.io/sionna/_modules/sionna/rt/scattering_pattern.html#DirectivePattern)\n\n```python\nclass DirectivePattern(ScatteringPattern):\n    # pylint: disable=line-too-long\n    r\"\"\"\n    Directive scattering model from [Degli-Esposti07]_ as given in :eq:`directive_model`\n\n    Parameters\n    ----------\n    alpha_r : int, [1,2,...]\n        Parameter related to the width of the scattering lobe in the\n        direction of the specular reflection.\n\n    dtype : tf.complex64 or tf.complex128\n        Datatype used for all computations.\n        Defaults to `tf.complex64`.\n\n    Input\n    -----\n    k_i : [batch_size, 3], dtype.real_dtype\n        Incoming directions\n\n    k_s : [batch_size,3], dtype.real_dtype\n        Outgoing directions\n\n    Output\n    ------\n    pattern : [batch_size], dtype.real_dtype\n        Scattering pattern\n\n    Example\n    -------\n    >>> DirectivePattern(alpha_r=10).visualize()\n\n    .. figure:: ../figures/directive_pattern_3d.png\n        :align: center\n\n    .. figure:: ../figures/directive_pattern_cut.png\n        :align: center\n    \"\"\"\n    def __init__(self,\n                 alpha_r,\n                 dtype=tf.complex64):\n        super().__init__(alpha_r=alpha_r, alpha_i=1, lambda_=1, dtype=dtype)\n```"}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Define the scalar value and tensor broadcastability in relation to the channel reliability parameter."}, {"role": "assistant", "content": "In the context provided, the scalar value and tensor broadcastability are discussed in relation to the channel reliability parameter in a discrete channel model. \n\nThe channel reliability parameter, denoted by $p_b$, can be either a scalar value or a tensor of any shape that can be broadcasted to match the input shape. Scalar values are single numerical values, whereas tensors can be multi-dimensional arrays of numerical values. \n\nBroadcasting is a process in tensor operations that enables tensors with different shapes to be used in operations by 'expanding' the smaller tensor across the larger one. \n\nIn relation to the channel reliability parameter, this scalar or tensor defines the error or bit flipping probability across the channel. By allowing $p_b$ to be a tensor that can be broadcasted to the input, different error probabilities can be efficiently implemented for channels with non-uniform error probabilities. This means that the error or bit flipping probability can vary across different positions of the channel.\n\nIn the code example given within the context,\n```python\npb = 0.1 # pb is the bit flipping probability\n```\nHere, `pb` is a scalar value defining the bit flipping probability. The value can also be a tensor that matches the shape of the channel input for a differential bit flipping probability."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the details of class NearestNeighborInterpolator, such as the parameters of the class, the input and output of the class instance and the link of source code."}, {"role": "assistant", "content": "Here is the detailed information of NearestNeighborInterpolator:   \n  \n[sionna.ofdm.NearestNeighborInterpolator(pilot_pattern)](https://nvlabs.github.io/sionna/_modules/sionna/ofdm/channel_estimation.html#NearestNeighborInterpolator)\n\nNearest-neighbor channel estimate interpolation on a resource grid.\n\nThis class assigns to each element of an OFDM resource grid one of num_pilots provided channel estimates and error variances according to the nearest neighbor method. It is assumed that the measurements were taken at the nonzero positions of a PilotPattern.\n\nThe figure below shows how four channel estimates are interpolated accross a resource grid. Grey fields indicate measurement positions while the colored regions show which resource elements are assigned to the same measurement value.\n\n[Example](https://nvlabs.github.io/sionna/_images/nearest_neighbor_interpolation.png)\n\n**Parameters**\n\n- `pilot_pattern` (PilotPattern): An instance of PilotPattern.\n\n**Input**\n\n- `h_hat` ([batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_pilot_symbols], tf.complex): Channel estimates for the pilot-carrying resource elements.\n- `err_var` ([batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_pilot_symbols], tf.complex): Channel estimation error variances for the pilot-carrying resource elements.\n\n**Output**\n\n- `h_hat` ([batch_size, num_rx, num_rx_ant, num_tx, num_streams_per_tx, num_ofdm_symbols, fft_size], tf.complex): Channel estimates across the entire resource grid for all transmitters and streams.\n- `err_var` (Same shape as h_hat, tf.float): Channel estimation error variances across the entire resource grid for all transmitters and streams."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain the different example codes provided in the context."}, {"role": "assistant", "content": "The context provided offers multiple code snippets demonstrating usage of various utilities in the `sionna` wireless channel model library. \n\n1. A Rayleigh block fading channel model with an orthogonal frequency-division multiplexing (OFDM) waveform is set up. An instance of `RayleighBlockFading` is created with appropriate parameters and then an OFDM Channel is constructed with the previously created Rayleigh model and a resource grid.\n\n```python\nfrom sionna.channel import RayleighBlockFading\nfrom sionna.channel import OFDMChannel\n\nrayleigh = RayleighBlockFading(num_rx = 1,\n                               num_rx_ant = 32,\n                               num_tx = 4,\n                               num_tx_ant = 2)\nchannel  = OFDMChannel(channel_model = rayleigh,\n                       resource_grid = rg) # rg \n```\nIn this code, a channel input `x` and a noise variance `no` are defined. The channel model is then run on `x` and `no` to get output `y`.\n\n```python\n# x is the channel input\n# no is the noise variance\ny = channel((x, no))\n```\n\n2. The code shows how to setup and run a Rayleigh block fading channel model using `GenerateOFDMChannel` and `ApplyOFDMChannel` classes. \n\n```python\nfrom sionna.channel import RayleighBlockFading\nfrom sionna.channel import GenerateOFDMChannel\nfrom sionna.channel import ApplyOFDMChannel \n\nrayleigh = RayleighBlockFading(num_rx = 1,\n                               num_rx_ant = 32,\n                               num_tx = 4,\n                               num_tx_ant = 2)\ngenerate_channel = GenerateOFDMChannel(channel_model = rayleigh,\n                                       resource_grid = rg)\napply_channel = ApplyOFDMChannel()\n```\n\nParallel to the code above, the channel model is run to produce a batch of channel responses `h` and the channel responses are applied to the channel input `x` to obtain the output `y`.\n\n```python\n# Generate a batch of channel responses\nh = generate_channel(batch_size)\n# Apply the channel\n# x is the channel input\n# no is the noise variance\ny = apply_channel((x, h, no))\n```\n\n3. The third code snippet shows how to access the Channel Impulse Responses (CIRs) through the `ApplyOFDMChannel` utility.\n\n```python\nrayleigh = RayleighBlockFading(num_rx = 1,\n                               num_rx_ant = 32,\n                               num_tx = 4,\n                               num_tx_ant = 2)\napply_channel = ApplyOFDMChannel()\n```\n\nThe channel model `rayleigh` is run to get CIRs `cir`, and then the OFDM channel for subcarrier frequencies is computed. Finally, the channel output `y` is computed by applying the generated channel to `x`.\n\n```python\ncir = rayleigh(batch_size)\nh = cir_to_ofdm_channel(frequencies, *cir)\ny = apply_channel([x, h, no])\n```\n\n4. The AWGN channel model is described, showing how to define and run it.\n\n```python\n>>> from sionna.channel import AWGN\n>>> awgn_channel = AWGN()\n```\nThis code instantiates `awgn_channel`. To run it:\n\n```python\n>>> # x is the channel input\n>>> # no is the noise variance\n>>> y = awgn_channel((x, no))\n```\nThese examples demonstrate different ways to set up and apply various channel models provided by the Sionna library."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the details of function sionna.utils.sim_ber in Sionna, such as the input and output of the class instance, the link of source code and source itself."}, {"role": "assistant", "content": "Here is the detailed information of sionna.utils.sim_ber:   \n\n[sionna.utils.sim_ber(mc_fun, ebno_dbs, batch_size, max_mc_iter, soft_estimates=False, num_target_bit_errors=None, num_target_block_errors=None, target_ber=None, target_bler=None, early_stop=True, graph_mode=None, distribute=None, verbose=True, forward_keyboard_interrupt=True, callback=None, dtype=tf.complex64)](https://nvlabs.github.io/sionna/_modules/sionna/utils/misc.html#sim_ber)\n\nSimulates BER/BLER curves until a target number of errors is reached, and returns BER/BLER. The simulation continues with the next SNR point if either `num_target_bit_errors` bit errors or `num_target_block_errors` block errors are achieved.\n\n### Input\n\n- **mc_fun** (callable): Callable that yields the transmitted bits `b` and the receiver\u2019s estimate `b_hat` for a given `batch_size` and `ebno_db`. If `soft_estimates` is True, `b_hat` is interpreted as logit.\n- **ebno_dbs** (tf.float32): A tensor containing SNR points to be evaluated.\n- **batch_size** (tf.int32): Batch size for evaluation.\n- **max_mc_iter** (tf.int32): Maximum number of Monte-Carlo iterations per SNR point.\n- **soft_estimates** (bool): If True, `b_hat` is interpreted as logit and additional hard-decision is applied internally. Defaults to False.\n- **num_target_bit_errors** (tf.int32): Target number of bit errors per SNR point until the simulation continues to the next SNR point. Defaults to None.\n- **num_target_block_errors** (tf.int32): Target number of block errors per SNR point until the simulation continues. Defaults to None.\n- **target_ber** (tf.float32): Simulation stops after the first SNR point which achieves a lower BER than specified. Requires `early_stop` to be True. Defaults to None.\n- **target_bler** (tf.float32): Simulation stops after the first SNR point which achieves a lower BLER than specified. Requires `early_stop` to be True. Defaults to None.\n- **early_stop** (bool): If True, stops the simulation after the first error-free SNR point. Defaults to True.\n- **graph_mode** (One of [\"graph\", \"xla\"], str): Execution mode of `mc_fun`. Defaults to None.\n- **distribute**: (None (default) | \u201call\u201d | list of indices | tf.distribute.strategy) \u2013 Distributes simulation on multiple parallel devices. If None, multi-device simulations are deactivated. If \u201call\u201d, the workload will be automatically distributed across all available GPUs via the tf.distribute.MirroredStrategy. If an explicit list of indices is provided, only the GPUs with the given indices will be used. Alternatively, a custom tf.distribute.strategy can be provided. Note that the same batch_size will be used for all GPUs in parallel, but the number of Monte-Carlo iterations max_mc_iter will be scaled by the number of devices such that the same number of total samples is simulated. However, all stopping conditions are still in-place which can cause slight differences in the total number of simulated samples.\n- **verbose** (bool): A boolean defaults to True. If True, the current progress will be printed.\n- **forward_keyboard_interrupt** (bool): A boolean defaults to True. If False, KeyboardInterrupts will be catched internally and not forwarded (e.g., will not stop outer loops). If False, the simulation ends and returns the intermediate simulation results.\n- **callback** (callable): (None (default) | callable) \u2013 If specified, callback will be called after each Monte-Carlo step. Can be used for logging or advanced early stopping. Input signature of callback must match callback(mc_iter, snr_idx, ebno_dbs, bit_errors, block_errors, nb_bits, nb_blocks) where mc_iter denotes the number of processed batches for the current SNR point, snr_idx is the index of the current SNR point, ebno_dbs is the vector of all SNR points to be evaluated, bit_errors the vector of number of bit errors for each SNR point, block_errors the vector of number of block errors, nb_bits the vector of number of simulated bits, nb_blocks the vector of number of simulated blocks, respectively. If callable returns sim_ber.CALLBACK_NEXT_SNR, early stopping is detected and the simulation will continue with the next SNR point. If callable returns sim_ber.CALLBACK_STOP, the simulation is stopped immediately. For sim_ber.CALLBACK_CONTINUE continues with the simulation.\n- **dtype** (tf.complex64): Datatype of the callable mc_fun to be used as input/output.\n\n### Output\n\n- **(ber, bler)**: Tuple containing:\n  - **ber** (tf.float32): The bit-error rate.\n  - **bler** (tf.float32): The block-error rate.\n\n### Raises\n\n- **AssertionError**: If `soft_estimates` is not a boolean.\n- **AssertionError**: If `dtype` is not tf.complex.\n\n**Note:**This function is implemented based on tensors to allow full compatibility with tf.function(). However, to run simulations in graph mode, the provided mc_fun must use the @tf.function() decorator.\n\nsource code:\n```python\ndef sim_ber(mc_fun,\n            ebno_dbs,\n            batch_size,\n            max_mc_iter,\n            soft_estimates=False,\n            num_target_bit_errors=None,\n            num_target_block_errors=None,\n            target_ber=None,\n            target_bler=None,\n            early_stop=True,\n            graph_mode=None,\n            distribute=None,\n            verbose=True,\n            forward_keyboard_interrupt=True,\n            callback=None,\n            dtype=tf.complex64):\n    # pylint: disable=line-too-long\n    # utility function to print progress\n    def _print_progress(is_final, rt, idx_snr, idx_it, header_text=None):\n        \"\"\"Print summary of current simulation progress.\n\n        Input\n        -----\n        is_final: bool\n            A boolean. If True, the progress is printed into a new line.\n        rt: float\n            The runtime of the current SNR point in seconds.\n        idx_snr: int\n            Index of current SNR point.\n        idx_it: int\n            Current iteration index.\n        header_text: list of str\n            Elements will be printed instead of current progress, iff not None.\n            Can be used to generate table header.\n        \"\"\"\n        # set carriage return if not final step\n        if is_final:\n            end_str = \"\\n\"\n        else:\n            end_str = \"\\r\"\n\n        # prepare to print table header\n        if header_text is not None:\n            row_text = header_text\n            end_str = \"\\n\"\n        else:\n            # calculate intermediate ber / bler\n            ber_np = (tf.cast(bit_errors[idx_snr], tf.float64)\n                        / tf.cast(nb_bits[idx_snr], tf.float64)).numpy()\n            ber_np = np.nan_to_num(ber_np) # avoid nan for first point\n            bler_np = (tf.cast(block_errors[idx_snr], tf.float64)\n                        / tf.cast(nb_blocks[idx_snr], tf.float64)).numpy()\n            bler_np = np.nan_to_num(bler_np) # avoid nan for first point\n\n            # load statuslevel\n            # print current iter if simulation is still running\n            if status[idx_snr]==0:\n                status_txt = f\"iter: {idx_it:.0f}/{max_mc_iter:.0f}\"\n            else:\n                status_txt = status_levels[int(status[idx_snr])]\n\n            # generate list with all elements to be printed\n            row_text = [str(np.round(ebno_dbs[idx_snr].numpy(), 3)),\n                        f\"{ber_np:.4e}\",\n                        f\"{bler_np:.4e}\",\n                        np.round(bit_errors[idx_snr].numpy(), 0),\n                        np.round(nb_bits[idx_snr].numpy(), 0),\n                        np.round(block_errors[idx_snr].numpy(), 0),\n                        np.round(nb_blocks[idx_snr].numpy(), 0),\n                        np.round(rt, 1),\n                        status_txt]\n\n        # pylint: disable=line-too-long, consider-using-f-string\n        print(\"{: >9} |{: >11} |{: >11} |{: >12} |{: >12} |{: >13} |{: >12} |{: >12} |{: >10}\".format(*row_text), end=end_str)\n\n    # distributed execution should not be done in Eager mode\n    # XLA mode seems to have difficulties with TF2.13\n    @tf.function(jit_compile=False)\n    def _run_distributed(strategy, mc_fun, batch_size, ebno_db):\n        # use tf.distribute to execute on parallel devices (=replicas)\n        outputs_rep = strategy.run(mc_fun,\n                                   args=(batch_size, ebno_db))\n        # copy replicas back to single device\n        b = strategy.gather(outputs_rep[0], axis=0)\n        b_hat = strategy.gather(outputs_rep[1], axis=0)\n        return b, b_hat\n\n     # init table headers\n    header_text = [\"EbNo [dB]\", \"BER\", \"BLER\", \"bit errors\",\n                   \"num bits\", \"block errors\", \"num blocks\",\n                   \"runtime [s]\", \"status\"]\n\n    # replace status by text\n    status_levels = [\"not simulated\", # status=0\n            \"reached max iter       \", # status=1; spacing for impr. layout\n            \"no errors - early stop\", # status=2\n            \"reached target bit errors\", # status=3\n            \"reached target block errors\", # status=4\n            \"reached target BER - early stop\", # status=5\n            \"reached target BLER - early stop\", # status=6\n            \"callback triggered stopping\"] # status=7\n\n\n    # check inputs for consistency\n    assert isinstance(early_stop, bool), \"early_stop must be bool.\"\n    assert isinstance(soft_estimates, bool), \"soft_estimates must be bool.\"\n    assert dtype.is_complex, \"dtype must be a complex type.\"\n    assert isinstance(verbose, bool), \"verbose must be bool.\"\n\n    # target_ber / target_bler only works if early stop is activated\n    if target_ber is not None:\n        if not early_stop:\n            print(\"Warning: early stop is deactivated. Thus, target_ber \" \\\n                  \"is ignored.\")\n    else:\n        target_ber = -1. # deactivate early stopping condition\n    if target_bler is not None:\n        if not early_stop:\n            print(\"Warning: early stop is deactivated. Thus, target_bler \" \\\n                  \"is ignored.\")\n    else:\n        target_bler = -1. # deactivate early stopping condition\n\n    if graph_mode is None:\n        graph_mode=\"default\" # applies default graph mode\n    assert isinstance(graph_mode, str), \"graph_mode must be str.\"\n\n    if graph_mode==\"default\":\n        pass # nothing to do\n    elif graph_mode==\"graph\":\n        # avoid retracing -> check if mc_fun is already a function\n        if not isinstance(mc_fun, tf.types.experimental.GenericFunction):\n            mc_fun = tf.function(mc_fun,\n                                 jit_compile=False,\n                                 experimental_follow_type_hints=True)\n    elif graph_mode==\"xla\":\n        # avoid retracing -> check if mc_fun is already a function\n        if not isinstance(mc_fun, tf.types.experimental.GenericFunction) or \\\n           not mc_fun.function_spec.jit_compile:\n            mc_fun = tf.function(mc_fun,\n                                 jit_compile=True,\n                                 experimental_follow_type_hints=True)\n    else:\n        raise TypeError(\"Unknown graph_mode selected.\")\n\n    # support multi-device simulations by using the tf.distribute package\n    if distribute is None: # disabled per default\n        run_multigpu = False\n    # use strategy if explicitly provided\n    elif isinstance(distribute, tf.distribute.Strategy):\n        run_multigpu = True\n        strategy = distribute # distribute is already a tf.distribute.strategy\n    else:\n        run_multigpu = True\n        # use all available gpus\n        if distribute==\"all\":\n            gpus = tf.config.list_logical_devices('GPU')\n        # mask active GPUs if indices are provided\n        elif isinstance(distribute, (tuple, list)):\n            gpus_avail = tf.config.list_logical_devices('GPU')\n            gpus = [gpus_avail[i] for i in distribute if i < len(gpus_avail)]\n        else:\n            raise ValueError(\"Unknown value for distribute.\")\n\n        # deactivate logging of tf.device placement\n        if verbose:\n            print(\"Setting tf.debugging.set_log_device_placement to False.\")\n        tf.debugging.set_log_device_placement(False)\n        # we reduce to the first device by default\n        strategy = tf.distribute.MirroredStrategy(gpus,\n                            cross_device_ops=tf.distribute.ReductionToOneDevice(\n                                                reduce_to_device=gpus[0].name))\n\n    # reduce max_mc_iter if multi_gpu simulations are activated\n    if run_multigpu:\n        num_replicas = strategy.num_replicas_in_sync\n        max_mc_iter = int(np.ceil(max_mc_iter/num_replicas))\n        print(f\"Distributing simulation across {num_replicas} devices.\")\n        print(f\"Reducing max_mc_iter to {max_mc_iter}\")\n\n    ebno_dbs = tf.cast(ebno_dbs, dtype.real_dtype)\n    batch_size = tf.cast(batch_size, tf.int32)\n    num_points = tf.shape(ebno_dbs)[0]\n    bit_errors = tf.Variable(   tf.zeros([num_points], dtype=tf.int64),\n                                dtype=tf.int64)\n    block_errors = tf.Variable( tf.zeros([num_points], dtype=tf.int64),\n                                dtype=tf.int64)\n    nb_bits = tf.Variable(  tf.zeros([num_points], dtype=tf.int64),\n                            dtype=tf.int64)\n    nb_blocks = tf.Variable(tf.zeros([num_points], dtype=tf.int64),\n                            dtype=tf.int64)\n\n    # track status of simulation (early termination etc.)\n    status = np.zeros(num_points)\n\n    # measure runtime per SNR point\n    runtime = np.zeros(num_points)\n\n    # ensure num_target_errors is a tensor\n    if num_target_bit_errors is not None:\n        num_target_bit_errors = tf.cast(num_target_bit_errors, tf.int64)\n    if num_target_block_errors is not None:\n        num_target_block_errors = tf.cast(num_target_block_errors, tf.int64)\n\n    try:\n        # simulate until a target number of errors is reached\n        for i in tf.range(num_points):\n            runtime[i] = time.perf_counter() # save start time\n            iter_count = -1 # for print in verbose mode\n            for ii in tf.range(max_mc_iter):\n\n                iter_count += 1\n\n                if run_multigpu: # distributed execution\n                    b, b_hat = _run_distributed(strategy,\n                                                mc_fun,\n                                                batch_size,\n                                                ebno_dbs[i])\n                else:\n                    outputs = mc_fun(batch_size=batch_size, ebno_db=ebno_dbs[i])\n                    # assume first and second return value is b and b_hat\n                    # other returns are ignored\n                    b = outputs[0]\n                    b_hat = outputs[1]\n\n                if soft_estimates:\n                    b_hat = hard_decisions(b_hat)\n\n                # count errors\n                bit_e = count_errors(b, b_hat)\n                block_e = count_block_errors(b, b_hat)\n\n                # count total number of bits\n                bit_n = tf.size(b)\n                block_n = tf.size(b[...,-1])\n\n                # update variables\n                bit_errors = tf.tensor_scatter_nd_add(  bit_errors, [[i]],\n                                                    tf.cast([bit_e], tf.int64))\n                block_errors = tf.tensor_scatter_nd_add(  block_errors, [[i]],\n                                                tf.cast([block_e], tf.int64))\n                nb_bits = tf.tensor_scatter_nd_add( nb_bits, [[i]],\n                                                    tf.cast([bit_n], tf.int64))\n                nb_blocks = tf.tensor_scatter_nd_add( nb_blocks, [[i]],\n                                                tf.cast([block_n], tf.int64))\n\n                cb_state = sim_ber.CALLBACK_CONTINUE\n                if callback is not None:\n                    cb_state = callback (ii, i, ebno_dbs, bit_errors,\n                                       block_errors, nb_bits,\n                                       nb_blocks)\n                    if cb_state in (sim_ber.CALLBACK_STOP,\n                                    sim_ber.CALLBACK_NEXT_SNR):\n                        # stop runtime timer\n                        runtime[i] = time.perf_counter() - runtime[i]\n                        status[i] = 7 # change internal status for summary\n                        break # stop for this SNR point have been simulated\n\n                # print progress summary\n                if verbose:\n                    # print summary header during first iteration\n                    if i==0 and iter_count==0:\n                        _print_progress(is_final=True,\n                                        rt=0,\n                                        idx_snr=0,\n                                        idx_it=0,\n                                        header_text=header_text)\n                        # print seperator after headline\n                        print('-' * 135)\n\n                    # evaluate current runtime\n                    rt = time.perf_counter() - runtime[i]\n                    # print current progress\n                    _print_progress(is_final=False, idx_snr=i, idx_it=ii, rt=rt)\n\n                # bit-error based stopping cond.\n                if num_target_bit_errors is not None:\n                    if tf.greater_equal(bit_errors[i], num_target_bit_errors):\n                        status[i] = 3 # change internal status for summary\n                        # stop runtime timer\n                        runtime[i] = time.perf_counter() - runtime[i]\n                        break # enough errors for SNR point have been simulated\n\n                # block-error based stopping cond.\n                if num_target_block_errors is not None:\n                    if tf.greater_equal(block_errors[i],\n                                        num_target_block_errors):\n                        # stop runtime timer\n                        runtime[i] = time.perf_counter() - runtime[i]\n                        status[i] = 4 # change internal status for summary\n                        break # enough errors for SNR point have been simulated\n\n                # max iter have been reached -> continue with next SNR point\n                if iter_count==max_mc_iter-1: # all iterations are done\n                    # stop runtime timer\n                    runtime[i] = time.perf_counter() - runtime[i]\n                    status[i] = 1 # change internal status for summary\n\n            # print results again AFTER last iteration / early stop (new status)\n            if verbose:\n                _print_progress(is_final=True,\n                                idx_snr=i,\n                                idx_it=iter_count,\n                                rt=runtime[i])\n\n            # early stop if no error occurred or target_ber/target_bler reached\n            if early_stop: # only if early stop is active\n                if block_errors[i]==0:\n                    status[i] = 2 # change internal status for summary\n                    if verbose:\n                        print(\"\\nSimulation stopped as no error occurred \" \\\n                              f\"@ EbNo = {ebno_dbs[i].numpy():.1f} dB.\\n\")\n                    break\n\n                # check for target_ber / target_bler\n                ber_true =  bit_errors[i] / nb_bits[i]\n                bler_true = block_errors[i] / nb_blocks[i]\n                if ber_true <target_ber:\n                    status[i] = 5 # change internal status for summary\n                    if verbose:\n                        print(\"\\nSimulation stopped as target BER is reached\" \\\n                              f\"@ EbNo = {ebno_dbs[i].numpy():.1f} dB.\\n\")\n                    break\n                if bler_true <target_bler:\n                    status[i] = 6 # change internal status for summary\n                    if verbose:\n                        print(\"\\nSimulation stopped as target BLER is \" \\\n                              f\"reached @ EbNo = {ebno_dbs[i].numpy():.1f} \" \\\n                              \"dB.\\n\")\n                    break\n\n            # allow callback to end the entire simulation\n            if cb_state is sim_ber.CALLBACK_STOP:\n                # stop runtime timer\n                status[i] = 7 # change internal status for summary\n                if verbose:\n                    print(\"\\nSimulation stopped by callback function \" \\\n                          f\"@ EbNo = {ebno_dbs[i].numpy():.1f} dB.\\n\")\n                break\n\n    # Stop if KeyboardInterrupt is detected and set remaining SNR points to -1\n    except KeyboardInterrupt as e:\n\n        # Raise Interrupt again to stop outer loops\n        if forward_keyboard_interrupt:\n            raise e\n\n        print(\"\\nSimulation stopped by the user \" \\\n              f\"@ EbNo = {ebno_dbs[i].numpy()} dB.\")\n        # overwrite remaining BER / BLER positions with -1\n        for idx in range(i+1, num_points):\n            bit_errors = tf.tensor_scatter_nd_update( bit_errors, [[idx]],\n                                                    tf.cast([-1], tf.int64))\n            block_errors = tf.tensor_scatter_nd_update( block_errors, [[idx]],\n                                                    tf.cast([-1], tf.int64))\n            nb_bits = tf.tensor_scatter_nd_update( nb_bits, [[idx]],\n                                                    tf.cast([1], tf.int64))\n            nb_blocks = tf.tensor_scatter_nd_update( nb_blocks, [[idx]],\n                                                    tf.cast([1], tf.int64))\n\n    # calculate BER / BLER\n    ber = tf.cast(bit_errors, tf.float64) / tf.cast(nb_bits, tf.float64)\n    bler = tf.cast(block_errors, tf.float64) / tf.cast(nb_blocks, tf.float64)\n\n    # replace nans (from early stop)\n    ber = tf.where(tf.math.is_nan(ber), tf.zeros_like(ber), ber)\n    bler = tf.where(tf.math.is_nan(bler), tf.zeros_like(bler), bler)\n\n    return ber, bler\n```"}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Create a clear, concise instruction for setting up the \"PanelArray\" class and its parameters."}, {"role": "assistant", "content": "To set up the \"PanelArray\" class, follow the steps below:\n\n1. Import the appropriate class from the Sionna module using the following code snippet:\n   ```python\n   from sionna.channel.tr38901 import PanelArray\n   ```\n\n2. Create an instance of the PanelArray class. Below is an example:\n   ```python\n   panel_array = PanelArray(num_rows_per_panel = 4,\n                            num_cols_per_panel = 4,\n                            polarization = 'dual',\n                            polarization_type = 'VH',\n                            antenna_pattern = '38.901',\n                            carrier_frequency = 3.5e9,\n                            num_cols=2,\n                            panel_horizontal_spacing = 3)\n   ```\n   \nParameters Explanation:\n- `num_rows_per_panel`: This represents the number of rows of elements per panel.\n- `num_cols_per_panel`: This represents the number of columns of elements per panel.\n- `polarization`: This indicates the polarization type which can be 'single' or 'dual'.\n- `polarization_type`: This represents the type of polarization. For single polarization, it must be 'V' or 'H'. For dual polarization, it must be 'VH' or 'cross'.\n- `antenna_pattern`: This sets the Element radiation pattern. It can be either 'omni' or '38.901'.\n- `carrier_frequency`: This is the carrier frequency in Hz.\n- `num_cols`: This denotes the number of columns of panels. Default is 1.\n- `panel_horizontal_spacing`: This is the horizontal spacing of panels in multiples of wavelength. If set to None (default value), it is set to the panel height + 0.5.\n\nTo view the panel array geometry, use the `show` method of the PanelArray instance as shown below:\n```python\npanel_array.show()\n```\nFor more details, please refer to the [Sionna API documentation](https://nvlabs.github.io/sionna/api/channel.wireless.html#sionna.channel.tr38901.PanelArray)."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Describe the functionality and use of the `MFEqualizer` class in OFDM MIMO transmissions."}, {"role": "assistant", "content": "The `MFEqualizer` class in OFDM MIMO transmissions is a part of the SIONNA programming language's OFDM module. This class implements the Matched Filter (MF) equalization technique for OFDM MIMO (Orthogonal Frequency-Division Multiplexing Multiple Input Multiple Output) transmissions.\n\nThe key functions of the `MFEqualizer` class are to compute the matched filter equalization for OFDM MIMO transmissions, and to generate soft-symbol estimates along with effective noise variances for all streams. This data can be used by a `Demapper` to obtain Log-Likelihood Ratios (LLRs), which are used in decoding transmitted data.\n\nThe `MFEqualizer` class uses the `resource_grid` and `stream_management` as inputs to understand the OFDM and stream configurations respectively. The `resource_grid` is an instance of the `ResourceGrid` class and defines the data and pilot symbols mapping onto a sequence of OFDM symbols. The `stream_management` is an instance of the `StreamManagement` class and manages the streams or antennas in multi-cell MIMO setups.\n\nAs inputs, the `MFEqualizer` takes the received OFDM resource grid (`y`), channel estimates (`h_hat`), variance of the channel estimation error (`err_var`), and the variance of the AWGN (`no`).\n\nThe class outputs 'estimated symbols' (`x_hat`) and the 'effective noise variance for each estimated symbol' (`no_eff`).\n\nPlease note that, if you want to use this class in Graph mode with XLA, you must set `sionna.Config.xla_compat=true`."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Discuss how to compute the time evolution of channels via Doppler shift in Sionna."}, {"role": "assistant", "content": "To compute the time evolution of channels via Doppler shift in Sionna, you can follow these steps:\n\n1. **Set up the scene**: Load the scene using the `load_scene` function from the `sionna.rt` module. You can add objects to the scene and set their positions and orientations.\n\n2. **Assign velocity vectors to moving objects**: Assign a velocity vector to all moving objects in the scene. This can be done by setting the `velocity` property of the scene objects. The velocity vector is used to compute the Doppler shift for each propagation path.\n\n3. **Compute the propagation paths**: Use the `compute_paths` method of the scene object to compute the propagation paths. This method takes into account the positions, orientations, and velocities of the scene objects.\n\n4. **Compute the Doppler shift**: Use the `apply_doppler` method of the `Paths` object to compute the Doppler shift for each path. This method uses the velocity vectors of the scene objects and the direction of the outgoing rays at each scattering point to compute the Doppler shift.\n\n5. **Compute the time evolution of the channel impulse response**: The Doppler shift can be used to compute the time evolution of the channel impulse response. This can be done by multiplying the path coefficient by a complex exponential with the Doppler shift as the exponent.\n\nRemember that the Doppler-based approach to simulating mobility is much faster than physically moving objects in the scene and recomputing paths, but it is only accurate over short time spans during which the scene objects have moved very short distances. For longer periods of time, you may need to combine both approaches."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Describe the simulation parameters used in the context."}, {"role": "assistant", "content": "The simulation parameters used in the context are as follows:\n\n1. Signal-to-Noise Ratio (SNR) range for evaluation and training: The minimum SNR is 4.0 dB and the maximum SNR is 8.0 dB.\n\n2. Modulation and coding configuration: The number of bits per symbol is 6, which means the baseline is 64-QAM. The modulation order is 2^6. The code rate for the outer code is 0.5. The codeword length is 1500 bits and it must be a multiple of the number of bits per symbol. The number of modulated baseband symbols per codeword is the codeword length divided by the number of bits per symbol. The number of information bits per codeword is the product of the codeword length and the code rate.\n\n3. Training configuration: The number of training iterations for conventional training is 10,000. The number of training iterations with RL-based training for the alternating training phase is 7,000 and for the fine-tuning of the receiver phase is 3,000. The training batch size is 128. The variance of the perturbation used for RL-based training of the transmitter is 0.01. The filenames to save the autoencoder weights once conventional training and RL-based training are done are \"awgn_autoencoder_weights_conventional_training\" and \"awgn_autoencoder_weights_rl_training\" respectively.\n\n4. Evaluation configuration: The location to save the results is \"awgn_autoencoder_results\"."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Identify the various example scenes available in the Sionna package and how to load and use them."}, {"role": "assistant", "content": "The Sionna package provides several integrated example scenes, such as:\n\n1. A ground plane with a vertical wall (`sionna.rt.scene.floor_wall`).\n2. A few rectangular building blocks and a ground plane (`sionna.rt.scene.simple_street_canyon`).\n3. The area around the Arc de Triomphe in Paris (`sionna.rt.scene.etoile`).\n4. The area around the Frauenkirche in Munich (`sionna.rt.scene.munich`).\n5. A wedge with a 90-degree opening angle (`sionna.rt.scene.simple_wedge`).\n6. A metallic square (`sionna.rt.scene.simple_reflector`).\n7. Two separated metallic squares (`sionna.rt.scene.double_reflector`).\n8. Three separated metallic rectangles (`sionna.rt.scene.triple_reflector`).\n9. A metallic box (`sionna.rt.scene.box`).\n\nYou can load and use them as follows:\n```python\nfrom sionna.rt import load_scene\nscene = load_scene(sionna.rt.scene.munich)  # For instance loading Munich scene\n```\n\nScene has methods like `compute_paths()`, `trace_paths()`, `compute_fields()`, and `coverage_map()` to perform various computations on the scene. For instance, the propagation paths can be computed as follows:\n\n```python\npaths = scene.compute_paths()\n```\n\nYou can preview a scene within an interactive environment using `preview()`:\n\n```python\nscene.preview()\n```\n\nScenes also allow for rendering to a file from the viewpoint of a camera using `render_to_file()`:\n\n```python\nscene.render_to_file(camera=\"scene-cam-0\", filename=\"scene.png\")\n```\n\nRemember that a scene contains all the physical objects and you can set geometry and materials for these objects. Transmitters and receivers for which propagation paths or channel impulse responses (CIRs) can be computed are also included in a scene."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the details of class StreamManagement, such as the parameters of the class, the input and output of the class instance and the link of source code."}, {"role": "assistant", "content": "Here is the detailed information of StreamManagement:   \n  \n[sionna.mimo.StreamManagement(rx_tx_association, num_streams_per_tx)](https://nvlabs.github.io/sionna/_modules/sionna/mimo/stream_management.html#StreamManagement) \n\nClass for management of streams in multi-cell MIMO networks.\n\n**Parameters**\n\n- `rx_tx_association` ([num_rx, num_tx], np.int): A binary NumPy array where `rx_tx_association[i,j]=1` indicates that receiver `i` receives one or multiple streams from transmitter `j`.\n- `num_streams_per_tx` (int): Indicates the number of streams transmitted by each transmitter.\n\n**Properties**\n\n- `detection_desired_ind`: Indices needed for gathering desired channels for receive processing. A NumPy array of shape `[num_rx * num_streams_per_rx]` can be used to gather desired channels from the flattened channel tensor of shape `[..., num_rx, num_tx, num_streams_per_tx, ...]`. The result of the gather operation can be reshaped to `[..., num_rx, num_streams_per_rx, ...]`.\n\n- `detection_undesired_ind`: Indices needed for gathering undesired channels for receive processing. A NumPy array of shape `[num_rx * num_streams_per_rx]` can be used to gather undesired channels from the flattened channel tensor of shape `[..., num_rx, num_tx, num_streams_per_tx, ...]`. The result of the gather operation can be reshaped to `[..., num_rx, num_interfering_streams_per_rx, ...]`.\n\n- `num_interfering_streams_per_rx`: Number of interfering streams received at each receiver.\n\n- `num_rx`: Number of receivers.\n\n- `num_rx_per_tx`: Number of receivers communicating with a transmitter.\n\n- `num_streams_per_rx`: Number of streams transmitted to each receiver.\n\n- `num_streams_per_tx`: Number of streams per transmitter.\n\n- `num_tx`: Number of transmitters.\n\n- `num_tx_per_rx`: Number of transmitters communicating with a receiver.\n\n- `precoding_ind`: Indices needed for gathering channels for precoding. A NumPy array of shape `[num_tx, num_rx_per_tx]` where `precoding_ind[i, :]` contains the indices of the receivers to which transmitter `i` is sending streams.\n\n- `rx_stream_ids`: Mapping of streams to receivers. A NumPy array of shape `[num_rx, num_streams_per_rx]`. This array is derived from `tx_stream_ids` along with the `rx_tx_association`. `rx_stream_ids[i, :]` contains the indices of streams that are decoded by receiver `i`.\n\n- `rx_tx_association`: Association between receivers and transmitters. A binary NumPy array of shape `[num_rx, num_tx]`, where `rx_tx_association[i, j]=1` means that receiver `i` receives one or multiple streams from transmitter `j`.\n\n- `stream_association`: Association between receivers, transmitters, and streams. A binary NumPy array of shape `[num_rx, num_tx, num_streams_per_tx]`, where `stream_association[i, j, k]=1` indicates that receiver `i` receives the `k`-th stream from transmitter `j`.\n\n- `stream_ind`: Indices needed to gather received streams in the correct order. A NumPy array of shape `[num_rx * num_streams_per_rx]` can be used to gather streams from the flattened tensor of received streams of shape `[..., num_rx, num_streams_per_rx, ...]`. The result of the gather operation is then reshaped to `[..., num_tx, num_streams_per_tx, ...]`.\n\n- `tx_stream_ids`: Mapping of streams to transmitters. A NumPy array of shape `[num_tx, num_streams_per_tx]`. Streams are numbered from 0, 1, ..., and assigned to transmitters in increasing order; i.e., transmitter 0 gets the first `num_streams_per_tx` streams and so on.\n\n**Note:** Several symmetry constraints on rx_tx_association are imposed to ensure efficient processing. All row sums and all column sums must be equal, i.e., all receivers have the same number of associated transmitters and all transmitters have the same number of associated receivers. It is also assumed that all transmitters send the same number of streams num_streams_per_tx."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Define the Constellation class and list its parameters."}, {"role": "assistant", "content": "The `Constellation` class in Sionna mapping is used for creating, modifying, and using constellations for mapping and demapping of bits to constellation symbols. This class can define a constellation\u2014a complex-valued vector of constellation points, which can also be made trainable.\n\nHere are its parameters:\n\n- `constellation_type`: It can be a string among \"qam\", \"pam\", and \"custom\". This parameter indicates the type of constellation. For a custom type, the constellation points are randomly initialized if no `initial_value` is provided.\n  \n- `num_bits_per_symbol`: It is an integer and represents the number of bits per constellation symbol. For example, the value will be 4 for QAM16.\n  \n- `initial_value`: This is an optional parameter. It takes a NumPy array or Tensor of size [2^num_bits_per_symbol]. It sets the initial values of the constellation points. The initial constellation might change if `normalize` or `center` are set to `True`. \n\n- `normalize`: This boolean parameter decides if the constellation is normalized to have unit power. It is `True` by default.\n\n- `center`: This boolean parameter ensures that the constellation has zero mean if set to `True`. It is `False` by default.\n\n- `trainable`: If set `True`, this boolean parameter makes the constellation points become trainable variables. It is `False` by default.\n\n- `dtype`: It specifies the data type of the constellation and can be either \"tf.complex64\" or \"tf.complex128\". Defaults to \"tf.complex64\".  \n\n- `**kwargs`: Additional keyword arguments. \n\nThe output of the class is a constellation of dtype with size [2^num_bits_per_symbol]."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Please provide me the details of function complex2real_covariance, such as the input and output of the class instance, the link of source code and source itself."}, {"role": "assistant", "content": "Here is the detailed information of complex2real_covariance:   \n\nTransforms a complex-valued covariance matrix to its real-valued equivalent.\n\nAssume a proper complex random variable $\\mathbf{z}\\in\\mathbb{C}^M$ [Proper complex random variables, Wikipedia, accessed 11 September, 2022.] with covariance matrix $\\mathbf{R}= \\in\\mathbb{C}^{M\\times M}$ and real and imaginary parts $\\mathbf{x}\\in \\mathbb{R}^M$ and $\\mathbf{y}\\in \\mathbb{R}^M$, respectively. This function transforms the given $\\mathbf{R}$ into the covariance matrix of the real-valued equivalent vector $\\tilde{\\mathbf{z}}=\\left[\\mathbf{x}^{\\mathsf{T}}, \\mathbf{y}^{\\mathsf{T}} \\right ]^{\\mathsf{T}}\\in\\mathbb{R}^{2M}$,  which is computed as [Covariance matrices of real and imaginary parts, Wikipedia, accessed 11 September, 2022.]\n$\\begin{split}\\mathbb{E}\\left[\\tilde{\\mathbf{z}}\\tilde{\\mathbf{z}}^{\\mathsf{H}} \\right] =\n\\begin{pmatrix}\n    \\frac12\\Re\\{\\mathbf{R}\\} & -\\frac12\\Im\\{\\mathbf{R}\\}\\\\\n    \\frac12\\Im\\{\\mathbf{R}\\} & \\frac12\\Re\\{\\mathbf{R}\\}\n\\end{pmatrix}.\\end{split}$\n\n\nInput\n    [\u2026,M,M], tf.complex\n\nOutput\n    [\u2026,2M, 2M], tf.complex.real_dtype\n\nsource code:\n```python\ndef complex2real_covariance(r):\n    # pylint: disable=line-too-long\n    r\"\"\"Transforms a complex-valued covariance matrix to its real-valued equivalent.\n\n    Assume a proper complex random variable :math:`\\mathbf{z}\\in\\mathbb{C}^M` [ProperRV]_\n    with covariance matrix :math:`\\mathbf{R}= \\in\\mathbb{C}^{M\\times M}`\n    and real and imaginary parts :math:`\\mathbf{x}\\in \\mathbb{R}^M` and\n    :math:`\\mathbf{y}\\in \\mathbb{R}^M`, respectively.\n    This function transforms the given :math:`\\mathbf{R}` into the covariance matrix of the real-valued equivalent\n    vector :math:`\\tilde{\\mathbf{z}}=\\left[\\mathbf{x}^{\\mathsf{T}}, \\mathbf{y}^{\\mathsf{T}} \\right ]^{\\mathsf{T}}\\in\\mathbb{R}^{2M}`, which\n    is computed as [CovProperRV]_\n\n    .. math::\n\n        \\mathbb{E}\\left[\\tilde{\\mathbf{z}}\\tilde{\\mathbf{z}}^{\\mathsf{H}} \\right] =\n        \\begin{pmatrix}\n            \\frac12\\Re\\{\\mathbf{R}\\} & -\\frac12\\Im\\{\\mathbf{R}\\}\\\\\n            \\frac12\\Im\\{\\mathbf{R}\\} & \\frac12\\Re\\{\\mathbf{R}\\}\n        \\end{pmatrix}.\n\n    Input\n    -----\n    : [...,M,M], tf.complex\n\n    Output\n    ------\n    : [...,2M, 2M], tf.complex.real_dtype\n    \"\"\"\n    q = complex2real_matrix(r)\n    scale = tf.cast(2, q.dtype)\n    return q/scale\n```"}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Discuss the Demapper class within the sionna mapping API."}, {"role": "assistant", "content": "The Demapper class in the Sionna mapping API is a key component used for computing log-likelihood ratios (LLRs) or making hard-decisions on bits for a tensor of received symbols. This class works by defining a layer implementing different demapping functions. All the demapping functions are fully differentiable when soft-decisions are computed. \n\nThe Demapper class accepts several important parameters which include demapping_method, constellation_type, num_bits_per_symbol, constellation, hard_out, with_prior, and dtype.\n\nThe 'demapping_method' parameter refers to the specific demapping method used, which could be either \"app\" or \"maxlog\". The 'constellation_type' signifies the type of constellation used, which can be \"qam\", \"pam\", or \"custom\". \n\nThe 'num_bits_per_symbol' parameter refers to the number of bits per constellation symbol. For instance, for QAM16, it would be 4. The 'constellation' parameter is used for specifying an instance of the Constellation class or None.\n\nThe 'hard_out' parameter, if set to True, enables the Demapper to provide hard-decided bits instead of soft-values. If the 'with_prior' flag is set to True, it\u2019s assumed that there is prior knowledge available on the bits. As for the 'dtype' parameter, it accepts the dtype of 'y', defaulting to tf.complex64. Its output dtype will be the corresponding real dtype (tf.float32 or tf.float64).\n\nIn terms of its methods, the Demapper class comes with one property method 'constellation' which returns the constellation used by the Demapper."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain how to generate the frozen positions for a Reed-Muller (RM) code using the generate_rm_code function and what information is returned."}, {"role": "assistant", "content": "To generate the frozen positions for a Reed-Muller (RM) code using the `generate_rm_code` function from the Sionna library, you will need to specify the order and the code length in log2 scale of the desired RM code.\n\nThe function signature, according to the provided context, looks like this:\n\n```python\ngenerate_rm_code(r, m)\n```\n\nHere, `r` is the order of the RM code, and `m` is defined as log2 of the desired codeword length, meaning that the codeword length `n` will be `2^m`.\n\nWhen you call this function, it returns a list containing five items:\n\n1. `frozen_pos`: An Numpy array of integers with the indices of frozen positions.\n2. `info_pos`: An Numpy array of integers with the indices of information bit positions.\n3. `n`: An integer representing the resulting codeword length (`2^m`).\n4. `k`: An integer representing the number of information bits.\n5. `d_min`: An integer representing the minimum distance of the code.\n\nThe frozen positions are the indices within the codeword that are fixed to known values (commonly zeros) during the encoding process; these positions do not carry information. The information positions are the complementary indices of the codeword that carry the actual information bits.\n\nHere is an example of how you might use this function:\n\n```python\nfrom sionna.fec.polar.utils import generate_rm_code\n\n# Set the parameters for the RM code\nr = 1 # Order\nm = 4 # log2 of codeword length\n\n# Generate the frozen positions for RM code\nfrozen_pos, info_pos, n, k, d_min = generate_rm_code(r, m)\n\n# Output the frozen positions and other information\nprint(\"Frozen Positions:\", frozen_pos)\nprint(\"Information Positions:\", info_pos)\nprint(\"Codeword length (n):\", n)\nprint(\"Number of information bits (k):\", k)\nprint(\"Minimum distance (d_min):\", d_min)\n```\n\nAfter running this piece of code, you will get the frozen and information positions which can later be used for encoding and decoding RM codes. Additionally, the codeword length (`n`), number of information bits (`k`), and the minimum distance of the code (`d_min`) are also provided, which are essential parameters for describing the code's structure and error-correcting capabilities. \n\nRemember to import the `generate_rm_code` function from the correct Sionna API package as shown in the example, and ensure you have installed the Sionna library and met all dependencies to successfully execute the function."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Discuss the mapper class and its purposes within the sionna mapping API."}, {"role": "assistant", "content": "The mapper class in the sionna mapping API is a key component that is used to map binary tensors to points of a given constellation. \n\nThe mapper class is initialized by specifying the type of the constellation, the number of bits per constellation symbol, and optionally, an instance of the `Constellation` class, which is also a part of the sionna mapping API. The mapper class specifically requires the last input dimension to be an integer multiple of the number of bits per constellation symbol.\n\nThe functionality of the mapper class includes transforming a tensor of binary values to a tensor of points from the provided constellation. This class further includes an attribute called `Constellation` which details the `Constellation` used by the `Mapper`.\n\nIf enabled, symbol indices can optionally be returned along with the mapped constellation symbols. By default, this functionality is set to False. \n\nIn summary, the main purpose of the mapper class in the sionna mapping API is to facilitate the conversion or mapping of binary tensors to constellation symbols based on the provided constellation configuration. This is crucial in the process of bit mapping in the context of digital communications, where symbols from a particular constellation are utilized."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Discuss how configure and use the TBConfig class and its properties in the Sionna's API."}, {"role": "assistant", "content": "To configure the TBConfig class in Sionna's API, you need to create an instance of it and provide your specifications (if any) as keyword arguments. \n\nOnce the instance is created, you can change its properties using the dot notation, here is an example:\n\n```python\ntb_config = TBConfig()  # Create an instance with default configurations\ntb_config.channel_type = \"PUSCH\"  # Change channel type\ntb_config.num_bits_per_symbol = 4  # Adjust modulation order\n```\n\nTBConfig class contains properties like `channel_type`, `num_bits_per_symbol`, and `num_layers`, amongst others, that represent various configurations for the transport block encoding. You can set these properties according to your specific requirements.\n\nTo use the TBConfig class, you'll integrate it with other classes such as PUSCHConfig. For instance:\n\n```python\ntb_config = TBConfig(mcs_index=13)\npusch_config = PUSCHConfig(tb_config=tb_config)  # Use tb_config with PUSCHConfig\n```\nLet's say you've successfully configured and used TBConfig with PUSCHConfig, next is to use the configurations with a Transmitter, and so on - the configurations carry through different stages of the simulation process.\n\nNote that you do not assume any values or behavior based on the provided context, you've to explicitly set the properties according to the 5G NR-compliant properties specified in TBConfig class of Sionna's API. Also beware not to make typographical mistakes when setting the properties (such as writing 'num_bit_per_symbol' instead of 'num_bits_per_symbol'). \n\nHopefully, this offers clarity on how to setup and use the TBConfig class and its properties in Sionna's API."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain how to plot the simulation results and interpret the performance of IDD compared to non-iterative methods."}, {"role": "assistant", "content": "To plot the simulation results and interpret the performance of Iterative Detection and Decoding (IDD) compared to non-iterative methods, follow these steps:\n\n1. Run the simulation: Execute the simulation for both IDD and non-IDD models over a range of Signal-to-Noise Ratio (SNR) values. The simulation should return Bit Error Rate (BER) and Block Error Rate (BLER) for each SNR value.\n\n2. Plot the results: Use a plotting library such as matplotlib to create a graph. The x-axis should represent the SNR values and the y-axis should represent the BLER. Plot the BLER results of each method (IDD, LMMSE, EP, K-Best) against the SNR values.\n\n3. Interpret the results: Compare the performance of IDD with the non-iterative methods by observing the BLER at different SNR values. A lower BLER at a given SNR indicates better performance. \n\nIn the provided context, the IDD method is compared with LMMSE, EP, and K-Best non-iterative methods. The results are plotted for two scenarios: perfect Channel State Information (CSI) with iid Rayleigh fading channels, and estimated CSI with 3GPP UMa channels. \n\nThe performance of IDD is observed to be better than the non-iterative methods by about 1 dB in the scenario with iid Rayleigh fading channels and perfect CSI. In the scenario with 3GPP UMa channels and estimated CSI, IDD performs slightly better than K-best, at considerably lower runtime. \n\nPlease note that the actual plotting and interpretation of results would require the specific simulation data, which is not provided in the context. The steps mentioned above are based on the provided context and the typical process of comparing the performance of different methods in wireless communication systems."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Describe how the parameters, input/output, and properties of the 'AWGN', 'FlatFadingChannel', 'GenerateFlatFadingChannel', 'ApplyFlatFadingChannel', 'SpatialCorrelation', 'KroneckerModel', 'PerColumnModel', 'ChannelModel','TimeChannel', 'GenerateTimeChannel', 'ApplyTimeChannel','cir_to_time_channel', 'time_to_ofdm_channel', 'OFDMChannel', 'GenerateOFDMChannel', 'ApplyOFDMChannel','cir_to_ofdm_channel', 'RayleighBlockFading' classes function."}, {"role": "assistant", "content": "These are descriptions of how the parameters, input/output, and properties of the mentioned classes function:\n\n1. **AWGN**: The AWGN class adds complex AWGN noise with a certain variance to the input. The class takes as input a tuple consisting of the channel input and the noise variance, outputting the channel input with added noise. The class has a dtype parameter to define the datatype for internal calculations and output.\n\n2. **FlatFadingChannel**: The FlatFadingChannel class implements a multi-input multi-output block flat fading model. The number of transmit and receive antennas and spatial correlation models can be passed as parameters. The class takes a tuple of input vectors and noise power, and outputs channel output and optionally, channel realizations. \n\n3. **GenerateFlatFadingChannel** is responsible for generating tensors of flat-fading channel matrices, using a spatial correlation model if configured. \n\n4. **ApplyFlatFadingChannel** applies given tensors of flat-fading channel matrices to an input tensor, also adding AWGN noise if configured. \n\n5. **SpatialCorrelation**: This abstract class provides an interface for spatial correlation models. It takes tensors containing spatially uncorrelated channel coefficients and outputs the spatially correlated channel coefficients.\n\n6. **KroneckerModel** and **PerColumnModel** are specific spatial correlation models. They use matrices representing correlation at the transmitter and/or receiver to generate correlated channel coefficients from uncorrelated ones.\n\n7. **ChannelModel** is an abstract class for channel models. A channel model generates channel impulse responses (CIRs) that include power delay profiles.\n\n8. **OFDMChannel, TimeChannel, GenerateOFDMChannel, GenerateTimeChannel, ApplyOFDMChannel, ApplyTimeChannel** are classes that generate or apply channel responses in frequency or time domain to the channel input.\n\n9. **cir_to_time_channel**, **cir_to_ofdm_channel**, **time_to_ofdm_channel** are utility functions that convert channel impulse responses (CIRs) to frequency or time domain responses.\n\n10. **RayleighBlockFading** is a channel model that generates single-path, block fading channel impulse responses.\n\nFor each class or function, the input shape and types, parameters, and output shapes must match what is specified in the descriptions. It's important to note that not all classes or functions may require all inputs or parameters, some may be optional or calculated based on other parameters if not explicitly provided."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain how to add channel coding to a transceiver in Sionna."}, {"role": "assistant", "content": "To add channel coding to a transceiver in Sionna, you need to follow these steps:\n\n1. Import the necessary libraries and modules. This includes Sionna, TensorFlow, and any other necessary libraries such as NumPy for numerical operations.\n\n```python\nimport sionna as sn\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras import Model\n```\n\n2. Define the parameters for your channel coding. This includes the number of bits per symbol, the block length, and the code rate.\n\n```python\nnum_bits_per_symbol = 2 # QPSK\nblock_length = 1024\ncoderate = 0.5\n```\n\n3. Initialize the necessary components for your transceiver. This includes the constellation, mapper, demapper, binary source, AWGN channel, and the encoder and decoder for your channel coding.\n\n```python\nconstellation = sn.mapping.Constellation(\"qam\", num_bits_per_symbol)\nmapper = sn.mapping.Mapper(constellation=constellation)\ndemapper = sn.mapping.Demapper(\"app\", constellation=constellation)\nbinary_source = sn.utils.BinarySource()\nawgn_channel = sn.channel.AWGN()\nencoder = sn.fec.ldpc.LDPC5GEncoder(k, n)\ndecoder = sn.fec.ldpc.LDPC5GDecoder(encoder, hard_out=True)\n```\n\n4. Define a Keras model for your communication system. This model should take in the batch size and Eb/N0 value as inputs, and output the transmitted bits and the received log-likelihood-ratio (LLR) values.\n\n```python\nclass CodedSystemAWGN(Model):\n    def __init__(self, num_bits_per_symbol, n, coderate):\n        super().__init__()\n        # Initialize components here...\n\n    def __call__(self, batch_size, ebno_db):\n        # Perform forward pass here...\n```\n\n5. Instantiate your model and run your simulation. You can use the `sn.utils.PlotBER` utility to compute and plot the bit error rate (BER) for your simulation.\n\n```python\nmodel_coded_awgn = CodedSystemAWGN(num_bits_per_symbol=NUM_BITS_PER_SYMBOL, n=2048, coderate=CODERATE)\nber_plots = sn.utils.PlotBER(\"AWGN\")\nber_plots.simulate(model_coded_awgn, ebno_dbs=np.linspace(EBN0_DB_MIN, EBN0_DB_MAX, 20), batch_size=BATCH_SIZE, num_target_block_errors=100, legend=\"Coded\", soft_estimates=True, max_mc_iter=100, show_fig=True)\n```\n\nPlease note that the above code snippets are just examples and may need to be adjusted based on your specific requirements."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain how to simulate forward passes through the system, including defining batch size, Eb/N0 in dB, and blocklength."}, {"role": "assistant", "content": "To simulate forward passes through the system, you need to define the batch size, Eb/N0 in dB, and blocklength. Here's how you can do it:\n\n1. **Define the batch size**: The batch size is the number of examples processed by Sionna in parallel. You can define it as follows:\n```python\nBATCH_SIZE = 128\n```\n\n2. **Define Eb/N0 in dB**: Eb/N0 is the energy per bit to noise power spectral density ratio, expressed in decibels (dB). You can define it as follows:\n```python\nEBN0_DB = 17.0\n```\n\n3. **Define the blocklength**: The blocklength is the number of bits in each block. You can define it as follows:\n```python\nbits = binary_source([BATCH_SIZE, 1200]) # Blocklength\n```\n\n4. **Simulate forward passes**: After defining the batch size, Eb/N0 in dB, and blocklength, you can simulate forward passes through the system as follows:\n```python\n# Binary source to generate uniform i.i.d. bits\nbinary_source = sn.utils.BinarySource()\n\n# 256-QAM constellation\nNUM_BITS_PER_SYMBOL = 6\nconstellation = sn.mapping.Constellation(\"qam\", NUM_BITS_PER_SYMBOL, trainable=True)\n\n# Mapper and demapper\nmapper = sn.mapping.Mapper(constellation=constellation)\ndemapper = sn.mapping.Demapper(\"app\", constellation=constellation)\n\n# AWGN channel\nawgn_channel = sn.channel.AWGN()\n\n# Simulate forward passes\nno = sn.utils.ebnodb2no(ebno_db=EBN0_DB, num_bits_per_symbol=NUM_BITS_PER_SYMBOL, coderate=1.0)\nbits = binary_source([BATCH_SIZE, 1200]) # Blocklength\nx = mapper(bits)\ny = awgn_channel([x, no])\nllr = demapper([y,no])\n```\n\nThis will simulate forward passes through the system with the defined batch size, Eb/N0 in dB, and blocklength."}]}
{"messages": [{"role": "system", "content": "You are an expert in Sionna, capable of writing code and illustrating information like formulas and APIs. Your proficiency in Sionna allows you to simulate and analyze various aspects of wireless communication systems effectively."}, {"role": "user", "content": "Explain how to simulate the coded bit error rate for a Polar coded and 64-QAM modulation in Sionna."}, {"role": "assistant", "content": "To simulate the coded bit error rate for a Polar coded and 64-QAM modulation in Sionna, you can follow these steps:\n\n1. **Import the necessary libraries and modules**: This includes Sionna, TensorFlow, NumPy, and the Keras Model from TensorFlow.\n\n```python\nimport os\nimport sionna as sn\nimport tensorflow as tf\nimport numpy as np\nfrom tensorflow.keras import Model\n```\n\n2. **Set up the Polar encoder and decoder**: You can use the `sn.fec.polar.Polar5GEncoder` and `sn.fec.polar.Polar5GDecoder` classes in Sionna to set up the Polar encoder and decoder. You need to specify the number of information bits `k` and the codeword length `n`.\n\n```python\nk = 100  # number of information bits\nn = 200  # codeword length\nencoder = sn.fec.polar.Polar5GEncoder(k, n)\ndecoder = sn.fec.polar.Polar5GDecoder(encoder, dec_type=\"SCL\")  # use Successive Cancellation List (SCL) decoding\n```\n\n3. **Set up the 64-QAM modulation**: You can use the `sn.mapping.Constellation` and `sn.mapping.Mapper` classes in Sionna to set up the 64-QAM modulation. The number of bits per symbol for 64-QAM is 6.\n\n```python\nnum_bits_per_symbol = 6  # 64-QAM\nconstellation = sn.mapping.Constellation(\"qam\", num_bits_per_symbol)\nmapper = sn.mapping.Mapper(constellation=constellation)\n```\n\n4. **Set up the AWGN channel**: You can use the `sn.channel.AWGN` class in Sionna to set up the AWGN channel.\n\n```python\nawgn_channel = sn.channel.AWGN()\n```\n\n5. **Simulate the transmission and reception**: You can use the `sn.utils.BinarySource` class to generate random bits, encode them using the Polar encoder, modulate them using the 64-QAM mapper, transmit them over the AWGN channel, demodulate the received symbols, and decode the demodulated bits using the Polar decoder.\n\n```python\nbinary_source = sn.utils.BinarySource()\nbits = binary_source([batch_size, k])\ncodewords = encoder(bits)\nx = mapper(codewords)\ny = awgn_channel([x, no])\nllr = demapper([y, no])\nbits_hat = decoder(llr)\n```\n\n6. **Calculate the bit error rate (BER)**: You can calculate the BER by comparing the transmitted bits and the decoded bits.\n\n```python\nber = tf.reduce_mean(tf.cast(tf.not_equal(bits, bits_hat), tf.float32))\n```\n\nPlease note that this is a simplified example and the actual implementation may require additional steps and considerations, such as setting the signal-to-noise ratio (SNR) for the AWGN channel, handling batch processing, and wrapping the system into a Keras model for easier simulation and evaluation."}]}
